[{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"notation","dir":"Articles","previous_headings":"Preliminaries","what":"Notation","title":"Rational Linear Dynamic Models (RLDM)","text":"following letters used denote dimensions objects: \\(m\\)-dimension process \\((y_t)\\) \\(n\\)- dimensional noise process \\((u_t)\\), \\(\\epsilon_t\\), … \\(s\\)- dimensional state process \\((a_t)\\) \\(N\\) sample size (n.obs)","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"sign-convention","dir":"Articles","previous_headings":"Preliminaries","what":"Sign Convention","title":"Rational Linear Dynamic Models (RLDM)","text":"sign convention autoregressive (AR) non-standard since lmfd objects store AR/MA polynomials form \\[ a_0 y_t + \\cdots + a_p y_{t-p} = b_0 \\epsilon_t + \\cdots + b_q \\epsilon_{t-q} \\] Therefore, AR model written \\[ y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = \\epsilon_t \\] signs coefficients ‘non standard’.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"processes","dir":"Articles","previous_headings":"","what":"Processes","title":"Rational Linear Dynamic Models (RLDM)","text":"package RLDM deals processes form \\[ y_t = \\sum_{j \\geq 0}^\\infty k_j u_{t-j} \\] solutions difference equations left-matrix-fraction-description (LMFD) \\[ a_0 y_t + a_1 y_{t-1} + \\cdots a_p y_{t-p} = b_0 u_t + b_1 u_{t-1} + \\cdots b_q u_{t-q}, \\] state space form, \\[ \\begin{aligned} s_{t+1} &= s_t + B u_t \\\\ y_t &= C s_t + D u_t \\end{aligned} \\] right-matrix-fraction-description (RMFD) \\[ \\begin{aligned} w_t &= c_0 u_{t} + c_1 u_{t-1} + \\cdots c_p u_{t-p}\\\\ y_t &= d_0 u_{t} + d_1 u_{t-1} + \\cdots d_q u_{t-q} \\end{aligned} \\] deterministic trends exogenously observed inputs.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"classes","dir":"Articles","previous_headings":"","what":"Classes","title":"Rational Linear Dynamic Models (RLDM)","text":"following, classes package RLDM described.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"varma-systemprocess","dir":"Articles","previous_headings":"Classes","what":"VARMA system/process","title":"Rational Linear Dynamic Models (RLDM)","text":"armamod objects lists slots: Class attribute c(\"armamod\", \"rldm\"). sigma_L slot contains “left” square root \\(L\\) noise covariance matrix \\(\\Sigma\\), .e. \\(\\Sigma = LL'\\). However, required \\(L\\) lower left triangular matrix. Defaults: label = NULL gives label = '' names = NULL gives names = ??? constructor class following methods available","code":"armamod(sys, sigma_L, names = NULL, label = NULL) methods(class = 'armamod') #>  [1] as.stspmod autocov    freqresp   impresp    ll         poles      #>  [7] predict    print      sim        spectrald  str        zeroes     #> see '?methods' for accessing help and source code"},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"statespace-systemprocess","dir":"Articles","previous_headings":"Classes","what":"Statespace system/process","title":"Rational Linear Dynamic Models (RLDM)","text":"stspmod objects lists slots: Class attribute c(\"armamod\", \"rldm\"). Defaults: label = NULL gives label = '' names = NULL gives names = ??? constructor class following methods available","code":"stspmod(sys, sigma_L, names = NULL, label = NULL) methods(class = 'stspmod') #>  [1] autocov   freqresp  impresp   ll        poles     predict   print     #>  [8] sim       spectrald str       zeroes    #> see '?methods' for accessing help and source code"},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"right-matrix-fraction-description","dir":"Articles","previous_headings":"Classes","what":"Right matrix fraction description","title":"Rational Linear Dynamic Models (RLDM)","text":"rmfd objects, see corresponding help file.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"autocovariance-function","dir":"Articles","previous_headings":"Classes","what":"Autocovariance function","title":"Rational Linear Dynamic Models (RLDM)","text":"autocov objects lists slots: Class attribute c(\"autocov\", \"rldm\"). direct constructor, compute via S3 method following methods available","code":"autocov.default(obj, lag.max, type)   ##\\sobj = data, calls stats::acf autocov.acf(obj, lag.max, type)        # obj = stats::acf object ???  autocov.armamod(obj, lag.max, type) autocov.stspmod(obj, lag.max, type) autocov.autocov(obj, lag.max, type) methods(class = 'autocov') #> [1] autocov   plot      print     spectrald str       #> see '?methods' for accessing help and source code"},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"impulse-response-function","dir":"Articles","previous_headings":"Classes","what":"Impulse Response function","title":"Rational Linear Dynamic Models (RLDM)","text":"impresp objects lists slots: Class attribute c(\"impresp\", \"rldm\"). direct constructor, compute via S3 method following methods available","code":"impresp.armamod(obj, lag.max, H) impresp.stspmod(obj, lag.max, H) impresp.impresp(obj, lag.max, H)  change orthogonalization H methods(class = 'impresp') #> [1] freqresp  impresp   plot      print     spectrald str       #> see '?methods' for accessing help and source code"},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"frequency-response-transfer-function","dir":"Articles","previous_headings":"Classes","what":"Frequency Response / Transfer function","title":"Rational Linear Dynamic Models (RLDM)","text":"frequency response function associated ARMA/statespace model \\[ \\begin{aligned} K(\\lambda) &= \\sum_{j=0}^{\\infty} k_j e^{-\\lambda j}                    & \\\\            &= (a_0 + a_1 e^{-\\lambda} + \\cdots + a_p e^{-\\lambda p})^{-1}               (b_0 + b_1 e^{-\\lambda} + \\cdots + b_q e^{-\\lambda q})   & \\mbox{ARMA model}\\\\            &= C(e^{\\lambda}I_s -)^{-1}B+D                              & \\mbox{statespace model} \\end{aligned} \\] \\((k_j \\,|\\, j\\geq 0)\\) impulse response model. Note \\(K()\\) discrete-time Fourier transform (DTFT) impulse response. impulse response absolutely summable ceofficents \\(k_j\\) may reconstructed frequency response via inverse DTFT \\[ k_j = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} K(\\lambda) e^{\\lambda j} d\\lambda \\] S3 methods freqresp.* evaluate function grid angular frequencies \\(\\lambda_j = 2\\pi j/N\\), \\(j=0,\\ldots,N-1\\) store result (together sigma_L) freqresp object. freqresp objects lists slots: Class attribute c(\"freqresp\", \"rldm\"). direct constructor, compute via S3 method available methods ","code":"freqresp.armamod(obj, n.f) freqresp.stspmod(obj, n.f) freqresp.impresp(obj, n.f) methods(class = 'freqresp') #> [1] plot  print str   #> see '?methods' for accessing help and source code"},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"spectral-density","dir":"Articles","previous_headings":"Classes","what":"Spectral Density","title":"Rational Linear Dynamic Models (RLDM)","text":"spectral density ARMA process, process defined via (stable) statespace model \\[ \\begin{aligned} \\Gamma(\\lambda) &= \\frac{1}{2\\pi} \\sum_{j=-\\infty}^{\\infty} \\gamma_j e^{-\\lambda j}  \\\\                 &= \\frac{1}{2\\pi} K(\\lambda) \\Sigma K^*(\\lambda) \\end{aligned} \\] \\((\\gamma_j\\,|\\, j\\\\mathbb{Z})\\) autocovariance function process \\(K(\\lambda)\\) frequency response associated model. spectral density (factor \\(2\\pi\\)) DTFT autocovariances hence \\[ \\gamma_j = \\int_{-\\pi}^\\pi \\Gamma(\\lambda) e^{\\lambda} d\\lambda \\] S3 methods spectrald.* evaluate function grid angular frequencies \\(\\lambda_j = 2\\pi j/N\\), \\(j=0,\\ldots,N-1\\) store result spectrald object. spectrald objects lists slots: Class attribute c(\"spectrald\", \"rldm\"). name chosen order avoid name clash stats::spectrum. direct constructor, compute via S3 method","code":"spectrald(obj, n.f = 128, ...)  # ARMA model spectrald(obj, n.f = 128, ...)  # statespace model spectrald(obj, n.f = 128, ...)  # autocov object (only approximation) spectrald(obj, n.f = 128, ...)  # impresp object (only approximation) spectrald(obj, n.f = NULL, demean = TRUE, ...)  # given a data matrix => periodogram"},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"forecast-error-variance-decomposition","dir":"Articles","previous_headings":"Classes","what":"Forecast Error Variance Decomposition","title":"Rational Linear Dynamic Models (RLDM)","text":"fevardec objects lists slots: Class attribute c(\"fevardec\"). complete process model: skip additional rldm class attribute name chosen order avoid name clash vars::fevd. direct constructor, compute via function:","code":"fevardec(obj, h.max = NULL, H = NULL) methods(class = 'fevardec') #> [1] plot  print str   #> see '?methods' for accessing help and source code"},{"path":"https://bfunovits.github.io/RLDM/articles/a_RLDM.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Rational Linear Dynamic Models (RLDM)","text":"(Scherrer Deistler 2019).","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"estimate-ar-models","dir":"Articles","previous_headings":"","what":"Estimate AR Models","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"Let \\((y_t)\\) \\(m\\)-dimensional AR(\\(p\\)) process defined stable AR(\\(p\\)) system \\[ y_t = a_1 y_{t-1} + \\cdots + a_p y_{t-p} + u_t \\] \\((u_t)\\) white noise process covariance matrix \\(\\Sigma=\\mathbb{E} u_t u_t' \\\\mathbb{R}^{m \\times m}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"yule-walker-estimate","dir":"Articles","previous_headings":"Estimate AR Models","what":"Yule-Walker Estimate","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"AR(\\(p\\)) model stable (.e. \\(\\det(I_m - a_1 z - \\cdots - a_p z^p)\\) non zero \\(z\\\\mathbb{C}\\) \\(|z|\\leq 1\\)) autocovariance function \\((\\gamma_k = \\mathbb{E} y_{t+k} y_t')\\) parameters model satisfy socalled Yule-Walker equations: \\[ \\begin{aligned} \\gamma_0 &= a_1  \\gamma_{-1} + \\cdots + a_p \\gamma_{-p} + \\Sigma \\\\ \\gamma_k &= a_1  \\gamma_{k-1} + \\cdots + a_p \\gamma_{k-p} & \\mbox{ } k > 0 \\end{aligned} \\] use notation \\[ = (a_p,\\ldots,a_1), \\; y_{t-1}^{p} = (y_{t-p}',\\ldots,y_{t-1}'), \\; \\Gamma_p = \\mathbb{E} y_{t-1}^{p} (y_{t-1}^{p})' \\mbox{ } \\; \\gamma_1^p = \\mathbb{E} y_t (y_{t-1}^p)' = (\\gamma_p,\\ldots,\\gamma_1) \\] Yule-Walker equations (\\(k=0,\\ldots,p\\)) may written \\[ \\begin{aligned} \\gamma_0 &= (\\gamma_1^p)' + \\Sigma \\\\ \\gamma_1^p &= \\Gamma_p \\end{aligned} \\] solve equations use Cholesky decomposition Toeplitz matrix \\[ \\Gamma_{p+1} = \\mathbb{E} \\begin{pmatrix} y_{t-1}^p \\\\ y_t \\end{pmatrix}                   \\begin{pmatrix} y_{t-1}^p \\\\ y_t \\end{pmatrix}'        = \\begin{pmatrix}          \\Gamma_p & (\\gamma_1^p)' \\\\          \\gamma_1^p & \\gamma_{0}          \\end{pmatrix}        = \\begin{pmatrix}          R_{11}' & 0_{mp\\times m} \\\\          R_{12}' & R_{22}'          \\end{pmatrix}          \\begin{pmatrix}          R_{11}  & R_{12} \\\\          0_{m\\times mp}       & R_{22}          \\end{pmatrix} \\] \\[ \\begin{aligned} &=  \\gamma_1^p \\Gamma_p^{-1}  = R_{12}' R_{11} (R_{11}'R_{11})^{-1} = R_{12}' R_{11}^{-T} \\\\ \\Sigma &= \\gamma_0 - (\\gamma_1^p)' =  R_{12}' R_{12} +  R_{22}' R_{22} - R_{12}' R_{11}^{-T} R_{11}' R_{12} = R_{22}'R_{22} \\end{aligned} \\] One advantage approach can easily “read ” noise covariances AR models orders \\(0,1,\\ldots,p\\) cholesky factor \\(R\\). Therefore determinant noise covariances may computed diagonal elements \\(R\\). E.g. model order \\(p\\) \\[ \\log\\det\\Sigma_p = 2 \\sum_{=mp+1}^{m(p+1)} \\log r_{ii} \\] \\(r_{ii}\\) denotes \\(\\)-th diagonal element \\(R\\). algorithm implemented function","code":"est_ar_yw(gamma, p.max = (dim(gamma)[3]-1), penalty = -1)"},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"durbin-levinson-whittle-algorithm","dir":"Articles","previous_headings":"Estimate AR Models","what":"Durbin-Levinson-Whittle Algorithm","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"Let \\((y_{t} \\,|\\, t \\\\mathbb{Z})\\) denote discrete time, stationary process mean zero autocovariance function \\(\\gamma_k = \\mathbb{E} y_{t+k} y_t'\\). Durbin-Levinson-Whittle procedure computes linear, least squares, one-step ahead predictions recursively number past values used prediction. See (Whittle 1963). one-step ahead prediction \\(y_t\\) given \\(p\\) past values \\[ y_{t|p} = ^{(p)}_1 y_{t-1} + \\cdots + ^{(p)}_p y_{t-p} \\] orthogonal projection \\(y_t\\) onto space \\[ \\mathbb{H}_{t-p}^{t-1} = \\mathrm{span}\\{y_{t-1}, \\ldots , y_{t-p}\\}. \\] denote corresponding projection operator \\(\\mathbb{P}_{t-p}^{t-1}\\) can write \\(y_{t|p}= \\mathbb{P}_{t-p}^{t-1} \\, y_t\\). forecast error covariance matrix denoted \\[ \\begin{aligned} u_{t|p} & = y_t - y_{t|p} = y_t - ^{(p)}_1 y_{t-1} - \\cdots - ^{(p)}_p y_{t-p} \\\\ \\Sigma_p & = \\mathbb{E} u_{t|p} u_{t|p}' = \\gamma_0 - \\mathbb{E} y_{t|p} y_{t|p}' \\end{aligned} \\] main trick, derive Durbin-Levinson-Whittle recursions, consider also backcasts, .e. linear, least squares, approximations \\(y_s\\) terms future values process. define \\[ \\begin{aligned} y^{b}_{s|p} & = \\mathbb{P}_{s+1}^{s+p} y_s = b^{(p)}_1 y_{s+1} + \\cdots + b^{(p)}_p y_{s+p} \\\\ v_{s|p} & = y_s - y^{b}_{s|p} = y_s - b^{(p)}_1 y_{s+1} - \\cdots - b^{(p)}_p y_{s+p} \\\\ \\Omega_p & = \\mathbb{E} v_{s|p} v_{s|p}' = \\gamma_0 - \\mathbb{E} y^{b}_{s|p} (y^{b}_{s|p})' \\end{aligned} \\] Durbin-Levinson-Whittle recursions consist following equations: \\[ \\begin{aligned} \\Delta_{p}' = \\mathbb{E} v_{t-p|t-1} y_t ' = \\mathbb{E} y_{t-p} u_{t|t-1}' & =     \\gamma_{-p} - b_{1}^{(p-1)} \\gamma_{1-p} - \\cdots - b_{p-1}^{(p-1)} \\gamma_{-1} \\\\     a_p^{(p)} &= \\Delta_p \\Omega_{p-1}^{-1} \\\\ \\left( a_{1}^{(p)}, \\ldots, a_{p-1}^{(p)} \\right) &=        \\left(a_{1}^{(p-1)}, \\ldots, a_{p-1}^{(p-1)} \\right) -     a_p^{(p)} \\left(b_{p-1}^{(p-1)}, \\ldots, b_{1}^{(p-1)} \\right) \\\\     b_p^{(p)} &= \\Delta_p' \\Sigma_{p-1}^{-1} \\\\ \\left( b_{1}^{(p)}, \\ldots, b_{p-1}^{(p)} \\right) &=    \\left( b_{1}^{(p-1)}, \\ldots, b_{p-1}^{(p-1)} \\right) -    b_p^{(p)} \\left(a_{p-1}^{(p-1)}, \\ldots, a_{1}^{(p-1)} \\right) \\\\ \\Sigma_{p} & = \\Sigma_{p-1} - \\Delta_p \\Omega_{p-1}^{-1} \\Delta_p' =                \\Sigma_{p-1} - ^{(p)}_p \\Delta_p' =                \\left( I_{n} - a_{p}^{(p)} b_{p}^{(p)} \\right) \\Sigma_{p-1}\\\\ \\Omega_{p} & = \\Omega_{p-1} - \\Delta_p' \\Sigma_{p-1}^{-1} \\Delta_p =                \\Omega_{p-1} - b^{(p)}_p \\Delta_p =                \\left( I_{n} - b_{p}^{(p)} a_{p}^{(p)} \\right) \\Omega_{p-1} \\end{aligned} \\] recursions start \\(p=1\\) initial values \\(\\Sigma_0 = \\Omega_0 = \\gamma_0\\).","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"express-the-forecast-y_tp-as-the-sum-of-two-projections-onto-orthogonal-spaces","dir":"Articles","previous_headings":"Estimate AR Models > Durbin-Levinson-Whittle Algorithm > Proof","what":"Express the forecast \\(y_{t|p}\\) as the sum of two projections onto orthogonal spaces","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"prediction \\(y_{t|p}\\) projection \\(y_{t}\\) onto space \\(\\mathbb{H}_{t-p}^{t-1} = \\mathrm{span}\\{y_{t-p},\\ldots, y_{t-1}\\}\\). space can decomposed sum two orthogonal subspaces \\(\\mathbb{H}_{t-p+1}^{t-1} = \\mathrm{span}\\{y_{t-p+1},\\ldots, y_{t-1}\\}\\) span components backcast error \\(v_{t-p|p-1} = y_{t-p} - \\mathbb{P}_{t-p+1}^{t-1} y_{t-p} =  y_{t-p} - b^{(p-1)}_1 y_{t-p+1} - \\cdots - b^{(p-1)}_{p-1} y_{t-1}.\\) Therefore \\(y_{t|p}\\) equal sum projection \\(y_t\\) onto \\(\\mathbb{H}_{t-p+1}^{t-1}\\) (.e. \\(y_{t|p-1}\\)) projection \\(y_t\\) onto space spanned \\(v_{t-p|p-1}\\). second projection, represents contribution \\(y_{t-p}\\) prediction, can expressed \\[ \\begin{aligned} (\\mathbb{E} y_{t} v_{t-p|p-1}')(\\mathbb{E} v_{t-p|p-1} v_{t-p|p-1}')^{-1} v_{t-p|p-1} = \\\\ (\\mathbb{E} (y_{t-p} - b^{(p-1)}_1 y_{t-p+1} - \\cdots - b^{(p-1)}_{p-1} y_{t-1}) y_t' )'   \\Omega_{p-1}^{-1} (y_{t-p} - b^{(p-1)}_1 y_{t-p+1} - \\cdots - b^{(p-1)}_{p-1} y_{t-1}) = \\\\ (\\gamma_{-p} - b^{(p-1)}_1 \\gamma_{1-p} - \\cdots - b^{(p-1)}_{p-1} \\gamma_{-1})'   \\Omega_{p-1}^{-1} (y_{t-p} - b^{(p-1)}_1 y_{t-p+1} - \\cdots - b^{(p-1)}_{p-1} y_{t-1}) \\end{aligned} \\] Collecting two projections, obtain \\[ \\begin{aligned} y_{t|p} = \\mathbb{P}_{t-p}^{t-1} y_t   &= a_{1}^{(p-1)}y_{t-1}+\\cdots+a_{p-1}^{(p-1)}y_{t-p+1} + \\Delta_p \\Omega_{p-1}^{-1} (y_{t-p} - b^{(p-1)}_1 y_{t-p+1} - \\cdots - b^{(p-1)}_{p-1} y_{t-1})\\\\ &= \\left(\\left(a_{1}^{(p-1)},\\ldots,a_{p-1}^{(p-1)},0\\right) +       \\Delta_p \\Omega_{p-1}^{-1} \\left(-b_{p-1}^{(p-1)},\\ldots,-b^{(p-1)}_1,I_{n}\\right)\\right) \\begin{pmatrix}y_{t-1}\\\\ \\vdots\\\\ y_{t-p+1}\\\\ y_{t-p} \\end{pmatrix} \\end{aligned} \\] \\[ \\Delta_p = (\\mathbb{E} v_{t-p|p-1} y_t')' = (\\gamma_{-p} - b^{(p-1)}_1 \\gamma_{1-p} - \\cdots - b^{(p-1)}_{p-1} \\gamma_{-1})'. \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"express-the-backcast-yb_t-pp-as-the-sum-of-two-projections-onto-orthogonal-spaces","dir":"Articles","previous_headings":"Estimate AR Models > Durbin-Levinson-Whittle Algorithm > Proof","what":"Express the backcast \\(y^b_{t-p|p}\\) as the sum of two projections onto orthogonal spaces","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"first decompose space \\(\\mathbb{H}_{t-p+1}^{t}\\) orthogonal sum spaces \\(\\mathbb{H}_{t-p+1}^{t-1} = \\mathrm{span}\\{y_{t-p+1},\\ldots,y_{t-1}\\}\\) span components forecast error \\(u_{t|p-1} = y_t - ^{(p-1)}_1 y_{t-1} - \\cdots - ^{(p-1)}_{p-1} y_{t-p+1}\\). projection \\(y_{t-p}\\) onto space spanned forecast error \\(u_{t|p-1}\\) given \\[ \\begin{aligned} (\\mathbb{E} y_{t-p} u_{t|p-1}')(\\mathbb{E} u_{t|p-1} u_{t|p-1}')^{-1} u_{t|p-1} = \\\\ (\\mathbb{E} (y_t - ^{(p-1)}_1 y_{t-1} - \\cdots - ^{(p-1)}_{p-1} y_{t-p+1}) y_{t-p}')'   \\Sigma_{p-1}^{-1} (y_t - ^{(p-1)}_1 y_{t-1} - \\cdots - ^{(p-1)}_{p-1} y_{t-p+1}) = \\\\ (\\gamma_{p} - ^{(p-1)}_1 \\gamma_{p-1} - \\cdots - ^{(p-1)}_{p-1} \\gamma_{1})'   \\Sigma_{p-1}^{-1} (y_t - ^{(p-1)}_1 y_{t-1} - \\cdots - ^{(p-1)}_{p-1} y_{t-p+1}) \\end{aligned} \\] Therefore backcast \\(y^{b}_{t-p|p}\\) equal \\[ \\begin{aligned} y^{b}_{t-p|p} = \\mathbb{P}_{t-p+1}^{t} y_{t-p}    &= b_{1}^{(p-1)}y_{t-p+1}+\\cdots+b_{p-1}^{(p-1)}y_{t-1} + \\Delta^b_{p} \\Sigma_{p-1}^{-1} (y_{t} - ^{(p-1)}_1 y_{t-1} - \\cdots - b^{(p-1)}_{p-1} y_{t-p+1})\\\\ &= \\left(\\left(b_{1}^{(p-1)},\\ldots,b_{p-1}^{(p-1)},0\\right) +       \\Delta^b_{p} \\Sigma_{p-1}^{-1} \\left(-a_{p-1}^{(p-1)},\\ldots,-^{(p-1)}_1,I_{n}\\right)\\right) \\begin{pmatrix}y_{t-p+1}\\\\ \\vdots\\\\ y_{t-1}\\\\ y_{t} \\end{pmatrix} \\end{aligned} \\] \\[ \\Delta^b_p = (\\mathbb{E} u_{t|p-1} y_{t-p}')' = \\left( \\gamma_{p} - ^{(p-1)}_1 \\gamma_{p-1} - \\cdots - ^{(p-1)}_{p-1} \\gamma_{1} \\right)'. \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"covariances-of-the-forecast-error-and-backcast-errors","dir":"Articles","previous_headings":"Estimate AR Models > Durbin-Levinson-Whittle Algorithm > Proof","what":"Covariances of the forecast error and backcast errors","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"covariance matrix forecast error \\(u_{t|p}\\) (due orthogonality) \\[ \\Sigma_p = \\mathbb{E} (u_{t|p} u_{t|p}') =  \\mathbb{E} (u_{t|p-1} u_{t|p-1}') - \\mathbb{E} ((\\Delta_p \\Omega_{p-1}^{-1} v_{t-p|p-1}) (\\Delta_p \\Omega_{p-1}^{-1} v_{t-p|p-1})') = \\Sigma_{p-1} - \\Delta_p \\Omega_{p-1}^{-1} \\Delta_p' \\] analogously covariance matrix backcast error given \\[ \\Omega_p = \\mathbb{E} (\\bar u_{t-p|p} \\bar u_{t-p|p}') =  \\mathbb{E} (\\bar u_{t-p|p-1} \\bar u_{t-p|p-1}') - \\mathbb{E} ((\\Delta^b_p \\Sigma_{p-1}^{-1} u_{t|p-1}) (\\Delta^b_p \\Sigma_{p-1}^{-1} u_{t|p-1})') = \\Omega_{p-1} - \\Delta^b_p \\Sigma_{p-1}^{-1} (\\Delta^b_p)'. \\] Note \\[ \\Delta_p = \\mathbb{E} y_t v_{t-p|p-1}' = \\mathbb{E} u_{t|p-1} v_{t-p|p-1}'          = \\mathbb{E} u_{t|p-1} y_{t-p}' = (\\Delta^b_p)'. \\] Together \\(^{(p)}_p = \\Delta_p \\Omega_{p-1}^{-1}\\) \\(b^{(p)}_p = \\Delta_p' \\Sigma_{p-1}^{-1}\\) thus obtain desired recursions covariance matrices \\[ \\begin{aligned} \\Sigma_p & = \\Sigma_{p-1} - \\Delta_p \\Omega_{p-1}^{-1} \\Delta_p' =              \\Sigma_{p-1} -  a_p^{(p)} \\Delta_p' =              \\Sigma_{p-1} -  a_p^{(p)} b_p^{(p)}\\Sigma_{p-1} \\\\ \\Omega_p & = \\Omega_{p-1} - \\Delta^b_p \\Sigma_{p-1}^{-1} (\\Delta^b_p)' =        \\Omega_{p-1} -  b_p^{(p)} \\Delta_p =        \\Omega_{p-1} -  b_p^{(p)} a_p^{(p)}\\Omega_{p-1} \\end{aligned} \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"implementation","dir":"Articles","previous_headings":"Estimate AR Models > Durbin-Levinson-Whittle Algorithm","what":"Implementation","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"described Durbin-Levinson-Wittle recursion implemented function procedure addition computes partial autocorrelation function, .e.  \\[ \\begin{aligned} \\delta_p &= (\\mbox{diag}(\\mathbb{E} u_{t|p-1}u_{t|p-1}'))^{-1/2}             ( \\mathbb{E} u_{t|p-1} v_{t-p|p-1}' )             (\\mbox{diag}(\\mathbb{E} v_{t-p|p-1}v_{t-p|p-1}'))^{-1/2} \\\\    &= (\\mbox{diag}(\\Sigma_{p-1}))^{-1/2} ( \\Delta_p ) (\\mbox{diag}(\\Omega_{p-1}))^{-1/2}  & \\mbox{ } p \\geq 0 \\end{aligned} \\]","code":"est_ar_dlw(gamma, p.max = (dim(gamma)[3]-1), penalty = -1)"},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"ols-estimate","dir":"Articles","previous_headings":"Estimate AR Models","what":"OLS Estimate","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"Let \\[ Y = \\begin{pmatrix}     y_1' & \\cdots & y_{p}' & y_{p+1}' \\\\     y_2' & \\cdots & y_{p+1}' & y_{p+2}' \\\\     \\vdots &     & \\vdots & \\vdots \\\\     y_{N-p}' & \\cdots & y_{N-1}' & y_{N}' \\\\     \\end{pmatrix}   = (Q_1 \\; Q_2) \\begin{pmatrix} R_{11} & R_{12} \\\\ 0 & R_{22} \\end{pmatrix} \\]","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"wrapper-function","dir":"Articles","previous_headings":"Estimate AR Models","what":"wrapper function","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"store mean, intercept!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"computation-of-the-acf","dir":"Articles","previous_headings":"ARMA Processes","what":"Computation of the ACF","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"\\[ a_0 y_t + a_1 y_{t-1} \\cdots + a_p y_{t-p} = b_0 \\epsilon_t + b_1 \\epsilon_{t-1} + \\cdots b_q \\epsilon_{t-q} \\] assume stability condition holds thus stationary solution ARMA system causal MA(\\(\\infty\\)) process \\[ y_t = \\sum_{\\geq 0} k_i \\epsilon_{t-}. \\] implies particular \\[ \\mathbb{E} \\epsilon_{t-}y_t' = \\begin{cases}      \\Sigma k_i' & \\mbox{ } \\geq 0 \\\\      0           & \\mbox{ } < 0. \\end{cases}   \\] genaralized Yule-Walker equations now obtained multiplying ARMA system right \\(y_{t-j}'\\) taking expectations \\[ \\begin{aligned} a_0 \\gamma_j + a_1 \\gamma_{j-1} + \\cdots + a_p \\gamma_{j-p} & = b_0 \\mathbb{E} \\epsilon_t y_{t-j}' + b_1 \\mathbb{E} \\epsilon_{t-1} y_{t-j}' + \\cdots + b_q \\mathbb{E} \\epsilon_{t-q} y_{t-j}'  \\\\ & = b_j \\Sigma k_0' + \\cdots + b_q \\Sigma k_{q-j}'  & \\mbox{} 0 \\leq j \\leq q \\\\ & = 0 & \\mbox{ } j> q \\end{aligned} \\] following right hand sides equations denoted \\(\\Delta_j\\), \\(j\\geq 0\\). first step consider equations \\(j=0,\\ldots,p\\) solve equations \\(\\gamma_0, \\ldots, \\gamma_p\\). end consider “vectorised” covariances \\(\\mathrm{vec}(\\gamma_k)\\) note \\[ \\mathrm{vec}(a_i \\gamma_k) = (I_m \\otimes a_i) \\mathrm{vec} (\\gamma_k) \\mbox{ } \\mathrm{vec}(a_i \\gamma_{-k}) = \\mathrm{vec}(a_i \\gamma_{k}') = (I_m \\otimes a_i) \\mathrm{vec}(\\gamma_k') = (I_m \\otimes a_i) P \\mathrm{vec} (\\gamma_k) \\] \\(P \\\\mathbb{R}^{m^2 \\times m^2}\\) permutation matrix. simple example consider case \\(p=2\\): Yule-Walker equations \\(j=0,\\ldots,2\\) \\[ \\begin{array}{rrrcr} a_0 \\gamma_0   &+ a_1 \\gamma_{-1} &+ a_2 \\gamma_{-2} &=& \\Delta_0 \\\\ a_0 \\gamma_{1} &+ a_1 \\gamma_{0}  &+ a_2 \\gamma_{-1} &=& \\Delta_1 \\\\ a_0 \\gamma_{2} &+ a_1 \\gamma_{1}  &+ a_2 \\gamma_{0}  &=& \\Delta_2 \\\\ \\end{array} \\] give following “vectorized” equation system: \\[ \\begin{array}{rrrcr} (I_m \\otimes a_0) \\mathrm{vec}(\\gamma_0)   &+ (I_m \\otimes a_1)P \\mathrm{vec}(\\gamma_{1})                                            &+ (I_m \\otimes a_2)P \\mathrm{vec}(\\gamma_{2}) &=& \\mathrm{vec}(\\Delta_0) \\\\ (I_m \\otimes a_1) \\mathrm{vec}(\\gamma_{0}) &+ ((I_m \\otimes a_0)+(I_m \\otimes a_2)P) \\mathrm{vec}(\\gamma_{1})                                            &+ 0 \\mathrm{vec}(\\gamma_{1}) &=& \\mathrm{vec}(\\Delta_1) \\\\ (I_m \\otimes a_2) \\mathrm{vec}(\\gamma_{0}) &+ (I_m \\otimes a_1) \\mathrm{vec}(\\gamma_{1})                                              &+ (I_m \\otimes a_0) \\mathrm{vec}(\\gamma_{2}) &=& \\mathrm{vec}(\\Delta_2) \\end{array} \\] second step AR coefficients \\(\\gamma_j\\), \\(j>p\\) determined recursion \\[ \\gamma_j = \\Delta_j - a_0^{-1}a_1 \\gamma_{j-1} - \\cdots - a_0^{-1}a_p \\gamma_{j-p} \\mbox{ } j > p \\] procedure implemented ","code":"autocov.armamod(obj, type=c('covariance','correlation','partial'), lag.max = 12)"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"arp-systems","dir":"Articles","previous_headings":"Solve Difference equations","what":"AR(p) Systems","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"\\[ y_t = a_1 y_{t-1} + \\cdots + a_p y_{t-p} + u_t = (a_p,\\ldots,a_1)(y_{t-p},\\ldots,y_{t-1}) + u_t   \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/b_RLDM_technicaldetails.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Rational Linear Dynamic Models (RLDM): Technical Details","text":"(Scherrer Deistler 2019).","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"differences-to-hrk-in-hd","dir":"Articles","previous_headings":"","what":"Differences to HRK in HD","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"Hannan-Rissanen-Kavalieris algorithm implemented package differs ways one described Hannan, Deistler 2012: Statistical Theory Linear Systems (henceforth HD) Chapter 6.7, starting page 294ff: HRK HD uses Toeplitz recursive calculations, .e. every stage, models orders (upper bound) \\(p,q\\) calculated. use OLS estimating one particular model AR MA orders \\(p\\) \\(q\\). HRK HD Kronecker echelon form treats generic neighborhood (Kronecker indices \\(n_1 = \\cdots = n_k = n_{k+1} + 1 = \\cdots = n_m + 1)\\), \\(m\\) output dimension. allow affine restrictions general. However, still required \\(a_0 = b_0\\), \\(diag(a_0)=I_m\\), \\(\\Sigma_L\\) lower-triangular.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"inputs-and-outputs","dir":"Articles","previous_headings":"Stage 3","what":"Inputs and Outputs","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"Given data \\(y\\) containing \\(m\\) variables, \\(T\\) number observations, stored matrix dimension \\((T \\times m)\\) residuals \\(\\varepsilon_t^{II}\\) obtained stage 2, .e. obtained \\(b_{II,f}(z)^{-1} a_{II}(z) y_t\\) zeros \\(b_{II,f}(z)\\) flipped outside unit circle. Note \\((z)\\) might still zeros inside unit circle! estimates \\(a_{II}(z)\\) \\(b_{II,f}(z)\\) . outputs algorithm \\(a_{III}(z)\\) \\(b_{III}(z)\\) obtained OLS regression. side-product, also obtain “ARX” residuals \\(u^{III}_t\\) Residuals \\(\\varepsilon_t^{III}\\). obtained \\(b_{III,f}(z)^{-1} a_{III}(z) y_t\\). , guaranteed \\(a_{III}(z)\\) zeros inside unit circle!","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"optimization-criterion","dir":"Articles","previous_headings":"Stage 3","what":"Optimization Criterion","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"goal minimize \\[ \\int_{-\\pi}^{\\pi} trace\\left[ \\left( k(e^{\\omega}) \\Sigma  k'(e^{-\\omega}) \\right)^{-1} \\left( w(\\omega) w^*(\\omega)\\right)\\right] d\\omega \\] respective parameter space, \\[ w(\\omega) = \\left( \\frac{1}{\\sqrt{T}} \\sum_{t=1}^T y_t e^{\\omega_j} \\right) \\] Similar univariate case, first order approximate transfer function \\[ \\left( k(e^{\\omega}) \\Sigma  k'(e^{-\\omega}) \\right)^{-1} \\] around initial value obtained stage 2, .e. \\[ \\left[ k(e^{\\omega})^{-*} \\Sigma^{-\\frac{1}{2}} \\right]  \\Sigma^{-\\frac{1}{2}} \\left(  \\hat{k}(e^{\\omega})^{-1} + \\frac{\\partial \\hat{k}(e^{\\omega})^{-1}}{\\partial \\tau'} \\left( \\tau - \\hat{\\tau}\\right) \\right) \\] following, derive regression obtained terms parentheses parametrisation \\(\\tau = vec\\left(a_1, \\ldots, a_p, b_1, \\ldots, b_q \\right)\\). term \\(\\frac{\\partial \\hat{k}(e^{-\\omega})}{\\partial \\tau'}\\) means partial derivative w.r.t. \\(\\tau\\) evaluated \\(\\hat{\\tau}\\). (restrict VARMA(p,q) model , course, applicable given affine restrictions described .) need regress \\[ \\left[ \\hat{k}(z)^{-1} - \\frac{\\partial \\hat{k}(z)^{-1}}{\\partial \\tau'} \\hat{\\tau} \\right] y_t \\] \\[ -\\left[ \\frac{\\partial \\hat{k}(z)^{-1}}{\\partial \\tau'} \\right] y_t \\] end, construct regression \\(T\\cdot m\\) dimensional stacked vector \\(\\left[ \\hat{k}(z) - \\frac{\\partial \\hat{k}(z)}{\\partial \\tau'} \\hat{\\tau} \\right] y_t\\) corresponding \\(\\left( T\\cdot m \\times m^2(p+q) \\right)\\)-dimensional matrix stacked \\(-\\left[ \\frac{\\partial \\hat{k}(z)}{\\partial \\tau'} \\right] y_t\\).","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"derivative-with-respect-to-ar-parameters","dir":"Articles","previous_headings":"Stage 3 > Toeplitz Regression: RHS","what":"Derivative with respect to AR parameters","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"Considering \\[ k(z)^{-1} y_t = u_t = y_t + \\left(a_1, \\ldots, a_p \\right) \\begin{pmatrix} y_{t-1}\\\\ \\vdots\\\\ y_{t-p} \\end{pmatrix} - \\left( b_1, \\ldots, b_q \\right) \\begin{pmatrix} u_{t-1}\\\\ \\vdots\\\\ u_{t-q} \\end{pmatrix}, \\] vectorization using \\(vec(ABC) = (C' \\otimes ) vec(B)\\) gives \\[ u_t = y_t + (x_{t-1}' \\otimes I_m) \\tau_1 - (w_{t-1}' \\otimes I_m) \\tau_2 \\] \\(x_{t-1}' = (y_{t-1}',\\ldots, y_{t-p}')\\), \\(\\tau_1 = vec\\left(a_1, \\ldots, a_p \\right)\\), \\(w_{t-1}' = (u_{t-1}',\\ldots, u_{t-q}')\\), \\(\\tau_2 = vec\\left(b_1, \\ldots, b_q \\right)\\). partial derivative \\[ \\frac{\\partial k(z)^{-1} y_t }{\\partial \\tau_1'} = (x_{t-1}' \\otimes I_m) - \\left( b_1, \\ldots, b_q \\right) \\begin{pmatrix} \\frac{\\partial u_{t-1}}{\\partial \\tau_1'}\\\\ \\vdots\\\\ \\frac{\\partial u_{t-q}}{\\partial \\tau_1'} \\end{pmatrix} \\] equivalent \\[ b(z) \\frac{\\partial u_{t}}{\\partial \\tau_1'} = (x_{t-1}' \\otimes I_m). \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"derivative-with-respect-to-ma-parameters","dir":"Articles","previous_headings":"Stage 3 > Toeplitz Regression: RHS","what":"Derivative with respect to MA parameters","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"Similarly, obtain \\[ \\frac{\\partial k(z)^{-1} y_t }{\\partial \\tau_2'} = - (w_{t-1}' \\otimes I_m) - \\left( b_1, \\ldots, b_q \\right) \\begin{pmatrix} \\frac{\\partial u_{t-1}}{\\partial \\tau_2'}\\\\ \\vdots\\\\ \\frac{\\partial u_{t-q}}{\\partial \\tau_2'} \\end{pmatrix} \\] equivalent \\[ b(z) \\frac{\\partial u_{t}}{\\partial \\tau_2'} = - (w_{t-1}' \\otimes I_m). \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"summary","dir":"Articles","previous_headings":"Stage 3 > Toeplitz Regression: RHS","what":"Summary","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"thus \\[ \\frac{\\partial k(z)^{-1} y_t }{\\partial (\\tau_1', \\tau_2') } = b(z)^{-1} \\left( (x_{t-1}', -w_{t-1}') \\otimes I_m \\right). \\] dimension \\((m \\times m^2(p+q))\\). matrices eventually stacked RHS regression dimension \\((Tm \\times m^2(p+q))\\). first elements (pertaining AR parameters) matrix \\[ b(z)^{-1} \\left( I_m y_{1,t-1}, \\ldots, I_m y_{m,t-1} | \\cdots | I_m y_{1,t-p}, \\ldots, I_m y_{m,t-p} \\right) . \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"toeplitz-regression-lhs","dir":"Articles","previous_headings":"Stage 3","what":"Toeplitz Regression: LHS","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"Calculating \\(\\frac{\\partial \\hat{k}(z)}{\\partial \\tau'} \\hat{\\tau}\\), \\(\\tau' = (\\tau_1', \\tau_2')\\), slightly difficult first need vectorize devectorize. univariate case, \\(\\frac{\\partial \\hat{k}(z)}{\\partial \\tau'} \\hat{\\tau} = \\hat{b}(z)^{-1} \\hat{k}(z)^{-1} - \\hat{b}(z)^{-1}\\). see , despite non-commutativity matrix multiplication, expression multivariate case.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"ar-parameters","dir":"Articles","previous_headings":"Stage 3 > Toeplitz Regression: LHS","what":"AR Parameters","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"\\[ \\begin{aligned} \\frac{\\partial vec(k(z)^{-1} )}{\\partial \\tau_1' } & = \\frac{\\partial}{\\partial \\tau_1' } \\left[ vec \\left( b(z)^{-1} \\left( I_m + \\left(a_1, \\ldots, a_p \\right) \\begin{pmatrix} z I_m\\\\ \\vdots\\\\ z^p I_m \\end{pmatrix} \\right) \\right) \\right] \\\\ & =   \\left( I_m \\otimes b(z)^{-1}\\right) \\frac{\\partial}{\\partial \\tau_1' } \\left[ vec \\left(  I_m + \\left(a_1, \\ldots, a_p \\right) \\begin{pmatrix} z I_m\\\\ \\vdots\\\\ z^p I_m \\end{pmatrix} \\right) \\right] \\\\ & = \\left( I_m \\otimes b(z)^{-1}\\right) \\left( \\left( z I_m, \\ldots, z^p I_m \\right) \\otimes I_m \\right) \\\\ & = \\left( \\left( z I_m, \\ldots, z^p I_m \\right) \\otimes b(z)^{-1}\\right) \\end{aligned} \\] Thus, \\[ \\begin{aligned} \\frac{\\partial vec(k(z)^{-1})}{\\partial \\tau_1' } \\tau_1 & = \\left( \\left( z I_m, \\ldots, z^p I_m \\right) \\otimes b(z)^{-1}\\right) vec\\left(a_1, \\ldots, a_p\\right) \\end{aligned} \\] devectorized \\[ \\begin{aligned} \\frac{\\partial k(z)^{-1} }{\\partial \\tau_1' } \\tau_1 & = vec^{-1} \\left( vec \\left[ b(z)^{-1} \\left(a_1, \\ldots, a_p\\right) \\begin{pmatrix} z I_m\\\\ \\vdots\\\\ z^p I_m \\end{pmatrix} \\right] \\right) \\\\ & = b(z)^{-1} \\left( a_1 z + \\cdots + a_p z^p + I_m - I_m \\right) \\\\ & = b(z)^{-1} (z) - b(z)^{-1} \\end{aligned} \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"ma-parameters","dir":"Articles","previous_headings":"Stage 3 > Toeplitz Regression: LHS","what":"MA Parameters","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"Similarly, \\[ \\begin{aligned} \\frac{\\partial vec(k(z)^{-1} )}{\\partial \\tau_2' } & = \\frac{\\partial}{\\partial \\tau_2' } \\left[ vec \\left(  \\left( I_m + \\left(b_1, \\ldots, b_q \\right) \\begin{pmatrix} z I_m\\\\ \\vdots\\\\ z^q I_m \\end{pmatrix} \\right)^{-1} (z)\\right) \\right] \\\\ & =   -\\left( '(z) \\otimes I_m \\right)   \\left( b'(z)^{-1} \\otimes b(z)^{-1} \\right) \\frac{\\partial}{\\partial \\tau_1' } \\left[ vec \\left(  I_m + \\left(b_1, \\ldots, b_q \\right) \\begin{pmatrix} z I_m\\\\ \\vdots\\\\ z^q I_m \\end{pmatrix} \\right) \\right] \\\\ & =   -\\left( '(z) b'(z)^{-1} \\otimes b(z)^{-1} \\right) \\left( \\left( z I_m, \\ldots, z^q I_m \\right) \\otimes I_m \\right) \\\\ & =   -\\left( '(z) b'(z)^{-1} \\left( z I_m, \\ldots, z^q I_m \\right) \\otimes b(z)^{-1} \\right) \\end{aligned} \\] Thus, \\[ \\begin{aligned} \\frac{\\partial vec(k(z)^{-1})}{\\partial \\tau_2' } \\tau_2 & = -\\left( '(z) b'(z)^{-1} \\left( z I_m, \\ldots, z^q I_m \\right) \\otimes b(z)^{-1} \\right) vec\\left(b_1, \\ldots, b_q \\right) \\end{aligned} \\] devectorized \\[ \\begin{aligned} \\frac{\\partial k(z)^{-1} }{\\partial \\tau_2' } \\tau_2 & = -vec^{-1} \\left( vec \\left[ b(z)^{-1} \\left(b_1, \\ldots, b_q\\right) \\begin{pmatrix} z I_m\\\\ \\vdots\\\\ z^p I_m \\end{pmatrix} b(z)^{-1} (z) \\right] \\right) \\\\ & = -b(z)^{-1} \\left( b_1 z + \\cdots + b_q z^q + I_m - I_m \\right) k(z)^{-1} \\\\ & = b(z)^{-1} k(z)^{-1} - k(z)^{-1} \\end{aligned} \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"summary-1","dir":"Articles","previous_headings":"Stage 3 > Toeplitz Regression: LHS","what":"Summary","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"finally obtain \\[ \\begin{aligned} \\frac{\\partial k(z)^{-1} }{\\partial (\\tau_1', \\tau_2') } \\tau &= b(z)^{-1} (z) - b(z)^{-1} +  b(z)^{-1} k(z)^{-1} - k(z)^{-1}\\\\ &= - b(z)^{-1} +  b(z)^{-1} k(z)^{-1} \\end{aligned} \\] thus LHS \\[ \\begin{aligned} \\left[ \\hat{k}(z)^{-1} - \\frac{\\partial \\hat{k}(z)}{\\partial \\tau'} \\hat{\\tau} \\right] y_t &= \\left[ \\hat{k}(z)^{-1} - \\hat{b}(z)^{-1} \\hat{k}(z)^{-1} + \\hat{b}(z)^{-1} \\right] y_t\\\\ &= \\varepsilon^{II}_t - \\hat{b}(z)^{-1} \\varepsilon^{II}_t + \\hat{b}(z)^{-1} y_t\\\\ \\end{aligned} \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"summary-2","dir":"Articles","previous_headings":"Stage 3","what":"Summary","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"regression \\[ \\left[ \\hat{k}(z)^{-1} - \\frac{\\partial \\hat{k}(z)^{-1}}{\\partial \\tau'} \\hat{\\tau} \\right] y_t \\] \\[ -\\left[ \\frac{\\partial \\hat{k}(z)^{-1}}{\\partial \\tau'} \\right] y_t \\] thus \\[ \\varepsilon^{II}_t - \\hat{b}(z)^{-1} \\varepsilon^{II}_t + \\hat{b}(z)^{-1} y_t = \\hat{b}(z)^{-1} \\left( (-x_{t-1}', w_{t-1}') \\otimes I_m \\right) \\cdot vec\\left(a_1, \\ldots, a_p, b_1, \\ldots, b_q \\right) + error. \\]","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/c_hrk_stage3.html","id":"remarks-on-root-flipping","dir":"Articles","previous_headings":"","what":"Remarks on Root Flipping","title":"Hannan-Rissanen-Kavalieris Estimation - Stage 3","text":"applying Blaschke matrices, necessary “shift” square root \\(\\Sigma_L\\) (case lower-triangular Choleski factor) covariance matrix \\(\\Sigma\\) spectral factorization \\[ f(z) = k(z) \\Sigma k'\\left(\\frac{1}{z}\\right) \\] transfer function. Right-multiplying Blaschke factor \\(k(z) \\Sigma_L\\) change spectral density guaranteed right-multiplying (implementation) \\(k(z)\\). Note right-multiplying Blaschke factor flips root inside outside unit circle increases “innovation” covariance, .e. \\(k(0) \\Sigma_L b(0) \\geq k(0) \\Sigma_L\\) usual partial order positive semi-definite matrices (https://en.wikipedia.org/wiki/Loewner_order).","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Case Study","text":"simple case study use Blanchard/Quah (1989) dataset quarterly data real GDP growth rates detrended unemployment rate USA.    data set contains 159 observations 1948-04-01 1987-10-01. estimation use first 87 observation till 1969-10-01. data scaled sample variances two series equal one.","code":"y = BQdata_xts  break_date = as_date(\"1970-01-01\")  y_train = BQdata_xts[index(BQdata_xts) < break_date] y_test  = BQdata_xts[index(BQdata_xts) >= break_date] dim_out = ncol(y_train)  plot(y) addLegend('topleft', c('GDP growth rate', 'Unemployment rate'), col = c('black', 'red'),        lwd = 2, bty = 'n') addEventLines(xts(\"Break\", break_date))"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"ar-model","dir":"Articles","previous_headings":"","what":"AR Model","title":"Case Study","text":", estimate AR model order determined via AIC. essential input function est_ar() data-object, e.g. matrix observations rows variables columns, covariance-object. defaults using AIC model selection, Yule-Walker estimation, sample.mean estimating \\(\\mathbb{E}\\left(y_t\\right)\\). Important statistics regarding model selection contained slot stats estimates armamod object stored remaining slots estimated models collected two lists modelsand estimates.","code":"out = est_ar(y_train, mean_estimate = 'zero') out %>% names() #> [1] \"model\"  \"p\"      \"stats\"  \"y.mean\" \"ll\" out$stats out$model #> ARMA model [2,2] with orders p = 1 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2] #> [1,]        1     0 -0.4579266 -0.1795184 #> [2,]        0     1  0.3098179 -0.9328347 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] #> u[1]  0.9567816 0.0000000 #> u[2] -0.2050479 0.3490723 out$ll #> [1] -1.741221 out$p #> [1] 1 out$y.mean #> [1] 0 0 models    = list(AR1 = out$model) estimates = list(AR1 = list(model = out$model, n.par = out$p * dim_out^2))"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"cca-estimate","dir":"Articles","previous_headings":"Statespace Models","what":"CCA Estimate","title":"Case Study","text":"“chosen” model s=1 value lndetSigma order selection criteria performed first (based singular values “normalized” Hankel matrix). slot models (plural) non-NULL keep_models == TRUE. Save model","code":"out = est_stsp_ss(y_train, method = 'cca', mean_estimate = 'zero') out %>% names() #> [1] \"model\"  \"models\" \"s\"      \"stats\"  \"info\"   \"y.mean\" out$model #> state space model [2,2] with s = 2 states #>            s[1]       s[2]       u[1]      u[2] #> s[1]  0.9191263  0.1912447 -0.1103757 0.7043585 #> s[2] -0.3340845  0.6472138 -0.6742802 0.2083379 #> x[1]  0.1800227 -0.5626354  1.0000000 0.0000000 #> x[2]  1.4254461  0.1339044  0.0000000 1.0000000 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] #> u[1]  0.9477920 0.0000000 #> u[2] -0.1968541 0.3460504 out$stats out$models #> NULL models$CCA    = out$model estimates$CCA = list(model = out$model, n.par = 2*dim_out*out$s)"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"ddlc-estimate","dir":"Articles","previous_headings":"Statespace Models","what":"DDLC estimate","title":"Case Study","text":"ML estimation statespace model “DDLC” parametrization. use concentrated log likelihood, hence noise covariance parametrized! course, wrap procedure suitable estimation procedure/function.","code":"tmpl = tmpl_DDLC(models$CCA, balance = 'minimum phase', sigma_L = 'identity') th0 = numeric(tmpl$n.par)  llfun = ll_FUN(tmpl, y_train, skip = 0, which = \"concentrated\") control = list(trace = 1, fnscale = -1, maxit = 10)  out = optim(th0, llfun, method = 'BFGS', control = control) #> initial  value 1.440187  #> iter  10 value 1.393777 #> final  value 1.393777  #> stopped after 10 iterations th = out$par model = fill_template(th, tmpl)  # reparametrize tmpl = tmpl_DDLC(model, balance = 'minimum phase', sigma_L = 'identity') llfun = ll_FUN(tmpl, y_train, skip = 0, which = \"concentrated\") control$maxit = 20  out = optim(th0, llfun, method = 'BFGS', control = control) #> initial  value 1.393777  #> iter  10 value 1.393607 #> final  value 1.393607  #> converged th = out$par model = fill_template(th, tmpl)  # reparametrize tmpl = tmpl_DDLC(model, balance = 'minimum phase', sigma_L = 'identity') llfun = ll_FUN(tmpl, y_train, skip = 0, which = \"concentrated\") control$maxit = 200  out   = optim(th0, llfun, method = 'BFGS', control = control) #> initial  value 1.393607  #> final  value 1.393607  #> converged th    = out$par model = fill_template(th, tmpl)  # out           = ll(model, y_train, skip = 0, which = \"concentrated\") model$sigma_L = t(chol(model$sigma_L))  models$DDLC    = model estimates$DDLC = list(model = model, n.par = tmpl$n.par)"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"ml-estimate-of-echelon-form-model","dir":"Articles","previous_headings":"Statespace Models","what":"ML Estimate of Echelon Form Model","title":"Case Study","text":"ML estimation statespace model echelon canonical form. first coerce CCA estimate echelon canonical form.","code":"lag.max = 20 ir = impresp(models$CCA, lag.max = lag.max)$irf # impulse response nu = pseries2nu(ir)                             # Kronecker indices  nu #> [1] 1 1  # transform the CCA estimate into echelon canonical form model = stspmod(sys = pseries2stsp(ir, method = 'echelon')$Xs,                  sigma_L = models$CCA$sigma_L) # check  all.equal(autocov(model, lag.max = lag.max),            autocov(models$CCA, lag.max = lag.max)) #> [1] TRUE  tmpl = tmpl_stsp_echelon(nu, sigma_L = 'identity') th0 = extract_theta(model, tmpl, on_error = 'stop', ignore_sigma_L = TRUE)  llfun = ll_FUN(tmpl, y_train, skip = 0, which = \"concentrated\")  control$maxit = 500  out = optim(th0, llfun, method = 'BFGS', control = control) #> initial  value 1.440187  #> iter  10 value 1.393688 #> final  value 1.393607  #> converged th = out$par model = fill_template(th, tmpl) out = ll(model, y_train, skip = 0, which = \"concentrated\") # model$sigma_L = t(chol(out$S))  models$SSECF    = model estimates$SSECF = list(model = model, n.par = tmpl$n.par)"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"hrk-estimate","dir":"Articles","previous_headings":"ARMA models","what":"HRK estimate","title":"Case Study","text":"Initial estimate via HRK procedure. replaced est_arma_hrk3().","code":"tmpl = tmpl_arma_echelon(nu, sigma_L = 'chol') out = est_arma_hrk(y_train, tmpl = tmpl, mean_estimate = 'zero') #> HRK estimation of ARMA model: m=2, n.obs=87, p=1, q=1 #> initial AR estimate of noise p.max=9, p=8, ll=-1.085391 #> iter |th - th0|  n.val      MSE       ll  #>    1      0.967     78    0.846   -1.282 models$HRK = out$model estimates$HRK = list(model = out$model, n.par = tmpl$n.par - dim_out*(dim_out+1)/2)"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"ml-estimate-of-echelon-form-model-1","dir":"Articles","previous_headings":"ARMA models","what":"ML Estimate of Echelon Form Model","title":"Case Study","text":"ML estimation ARMA model echelon form.","code":"tmpl = tmpl_arma_echelon(nu, sigma_L = 'identity') th0 = extract_theta(models$HRK, tmpl, on_error = 'stop', ignore_sigma_L = TRUE)  llfun = ll_FUN(tmpl, y_train, skip = 0, which = \"concentrated\")  out = optim(th0, llfun, method = 'BFGS', control = control) #> initial  value 1.404641  #> iter  10 value 1.393736 #> final  value 1.393607  #> converged th = out$par model = fill_template(th, tmpl) out = ll(model, y_train, skip = 0, which = \"concentrated\") # model$sigma_L = t(chol(out$S))  models$ARMAECF = model estimates$ARMAECF = list(model = model, n.par = tmpl$n.par)"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"compare-models","dir":"Articles","previous_headings":"","what":"Compare Models","title":"Case Study","text":"data set three ML estimates essentially equivalent: Therefore keep “SSECF” estimate evluations/comparisons. Portmanteau test serial correlation AR1 estimate: Compare estimates: collect statistics/tests matrix easy comparison:","code":"all.equal(impresp(models$DDLC, lag.max = lag.max),            impresp(models$SSECF, lag.max = lag.max)) #> [1] \"Component \\\"irf\\\": Mean relative difference: 2.075071e-05\" all.equal(impresp(models$DDLC, lag.max = lag.max),            impresp(models$ARMAECF, lag.max = lag.max)) #> [1] \"Component \\\"irf\\\": Mean relative difference: 9.231668e-06\" models = models[c('AR1','CCA','HRK','SSECF')] estimates = estimates[c('AR1','CCA','HRK','SSECF')] u = solve_inverse_de(models$AR1$sys, as.matrix(y_train))$u pm_test(u, 8, dim_out^2) stats = compare_estimates(estimates, y_train, n.lags = 8) if (requireNamespace(\"kableExtra\", quietly = TRUE)) {   stats %>%     kable() %>%     kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) } else {   stats }"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"acf","dir":"Articles","previous_headings":"","what":"ACF","title":"Case Study","text":"","code":"plot(autocov(y, lag.max = lag.max),       lapply(models, FUN = autocov, lag.max = lag.max),      legend = c('sample', names(models)),      col = c('black', default_colmap(length(models))))"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"spectral-density","dir":"Articles","previous_headings":"","what":"Spectral Density","title":"Case Study","text":"","code":"plot(spectrald(models[[1]], n.f = 2^10),       lapply(models[-1], FUN = spectrald, n.f = 2^10),      legend = names(models))"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"impulse-response","dir":"Articles","previous_headings":"","what":"Impulse Response","title":"Case Study","text":"","code":"plot(impresp(models[[1]], lag.max = lag.max),       lapply(models[-1], FUN = impresp, lag.max = lag.max),      legend = names(models))"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"plot","dir":"Articles","previous_headings":"Prediction","what":"Plot","title":"Case Study","text":"","code":"n.ahead = 8 n.obs = nrow(y) pred = predict(models$SSECF, y, h = c(1,4), n.ahead = n.ahead) # add the date/time information to the list \"pred\" # date = seq((start(y)-1)*3+1, by = 3, length.out = nrow(y)+n.ahead) # date = as.Date(paste(start(y)[1] + (date-1) %/% 12, (date-1) %% 12 + 1, 1, sep='-')) # pred$date = date  # the default \"predictor names\" h=1, h=2, ... # don't look well, when plotted as expressions dimnames(pred$yhat)[[3]] = gsub('=','==',dimnames(pred$yhat)[[3]])  # generate some plots ####################  # a simple/compressed plot of the data p.y0 = plot_prediction(pred, which = 'y0', style = 'bw',                        parse_names = TRUE, plot = FALSE) p.y0() # a simple/compressed plot of the prediction errors plot_prediction(pred, which = 'u0', parse_names = TRUE) # plot of the prediction errors (with 95% confidence intervals) plot_prediction(pred, which = 'error', qu = c(2,2,2),                 parse_names = TRUE) # plot of the true vales and the predicted values (+ 50% confidence region # for the 1-step ahead prediction and the \"out of sample\" predictions) p.y = plot_prediction(pred, qu = c(qnorm(0.75), NA, qnorm(0.75)),                       parse_names = TRUE, plot = FALSE) # subfig = p.y(xlim = date[c(n.obs-12, n.obs+n.ahead)]) # opar = subfig(1) # abline(v = mean(as.numeric(date[c(n.obs, n.obs+1)])), col = 'red') # # subfig(2) # abline(v = mean(as.numeric(date[c(n.obs, n.obs+1)])), col = 'red') # mtext(paste(' example plot:', date()), side = 1, outer = TRUE, #       cex = 0.5, col = 'gray', adj = 0) # graphics::par(opar) # reset the graphical parameters  # CUSUM plot of the prediction errors plot_prediction(pred, which = 'cusum',                 style = 'gray', parse_names = TRUE) # CUSUM2 plot of the prediction errors plot_prediction(pred, which = 'cusum2', parse_names = TRUE)"},{"path":"https://bfunovits.github.io/RLDM/articles/d_casestudy2.html","id":"evaluate-and-compare-predictions","dir":"Articles","previous_headings":"Prediction","what":"Evaluate and Compare Predictions","title":"Case Study","text":"","code":"out = lapply(models, FUN = function(model) {predict(model, y, h = c(1,4))$yhat}) yhat = do.call(dbind, c(3, out) ) dimnames(yhat)[[3]] = kronecker(names(models), c(1,4), FUN = paste, sep = ':') stats = evaluate_prediction(y, yhat, h = rep(c(1,4), length(models)),                              criteria = list('RMSE', 'MAE','MdAPE'),                              samples = list(in.sample = 1:dim(y_train), out.of.sample = (dim(y_train)+1):dim(y))) #> Warning in 1:dim(y_train): numerical expression has 2 elements: only the first #> used #> Warning in (dim(y_train) + 1):dim(y): numerical expression has 2 elements: only #> the first used # dimnames.stats = dimnames(stats) # stats = stats[,,c(seq(from = 1, by = 2, length.out = 6),  #                   seq(from = 2, by = 2, length.out = 6)), ] # dim(stats) = c(3,2,6,2,3) # dimnames(stats) = list(criterion = dimnames.stats[[1]], sample = dimnames.stats[[2]],  #                        predictor = names(models), h = paste('h=', c(1,4), sep = ''), #                        data = dimnames.stats[[4]])  # use array2data.frame for \"tabular\" display of the results stats.df = array2data.frame(stats, cols = 4) stats.df$h = sub(\"^.*:\",\"\", as.character(stats.df$predictor)) stats.df$predictor = sub(\":.$\",\"\", as.character(stats.df$predictor)) stats.df = stats.df[c('sample','h','criterion','predictor','rGDPgrowth_demeaned','unemp_detrended','total')] stats.df = stats.df[order(stats.df$sample, stats.df$h, stats.df$criterion, stats.df$predictor),] rownames(stats.df) = NULL if (requireNamespace(\"kableExtra\", quietly = TRUE)) {   stats.df %>%      kable() %>%     kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%     kableExtra::collapse_rows(columns = 1:3, valign = \"top\") } else {   stats.df } stats.df %>% names() #> [1] \"sample\"              \"h\"                   \"criterion\"           #> [4] \"predictor\"           \"rGDPgrowth_demeaned\" \"unemp_detrended\"     #> [7] \"total\""},{"path":"https://bfunovits.github.io/RLDM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Wolfgang Scherrer. Author. Bernd Funovits. Author, maintainer.","code":""},{"path":"https://bfunovits.github.io/RLDM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Scherrer W, Funovits B (2023). RLDM: Rational Linear Dynamic (Time Series) Models. R package version 0.0.0.9006, https://github.com/bfunovits/RLDM, https://bfunovits.github.io/RLDM/, https://bfunovits.github.io/RLDM.","code":"@Manual{,   title = {RLDM: Rational Linear Dynamic (Time Series) Models},   author = {Wolfgang Scherrer and Bernd Funovits},   year = {2023},   note = {R package version 0.0.0.9006, https://github.com/bfunovits/RLDM, https://bfunovits.github.io/RLDM/},   url = {https://bfunovits.github.io/RLDM}, }"},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"rational-linear-dynamic-models-rldm","dir":"","previous_headings":"","what":"Rational Linear Dynamic (Time Series) Models","title":"Rational Linear Dynamic (Time Series) Models","text":"RLDM (Rational Linear Dynamic Models) R package provides models stationary processes rational spectral density methods estimation. refer rational models. builds heavily sister R package rationalmatrices, see https://bfunovits.github.io/rationalmatrices/.","code":""},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Rational Linear Dynamic (Time Series) Models","text":"can install latest version code using remotes R package.","code":"remotes::install_github(\"bfunovits/RLDM\")"},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"content","dir":"","previous_headings":"","what":"Content","title":"Rational Linear Dynamic (Time Series) Models","text":"package provides following sets functions whose documentation can found reference page https://bfunovits.github.io/RLDM/reference website https://bfunovits.github.io/RLDM/ (created https://pkgdown.r-lib.org/): VARMA models armamod() State space models stspmod() Right matrix fraction description (RMFD) models rmfdmod() (experimental) matrix H number rows number linear parameters given model number columns number deep parameters given model column vector h appropriate dimension See help(\"model structures\") help(\"local model structures\") details. Generic functions create objects derived rational models autocovariance sequence, see autocov() Spectral density, see spectrald() Forecast error variance decomposition, see fevardec(), given IRF Frequency response (transfer function evaluated unit circle), see freqresp() Several generic functions extend R’s generic functions plot(), print(), str(), predict() helpers estimation methods: solve_de(), solve_inverse_de(), Moment estimation methods AR models, see e.g. est_ar() ARMA models, see Hannan-Rissannen-Kavalieris algorithm est_arma_hrk3() state space models, see e.g. est_stsp_cca() Likelihood estimation methods ll() ll_theta() ll_FUN() estimation deep parameters rational model ll_kf() tooling like simulation sim() model comparison KL_divergence(), pm_test(), compare_estimates()","code":""},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Rational Linear Dynamic (Time Series) Models","text":"See case study vignette(\"d_casestudy2\") detailed example use package.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/BQdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Blanchard/Quah (1989) dataset — BQdata","title":"Blanchard/Quah (1989) dataset — BQdata","text":"dataset contains (159 x 2)-dimensional matrix quarterly data real GDP growth rates (first column) unemployment rate USA. starts second quarter 1948 ends last quarter 1987. script transforming raw data (csv-file) matrix BQdata available data-raw directory. dataset used Gourieroux, Monfort, Renne (2019)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/BQdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Blanchard/Quah (1989) dataset — BQdata","text":"","code":"BQdata  BQdata_ts  BQdata_xts"},{"path":"https://bfunovits.github.io/RLDM/reference/BQdata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Blanchard/Quah (1989) dataset — BQdata","text":"tibble (BQdata), ts-object (BQdata_ts), xts-object (BQdata_xts) 159 rows 2 variables (plus timestamp, total 3): date Timestamp column type dttm tibble, index ts xts object. rGDPgrowth_demeaned real GDP growth series demeaned respect two different subperiods: Till last quarter 1973 first quarter 1974 unemp_detrended unemployment rate detrended respect linear trend (intercept). object class mts (inherits ts, matrix) 159 rows 2 columns. object class xts (inherits zoo) 159 rows 2 columns.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/BQdata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Blanchard/Quah (1989) dataset — BQdata","text":"https://academic.oup.com/restud/advance-article/doi/10.1093/restud/rdz028/5490841#supplementary-data","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Kullback–Leibler divergence — KL_divergence","title":"Kullback–Leibler divergence — KL_divergence","text":"Compute Kullback-Leibler divergence \"true\" state space model estimated state space model. function works square systems, \"true\" model stable estimate (strictly) miniphase.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kullback–Leibler divergence — KL_divergence","text":"","code":"KL_divergence(model, model_hat)"},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kullback–Leibler divergence — KL_divergence","text":"model stspmod() object, true model model_hat stspmod() object, estimated model","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kullback–Leibler divergence — KL_divergence","text":"KL divergence.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kullback–Leibler divergence — KL_divergence","text":"KL divergence computed follows. Suppose \\(y_t = k(z) u_t\\), \\(\\mathbf{E} u_t u_t' = \\Sigma\\) true model, let \\(y_t = h(z) u_t\\), \\(\\mathbf{E} u_t u_t'=\\Omega\\) denote estimate. W.l.o.g. assume models innovation form, .e. \\(k(0) = h(0) = \\). procedure computes covariance matrix, \\(\\Delta = \\mathbf{E} e_t e_t'\\) say, one-step-ahead prediction errors \\(e_t = h^{-1}(z) k(z) u_t\\) KL divergence $$ \\mathrm{KL} = (1/2)(\\mathrm{tr}(\\Omega^{-1}\\Delta) - m - \\ln\\det(\\Omega^{-1}\\Delta))) $$ Note procedure breaks transfer function \\(h^{-1}(z) k(z)\\) stable. Therefore true models stable estimated model strictly miniphase.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RLDM.html","id":null,"dir":"Reference","previous_headings":"","what":"A Collection of Tools for VARMA and State Space Processes — RLDM","title":"A Collection of Tools for VARMA and State Space Processes — RLDM","text":"package provides models stationary processes rational spectral density methods estimation.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RLDM.html","id":"author-s-","dir":"Reference","previous_headings":"","what":"Author(s)","title":"A Collection of Tools for VARMA and State Space Processes — RLDM","text":"Wolfgang Scherrer Bernd Funovits Maintainer: bernd.funovits@gmail.com","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RSdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Ramey/Shapiro dataset — RSdata","title":"Ramey/Shapiro dataset — RSdata","text":"dataset contains (248 x 7)-dimensional matrix quarterly US data first quarter 1947 till last quarter 2008. script transforming raw data (csv-file) matrix RSdata available data-raw directory. data set used identify government spending shocks particular investigate response consumption real wages respect shocks. variables orthogonalized respect intercept linear trend. See https://doi.org/10.1093/qje/qjq008 details.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RSdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ramey/Shapiro dataset — RSdata","text":"","code":"RSdata  RSdata_ts  RSdata_xts"},{"path":"https://bfunovits.github.io/RLDM/reference/RSdata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Ramey/Shapiro dataset — RSdata","text":"matrix 248 rows 7 variables (plus timestamp, total 8 variables). Versions tibble (RSdata), ts (RSdata_ts), xts (RSdata_xts) object available: Date column logarithm real per capita quantities total government spending real GDP total hours worked nondurable plus services consumption private fixed investment real wage (precisely nominal compensation private business divided deflator private business) tax rate object class mts (inherits ts, matrix) 248 rows 7 columns. object class xts (inherits zoo) 248 rows 7 columns.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RSdata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Ramey/Shapiro dataset — RSdata","text":"https://econweb.ucsd.edu/~vramey/research.html","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Structural Time Series Models — STSmodels","title":"Structural Time Series Models — STSmodels","text":"Tools Structural Time Series Models, described e.g. (Harvey 1994) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Structural Time Series Models — STSmodels","text":"","code":"tmpl_llm()  tmpl_lltm()  tmpl_cycle(fr, rho)  tmpl_season(s)  cbind_templates(...)"},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Structural Time Series Models — STSmodels","text":"fr, rho frequency damping factor cyclical components s (integer > 1) period seasonal component. ... compatible (state space model) templates. output dimensions state space models must templates.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Structural Time Series Models — STSmodels","text":"Model template, .e. list slots h \\(((m+s)(n+s) + m^2)\\)-dimensional vector, H \\(((m+s)(n+s) + m^2, k)\\)-dimensional matrix, class class = \"stspmod\", state space models implemented order order = c(m,n,s) (output, noise state dimensions), n.par number free parameters \\(=k\\) idx list slots state, noise par. indices code states, noise components parameters associated respective components. See example(s) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Structural Time Series Models — STSmodels","text":"Local Level Model (LLM): tmpl_llm() $$a_{t+1} = a_t + u_t,\\quad y_t = a_t$$ \\((u_t)\\) white noise variance \\(\\sigma_u^2\\). model one free parameter \\(\\theta = \\sigma_u\\). output process \\((y_t)\\) random walk. Local Linear Trend Model (LLTM): tmpl_lltm() $$a_{t+1} = a_t + b_t + u_t,\\quad b_{t+1} = b_t + v_t,\\quad y_t = a_t$$ \\((u_t)\\), \\((v_t)\\) two independent white noise processes variance  \\(\\sigma_u^2\\)  \\(\\sigma_v^2\\). model two free parameter \\(\\theta_1 = \\sigma_u\\)  \\(\\theta_2 = \\sigma_v\\). general output process integrated order two (\\((2)\\)). \\(sigma[v]^2=0\\) model generates random walk drift \\(sigma[u]^2=0\\) one gets integrated random walk. Cyclical Models: tmpl_cycle(fr, rho) tmpl_cycl(fr. rho) generates template scalar AR(2) models, AR polynomial two roots $$z = \\rho^{-1}\\exp((\\pm 2\\pi f)$$ \"damping factor\" \\(\\rho\\) close one model generates processes strong \"cyclical component\" frequency \\(f\\). \\(\\rho <1\\) AR(2) model satisfies stability condition, .e. forward solution converges stationary process. \\(\\rho > 1\\) trajectories forward solution diverge exponentially. template one free parameter, standard deviation driving white noise: \\(\\theta = \\sigma_u\\). Seasonal Models: tmpl_season(s) tmpl_season(s) generates template scalar seasonal models, .e. models generate trajectories \"almost\" periodic given period, \\(s\\) say. template one free parameter, standard deviation driving white noise: \\(\\theta = \\sigma_u\\). Combine Models cbind_templates(...) utility cbind_templates(...) may used construct models simple \"bulding blocks\". Suppose e.g. observed process described sum two (unobserved) components $$y_t = k_1(z) u_t + k_2(z) v_t$$ \\((u_t)\\), \\((v_t)\\) two independent white noise processes. components described templates tmpl1 tmpl2 may construct template combined model simply cbind_templates(tmpl1, tmpl2). function cbind_templates deals state space models course templates must describe outputs dimension. functions tmpl_llm(), ..., tmpl_season() generate templates scalar time series. However, utility cbind_templates(...) also handles multivariate case.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Structural Time Series Models — STSmodels","text":"Harvey AC (1994). Forecasting, Structural Time Series Models Kalman Filter. Cambridge University Press, Cambridge.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Structural Time Series Models — STSmodels","text":"","code":"# build a structural times series model (see Harve 94) with #   a \"local linear trend component\", #   a cyclical component with period 50 (frequency 1/50), #   a seasonal component with period 6 and #   an AR(1) component. tmpl = cbind_templates(tmpl_lltm(), tmpl_cycle(1/50,1), tmpl_season(6),                        tmpl_stsp_ar(1, 1, sigma_L = 'identity')) # set some \"reasonable\" values for the standard deviations # of the respective noise and for the AR(1) coefficient. model = fill_template(c(0.0, 0.1,  # parameters for trend (lltm) component                             0.1,       # parameter for cyclical component                             0.1,       # parameter for seasonal component                            -0.5        # AR(1) coefficient                            ), tmpl) print(model) #> state space model [1,5] with s = 10 states #>       s[1] s[2]     s[3] s[4] s[5] s[6] s[7] s[8] s[9] s[10] u[1] u[2] u[3] #> s[1]     1    1 0.000000    0    0    0    0    0    0   0.0    1    0    0 #> s[2]     0    1 0.000000    0    0    0    0    0    0   0.0    0    1    0 #> s[3]     0    0 1.984229   -1    0    0    0    0    0   0.0    0    0    1 #> s[4]     0    0 1.000000    0    0    0    0    0    0   0.0    0    0    0 #> s[5]     0    0 0.000000    0   -1   -1   -1   -1   -1   0.0    0    0    0 #> s[6]     0    0 0.000000    0    1    0    0    0    0   0.0    0    0    0 #> s[7]     0    0 0.000000    0    0    1    0    0    0   0.0    0    0    0 #> s[8]     0    0 0.000000    0    0    0    1    0    0   0.0    0    0    0 #> s[9]     0    0 0.000000    0    0    0    0    1    0   0.0    0    0    0 #> s[10]    0    0 0.000000    0    0    0    0    0    0  -0.5    0    0    0 #> x[1]     1    0 1.984229   -1   -1   -1   -1   -1   -1  -0.5    0    0    1 #>       u[4] u[5] #> s[1]     0    0 #> s[2]     0    0 #> s[3]     0    0 #> s[4]     0    0 #> s[5]     1    0 #> s[6]     0    0 #> s[7]     0    0 #> s[8]     0    0 #> s[9]     0    0 #> s[10]    0    1 #> x[1]     1    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] u[4] u[5] #> u[1]    0  0.0  0.0  0.0    0 #> u[2]    0  0.1  0.0  0.0    0 #> u[3]    0  0.0  0.1  0.0    0 #> u[4]    0  0.0  0.0  0.1    0 #> u[5]    0  0.0  0.0  0.0    1  # simulate the time series (with initial states) out = sim(model, n.obs = 100,           a1 = c(100, 1,     # initial states for the trend component                  3, 0,       # initial states for the cyclical component                  5, 10, 10, -10, -10,   # ... for the seasonal component                  0           # initial state for the AR(1) component           ))  # extract the contribution of the respective components X = cbind(out$y,  out$a[1:100,tmpl$idx$state == 1, drop = FALSE] %*% model$sys$C[1, tmpl$idx$state == 1] +   out$u[,tmpl$idx$noise == 1, drop = FALSE] %*% model$sys$D[1, tmpl$idx$noise == 1],  out$a[1:100,tmpl$idx$state == 2, drop = FALSE] %*% model$sys$C[1, tmpl$idx$state == 2] +   out$u[,tmpl$idx$noise == 2, drop = FALSE] %*% model$sys$D[1, tmpl$idx$noise == 2],  out$a[1:100,tmpl$idx$state == 3, drop = FALSE] %*% model$sys$C[1, tmpl$idx$state == 3] +   out$u[,tmpl$idx$noise == 3, drop = FALSE] %*% model$sys$D[1, tmpl$idx$noise == 3],  out$a[1:100,tmpl$idx$state == 4, drop = FALSE] %*% model$sys$C[1, tmpl$idx$state == 4] +   out$u[,tmpl$idx$noise == 4, drop = FALSE] %*% model$sys$D[1, tmpl$idx$noise == 4])  matplot(X, ylab = 'y', xlab = 't',         type = 'l', lty = 1, col = 1:5) grid() legend('topleft', legend = c('y','trend','cycle','season','AR(1) noise'),        lwd = 2, col = 1:5, bty = 'n')   if (FALSE) { # the following examples throw errors # 1 is not a template cbind_templates(1, tmpl_season(4)) # the respective output dimensions are not equal cbind_templates(tmpl_season(4), tmpl_stsp_ar(2, 2)) # the third argument is a \"VARMA template\" cbind_templates(tmpl_lltm(), tmpl_cycle(1/20,1), tmpl_arma_pq(1, 1, 1, 1)) }"},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructor for LMFD (ARMA) Models — armamod","title":"Constructor for LMFD (ARMA) Models — armamod","text":"left-matrix fraction description (LMFD) plus parameterisation noise covariance.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor for LMFD (ARMA) Models — armamod","text":"","code":"armamod(sys, sigma_L = NULL, names = NULL, label = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor for LMFD (ARMA) Models — armamod","text":"sys rationalmatrices::lmfd() rationalmatrices::rmfd() object sigma_L Left-factor noise covariance, .e. covariance \\(\\sigma\\) obtained sigma_L * t(sigma_L). sigma_L vector dimension \\(n\\), \\(n\\) input dimension, diagonal elements parametrized. vector dimension \\(n^2\\), elements sigma_L filled column column. names optional vector character strings label optional character string","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor for LMFD (ARMA) Models — armamod","text":"Object class armamod.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Constructor for LMFD (ARMA) Models — armamod","text":"Hannan, Deistler (2012, page 7), RMFDs also called dynamic adjustment forms. Internally, MFDs lists slots sys, sigma_L, names, label.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructor for LMFD (ARMA) Models — armamod","text":"","code":"x = armamod(sys = lmfd(c(1, 0.5), 1), sigma_L = diag(1)) x #> ARMA model [1,1] with orders p = 1 and q = 0 #> AR polynomial a(z): #>      z^0 [,1] z^1 [,1] #> [1,]        1      0.5 #> MA polynomial b(z): #>      z^0 [,1] #> [1,]        1 #> Left square root of noise covariance Sigma: #>      u[1] #> u[1]    1"},{"path":"https://bfunovits.github.io/RLDM/reference/as.stspmod.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce to State Space Model — as.stspmod","title":"Coerce to State Space Model — as.stspmod","text":"function .stsp.pseries() calls pseries2stsp() default parameters. course pseries() object must contain sufficiently many lags. YET implemented","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/as.stspmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce to State Space Model — as.stspmod","text":"","code":"as.stspmod(obj, ...)  # S3 method for armamod as.stspmod(obj, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/as.stspmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce to State Space Model — as.stspmod","text":"obj object ... optional additional parameters method character string","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/as.stspmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce to State Space Model — as.stspmod","text":"object class stspmod().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":null,"dir":"Reference","previous_headings":"","what":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"Compute respectively estimate autocovariance, autocorrelation partial autocorrelation function stationary process.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"","code":"autocov(obj, type, ...)  # S3 method for default autocov(   obj,   type = c(\"covariance\", \"correlation\", \"partial\"),   lag.max = NULL,   na.action = stats::na.fail,   demean = TRUE,   ... )  # S3 method for autocov autocov(obj, type = c(\"covariance\", \"correlation\", \"partial\"), ...)  # S3 method for armamod autocov(   obj,   type = c(\"covariance\", \"correlation\", \"partial\"),   lag.max = 12,   ... )  # S3 method for stspmod autocov(   obj,   type = c(\"covariance\", \"correlation\", \"partial\"),   lag.max = 12,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"obj either armamod(), stspmod(), autocov() object \"data\" object. type character string giving type acf computed. Allowed values \"covariance\" (default), \"correlation\", \"partial\". partially matched. Note default value \"covariance\" whereas stats::acf() uses \"correlation\" default. ... used. lag.max (integer) maximum lag. na.action function called handle missing values. stats::na.pass() can used. demean logical. covariances sample means?","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"autocov object, .e. list slots acf rationalmatrices::pseries() object, stores covariances (correlations). type character string indicates type ACF. gamma (m,m,lag.max+1) dimensional array stores autocovariance function. names (m)-dimensional character vector NULL. optional slot stores names components time series/process. label character string NULL. n.obs integer NULL. slot stores sample size.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"class input parameter \"obj\" determines S3 method called hence actually computed. Population ACF: \"obj\" armamod() stspmod() object autocov(obj, ...) computes ACF corresponding stationary process. Note however, function returns nonsense, model satisfy stability condition. Change type ACF: Calling autocov(obj, type), \"obj\" autocov object returns ACF desired type. E.g. \"obj\" holds partial autocorrelation function autocov(obj, type = 'covariance') may used retrieve corresponding autocovariance function. possible since autocov object stores \"original\" autocovariances slot named gamma. Sample ACF: default S3 method estimates ACF given data. assumes \"obj\" univariate multivariate numeric time series object, (numeric) data frame (numeric) vector, respectively matrix simply calls function stats::acf() stats package compute sample autocovariance function. needed, corresponding sample autocorrelation, respectively sample partial autocorrelation function computed (returned). syntax quite analogous stats::acf(), please consider documentation stats::acf() details. Note stats stores autocovariance/autocorrelation functions (lag.max+1,m,m) dimensional arrays, whereas RLDM uses (m,m,lag.max+1) dimensional arrays. definition partial autocorrelations used stats::acf() differs definition used , see e.g. (Reinsel 1997) . Furthermore stats::acf() skips lag zero partial autocorrelation coefficient thus pacf computed  stats::acf() (lag.max,n,n) dimensional. default choice number lags \\(10*log10(N/m)\\) \\(N\\) number observations \\(m\\) number series. number automatically limited one less number observations series.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"Reinsel GC (1997). Elements Multivariate Time Series Analysis. Springer.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"","code":"model = stspmod(sys = stsp(A = c(0,0.2,1,-0.5), B = c(1,1,1,-1),                            C = c(1,0,0,1)), sigma_L = diag(c(4,1)),                 names = c('y1','y2'), label = 'test model') g = autocov(model, lag.max=10)       # ACF r = autocov(model, lag.max=10, type = 'correlation')  # autocorrelation function r = autocov(g, type = 'correlation')                  # this gives the same result! c = autocov(r, type = 'partial')     # partial autocorrelation function  if (FALSE) { # consider an equivalent VARMA model model2 = impresp2varma(irf(model, lag.max = 20))$model g2 = autocov(model2, lag.max = 10) all.equal(g,g2) # of course both return the same ACF  autocov(matrix(rnorm(100*2), nrow = 100)) autocov(stspmod(test_stsp(dim = c(2,2), s = 2), sigma_L = diag(2)))  # generate a random sample with 100 observations and 3 outputs/series. x = matrix(rnorm(100*3), nrow = 100, ncol = 3)  # the covariance estimates are of course identical stats_acfobj = stats::acf(x, type = 'covariance', demean = TRUE, plot = FALSE) rldm_acfobj  = acf_estimate(x, type = 'covariance', demean = TRUE) testthat::expect_equivalent(rldm_acfobj$gamma, aperm(stats_acfobj$acf,c(2,3,1)))  # also the correlation estimates are identical stats_acfobj = stats::acf(x, type = 'correlation', demean = TRUE, plot = FALSE) rldm_acfobj  = acf_estimate(x, type = 'correlation', demean = TRUE) testthat::expect_equivalent(rldm_acfobj$gamma, aperm(stats_acfobj$acf,c(2,3,1)))  # However, the partial correlations dont match! stats_acfobj = stats::acf(x, type = 'partial', demean = TRUE, plot = FALSE) rldm_acfobj  = acf_estimate(x, type = 'partial', demean = TRUE) testthat::expect_equivalent(rldm_acfobj$gamma[,,-1,drop=FALSE], aperm(stats_acfobj$acf,c(2,3,1))) }"},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the (concentrated) conditional log likelihood for ARMA models\ndescribed by a model template. — cll_theta_ARMA_cpp","title":"Compute the (concentrated) conditional log likelihood for ARMA models\ndescribed by a model template. — cll_theta_ARMA_cpp","text":"internal helper function computes (concentrated) conditional log Likelihood ARMA systems form $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + \\cdots + b_q u_{t-q}$$ conditional likelihood computed zero initial values \\(u_s=y_s=0\\) \\(s\\leq 0\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the (concentrated) conditional log likelihood for ARMA models\ndescribed by a model template. — cll_theta_ARMA_cpp","text":"","code":"cll_theta_ARMA_cpp(   th,   y,   skip,   concentrated,   ib0,   H_b,   h_b,   B1,   H_B,   h_B,   a0,   A,   H_A,   h_A,   L,   H_L,   h_L,   u,   dU )"},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the (concentrated) conditional log likelihood for ARMA models\ndescribed by a model template. — cll_theta_ARMA_cpp","text":"th \\((K)\\) dimensional vector \"deep\" parameters. y \\((m,N)\\) matrix observed outputs: \\((y_1,y_2,\\ldots,y_N)\\). skip (integer), omit first \"skip\" residuals, computing likelihood. concentrated (bool), TRUE concentrated, conditional log Likelihood computed ib0 \\((m, m)\\) matrix, overwritten matrix \\(b_0^{-1}a_0\\). H_b \\((m^2, K)\\) matrix. h_b \\(((m^2)\\)-dimensional vector. Note vec(b[0]) = H_b*th + h_b. B1 \\((m, mq)\\) matrix, overwritten \\(-b_0^{-1}(b_q,...,b_1)\\). H_B \\(((m^2)*q, K)\\) matrix. h_B \\(((m^2)*q)\\)-dimensional vector. Note vec(-(b[q],...,b[1])) = H_B*th + h_B. a0 \\((m, m)\\) matrix, overwritten \\(a_0\\). \\((m, m(q+1))\\) matrix, overwritten \\(b_0^{-1}(a_0,...,a_p\\). H_A \\(((m^2)*(p+1), K)\\) matrix. h_A \\(((m^2)*(p+1))\\)-dimensional vector. Note vec(([0],[1],...,[p])) = H_A*th + h_A. L \\((m,m)\\) matrix. (concentrated==FALSE) L overwritten left square \\(L\\) noise covariance matrix \\(\\Sigma=LL'\\) corresponding deep parameters th. However, (concentrated==TRUE) L overwritten sample covariance matrix computed residuals! H_L \\((m^2, K)\\) matrix. h_L \\((m^2)\\)-dimensional vector. Note vec(L) = H_L*th + h_L. u \\((m,N)\\) matrix. matrix overwritten (computed) residuals: \\((u_1,u_2,\\ldots,u_N)\\). dU \\((mN,(m^2)(p+q+2))\\) matrix \\((0,0)\\) matrix. non empty matrix overwritten directional derivatives residuals. However, matrix empty derivatives computed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the (concentrated) conditional log likelihood for ARMA models\ndescribed by a model template. — cll_theta_ARMA_cpp","text":"(double) log Likelihood","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the (concentrated) conditional log likelihood for ARMA models\ndescribed by a model template. — cll_theta_ARMA_cpp","text":"function mainly used function factory ll_FUN. detailed documentation (concentrated) conditional log Likelihood, see ll. procedure first constructs ARMA parameter matrices given vector th \"deep\" parameters. AR parameters vec(([0],[1],...,[p])) = h_A + H_A * th. MA parameters vec(b[0]) = h_b + H_b * th vec(-(b[q],...,b[1])) = h_B + H_B * th Left square root noise covariance matrix \\(\\Sigma = LL'\\) vec(L) = h_L + H_L * th. residuals (directional derivatives) computed residuals_ARMA_cpp.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the (concentrated) conditional log likelihood for ARMA models\ndescribed by a model template. — cll_theta_ARMA_cpp","text":"Use procedure care! procedure check input arguments. procedure overwrites input arguments data matrices organized columnwise (avoid memory shuffling)! Note also non standard representation coefficient matrices.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_STSP_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the (concentrated) conditional log likelihood for a statespace system\ndescribed by a model template. — cll_theta_STSP_cpp","title":"Compute the (concentrated) conditional log likelihood for a statespace system\ndescribed by a model template. — cll_theta_STSP_cpp","text":"internal helper function, used function factory ll_FUN. detailed documentation conditional log Likelihood, see ll. conditional likelihood computed initial state \\(a_1\\) given first column [,1] matrix .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_STSP_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the (concentrated) conditional log likelihood for a statespace system\ndescribed by a model template. — cll_theta_STSP_cpp","text":"th \\((K)\\) dimensional vector \"deep\" parameters. y \\((m,N)\\) matrix observed outputs: \\((y_1,y_2,\\ldots,y_N)\\). skip (integer), skip first residuals, computing sample covariance residuals. concentrated (bool), TRUE concentrated, conditional log Likelihood computed pi \\((m+s,m+s)\\) matrix, overwritten system matrix \\([,B | C,D]\\). H_pi \\((m+s)^2, K)\\) matrix. h_pi \\(((m+s)^2)\\)-dimensional vector. Note vec(pi) = H_pi*th + h_pi. L \\((m,m)\\) matrix. (concentrated==FALSE) L overwritten left square noise covariance matrix L corresponding deep parameters th. However, (concentrated==TRUE) L overwritten sample covariance matrix computed residuals! H_L \\((m^2, K)\\) matrix. h_L \\((m^2)\\)-dimensional vector. Note vec(L) = H_L*th + h_L. \\((s,N+1)\\) matrix. matrix overwritten (computed) states: \\((a_1,a_2,\\ldots,a_N,a_{N+1})\\). input [,1] must hold initial state \\(a_1\\). u \\((m,N)\\) matrix. matrix overwritten (computed) residuals: \\((u_1,u_2,\\ldots,u_N)\\). dU \\((mN,K)\\) matrix \\((0,0)\\) matrix. matrix overwritten directional derivatives residuals. However, matrix empty derivatives computed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_STSP_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the (concentrated) conditional log likelihood for a statespace system\ndescribed by a model template. — cll_theta_STSP_cpp","text":"(double) log Likelihood","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Estimated Models — compare_estimates","title":"Compare Estimated Models — compare_estimates","text":"utility function computes number statistics may used compare/evaluate set estimated models. particular function returns log Likelihood (ll), Akaike Information Criterion (AIC), Bayes Information Criterion (BIC), Final Prediction Error (FPE) p-values Portmanteau test serial correlation residuals.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Estimated Models — compare_estimates","text":"","code":"compare_estimates(estimates, y, n.lags = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Estimated Models — compare_estimates","text":"estimates (named) list estimates. slot contain list slots $model (estimated model) $n.par corresponding number (free) parameters model (class). y (N--m)-dimensional matrix observed data (object may coerced matrix .matrix(y)). n.lags number lags Portmantaeu test serial correlation residuals, see also pm_test().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Estimated Models — compare_estimates","text":"Matrix computed statistics estimated models. matrix attributes m, n.obs n.lags.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare Estimated Models — compare_estimates","text":"concentrated, conditional (scaled) log Likelihood $$ll = -(1/2)(m \\ln(2\\pi) + m + \\ln\\det S + 2 \\ln\\det (k_0)$$ computed ll(model, y, skip = 0, concentrated = TRUE), see ll(). \\(S\\) denotes sample covariance residuals model. information criteria $$AIC = -2 ll + (2/N) \\kappa$$ $$BIC = -2 ll + (\\ln(N)/N) \\kappa$$ \\(\\kappa\\) denotes respective number free parameters. Final Prediction Error $$FPE = \\det(S)\\frac{N+\\kappa}{N-\\kappa}$$ portmanteau test, see pm_test(). number lags specified procedure choses default value based sample size. (values attached output attribute). Note procedure (re)evaulates measures, even estimates contain information (e.g. residuals log likelihood may stored corresponding list). reason common data set common evaluation procedure estimates. Typically data y \"estimation data set\", .e. data used estimate models. However, one may also pass new data set procedure.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/dft_3D.html","id":null,"dir":"Reference","previous_headings":"","what":"Discrete Time Fourier Transform — dft_3D","title":"Discrete Time Fourier Transform — dft_3D","text":"Compute Discrete Time Fourier Transform data stored 3-dimensional array.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/dft_3D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discrete Time Fourier Transform — dft_3D","text":"","code":"dft_3D(a, n.f = dim(a)[3])"},{"path":"https://bfunovits.github.io/RLDM/reference/dft_3D.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Discrete Time Fourier Transform — dft_3D","text":"\\((m,n,k)\\) dimensional (numeric) array n.f (integer) number frequencies","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/dft_3D.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Discrete Time Fourier Transform — dft_3D","text":"rationalmatrices::zvalues() object.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Likelihood Estimation — est_ML","title":"Maximum Likelihood Estimation — est_ML","text":"naive implementation Maximum Likelihood Estimation. Rather use ll() ll_FUN().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Likelihood Estimation — est_ML","text":"","code":"est_ML(   y,   tmpl,   th,   which = c(\"concentrated\", \"conditional\", \"kf\"),   method = c(\"BFGS\", \"Nelder-Mead\", \"CG\", \"L-BFGS-B\", \"SANN\", \"Brent\"),   hessian = FALSE,   control = list() )"},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Likelihood Estimation — est_ML","text":"y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. tmpl model template describes model class, see model structures(). Note case (non-empty, square) state space ARMA models implemented. th Initial parameter estimate. (character string) determines \"likelihood\" used, see also ll(). option \"kf\"  supported state space models. method, hessian, control passed optimization routine stats::optim().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Likelihood Estimation — est_ML","text":"list components model estimated model. th corresponding vector deep parameters. ll log likelihood estimated model. type likelihood used. counts, convergence, message, hessian returned  stats::optim().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Maximum Likelihood Estimation — est_ML","text":"optimization computed general-purpose routine stats::optim(). initial estimate needed. procedure respect constraints like stability minimum phase. case conditional, concentrated likelihood somewhat special. case model template must particular structure: (1) noise covariance parametrized via left cholesky factor. (2) last \\(m(m+1)/2\\) components parameter vector \\(\\theta\\) parametrize left cholesky factor components describe system. (implies overlap/dependency betweeen \"system parameters\" \"noise parameters\".)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum Likelihood Estimation — est_ML","text":"","code":"# Generate a random model in echelon form model (m = 3) tmpl = tmpl_stsp_echelon(nu = c(2,1,1)) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> state space model [3,3] with s = 4 states #>             s[1]        s[2]        s[3]        s[4]         u[1]        u[2] #> s[1]  0.00000000  0.00000000  0.00000000  1.00000000  0.001479776 -0.58277908 #> s[2] -0.12887321 -0.10579898  0.42453014 -0.05452528  0.024723479  0.34022718 #> s[3] -0.03992119 -0.09695103 -0.31816955  0.04846164 -0.088227227  0.47276201 #> s[4] -0.15776897  0.02080758 -0.08676117  0.10238998 -0.263192941 -0.01245053 #> x[1]  1.00000000  0.00000000  0.00000000  0.00000000  1.000000000  0.00000000 #> x[2]  0.00000000  1.00000000  0.00000000  0.00000000  0.000000000  1.00000000 #> x[3]  0.00000000  0.00000000  1.00000000  0.00000000  0.000000000  0.00000000 #>             u[3] #> s[1] -0.15236589 #> s[2] -0.15456615 #> s[3] -0.12335397 #> s[4]  0.03233351 #> x[1]  0.00000000 #> x[2]  0.00000000 #> x[3]  1.00000000 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] u[3] #> u[1]  1.0000000 0.0000000    0 #> u[2] -0.4435051 1.0000000    0 #> u[3] -0.5125414 0.2429365    1 # extract the corresponding free/deep parameters th = extract_theta(model, tmpl)  # generate a sample with 500 observations y = sim(model, n.obs = 500, n.burn_in = 100)$y  # We are cheating here and use the true model parameters # as starting values for the optimization routine:  # estimate the model with the \"exakt log likelihood\" out = est_ML(y, tmpl, th, which = 'kf') KL_divergence(model, out$model) #> [1] 0.002573326  # estimate the model with \"conditional log likelihood\" out = est_ML(y, tmpl, th, which = 'conditional') KL_divergence(model, out$model) #> [1] 0.002511492  # estimate the model with \"concentrated, conditional log likelihood\" out = est_ML(y, tmpl, th, which = 'concentrated') KL_divergence(model, out$model) #> [1] 0.002513427"},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Autoregressive Models — est_ar","title":"Estimate Autoregressive Models — est_ar","text":"function est_ar estimates (V)AR models $$(y_t - \\mu) = a_1 (y_{t-1} - \\mu) + \\cdots + a_p (y_{t-p} - \\mu) + u_t$$ given sample given (sample) autocovariance function. model order \\(p\\) chosen information criterion, like AIC BIC. \"helper\" functions est_ar_ols, est_ar_yw est_ar_dlw implement three available estimation methods: estimation ordinary least squares, Yule-Walker estimates Durbin-Levinson-Whittle method.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Autoregressive Models — est_ar","text":"","code":"est_ar(   obj,   p.max = NULL,   penalty = NULL,   ic = c(\"AIC\", \"BIC\", \"max\"),   method = c(\"yule-walker\", \"ols\", \"durbin-levinson-whittle\"),   mean_estimate = c(\"sample.mean\", \"intercept\", \"zero\"),   n.obs = NULL )  est_ar_yw(gamma, p.max = (dim(gamma)[3] - 1), penalty = -1)  est_ar_dlw(gamma, p.max = (dim(gamma)[3] - 1), penalty = -1)  est_ar_ols(   y,   p.max = NULL,   penalty = -1,   mean_estimate = c(\"sample.mean\", \"intercept\", \"zero\"),   p.min = 0L )"},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Autoregressive Models — est_ar","text":"obj either \"time series\" object (.e .matrix(obj) returns \\((N,m)\\)-dimensional numeric matrix) autocov() object represents (estimated) autocovariance function. type autocov object irrelevant since est_ar always uses slot obj$gamma contains autocovariance function. p.max (integer NULL) Maximum order candidate AR models. default choice see . penalty scalar (NULL) determines \"penalty\" per parameter model. Note parameter (NULL) overrides paramater ic. ic (character string) information criterion shall used find optimal order. Note ic=\"max\" means AR(p) model p=p.max estimated. Default ic=\"AIC\". method Character string giving method used fit model. Note 'yule-walker' 'durbin-levinson-whittle' (numerical errors) equivalent choice 'ols' available \"time-series\" object obj. mean_estimate Character string giving method used estimate mean \\(\\mu\\). Default mean_estimate = \"sample.mean\". See details . n.obs Optional integer gives sample size \\(N\\). parameter used, obj autocov object. n.obs=NULL slot obj$n.obs used. Note obj$n.obs=NULL obj$n.obs=Inf refers case population autocovariance function, .e. \\(N=\\infty\\).  \"time series\" object sample size course set number observations, .e. n.obs = nrow(.matrix(obj)).  sample size \\(N\\) controls computation default maximum order p.max computation information criterion. gamma \\((m,m,lag.max+1)\\)-dimensional array, contains (sample) autocovariance function. y \\((N,m)\\)-dimensional matrix, contains sample. p.min (non negative integer) Minimum order candidate AR models. used est_ar_ols.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Autoregressive Models — est_ar","text":"function est_ar returns list components model armamod() object represents estimated AR model. p optimal model order. stats (p.max+1,4) dimensional matrix stores \\(\\ln\\det(\\Sigma_p)\\) values, number parameters IC values. See details . y.mean estimate mean \\(\\mu\\). ll log likelihood estimated model. \"helper\" functions est_ar_yw, est_ar_dlw est_ar_ols return list components (m,m,p)-dimensional array estimated AR coefficients \\(a_i\\). sigma (m,m)-dimensional matrix estimated noise covariance \\(\\Sigma\\). p estimate AR order. stats (p.max+1,4) dimensional matrix stores \\(\\ln\\det(\\Sigma_p)\\) values, number parameters IC values. See details . y.mean (est_ar_ols ) estimate mean \\(\\mu\\). residuals (est_ar_ols ) (n.obs,m) dimensional matrix OLS residuals. partial (est_ar_dlw ) (m,m,p.max+1) dimensional array (estimated) partial autocorrelation coefficients.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"ols-method","dir":"Reference","previous_headings":"","what":"OLS method","title":"Estimate Autoregressive Models — est_ar","text":"helper function est_ar_ols implements three schemes estimate mean \\(\\mu\\) AR parameters. choice mean_estimate = \"zero\" assumes \\(\\mu=0\\) thus AR parameters determined regression: $$y_t = a_1 y_{t-1} + \\cdots + a_p y_{t-p} + u_t \\mbox{ } t=p+1,\\ldots,N$$ case mean_estimate = \"sample.mean\" mean \\(\\mu\\) estimated sample mean AR parameters determined LS estimate regression $$(y_t - \\mu) = a_1 (y_{t-1} - \\mu) + \\cdots + a_p (y_{t-p} - \\mu) + u_t \\mbox{ } t=p+1,\\ldots,N$$ last case mean_estimate = \"intercept\", regression intercept $$y_t = d + a_1 y_{t-1} + \\cdots + a_p y_{t-p} + u_t \\mbox{ } t=p+1,\\ldots,N$$ considered. estimate \\(\\mu\\) obtained $$\\mu = (I_m - a_1 - \\cdots - a_p)^{-1} d$$ estimate mean \\(\\mu\\) fails estimated AR model unit root, .e. \\((I_m - a_1 - \\cdots - a_p)\\) singular. sample covariance corresponding residuals (scaled \\(1/(N-p)\\)) serves estimate noise covariance \\(\\Sigma\\). actual computations routine stats::lsfit() stats package used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"yule-walker-estimates","dir":"Reference","previous_headings":"","what":"Yule-Walker estimates","title":"Estimate Autoregressive Models — est_ar","text":" est_ar_yw est_ar_dlw use Yule-Walker equations estimate AR coefficients \\((a_i)\\) noise covariance matrix \\(\\Sigma\\). However, use different numerical scheme solve equations. function est_ar_dlw uses Durbin-Levinson-Whittle recursions addition returns (estimates ) partial autocorrelation coefficients. obj \"time series\" object, first ACF estimated call autocov(). option mean_estimate = \"zero\" implies mean assumed zero (\\(\\mu = 0\\)) therefore autocov called option demean = FALSE. mean_estimate = \"sample.mean\" mean_estimate = \"intercept\" mean \\(\\mu\\) estimated sample mean ACF computed  demean = TRUE.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"estimation-of-the-ar-order","dir":"Reference","previous_headings":"","what":"Estimation of the AR order","title":"Estimate Autoregressive Models — est_ar","text":"order \\(p\\) AR model chosen minimizing information criterion form $$IC(p) = \\ln\\det\\Sigma_p + c(p)r(N) \\mbox{ } p = 0,\\ldots,p_{\\max}$$ \\(\\Sigma_p\\) estimate noise (innovation) covariance, \\(c(p)\\) counts number parameters model, \\(r(N)\\) \"penalty\" per parameter model. Note \\(\\log\\det\\Sigma\\) constant scaling factor \\(-(N-p)/2\\) equal (scaled, approximate) Gaussian log likelihood model $$ll = -(1/2)(m \\ln(2\\pi) + m + \\ln\\det \\Sigma_p)$$ See also ll(). Note value \\(ll\\), returned routine, (approximate) log Likelihood scaled factor \\(1/(N-p)\\). AR(p) model intercept, number parameters \\(c(p) = p m^2 + m\\) AR model without intercept \\(c(p) = p m^2\\). Akaike information criterion (AIC) corresponds \\(r(N)=2/N\\) Bayes information criterion (BIC) uses penatlty \\(r(N)=\\log(N)/N\\). helper routines, user set penalty term \\(r(N)\\) explicitly via input parameter \"penalty\". default choice penalty = -1 means maximum possible order p=p.max chosen. function est_ar offers parameter \"ic\" tells routine set penalty accordingly. Note choice ic=\"max\" sets \\(r(N) = -1\\) thus model maximum possible order fitted. default maximum order p.max chosen follows. helper functions est_ar_yw est_ar_dlw simply chose maximum accordng maximum lag given autocovariances, p.max = dim(gamma)[3] - 1. routine est_ar_ols uses minimum \\(12\\), \\((N-1)/(m+1)\\) \\(10*log10(N)\\) default. function est_ar uses value. However, \"obj\" autocov object p.max addition bounded number lags contained object.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Estimate Autoregressive Models — est_ar","text":"Yule-Walker estimates offer easy way reconstruct \"true\" model population autocovariance function given. noise covariance (thus likelihood values) improve model order larger true model order \"estimated\". However due numerical errors may true. simple trick one may call est_ar (est_ar_yw est_ar_dlw) small positive penalty. See example . functions essentially equivalent stats routines. (re) implemented convenience, input output parameters (models) fit RLDM conventions. AIC values RLDM routines equivalent AIC values computed stats routines constant scaling \\(N\\). seems Yule-Walker estimate stats::[ar.yw][stats::ar.yw] uses scaling factor \\((N - m(p+1))/N\\) noise covariance \\(\\Sigma\\). Finally note est_ar_ols, est_ar_yw est_ar_dlw mainly intended \"internal helper\" functions. Therefore, functions check validity input parameters.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Autoregressive Models — est_ar","text":"","code":"# set seed, to get reproducable results set.seed(5436)  ############################################################### # generate a (bivariate) random, stable AR(3) model  m = 2 p = 3 n.obs = 100 p.max = 10 tmpl = tmpl_arma_pq(m = m, n = m, p = p, q = 0) model = r_model(tmpl, bpoles = 1, sd = 0.25) # make sure that the diagonal entries of sigma_L are non negative model$sigma_L = model$sigma_L %*% diag(sign(diag(model$sigma_L)))  ############################################################### # reconstruct the true AR model from the population ACF  true_acf = autocov(model, lag.max = 12, type = 'covariance') ARest = est_ar(true_acf, p.max = p.max, method = 'yule-walker', penalty = 1e-6) all.equal(model, ARest$model) #> [1] TRUE  ############################################################### # simulate a sample  y = sim(model, n.obs = n.obs, start = list(s1 = NA))$y  ############################################################### # estimate the AR(p) model with the true order p  # OLS ARest = est_ar(y, ic = 'max', p.max = p, method = 'ols', mean_estimate = \"zero\") # check the log Likelihood p.opt = ARest$p all.equal(ll(ARest$model, y, 'conditional', skip = p.opt), ARest$ll) #> [1] TRUE  # Yule-Walker and Durbin-Levinson-Whittle are equivalent (up to numerical errors) ARest = est_ar(y, ic = 'max', p.max = p, method = 'yule-walker', mean_estimate = \"zero\") junk = est_ar(y, ic = 'max', p.max = p, method = 'durbin-levinson-whittle', mean_estimate = \"zero\") all.equal(ARest$model, junk$model) #> [1] TRUE  # alternatively we may first estimate the sample autocovariance function # note that the 'type' of the ACF is irrelevant sample_acf = autocov(y, type = 'correlation', demean = FALSE) junk = est_ar(sample_acf, ic = 'max', p.max = p, method = 'yule-walker') all.equal(ARest$model, junk$model) #> [1] TRUE  ############################################################### # estimate the order of the AR model with 'AIC', estimate a model with intercept ARest = est_ar(y, ic = 'AIC', p.max = p.max, method = 'ols', mean_estimate = \"intercept\") print(ARest$model) #> ARMA model [2,2] with orders p = 3 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  z^1 [,1]       [,2]  z^2 [,1]       [,2]  z^3 [,1] #> [1,]        1     0 0.1758752 -0.2469383 0.4064368 -0.2595963 0.7758289 #> [2,]        0     1 0.3113271 -0.3092643 0.3315128 -0.1661434 0.3077410 #>            [,2] #> [1,] -0.2624946 #> [2,] -0.2492206 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>          u[1]      u[2] #> u[1] 0.144723 0.0000000 #> u[2] 0.188681 0.1501011  # compare with the stats::ar function ARest2 = stats::ar(y, aic = TRUE, order.max = p.max, method = 'ols', intercept = TRUE) # the estimated coefficients are equal all.equal(unclass(ARest$model$sys$a)[,,-1], -aperm(ARest2$ar, c(2,3,1)), check.attributes = FALSE) #> [1] TRUE # also the AIC values are up to scaling equivalent all.equal( ARest$stats[,'ic'] - min(ARest$stats[,'ic']), ARest2$aic/n.obs, check.attributes = FALSE) #> [1] TRUE  # reset seed set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":null,"dir":"Reference","previous_headings":"","what":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"Estimate (V)ARMA models Hannan, Rissanen Kavalieris procedure, see e.g. (Hannan Rissanen 1982)  (Hannan et al. 1986) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"","code":"est_arma_hrk(   y,   e = NULL,   tmpl,   maxit = 1,   tol = 0.001,   trace = TRUE,   p.max = NULL,   ic = c(\"AIC\", \"BIC\", \"max\"),   mean_estimate = c(\"sample.mean\", \"intercept\", \"zero\") )"},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. e (initial) estimate disturbances \\(u_t\\). non NULL e \\((N,m)\\) dimensional matrix, \"time series\" object (.e object may coerced \\((N,m)\\) dimensional matrix .matrix(e)).  NULL procedure computes estimate disturbances fitting \"long\" AR model data, see est_ar_ols().  matrix e may contain missing values (NA, NaN Inf). Note e.g. est_ar_ols returns residuals first \\(p\\) (\\(p\\) refers order fitted AR model) values missing. tmpl model template, see model structures(). Note case implemented, \\(a_0=b_0\\) holds, diagonal entries \\(a_0=b_0\\) equal one fixed elements equal zero. Furthermore square root sigma_L noise covariance matrix asssumed lower triangular matrix without restrictions.  given template coerced template kind. given template comply restrictions, warning message issued. maxit (integer) maximum number iterations tol (numeric) tolerance level trace (boolean) trace=TRUE, tracing information iterations printed. p.max (integer NULL) Maximum order candidate AR models. default choice see . ic (character string) information criterion shall used find optimal AR order. Note ic=\"max\" means AR(p) model p=p.max fitted. Default ic=\"AIC\". mean_estimate Character string giving method used estimate mean \\(\\mu\\). Default mean_estimate = \"sample.mean\". See details .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"List components model estimated (V)ARMA model (.e. armamod() object). th vector (free) parameters estimated (V)ARMA model. tmpl (coerced) model template. y.mean estimate mean \\(\\mu\\). residuals residuals model, computed solve_inverse_de(). sigma sample variance \\(S\\) residuals, .e. estimate noise covariance matrix \\(\\Sigma\\). n.valid number \"valid\" observations, .e. observations needed lagged values \\(y_{t-}\\) \\(e_{t-}\\) availiable. ARMA(p,q) model implies number valid observations less equal n.obs -max(p,q). ll Gaussian log likelihood: $$(-1/2)(m \\ln(2\\pi) + m + \\ln\\det(S))$$ \\(S\\) denotes sample variance residuals. iter number iterations. converged (boolean) indicates whether algorithm converged.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"main idea HRK procedure follows. given estimates, \\(e_t\\) say, disturbances, ARMA model estimated equation $$y_t = -^*_0(y_t+e_t) - a_1 y_{t-1} - \\cdots - a_p y_{t-p} +                 b_1 e_{t-1} + \\cdots + b_q e_{t-q} + v_{t-1}$$ \\(^*_0\\) obtained \\(a_0 = b_0\\) setting diagonal elements equal zero. entries parameter matrices \\(a_i\\) \\(b_i\\) either treated fixed (equal zero) \"free\". Now regression estimated \"componentwise\", .e. component \\(y_t\\) corresponding \"free\" parameters estimated OLS. Given parameter estimates one computes new estimates disturbances, recursively solving ARMA system, see solve_inverse_de(). sample variance residuals used estimate noise covariance matrix \\(\\Sigma\\). procedure may iterated: use \"new\" estimates disturbances (re) estimate ARMA parameters (re) estimate disturbances, ... parameters maxit tol control iterative scheme. iterations stopped maxit iterations \"small\" change estimates. precise, th, th0 denote vector parameter estimates actual round previous round, procedure stops max(abs(th-th0)) <= tol. Note general guarantee iterative scheme converges estimates improved iterating. user may supply \"\" (initial) estimates e disturbances. parameter e missing (NULL) procedure est_arma_hrk computes estimates disturbances fitting \"long\" AR model data. end procedure simply calls est_ar_ols() respective paramaters p.max (controls maximum possible AR order), ic (controls information criterion used select order AR model) mean_estimate (tells est_ar_ols estimate mean \\(\\mu\\)). default maximum order p.max $$\\max(12, 10\\log_{10}(N), (N-1)/(m+1))$$ procedure supports three options estimation mean \\(\\mu = \\mathbf{E} y_t\\). mean_estimate=\"zero\" procedure sets (estimate ) mean equal zero. mean_estimate=\"sample.mean\" procedure simply uses sample mean y estimate. Third option mean_estimate=\"intercept\" uses intercept regression(s) computes estimate mean correspondingly. Note fails estimated AR polynomial unit root, .e. $$\\det \\hat{}(1) = 0.$$ guarantee HRK algorithm returns stable minimum phase ARMA model. particular, estimated model minimum phase recursive computation residuals often yields useless results correspondingly cholesky decomposition sample variance residuals (used estimate noise covariance matrix \\(\\Sigma\\)) fails. case procedure stops error message.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"Hannan EJ, Rissanen J (1982). “Recursive estimation mixed autoregressive-moving average order.” Biometrika, 69, 81--94. Hannan EJ, Kavalieris L, Mackisack M (1986). “Recursive Estimation Linear Systems.” Biometrika, 73(1), 119-133.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"","code":"# in order to get reproducible results set.seed(4321)  # generate a random VARMA(p=2,q=1) model with m=2 outputs ##################### tmpl = tmpl_arma_pq(m = 2, n = 2, p = 2, q = 1) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> ARMA model [2,2] with orders p = 2 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]    z^1 [,1]      [,2]    z^2 [,1]        [,2] #> [1,]        1     0 -0.10668935 0.1794017 -0.03208932 -0.07429186 #> [2,]        0     1 -0.05590295 0.2103614  0.40233680  0.04900116 #> MA polynomial b(z): #>      z^0 [,1]  [,2]   z^1 [,1]        [,2] #> [1,]        1     0  0.3101866 -0.01680908 #> [2,]        0     1 -0.1796745  0.08609177 #> Left square root of noise covariance Sigma: #>          u[1] u[2] #> u[1] 1.000000    0 #> u[2] 0.284866    1  # generate a sample with 200 observations data = sim(model, n.obs = 200, n.burn_in = 100)  # estimate model with HRK # note: we are cheating here and use the true disturbances! out = est_arma_hrk(data$y, data$u, tmpl) #> HRK estimation of ARMA model: m=2, n.obs=200, p=2, q=1 #> iter |th - th0|  n.val      MSE       ll  #>    1      0.977    198    1.958   -2.754   print(out$model) #> ARMA model [2,2] with orders p = 2 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  z^1 [,1]        [,2]    z^2 [,1]        [,2] #> [1,]        1     0 0.4774058 0.231267694 -0.08031496 -0.05099365 #> [2,]        0     1 0.1309504 0.005178953  0.33292233  0.06794187 #> MA polynomial b(z): #>      z^0 [,1]  [,2]   z^1 [,1]        [,2] #> [1,]        1     0 0.86715882 -0.05585317 #> [2,]        0     1 0.06883826 -0.24833582 #> Left square root of noise covariance Sigma: #>           u[1]      u[2] #> u[1] 0.9772386 0.0000000 #> u[2] 0.3424949 0.9410523 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 2)) #> [1] TRUE  # estimate the model with HRK # use the residuals of a long AR model as estimates for the noise out = est_arma_hrk(data$y, e = NULL, tmpl,                    trace = TRUE, maxit = 10, mean_estimate = 'zero') #> HRK estimation of ARMA model: m=2, n.obs=200, p=2, q=1 #> initial AR estimate of noise p.max=11, p=2, ll=-2.711726 #> iter |th - th0|  n.val      MSE       ll  #>    1      0.939    197    1.865   -2.697   #>    2      0.140    198    1.856   -2.692   #>    3      0.060    198    1.856   -2.692   #>    4      0.018    198    1.856   -2.692   #>    5      0.007    198    1.856   -2.692   #>    6      0.002    198    1.856   -2.692   #>    7      0.002    198    1.856   -2.692   #>    8      0.000    198    1.856   -2.692   #> algorithm converged print(out$model) #> ARMA model [2,2] with orders p = 2 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2]   z^2 [,1]        [,2] #> [1,]        1     0 0.20158389 0.13764630 0.05391753 -0.08392618 #> [2,]        0     1 0.06234842 0.09370431 0.37190127  0.05010730 #> MA polynomial b(z): #>      z^0 [,1]  [,2]     z^1 [,1]       [,2] #> [1,]        1     0  0.615023757 -0.1511000 #> [2,]        0     1 -0.001179974 -0.1500922 #> Left square root of noise covariance Sigma: #>           u[1]      u[2] #> u[1] 0.9230599 0.0000000 #> u[2] 0.3558209 0.9364313 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 2)) #> [1] TRUE  # Generate a random Model in echelon form model (m = 3) ####################### tmpl = tmpl_arma_echelon(nu = c(1,1,1)) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> ARMA model [3,3] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  [,3]   z^1 [,1]        [,2]       [,3] #> [1,]        1     0     0  0.5893418 -0.00553193 -0.2113619 #> [2,]        0     1     0  0.1842932  0.06201503  0.1328532 #> [3,]        0     0     1 -0.1422159  0.23607602  0.3943483 #> MA polynomial b(z): #>      z^0 [,1]  [,2]  [,3]    z^1 [,1]       [,2]      [,3] #> [1,]        1     0     0 -0.07942568 -0.1992309 0.5002033 #> [2,]        0     1     0 -0.29348965  0.1566674 0.1483497 #> [3,]        0     0     1 -0.14925189  0.4185160 0.3153198 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] u[3] #> u[1]  1.0000000 0.0000000    0 #> u[2]  0.2661327 1.0000000    0 #> u[3] -0.4719906 0.1258785    1  # generate a sample with 200 observations data = sim(model, n.obs = 200, n.burn_in = 100) # add mean value(s) data$y = data$y + matrix(1:3, nrow = 200, ncol = 3, byrow = TRUE)  # estimate model with HRK # note: we are cheating here and use the true disturbances! out = est_arma_hrk(data$y, data$u, tmpl,                    trace = FALSE, maxit = 1, mean_estimate = 'sample.mean') print(out$y.mean) #> [1] 0.9511495 1.9436019 2.8487408 print(out$model) #> ARMA model [3,3] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  [,3]   z^1 [,1]        [,2]         [,3] #> [1,]        1     0     0  0.6687489 -0.12600713 -0.154716557 #> [2,]        0     1     0  0.1944165 -0.04965131  0.057462781 #> [3,]        0     0     1 -0.3418481  0.50977514  0.007750021 #> MA polynomial b(z): #>      z^0 [,1]  [,2]  [,3]    z^1 [,1]        [,2]        [,3] #> [1,]        1     0     0  0.05047286 -0.31806802  0.52077685 #> [2,]        0     1     0 -0.21348959 -0.01193928  0.04368415 #> [3,]        0     0     1 -0.45130821  0.70739668 -0.11303414 #> Left square root of noise covariance Sigma: #>            u[1]       u[2]    u[3] #> u[1]  0.9644771 0.00000000 0.00000 #> u[2]  0.1932537 0.98300427 0.00000 #> u[3] -0.4325050 0.06192851 1.05045 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 1)) #> [1] TRUE  # estimate the model with HRK # use the residuals of a long AR model as estimates for the noise out = est_arma_hrk(data$y, e = NULL, tmpl,                    maxit = 10, mean_estimate = 'intercept') #> HRK estimation of ARMA model: m=3, n.obs=200, p=1, q=1 #> initial AR estimate of noise p.max=7, p=2, ll=-4.235502 #> iter |th - th0|  n.val      MSE       ll  #>    1      1.051    197    3.200   -4.235   #>    2      0.135    199    3.220   -4.249   #>    3      0.081    199    3.223   -4.251   #>    4      0.048    199    3.220   -4.250   #>    5      0.035    199    3.222   -4.251   #>    6      0.022    199    3.221   -4.250   #>    7      0.015    199    3.222   -4.250   #>    8      0.010    199    3.221   -4.250   #>    9      0.007    199    3.222   -4.250   #>   10      0.005    199    3.221   -4.250   print(out$y.mean) #> [1] 0.9537144 1.9386421 2.8536800 print(out$model) #> ARMA model [3,3] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  [,3]   z^1 [,1]         [,2]       [,3] #> [1,]        1     0     0  0.6740053 -0.261126479 -0.3217273 #> [2,]        0     1     0  0.1479565  0.008074719 -0.1286455 #> [3,]        0     0     1 -0.2984776  0.523115301  0.1643308 #> MA polynomial b(z): #>      z^0 [,1]  [,2]  [,3]    z^1 [,1]        [,2]        [,3] #> [1,]        1     0     0  0.05225048 -0.45689436  0.35600140 #> [2,]        0     1     0 -0.25603151  0.04533693 -0.14860902 #> [3,]        0     0     1 -0.41217354  0.72060291  0.04411931 #> Left square root of noise covariance Sigma: #>            u[1]       u[2]     u[3] #> u[1]  0.9625622 0.00000000 0.000000 #> u[2]  0.1902924 0.98177314 0.000000 #> u[3] -0.4307534 0.06340989 1.051195 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 1)) #> [1] TRUE  # We may also use this procedure to estimate AR models ##################### # where some coefficients are fixed = 0 a = dbind(d = 3, diag(2), array(NA_real_, dim = c(2,2,2))) a[1,2,] = 0 # all coefficient matrices are lower triangular, i.e. # y[2t] does not Granger cause y[1t] tmpl = model2template(armamod(sys = lmfd(a=a),                               sigma_L = matrix(NA_real_, nrow = 2, ncol = 2)),                       sigma_L = 'chol') model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> ARMA model [2,2] with orders p = 2 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]      [,2]    z^2 [,1]       [,2] #> [1,]        1     0 -0.1836216 0.0000000 -0.04334075 0.00000000 #> [2,]        0     1  0.2345054 0.2220447 -0.54760618 0.04449801 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>             u[1] u[2] #> u[1]  1.00000000    0 #> u[2] -0.07017046    1  # generate a sample with 200 observations data = sim(model, n.obs = 200, n.burn_in = 100)  # estimate model with HRK out = est_arma_hrk(data$y, NULL, tmpl,                    trace = FALSE, maxit = 1, mean_estimate = 'zero') print(out$y.mean) #> [1] 0 0 print(out$model) #> ARMA model [2,2] with orders p = 2 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]    [,2]    z^2 [,1]       [,2] #> [1,]        1     0 -0.1045799 0.00000 -0.04138278 0.00000000 #> [2,]        0     1  0.3202084 0.22883 -0.58485638 0.09887707 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>             u[1]      u[2] #> u[1]  0.91829065 0.0000000 #> u[2] -0.04809834 0.9383795 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 2)) #> [1] TRUE  # reset the \"seed\" set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":null,"dir":"Reference","previous_headings":"","what":"Different version of HRK Procedure — est_arma_hrk3","title":"Different version of HRK Procedure — est_arma_hrk3","text":"See est_arma_hrk. Stage III Hannan-Rissanen-Kavalieris procedure implemented well. function returns best model (since iterations might always improve log-likelihood value) allows returning results different stages HRK procedure.  One notable differences data needs demeaned use Yule-Walker estimation first stage ensure stability implementation stage III otherwise even cumbersome.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Different version of HRK Procedure — est_arma_hrk3","text":"","code":"est_arma_hrk3(   y,   tmpl,   maxit_stage2 = 5,   tol_stage2 = 0.001,   maxit_stage3 = 5,   tol_stage3 = 0.001,   info = TRUE,   trace = FALSE,   p.max = NULL,   ic = c(\"AIC\", \"BIC\", \"max\"),   mean_estimate = c(\"zero\", \"sample.mean\", \"intercept\"),   tol = sqrt(.Machine$double.eps) )"},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Different version of HRK Procedure — est_arma_hrk3","text":"y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. tmpl model template, see model structures(). Note case implemented, \\(a_0=b_0\\) holds, diagonal entries \\(a_0=b_0\\) equal one fixed elements equal zero. Furthermore square root sigma_L noise covariance matrix asssumed lower triangular matrix without restrictions.  given template coerced template kind. given template comply restrictions, warning message issued. maxit_stage2, maxit_stage3 Integers. Default stages 5. tol_stage2, tol_stage3 Default set 1e-3. Maximal absolute distance deep parameters adjacent iterations info Boolean. Indicates whether slot extra_info returned list contain tibble additional info model different iterations, e.g., min max absolute value zeros, poles, value objective function etc. trace (boolean) trace=TRUE, tracing information iterations printed. p.max (integer NULL) Maximum order candidate AR models. default choice see . ic (character string) information criterion shall used find optimal AR order. Note ic=\"max\" means AR(p) model p=p.max fitted. Default ic=\"AIC\". mean_estimate Character string giving method used estimate mean \\(\\mu\\). Default mean_estimate = \"sample.mean\". See details . tol Small tolerance, used check whether mean supplied data matrix indeed zero.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Different version of HRK Procedure — est_arma_hrk3","text":"See est_arma_hrk(). list contains additional slots stage_opt Since best stable miniphase model returned, also indicate whether happened stage II stage III. info_tibble Tibble containing relevant info outcome different stages iterations. contain slots y.mean (since mean required zero) converged.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Different version of HRK Procedure — est_arma_hrk3","text":"","code":"data = BQdata_xts for (pp in 0:2){   for (qq in 0:2){     if (pp + qq == 0){next}     cat(paste0(\"p = \", pp, \" q = \", qq, \"\\n\"))     tmpl = tmpl_arma_pq(m = 2, n = 2,                         p = pp, q = qq)     ff = est_arma_hrk3(data, tmpl = tmpl)   } } #> p = 0 q = 1 #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> p = 0 q = 2 #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> p = 1 q = 0 #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> p = 1 q = 1 #> p = 1 q = 2 #> p = 2 q = 0 #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> p = 2 q = 1 #> p = 2 q = 2 ff$info_tibble %>% print(n=100) #> # A tibble: 21 × 10 #>    stage iteration flipped min_pole max_pole min_zero max_zero trace log_lik #>    <dbl>     <dbl> <lgl>      <dbl>    <dbl>    <dbl>    <dbl> <dbl>   <dbl> #>  1     1         1 FALSE       1.23     3.13   Inf      Inf    0.945  Inf    #>  2     2         1 FALSE       1.36     2.56     1.49     5.10 0.948   -1.33 #>  3     2         1 TRUE        1.36     2.56     1.49     5.10 0.948   -1.37 #>  4     2         2 FALSE       1.28     1.98     1.51     2.38 0.957   -1.34 #>  5     2         2 TRUE        1.28     1.98     1.51     2.38 0.957   -1.36 #>  6     2         3 FALSE       1.43    25.0      1.37     5.67 0.955   -1.34 #>  7     2         3 TRUE        1.43    25.0      1.37     5.67 0.955   -1.34 #>  8     2         4 FALSE       1.39     2.93     1.40     8.26 0.948   -1.33 #>  9     2         4 TRUE        1.39     2.93     1.40     8.26 0.948   -1.35 #> 10     2         5 FALSE       1.35     2.92     1.17     3.60 0.959   -1.34 #> 11     2         5 TRUE        1.35     2.92     1.17     3.60 0.959   -1.34 #> 12     3         1 FALSE       1.29     2.09     1.47     6.75 0.948   -1.34 #> 13     3         1 TRUE        1.29     2.09     1.47     6.75 0.963   -1.36 #> 14     3         2 FALSE       1.29     4.23     1.65     3.21 0.948   -1.34 #> 15     3         2 TRUE        1.29     4.23     1.65     3.21 0.958   -1.34 #> 16     3         3 FALSE       1.39     2.45     1.64     5.11 0.951   -1.34 #> 17     3         3 TRUE        1.39     2.45     1.64     5.11 0.958   -1.35 #> 18     3         4 FALSE       1.34     5.34     2.02     3.61 0.950   -1.34 #> 19     3         4 TRUE        1.34     5.34     2.02     3.61 0.952   -1.34 #> 20     3         5 FALSE       1.52     3.33     2.91     5.90 0.950   -1.34 #> 21     3         5 TRUE        1.52     3.33     2.91     5.90 0.952   -1.34 #> # ℹ 1 more variable: lndetSigma <dbl>"},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"DEPRECATED? internal helper function computes outputs , general unstable, statespace system $$a_{t+1} = a_t + B u_t, \\; y_t = C a_t + D u_t$$ forward backward recursion. procedure assumes state transition matrix \\(\\) block upper triangular, upper block \\(A_{11}\\) stable (.e. eigenvalues moduli less one) lower block \\(A_{22}\\) unstable (.e. eigenvalues moduli larger one). function mainly used routine innovation_form.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"\\((s, s)\\) matrix. B \\((s, n)\\) matrix. C \\((m, s)\\) matrix. D \\((m, n)\\) matrix. u \\((n, N)\\) matrix inputs \\((u_1,...,u_N\\). au \\((su,N+1)\\) matrix. matrix overwritten (computed) states unstable part system. \\((a_{u1},a_{u2},\\ldots,a_{uN},a_{u,N+1})\\). input au[,N+1] must hold \"initial\" state \\(a_{u,N+1}\\). \\((ss,N+1)\\) matrix. matrix overwritten (computed) states stable part system. \\((a_{s1},a_{s2},\\ldots,a_{sN},a_{s,N+1})\\). input [,1] must hold \"initial\" state \\(a_{s1}\\). y \\((m,N)\\) matrix. matrix overwritten (computed) outputs: \\((y_1,y_2,\\ldots,y_N)\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"RcppArmadillo routine returns NULL overwrites input argument y, au computed outputs states!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"Use procedure care! procedure check input arguments. require \\(m > 0\\), \\(n > 0\\). Furthermore assumed state transition matrix \\(\\) block upper triangular, explained . procedure overwrites input arguments y, au. data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":null,"dir":"Reference","previous_headings":"","what":"Forecast Error Variance Decomposition — fevardec","title":"Forecast Error Variance Decomposition — fevardec","text":"Computes Forecast Errors Variance Decomposition given (orthogonalized) impulse response function.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forecast Error Variance Decomposition — fevardec","text":"","code":"fevardec(obj, h.max = NULL, H = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forecast Error Variance Decomposition — fevardec","text":"obj impresp() object represents (orthogonalized) impulse response function. h.max maximum forecast horizon. default one plus number lags impresp object. H (n x n) (non singular) matrix renders impulse response orthogonalized impulse response. noise \\(u_t\\) transformed \\(H^{-1}u_t\\) impulse response coefficients (\\(k_j \\rightarrow k_j H\\)) (left) square root noise covariance matrix (\\(L \\rightarrow H^{-1}L\\)) transformed correspondingly.  default case H=NULL corresponds identity matrix (.e. transformation).  H='chol', transformation matrix H = t(chol(Sigma)) obtained Choleski decomposition noise covariance \\(\\Sigma\\). H='eigen' symmetric square root \\(\\Sigma\\) (obtained eigenvalue decomposition \\(\\Sigma\\)) used. H='sigma_L' left square root noise covariance, stored object obj, used. orthogonalization schemes may obtained setting \\(H\\) suitable square root \\(\\Sigma\\).  procedure checks whether transformation yields orthogonalized impulse response. , error thrown.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forecast Error Variance Decomposition — fevardec","text":"fevardec object, .e. list components vd n--n--h.max array contains forecast error variance decomposition: vd[,j,h] percentage variance h-step ahead forecast error -th component due j-th orthogonalized shock. v n--h.max matrix contains forecast error variances: v[,h] variance h-step ahead forecast error -th component. names (m)-dimensional character vector label character string NULL","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forecast Error Variance Decomposition — fevardec","text":"","code":"model = stspmod(sys = stsp(A = c(0,0.2,1,-0.5), B = c(1,1,1,-1),                            C = c(1,0,0,1)),                 sigma_L = t(chol(matrix(c(4,2,2,3),nrow=2))),                 names = c('y1','y2'), label = 'test model') fevardec(impresp(model, lag.max=10), H = 'chol', h.max = 5) %>% print(digits = 2, format = 'iz|j') #> test model: Forecast error variance decompositon [2,2] maximum horizon = 5 #>        u[1] u[2] #> h=1 y1 1.00 0.00 #>     y2 0.33 0.67 #> h=2 y1 0.87 0.13 #>     y2 0.33 0.67 #> h=3 y1 0.78 0.22 #>     y2 0.29 0.71 #> h=4 y1 0.74 0.26 #>     y2 0.27 0.73 #> h=5 y1 0.72 0.28 #>     y2 0.26 0.74 fevardec(impresp(model, lag.max=4, H = 'eigen'))            %>% print(digits = 2, format = 'iz|j') #> test model: Forecast error variance decompositon [2,2] maximum horizon = 5 #>        u[1] u[2] #> h=1 y1 0.92 0.08 #>     y2 0.11 0.89 #> h=2 y1 0.66 0.34 #>     y2 0.36 0.64 #> h=3 y1 0.65 0.35 #>     y2 0.31 0.69 #> h=4 y1 0.62 0.38 #>     y2 0.30 0.70 #> h=5 y1 0.60 0.40 #>     y2 0.30 0.70"},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect Deep Parameters with a Model — fill_template","title":"Connect Deep Parameters with a Model — fill_template","text":"fill_template fills given template, .e. essence affine mapping free parameters linear parameters model class specified template, given free (deep) parameters th returns model (e.g. armamod() stspmod()). procedure can used generate random models, see e.g. r_model(), M-estimates, .e. estimation procedures estimate obtained minimizing (maximizing) criterion (e.g. ML GMM estimation).  \"inverse function\" extract_theta extracts free/deep parameters linear parameters model, using information provided template. end procedure first constructs vector \\(\\pi\\) stacked (linear) model parameters determines deep parameters \\(\\theta\\) least squares solution equation system $$(\\pi - h) =  H\\theta$$ residuals non zero, model (exactly) fit model structure. threshold tol used decide whether model fits template . parameter on_error decides case \"significant\" misfit. \"ignore\" procedure ignores misfit, \"warn\" procedure issues warning, \"stop\" procedure stops appropriate error message.  many cases noise covariance explicitly parametrized, since \\(\\Sigma\\) estimated another route. may accomplished fixing sigma_L identity matrix, option sigma_L = \"identity\" tmpl_*** functions. order extract system parameters (e.g. AR MA parameters ARMA model) model sigma_L equal identity, one may use option ignore_sigma_L = TRUE. ignores possible mismatch sigma_L still checks whether system parameters accordance model structure.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect Deep Parameters with a Model — fill_template","text":"","code":"fill_template(th, template)  extract_theta(   model,   template,   tol = sqrt(.Machine$double.eps),   on_error = c(\"ignore\", \"warn\", \"stop\"),   ignore_sigma_L = FALSE )"},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect Deep Parameters with a Model — fill_template","text":"th Vector containing free (deep) parameters. template template like listed model structures(), template explicitly specified user model2template(). Essentially, template affine mapping parametrised vector h matrix H connect free (deep) parameters linear parameters model. model model object, .e. armamod(), stspmod(), rmfdmod() object, deep parameters extracted. tol extract_theta, small double specifying tolerance acceptable distance linear parameters H times deep parameters. Default st sqrt(.Machine$double.eps). on_error extract_theta, character string possible choices ignore, warn, stop. Specifies happen distance linear parmameters H times deep parameters, larger specified tol. Default ignore ignore_sigma_L Boolean, default set FALSE. TRUE, linear free parameters pertaining left square root sigma_L error covariance matrix ignored. See also tmpl_sigma_L() model structures() detail.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect Deep Parameters with a Model — fill_template","text":"fill_template returns model object, .e. armamod(), stspmod(), rmfdmod() object, according class template (given parameters th). function extract_theta returns vector free parameters given model template.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"connection-to-likelihood-estimation","dir":"Reference","previous_headings":"","what":"Connection to Likelihood Estimation","title":"Connect Deep Parameters with a Model — fill_template","text":"functions important likelihood estimation following instances functionality necessary. initial estimate given model (together template), one may use extract_theta extract deep parameters. vector initial free/deep parameter values needs supplied optimizer. optimized deep parameter values need filled model using structure provided template. done fill_template","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Connect Deep Parameters with a Model — fill_template","text":"","code":"# Extract deep parameter from ARMA object with ARMA(p,q) template ########## (armamod_obj = test_armamod(dim = c(2,2), degree = c(3,1))) #> ARMA model [2,2] with orders p = 3 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]      [,2]  z^2 [,1]       [,2]   z^3 [,1] #> [1,]        1     0 -1.4899040 0.2563959 0.6977291  0.5997609  1.0785545 #> [2,]        0     1  0.1959636 1.3001459 1.0588514 -1.5316510 -0.4431985 #>           [,2] #> [1,] -1.163929 #> [2,]  1.547800 #> MA polynomial b(z): #>      z^0 [,1]  [,2]   z^1 [,1]     [,2] #> [1,]        1     0 -0.1053589 1.554452 #> [2,]        0     1 -0.5773797 0.268904 #> Left square root of noise covariance Sigma: #>           u[1]      u[2] #> u[1] 0.5956404 0.0000000 #> u[2] 1.2590720 0.2726968 (tmpl_obj = tmpl_arma_pq(2, 2, 3, 1)) #> $h #>  [1] 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 #>  #> $H #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [2,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [5,]    1    0    0    0    0    0    0    0    0     0     0     0     0 #>  [6,]    0    1    0    0    0    0    0    0    0     0     0     0     0 #>  [7,]    0    0    1    0    0    0    0    0    0     0     0     0     0 #>  [8,]    0    0    0    1    0    0    0    0    0     0     0     0     0 #>  [9,]    0    0    0    0    1    0    0    0    0     0     0     0     0 #> [10,]    0    0    0    0    0    1    0    0    0     0     0     0     0 #> [11,]    0    0    0    0    0    0    1    0    0     0     0     0     0 #> [12,]    0    0    0    0    0    0    0    1    0     0     0     0     0 #> [13,]    0    0    0    0    0    0    0    0    1     0     0     0     0 #> [14,]    0    0    0    0    0    0    0    0    0     1     0     0     0 #> [15,]    0    0    0    0    0    0    0    0    0     0     1     0     0 #> [16,]    0    0    0    0    0    0    0    0    0     0     0     1     0 #> [17,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [18,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [19,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [20,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [21,]    0    0    0    0    0    0    0    0    0     0     0     0     1 #> [22,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [23,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [24,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [25,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [26,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [27,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [28,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] #>  [1,]     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0 #> [14,]     0     0     0     0     0     0 #> [15,]     0     0     0     0     0     0 #> [16,]     0     0     0     0     0     0 #> [17,]     0     0     0     0     0     0 #> [18,]     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0 #> [21,]     0     0     0     0     0     0 #> [22,]     1     0     0     0     0     0 #> [23,]     0     1     0     0     0     0 #> [24,]     0     0     1     0     0     0 #> [25,]     0     0     0     1     0     0 #> [26,]     0     0     0     0     1     0 #> [27,]     0     0     0     0     0     0 #> [28,]     0     0     0     0     0     1 #>  #> $class #> [1] \"armamod\" #>  #> $order #> [1] 2 2 3 1 #>  #> $n.par #> [1] 19 #>   extract_theta(armamod_obj, tmpl_obj) #>  [1] -1.4899040  0.1959636  0.2563959  1.3001459  0.6977291  1.0588514 #>  [7]  0.5997609 -1.5316510  1.0785545 -0.4431985 -1.1639289  1.5477995 #> [13] -0.1053589 -0.5773797  1.5544515  0.2689040  0.5956404  1.2590720 #> [19]  0.2726968   # Fill template with deep parameters ################# (tmpl_obj = tmpl_arma_echelon(nu = c(3,2))) #> $h #>  [1] 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 #>  #> $H #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [2,]    1    0    0    0    0    0    0    0    0     0     0     0     0 #>  [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [5,]    0    1    0    0    0    0    0    0    0     0     0     0     0 #>  [6,]    0    0    1    0    0    0    0    0    0     0     0     0     0 #>  [7,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [8,]    0    0    0    1    0    0    0    0    0     0     0     0     0 #>  [9,]    0    0    0    0    1    0    0    0    0     0     0     0     0 #> [10,]    0    0    0    0    0    1    0    0    0     0     0     0     0 #> [11,]    0    0    0    0    0    0    1    0    0     0     0     0     0 #> [12,]    0    0    0    0    0    0    0    1    0     0     0     0     0 #> [13,]    0    0    0    0    0    0    0    0    1     0     0     0     0 #> [14,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [15,]    0    0    0    0    0    0    0    0    0     1     0     0     0 #> [16,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [17,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [18,]    1    0    0    0    0    0    0    0    0     0     0     0     0 #> [19,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [20,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [21,]    0    0    0    0    0    0    0    0    0     0     1     0     0 #> [22,]    0    0    0    0    0    0    0    0    0     0     0     1     0 #> [23,]    0    0    0    0    0    0    0    0    0     0     0     0     1 #> [24,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [25,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [26,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [27,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [28,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [29,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [30,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [31,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [32,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [33,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [34,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [35,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [36,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] #>  [1,]     0     0     0     0     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0     0     0     0     0 #> [14,]     0     0     0     0     0     0     0     0     0     0 #> [15,]     0     0     0     0     0     0     0     0     0     0 #> [16,]     0     0     0     0     0     0     0     0     0     0 #> [17,]     0     0     0     0     0     0     0     0     0     0 #> [18,]     0     0     0     0     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0     0     0     0     0 #> [21,]     0     0     0     0     0     0     0     0     0     0 #> [22,]     0     0     0     0     0     0     0     0     0     0 #> [23,]     0     0     0     0     0     0     0     0     0     0 #> [24,]     1     0     0     0     0     0     0     0     0     0 #> [25,]     0     1     0     0     0     0     0     0     0     0 #> [26,]     0     0     1     0     0     0     0     0     0     0 #> [27,]     0     0     0     1     0     0     0     0     0     0 #> [28,]     0     0     0     0     1     0     0     0     0     0 #> [29,]     0     0     0     0     0     1     0     0     0     0 #> [30,]     0     0     0     0     0     0     0     0     0     0 #> [31,]     0     0     0     0     0     0     1     0     0     0 #> [32,]     0     0     0     0     0     0     0     0     0     0 #> [33,]     0     0     0     0     0     0     0     1     0     0 #> [34,]     0     0     0     0     0     0     0     0     1     0 #> [35,]     0     0     0     0     0     0     0     0     0     0 #> [36,]     0     0     0     0     0     0     0     0     0     1 #>  #> $class #> [1] \"armamod\" #>  #> $order #> [1] 2 2 3 3 #>  #> $n.par #> [1] 23 #>  #> $nu #> [1] 3 2 #>  # Number of columns of matrix H in affine mapping = number of free parameters (n_par_deep = dim(tmpl_obj$H)[2]) #> [1] 23  fill_template(rnorm(n_par_deep), tmpl_obj) #> ARMA model [2,2] with orders p = 3 and q = 3 #> AR polynomial a(z): #>       z^0 [,1]  [,2]   z^1 [,1]        [,2]   z^2 [,1]       [,2]   z^3 [,1] #> [1,]  1.000000     0 -0.2904415  0.00000000 -0.7721123  2.2950458 -0.9328304 #> [2,] -1.127917     1 -2.6850091 -0.02041191 -1.0866720 -0.7907518  0.0000000 #>           [,2] #> [1,] -1.370436 #> [2,]  0.000000 #> MA polynomial b(z): #>       z^0 [,1]  [,2]  z^1 [,1]        [,2]  z^2 [,1]      [,2] z^3 [,1] #> [1,]  1.000000     0 0.8836920  0.06518682 0.8472276 -1.406137 1.465333 #> [2,] -1.127917     1 0.3677087 -0.43116780 0.4711488 -1.301526 0.000000 #>            [,2] #> [1,] -0.1980774 #> [2,]  0.0000000 #> Left square root of noise covariance Sigma: #>            u[1]       u[2] #> u[1]  0.3795273  0.0000000 #> u[2] -0.2809939 -0.3028435"},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":null,"dir":"Reference","previous_headings":"","what":"Frequency Response Function — freqresp","title":"Frequency Response Function — freqresp","text":"Compute frequency response function (also called transfer function) associated VARMA state space model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frequency Response Function — freqresp","text":"","code":"freqresp(obj, n.f, ...)  # S3 method for armamod freqresp(obj, n.f = 128, ...)  # S3 method for stspmod freqresp(obj, n.f = 128, ...)  # S3 method for impresp freqresp(obj, n.f = 128, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frequency Response Function — freqresp","text":"obj armamod(), stspmod() impresp() object. Note impulse response object result approximation \"true\" frequency response due finite number coefficients. n.f number frequencies. ... used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Frequency Response Function — freqresp","text":"freqresp object, .e. list slots frr rationalmatrices::zvalues() object. sigma_L (n,n)-dimensional matrix contains left square root noise covariance matrix \\(\\Sigma\\). names (m)-dimensional character vector NULL. optional slot stores names components time series/process. label character string NULL.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Frequency Response Function — freqresp","text":"frequency response function (transfer function) associated ARMA state space model $$ K(\\lambda) = \\sum_{j=0}^{\\infty} k_j e^{-\\lambda j} $$ \\((k_j \\,|\\, j\\geq 0)\\) impulse response model. See also impresp(). ARMA model frequency response equal $$ K(\\lambda) = (a_0 + a_1 e^{-\\lambda} + \\cdots + a_p e^{-\\lambda p})^{-1} (b_0 + b_1 e^{-\\lambda} + \\cdots + b_q e^{-\\lambda q}) $$ state space model $$ K(\\lambda) = C(e^{\\lambda}I_s - )^{-1}B+D $$ Note \\(K()\\) discrete-time Fourier transform (DTFT) impulse response. impulse response absolutely summable coefficents \\(k_j\\) may reconstructed frequency response via inverse DTFT $$ k_j = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} K(\\lambda) e^{\\lambda j} d\\lambda $$ S3 methods freqresp.* evaluate function grid angular frequencies \\(\\lambda_j = 2\\pi j/N\\), \\(j=0,\\ldots,N-1\\) store result (together sigma_L) freqresp object.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frequency Response Function — freqresp","text":"","code":"set.seed(3451) # set seed in order to get reproducible results  ### generate random bivariate ARMA(1,1) model # \"bpoles = 1.1\" implies that the poles have moduli larger than 1.1 # and therefore the impulse response coefficients decay with a rate (1.1)^k arma_model = test_armamod(dim = c(2,2), degrees = c(1,1), bpoles = 1.1) # frequency response frr = freqresp(arma_model) # compute the frequency response via the impulse response irf = impresp(arma_model, lag.max = 100) frr1 = freqresp(irf) # since the impulse response quickly decays # the \"truncated\" frequency response should be close to the true frequency response all.equal(frr, frr1) #> [1] TRUE # create an equivalent state space model stsp_model = as.stspmod(arma_model) # of course the state space model has the same frequency response # as the original ARMA model frr1 = freqresp(stsp_model) all.equal(frr, frr1) #> [1] TRUE  # we can also reconstruct the impulse response from the # frequency response, provided the frequency grid is \"fine enough\" n.f = 2^6 frr = freqresp(arma_model, n.f = n.f) # compute the impulse response via the inverse DTFT K = unclass(frr$frr) k1 = Re(apply(K, MARGIN = c(1,2), FUN = fft, inverse = TRUE)) / n.f k1 = aperm(k1, c(2,3,1)) # impulse response irf = impresp(arma_model, lag.max = n.f-1) k = unclass(irf$irf) # compare all.equal(k, k1) #> [1] TRUE  set.seed(NULL) # reset seed"},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":null,"dir":"Reference","previous_headings":"","what":"Impulse Response Function — impresp","title":"Impulse Response Function — impresp","text":"Compute (orthogonalized) impulse response function VARMA model state space model. impulse response coefficients also called Power series parameters system.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impulse Response Function — impresp","text":"","code":"impresp(obj, lag.max, H)  # S3 method for armamod impresp(obj, lag.max = 12, H = NULL)  # S3 method for rmfdmod impresp(obj, lag.max = 12, H = NULL)  # S3 method for stspmod impresp(obj, lag.max = 12, H = NULL)  # S3 method for impresp impresp(obj, lag.max = NULL, H = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impulse Response Function — impresp","text":"obj armamod(), stspmod() object impresp() object. last case may used transform impulse response function different orthogonalization scheme. lag.max Maximum lag impulse response coefficients. parameter ignored case obj impresp object. H (n x n) (non singular) matrix specifies transformation noise. noise \\(u_t\\) transformed \\(H^{-1}u_t\\) impulse response coefficients (\\(k_j \\rightarrow k_j H\\)) (left) square root noise covariance matrix (\\(L \\rightarrow H^{-1}L\\)) transformed correspondingly.  default case H=NULL corresponds identity matrix (.e. transformation).  H='chol', transformation matrix H = t(chol(Sigma)) determined Choleski decomposition noise covariance \\(\\Sigma\\). H='eigen' symmetric square root \\(\\Sigma\\) (obtained eigenvalue decomposition \\(\\Sigma\\)) used. H='sigma_L' left square root noise covariance, stored object obj, used. cases one obtains orthogonalized impulse response function. orthogonalization schemes may obtained setting \\(H\\) suitable square root \\(\\Sigma\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impulse Response Function — impresp","text":"impresp object, .e. list components irf pseries object. sigma_L (n,n)-dimensional matrix contains left square noise covariance matrix. names (n)-dimensional character vector NULL label character string NULL","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Impulse Response Function — impresp","text":"impulse response coefficients \\((k_j \\,|\\, j \\geq 0)\\) define map noise output process. model stable stationary solution ARMA system, respectively state space system, given $$ y_t = \\sum_{j \\geq 0} k_j u_{t-j}. $$ state space system impulse response coefficients $$k_0 = D \\mbox{ }$$ $$k_j = CA^{j-1}B \\mbox{ }j >0.$$ ARMA model coefficients (recursively) computed comparison coefficients equation $$ (a_0 + a_1 z + \\cdots + a_p z^p)(k_0 + k_1 z + k_2 z^2 + \\cdots ) = b_0 + b_1 z + \\cdots + b_q z^q $$ S3 methods impresp.* compute coefficients \\(k_j\\) \\(j = 0,\\cdots,N\\) store result, together left square root (sigma_L) noise covariance \\(\\Sigma\\), impresp object. impresp objects contain complete information underlying model, provided maximum lag \\(N\\) large enough. means one may reconstruct underlying model impulse response object.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Impulse Response Function — impresp","text":"Lütkepohl H (2005). New Introduction Multiple Time Series Analysis. Springer Berlin.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impulse Response Function — impresp","text":"","code":"# IRF from state space model ################################################ model = stspmod(stsp(A = c(0,0.2,1,-0.5), B = c(1,1,1,-1),                      C = c(1,0,0,1)),                 sigma_L = matrix(c(4, 1, 1, 3), 2, 2),                 names = c('y1','y2'), label = 'test model')  # IRF irf = impresp(model, lag.max=10) irf #> test model: Impulse response [2,2] with 10 lags #>      lag=0 [,1]  [,2] lag=1 [,1]  [,2] lag=2 [,1]  [,2] lag=3 [,1]  [,2] #> [1,]          1     0          1     1        1.0  -1.0      -0.30  0.70 #> [2,]          0     1          1    -1       -0.3   0.7       0.35 -0.55 #>      lag=4 [,1]   [,2] lag=5 [,1]    [,2] lag=6 [,1]     [,2] lag=7 [,1] #> [1,]      0.350 -0.550    -0.2350  0.4150    0.18750 -0.31750  -0.140750 #> [2,]     -0.235  0.415     0.1875 -0.3175   -0.14075  0.24175   0.107875 #>           [,2] lag=8 [,1]       [,2]  lag=9 [,1]       [,2] lag=10 [,1] #> [1,]  0.241750  0.1078750 -0.1843750 -0.08208750  0.1405375  0.06261875 #> [2,] -0.184375 -0.0820875  0.1405375  0.06261875 -0.1071438 -0.04772688 #>             [,2] #> [1,] -0.10714375 #> [2,]  0.08167938  # Orthogonalized IRF: Cholesky irf_chol = impresp(model, lag.max = 10, H = 'chol') irf_chol #> test model: Impulse response [2,2] with 10 lags #>      lag=0 [,1]     [,2] lag=1 [,1]      [,2]  lag=2 [,1]      [,2]  lag=3 [,1] #> [1,]   4.123106 0.000000   5.820855  2.667892  2.42535625 -2.667892 -0.04850713 #> [2,]   1.697749 2.667892   2.425356 -2.667892 -0.04850713  1.867524  0.50932481 #>           [,2] lag=4 [,1]      [,2] lag=5 [,1]       [,2] lag=6 [,1]       [,2] #> [1,]  1.867524  0.5093248 -1.467341 -0.2643638  1.1071751  0.2340469 -0.8470557 #> [2,] -1.467341 -0.2643638  1.107175  0.2340469 -0.8470557 -0.1698962  0.6449629 #>      lag=7 [,1]       [,2]  lag=8 [,1]       [,2]  lag=9 [,1]       [,2] #> [1,] -0.1698962  0.6449629  0.13175748 -0.4918926 -0.09985798  0.3749389 #> [2,]  0.1317575 -0.4918926 -0.09985798  0.3749389  0.07628049 -0.2858479 #>      lag=10 [,1]       [,2] #> [1,]  0.07628049 -0.2858479 #> [2,] -0.05811184  0.2179117 print(irf_chol$sigma_L) # Sigma is (approximately equal to) the identity matrix #>            [,1]      [,2] #> [1,]  0.9701425 0.2425356 #> [2,] -0.2425356 0.9701425   # IRF from VARMA model ################################################ model = armamod(sys = test_lmfd(dim = c(2,2), degrees = c(2,1)))  irf = impresp(model) print(irf, digits = 2, format = 'iz|j') #> Orthogonalized impulse response [2,2] with 12 lags #>              [,1]  [,2] #>  lag=0 [1,] -0.75 -0.33 #>        [2,] -0.34  0.04 #>  lag=1 [1,] -0.12 -0.18 #>        [2,]  0.27  0.49 #>  lag=2 [1,]  0.08  0.12 #>        [2,]  0.88  0.46 #>  lag=3 [1,]  0.54  0.54 #>        [2,]  0.13 -0.06 #>  lag=4 [1,]  0.90  0.64 #>        [2,] -0.78 -0.64 #>  lag=5 [1,]  0.48  0.20 #>        [2,] -1.20 -0.92 #>  lag=6 [1,] -0.57 -0.60 #>        [2,] -0.90 -0.53 #>  lag=7 [1,] -1.51 -1.21 #>        [2,]  0.33  0.52 #>  lag=8 [1,] -1.53 -1.00 #>        [2,]  1.84  1.55 #>  lag=9 [1,] -0.20  0.18 #>        [2,]  2.35  1.65 #> lag=10 [1,]  1.88  1.71 #>        [2,]  0.98  0.32 #> lag=11 [1,]  3.19  2.38 #>        [2,] -1.84 -1.86 #> lag=12 [1,]  2.22  1.22 #>        [2,] -4.24 -3.33"},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":null,"dir":"Reference","previous_headings":"","what":"Innovation Form state space Model — innovation_form","title":"Innovation Form state space Model — innovation_form","text":"Convert given state space model innovation form, .e. transformed model satisfies \\(D=\\) model stable minimum phase. procedure \"flips\" bad poles zeroes helper functions reflect_zeroes() reflect_poles(). transformed model equivalent description process terms second order moments. means spectral density changed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Innovation Form state space Model — innovation_form","text":"","code":"innovation_form(model, echelon_form = TRUE, y = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Innovation Form state space Model — innovation_form","text":"model state space model, .e. object type stspmod(). echelon_form boolean, TRUE innovation form model addition transformed echelon form. y NULL data sample. .matrix(y) return (N,m)-dimensional numeric matrix. NULL noise covariance matrix estimated sample.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Innovation Form state space Model — innovation_form","text":"List slots model state space model innovation form. z (complex) vector zeroes innovation form model. z_flipped (boolean) vector indicates zeroes flipped. p (complex) vector poles innovation form model. p_flipped (boolean) vector indicates poles flipped.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Innovation Form state space Model — innovation_form","text":"","code":"# in order to get reproducable results set.seed(342)  model = r_model(tmpl_stsp_full(3, 3, 5)) print(model, digits = 4) #> state space model [3,3] with s = 5 states #>         s[1]    s[2]    s[3]    s[4]    s[5]    u[1]    u[2]    u[3] #> s[1] -0.7701 -0.7534  0.4933 -1.2629  0.3608  0.0149  0.8278 -1.1295 #> s[2] -0.9100  2.2148 -0.4970 -2.2051 -1.0721 -0.9960  0.5980 -1.5275 #> s[3]  1.2751  0.9052 -0.7475 -0.5919 -1.6086 -1.1893  0.0486 -1.6221 #> s[4] -0.1740 -1.3902  1.4165  0.8076  0.5328 -0.9149 -0.2580 -0.4574 #> s[5]  0.5116 -0.0054 -0.6111  0.5597 -0.0738  0.0839 -0.3527 -0.6538 #> x[1]  0.1336  1.7917  0.5724  0.5907  0.1006  1.0000  0.0000  0.0000 #> x[2]  1.1534  1.2193  1.4340 -0.4257  0.6177  0.0000  1.0000  0.0000 #> x[3] -1.2113 -0.5287 -1.2432 -0.8186  0.8428  0.0000  0.0000  1.0000 #> Left square root of noise covariance Sigma: #>            u[1]      u[2]     u[3] #> u[1]  0.6968024 0.0000000 0.000000 #> u[2] -0.3246241 0.1801707 0.000000 #> u[3]  0.9493687 0.6805352 1.089781 # the model has two non-minimum phase zeroes and two non-stable poles. z = zeroes(model, print_message = FALSE) abs(z) #> [1] 0.2430920 0.3822571 1.4472231 1.4472231 1.7947154 p = poles(model, print_message = FALSE) abs(p) #> [1] 0.3184163 0.3801766 1.1047541 1.1047541 7.2894009  # convert to innnovation form, by flipping the \"bad\" poles and zeroes. out = innovation_form(model) print(out$model, digits = 4) #> state space model [3,3] with s = 5 states #>         s[1]    s[2]    s[3]    s[4]    s[5]     u[1]     u[2]    u[3] #> s[1]  0.0000  0.0000  0.0000  1.0000  0.0000  -2.1013   0.4187 -3.8366 #> s[2]  0.0000  0.0000  0.0000  0.0000  1.0000  -4.0003  -1.8191 -5.5912 #> s[3]  0.8764 -0.0799  1.0267  0.0449 -0.4833   6.2841   4.3642  4.3778 #> s[4] -1.0675 -0.1793 -2.2047 -2.5517  1.3806 -16.2235 -18.8212 -3.6213 #> s[5] -0.7212 -0.4139 -2.5557 -4.6404  2.3841 -17.7956 -23.0643 -1.8357 #> x[1]  1.0000  0.0000  0.0000  0.0000  0.0000   1.0000   0.0000  0.0000 #> x[2]  0.0000  1.0000  0.0000  0.0000  0.0000   0.0000   1.0000  0.0000 #> x[3]  0.0000  0.0000  1.0000  0.0000  0.0000   0.0000   0.0000  1.0000 #> Left square root of noise covariance Sigma: #>             u[1]       u[2]     u[3] #> u[1]  0.52953545  0.0000000 0.000000 #> u[2] -0.31786378  0.3060925 0.000000 #> u[3]  0.06273688 -1.0192496 1.099613 flip = function(x) {   x[abs(x) < 1] = 1/x[abs(x) < 1]   return(x)} data.frame(poles.inno = out$p, flipped = out$p_flipped,            poles.ori = p[match_vectors(out$p, p)],            zeroes.inno = out$z, flipped = out$z_flipped,            zeroes.ori = z[match_vectors(out$z, flip(z))]) #>              poles.inno flipped             poles.ori         zeroes.inno #> 1  0.6456403-0.8964543i   FALSE  0.6456403-0.8964543i -1.794715+0.000000i #> 2  0.6456403+0.8964543i   FALSE  0.6456403+0.8964543i  0.858382-1.165176i #> 3 -7.2894009+0.0000000i   FALSE -7.2894009+0.0000000i  0.858382+1.165176i #> 4  3.1405429+0.0000000i    TRUE  0.3184163+0.0000000i -4.113669+0.000000i #> 5 -2.6303566+0.0000000i    TRUE -0.3801766+0.0000000i  2.616040+0.000000i #>   flipped.1           zeroes.ori #> 1     FALSE -1.7947154+0.000000i #> 2     FALSE  0.8583822-1.165176i #> 3     FALSE  0.8583822+1.165176i #> 4      TRUE -0.2430920+0.000000i #> 5      TRUE  0.3822571+0.000000i  # check that the innovation form model describes the same process, # by checking that the spectral density is not changed! junk = spectrald(model, n.f = 128) junk1 = spectrald(out$model, n.f = 128) all.equal(junk, junk1) #> [1] TRUE  # reset seed set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":null,"dir":"Reference","previous_headings":"","what":"Check templates — is.template","title":"Check templates — is.template","text":"Check templates","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check templates — is.template","text":"","code":"is.template(tmpl, class = c(\"any\", \"stspmod\", \"armamod\", \"rmfdmod\"))"},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check templates — is.template","text":"tmpl object tested class test specific class","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check templates — is.template","text":"TRUE/FALSE","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check templates — is.template","text":"","code":"is.template(1) #> [1] FALSE is.template(tmpl_llm(), 'armamod') #> [1] FALSE is.template(tmpl_llm(), 'stspmod') #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":null,"dir":"Reference","previous_headings":"","what":"Kalman Filter — kf","title":"Kalman Filter — kf","text":"functions implement \"standard\" Kalman filter \"square root\" Kalman filter (also called \"square root covariance filter\") time invariant, linear state space systems without exogenous inputs, see e.g. (Anderson Moore 2005) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kalman Filter — kf","text":"","code":"kf_cpp(A, C, Q, R, S, y_t, P1, a1)  kf2_cpp(A, C, H_t, y_t, P1_R, a1)  kf(model, y, method = c(\"kf\", \"kf2\"), P1 = NULL, a1 = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kalman Filter — kf","text":"\\((s,s)\\) dimensional state transition matrix \\(\\). C \\((m,s)\\) dimensional matrix \\(C\\). Q, R, S variance, covariance matrices \"state disturbances\" (\\(Bu_t\\)) \"measurement disturbances\" (\\(Du_t\\)) described . matrices must dimension \\((s,s)\\),  \\((m,m)\\) \\((s,m)\\) respectively. y_t \\((m,N)\\) transposed data matrix y_t = t(y). P1 \\((s,s)\\) dimensional covariance matrix error initial state estimate, .e. \\(\\Pi_{1|0}\\). NULL, state covariance \\(P = APA'+B\\Sigma B'\\) used. Note scheme assumes state space model stable, .e. state transition matrix \\(\\) stable. a1 \\(s\\) dimensional vector, holds initial estimate \\(a_{1|0}\\) state time \\(t=1\\).  a1=NULL, zero vector used. H_t \\((n,s+m)\\) dimensional matrix. parameter corresponds transpose \\(H'\\) \\(H=(D',B')'\\Sigma^{1/2}\\). P1_R (right) square root P1, .e. P1 = t(P1_R) \\%*\\% P1_R. model stspmod() object, represents state space model. y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. method Character string. method=\"kf\" kf calls kf_cpp (\"standard form\" Kalman filter) method=\"kf2\" \"square root\" form Kalman filter used, .e. kf2_cpp called. numerical errors outputs depend chosen method.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kalman Filter — kf","text":"List components e \\((N,m)\\) dimensional matrix standardized one-step ahead prediction errors. \\(t\\)-th row matrix e corresponds $$e_t = \\Sigma_{t|t-1}^{-1/2}\\epsilon_{t|t-1}.$$ model correctly specified standardized residuals white noise unit covariance matrix. may used validaton model. \\((N+1,s)\\) dimensional matrix estimated states. \\(t\\)-th row matrix corresponds \\(a_{t|t-1}\\). Given y , one step ahead predictions \\(y_{t|t-1}\\) may computed yh = \\%*\\% t(C). ll (scaled) Gaussian log likelihood model $$-\\frac{1}{2N}\\sum_{t=1}^{N}\\left(m\\log(2\\pi) + \\log\\det\\Sigma_{t|t-1} +           (y_t - y_{t|t-1})' \\Sigma_{t|t-1}^{-1} (y_t - y_{t|t-1}) \\right).$$ P1 \\((s,s)\\) dimensional covariance matrix error state prediction \\(a_{N+1|N}\\), .e. matrix corresponds \\(\\Pi_{N+1|N}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kalman Filter — kf","text":"model considered $$a_{t+1} = a_t + Bu_t$$ $$y_t = C a_t + Du_t$$ \\(m\\)-dimensional outputs \\(y_t\\), \\(s\\)-dimensional states \\(a_t\\) \\(n\\)-dimensional disturbances \\(u_t\\). disturbances white noise covariance matrix \\(\\mathbf{E} u_tu_t'=\\Sigma\\). Note disturbances outputs may different dimensions, however, \"wide\" systems (\\(m\\leq n\\)) implemented. Kalman filter recursive scheme compute linear, least squares predictions \\(a_{t+1}\\) \\(y_{t+1}\\) given observations \\(y_t,\\ldots,y_1\\) time \\(t\\). predictions notated \\(a_{t+1|t}\\) \\(y_{t+1|t}\\), prediction error output \\(y_{t+1}\\) \\(\\epsilon_{t+1|t}=(y_{t+1}-y_{t+1|t})\\) corresponding variances prediction errors $$\\Pi_{t+1|t}=\\mathbf{E}(a_{t+1}-a_{t+1|t}) (a_{t+1}-a_{t+1|t})',$$ $$\\Sigma_{t+1|t}=\\mathbf{E}(\\epsilon_{t+1|t} \\epsilon_{t+1|t}').$$ standard form Kalman filter based parameter matrices \\(,C\\), variance \"state disturbances\" \\(Q=\\mathbf{E}(Bu_t (Bu_t)')=(B\\Sigma B')\\), variance \"measurement disturbances\" \\(R=\\mathbf{E}(Du_t (Du_t)')=(D\\Sigma D')\\) covariance \\(S=\\mathbf{E}(Bu_t(Du_t)')=(B\\Sigma D')\\). Furthermore need initial prediction \\(a_{1|0}\\) corresponding error variance \\(\\Pi_{1|0}\\). square root form filter need \"square roots\" \\(\\Pi_{1|0}^{1/2}\\) \\(\\Sigma^{1/2}\\), .e. matrices \\(\\Pi_{1|0} = \\Pi_{1|0}^{1/2} (\\Pi_{1|0}^{1/2})'\\) \\(\\Sigma = \\Sigma^{1/2}(\\Sigma^{1/2})'\\). addition, define \\(H=(D',B')'\\Sigma^{1/2}\\). routines kf_cpp, kf2_cpp RcppArmadillo implementations standard form square root form Kalman filter. wrapper function kf takes stspmod() object, describes state space model, calls approriate RcppArmadillo function. Square root Kalman filter: square root \\(\\Pi_{1|0}^{1/2}\\) procedure first tries Cholesky decomposition. fails (since \\(\\Pi_{1|0}^{1/2}\\) (close ) singular), ll_kf tries compute symmetric square root via eigenvalue decomposition \\(\\Pi_{1|0}^{1/2}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Kalman Filter — kf","text":"RcppArmadillo functions (kf_cpp kf2_cpp) check input parameters, function must used care. procedures accept \"wide\" state space systems (\\(m \\leq n\\)), since \"tall\" systems (\\(m > n\\)) variance prediction errors (\\(\\Sigma_{t+1|t}\\)) singular \\(t\\) larger threshold. now, support models exogenous inputs.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kalman Filter — kf","text":"Anderson BDO, Moore JB (2005). Optimal filtering. Dover Publications Inc., London. Originally published: Englewood Cliffs, Prentice-Hall 1979.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kalman Filter — kf","text":"","code":"s = 4  # state dimension m = 2  # number of outputs n = 3  # number of inputs, n.obs = 100 # sample size  # generate a (stable) state space model tmpl = tmpl_stsp_full(m, n, s, sigma_L = \"chol\") model = r_model(tmpl, bpoles = 1, sd = 0.5) # generate a sample data = sim(model, n.obs = n.obs, a1 = NA)  # compute Q, R, S and P1 sigma_L = model$sigma_L sigma = tcrossprod(sigma_L) R = model$sys$D %*% sigma %*% t(model$sys$D) S = model$sys$B %*% sigma %*% t(model$sys$D) Q = model$sys$B %*% sigma %*% t(model$sys$B) P1 = lyapunov(model$sys$A, Q)  # call Kalman filter. Note y_t = t(y)! out = kf_cpp(model$sys$A, model$sys$C, Q, R, S, t(data$y), P1, double(s)) # use the wrapper function out_test = kf(model, data$y, method = 'kf') all.equal(out, out_test) #> [1] TRUE  # compute H and square root of P1 H = rbind(model$sys$D, model$sys$B) %*% sigma_L P1_R = chol(P1)  # call square root Kalman filter. Note H_t = t(H) and y_t = t(y)! out_test = kf2_cpp(model$sys$A, model$sys$C, t(H), t(data$y), P1_R, double(s)) all.equal(out, out_test) #> [1] TRUE # use the wrapper function out_test = kf(model, data$y, method = 'kf2') all.equal(out, out_test) #> [1] TRUE  # The one step ahead predictions for y[t] may be computed by yh = out$a %*% t(model$sys$C) # and the (non scaled) prediction errors are uh = data$y - out$a[1:n.obs,] %*% t(model$sys$C)"},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Likelihood Methods — ll","title":"Log Likelihood Methods — ll","text":"Tools methods computation (conditional exact) Gaussian log-likelihood ARMA, RMFD, state space models. functions serve input optimizers like optim, see ll_theta ll_FUN (latter function factory generates closure serves input).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Likelihood Methods — ll","text":"","code":"ll(obj, y, which, ...)  # S3 method for armamod ll(obj, y, which = c(\"concentrated\", \"conditional\"), skip = 0L, ...)  # S3 method for stspmod ll(   obj,   y,   which = c(\"concentrated\", \"conditional\", \"kf\", \"kf2\"),   skip = 0L,   P1 = NULL,   a1 = NULL,   tol = 1e-08,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Likelihood Methods — ll","text":"obj Object type armamod(), rmfdmod(), stspmod(). y Data sample given \\((N,m)\\) dimensional matrix, \"time series\" object (sense .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. (character) likelihood compute. ... used. skip (integer) skip initial observations. parameter used, (concentrated) conditional likelihood computed. P1 \\((s,s)\\) dimensional covariance matrix error initial state estimate. NULL state covariance \\(P=APA'+B\\Sigma B'\\) used. parameter used, (exact) likelihood computed via Kalman Filter. See ll_kf() details. a1 \\(s\\) dimensional vector, holds initial estimate state time t=1. a1=NULL, zero vector used. parameter used, (exact) likelihood computed via Kalman Filter. See ll_kf() details. tol (small) tolerance value (zero) used Kalman Filter routines, see ll_kf().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Likelihood Methods — ll","text":"(double) (scaled) log Likelihood model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Likelihood Methods — ll","text":"procedure three choices ... ARMA model $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + b_1 u_{t-1} + \\cdots + b_q u_{t-q}$$ Gaussian noise \\(u_t \\sim N(0,\\Sigma)\\) approximation scaled log likelihood $$ll = -(1/2)(m \\ln(2\\pi) + \\mathrm{tr}(S\\Sigma^{-1}) + \\ln\\det \\Sigma + 2 \\ln\\det (a_0^{-1}b_0)$$ \\(S\\) denotes sample covariance residuals model $$S=\\frac{1}{N-s}\\sum_{t=s+1}^N e_t e_t'$$ residuals computed sample \\(y_t, t=1,\\ldots,N\\) solving (inverse) ARMA system $$b_0 e_t = -b_1 e_{t-1} - \\cdots - b_q e_{t-q} + a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p}$$ setting unknown initial values \\(y_t=0\\) \\(e_t=0\\) \\(t\\leq 0\\) equal zero. See e.g. solve_inverse_de(). Note log Likelihood scaled factor \\(1/(N-s)\\) first \\(s\\) observations skipped computing sample covariance matrix. log-likelihood may easily maximized respect noise covariance matrix \\(\\Sigma\\). given \\(S\\), optimal value \\(\\Sigma\\) \\(\\Sigma=S\\). plug maximizer log-likelihood function, obtain \"concentrated\" log likelihood function $$cll = -(1/2)(m \\ln(2\\pi) + m + \\ln\\det S + 2 \\ln\\det (a_0^{-1}b_0)$$ depends sample y ARMA parameter matrices \\(a_i\\) \\(b_i\\). state space models (approximate) log likelihood computed quite analogously.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Log Likelihood Methods — ll","text":"precise, functions returns \\(1/(N-s)\\) times (approximate) log likelihood. routines handle case centered data, .e. assumed output process \\((y_t)\\) mean zero! computation concentrated log likelihood assumes model structure impose restrictions noise covariance matrix.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Likelihood Methods — ll","text":"","code":"# Generate a random model in echelon form model (m = 3) tmpl = tmpl_arma_echelon(nu = c(2,1,1)) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> ARMA model [3,3] with orders p = 2 and q = 2 #> AR polynomial a(z): #>        z^0 [,1]  [,2]  [,3]    z^1 [,1]       [,2]         [,3]   z^2 [,1] #> [1,]  1.0000000     0     0  0.08448339  0.0000000  0.000000000 -0.4141014 #> [2,] -0.3856640     1     0 -0.15327281 -0.1088607 -0.136751717  0.0000000 #> [3,]  0.0714508     0     1 -0.06411667 -0.3132063 -0.000992856  0.0000000 #>           [,2]        [,3] #> [1,] 0.1820221 -0.04632626 #> [2,] 0.0000000  0.00000000 #> [3,] 0.0000000  0.00000000 #> MA polynomial b(z): #>        z^0 [,1]  [,2]  [,3]    z^1 [,1]       [,2]       [,3]   z^2 [,1] #> [1,]  1.0000000     0     0 -0.05355525  0.2364363 -0.2012077 -0.1646539 #> [2,] -0.3856640     1     0 -0.45286392 -0.3274492  0.2182757  0.0000000 #> [3,]  0.0714508     0     1  0.07322411  0.0407279 -0.3713920  0.0000000 #>            [,2]       [,3] #> [1,] -0.1299437 0.01622099 #> [2,]  0.0000000 0.00000000 #> [3,]  0.0000000 0.00000000 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] u[3] #> u[1]  1.0000000 0.0000000    0 #> u[2] -0.2220585 1.0000000    0 #> u[3]  0.0508879 0.2268728    1 # extract the corresponding free/deep parameters th = extract_theta(model, tmpl)  # generate a sample with 50 observations y = sim(model, n.obs = 50, n.burn_in = 100)$y  # conditional log likelihood # the following statements return the same ll value! ll(model, y, which = 'conditional', skip = 0) #> [1] -4.35286 ll_theta(th, template= tmpl, y, which = 'conditional', skip = 0) #> [1] -4.35286 llfun = ll_FUN(tmpl, y, which = 'conditional', skip = 0) llfun(th) #> [1] -4.35286  # concentrated, conditional log likelihood # the following statements return the same ll value! ll(model, y, which = 'concentrated', skip = 0) #> [1] -4.279185 ll_theta(th, template= tmpl, y, which = 'concentrated', skip = 0) #> [1] -4.279185 llfun = ll_FUN(tmpl, y, which = 'concentrated', skip = 0) llfun(th) #> [1] -4.279185"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Likelihood Function Factory — ll_FUN","title":"Log Likelihood Function Factory — ll_FUN","text":"Creates function similar ll_theta() faster memory efficient. model structure (template) data (y) encoded within generated closure (function plus enclosing environment). generated function calls compiled C/C++ code (see RcppArmadillo-package) hence much faster calling ll_theta(th, template, y, ...).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Likelihood Function Factory — ll_FUN","text":"","code":"ll_FUN(   template,   y,   which = c(\"concentrated\", \"conditional\", \"kf\", \"gr_concentrated\"),   skip = 0L,   tol = 1e-08,   err = NA_real_ )"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Likelihood Function Factory — ll_FUN","text":"template model template, see model structures. y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. (string) Determines type ll function. skip (integer) skip initial observations. NULL skip set \\(0\\) state space models \\(\\max(p,q)\\) ARMA models. parameter used cases \"concentrated\", \"conditional\" \"gr_concentrated\" tol (double) tolerance used ll_kf_cpp(). err (double) return value case \"kf\", computation initial state covariance fails.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Likelihood Function Factory — ll_FUN","text":"function, llfun(th) say, computes log-likelihood given deep parameters th. function may used ML estimation model. Function fn(th)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Likelihood Function Factory — ll_FUN","text":"","code":"# Generate a random model in echelon form model (m = 3) tmpl = tmpl_stsp_echelon(nu = c(2,1,1)) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> state space model [3,3] with s = 4 states #>            s[1]       s[2]        s[3]        s[4]       u[1]        u[2] #> s[1]  0.0000000  0.0000000  0.00000000  1.00000000  0.3046160  0.03037297 #> s[2] -0.3438114  0.1515971 -0.05836958 -0.03203265 -0.1934661  0.10434524 #> s[3] -0.2445186 -0.1554902  0.10672828 -0.18047795 -0.2976453 -0.51320957 #> s[4]  0.1679769 -0.2817961 -0.17701883  0.28870462 -0.4841110 -0.15506802 #> x[1]  1.0000000  0.0000000  0.00000000  0.00000000  1.0000000  0.00000000 #> x[2]  0.0000000  1.0000000  0.00000000  0.00000000  0.0000000  1.00000000 #> x[3]  0.0000000  0.0000000  1.00000000  0.00000000  0.0000000  0.00000000 #>            u[3] #> s[1] -0.3014446 #> s[2] -0.3404946 #> s[3] -0.1908577 #> s[4]  0.2265720 #> x[1]  0.0000000 #> x[2]  0.0000000 #> x[3]  1.0000000 #> Left square root of noise covariance Sigma: #>             u[1]      u[2] u[3] #> u[1]  1.00000000 0.0000000    0 #> u[2]  0.01445972 1.0000000    0 #> u[3] -0.07442579 0.2082845    1 # extract the corresponding free/deep parameters th = extract_theta(model, tmpl)  # generate a sample with 50 observations y = sim(model, n.obs = 50)$y  # conditional log likelihood # the following statements return the same ll value! ll(model, y, 'conditional') #> [1] -3.929065 ll_theta(th, tmpl, y, 'conditional') #> [1] -3.929065 fn = ll_FUN(tmpl, y, 'conditional') fn(th) #> [1] -3.929065  # concentrated conditional log likelihood # the following statements return the same ll value! ll(model, y, 'concentrated') #> [1] -3.786622 ll_theta(th, tmpl, y, 'concentrated') #> [1] -3.786622 fn = ll_FUN(tmpl, y, 'concentrated') fn(th) #> [1] -3.786622 # for this case, we may also compute the (analytic) gradient gr = ll_FUN(tmpl, y, 'gr_concentrated') gr(th) #>  [1]  0.142786767  0.347836126  0.035396420  0.042796589 -0.007547839 #>  [6]  0.049341668 -0.204785898 -0.314598249  0.165886461  0.001166772 #> [11]  0.115291105 -0.274694737  0.379539598 -0.256496398 -0.159986081 #> [16]  0.141186020 -0.019388085  0.094634317 -0.113961830 -0.933181036 #> [21]  0.190737356 -0.010627109  0.007006018 -0.400099144  0.000000000 #> [26]  0.000000000  0.000000000  0.000000000  0.000000000  0.000000000  # log likelihood (via Kalman filter) # the following statements return the same ll value! ll(model, y, 'kf2') #> [1] -3.944378 ll_theta(th, tmpl, y, 'kf2') #> [1] -3.944378 ll(model, y, 'kf') #> [1] -3.944378 ll_theta(th, tmpl, y, 'kf') #> [1] -3.944378 fn = ll_FUN(tmpl, y, 'kf') fn(th) #> [1] -3.944378"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian log Likelihood of a State Space Model — ll_kf","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"routines compute log Likelihood time invariant, linear state space models form $$a_{t+1} = a_t + Bu_t$$ $$y_t = C a_t + Du_t$$ \\(m\\)-dimensional outputs \\(y_t\\), \\(s\\)-dimensional states \\(a_t\\) \\(n\\)-dimensional disturbances \\(u_t\\). disturbances white noise covariance matrix \\(\\mathbf{E} u_t u_t'=\\Sigma\\). Note disturbances outputs may different dimensions, however, \"wide\" systems (\\(m\\leq n\\)) implemented. Gaussian log likelihood (case Gaussian disturbances \\(u_t\\sim N(0,\\Sigma)\\) \\(a_1\\sim N(a_{1|0},\\Pi_{1|0})\\)) computed standard Kalman Filter square root Kalman filter, see kf(). Kalman filter recursive scheme compute linear, least squares predictions \\(a_{t+1}\\) \\(y_{t+1}\\) given observations \\(y_t,\\ldots,y_1\\) time \\(t\\). predictions notated \\(a_{t+1|t}\\) \\(y_{t+1|t}\\), prediction error output \\(y_{t+1}\\) \\(\\epsilon_{t+1|t}=(y_{t+1}-y_{t+1|t})\\) corresponding variances prediction errors $$\\Pi_{t+1|t}=\\mathbf{E}(a_{t+1}-a_{t+1|t}) (a_{t+1}-a_{t+1|t})',$$ $$\\Sigma_{t+1|t}=\\mathbf{E}(\\epsilon_{t+1|t} \\epsilon_{t+1|t}').$$ standard form Kalman filter based parameter matrices \\(,C\\), variance \"state disturbances\" \\(Q=\\mathbf{E}(Bu_t (Bu_t)')=(B\\Sigma B')\\), variance \"measurement disturbances\" \\(R=\\mathbf{E}(Du_t (Du_t)')=(D\\Sigma D')\\) covariance \\(S=\\mathbf{E}(Bu_t(Du_t)')=(B\\Sigma D')\\). Furthermore need initial prediction \\(a_{1|0}\\) corresponding error variance \\(\\Pi_{1|0}\\). square root form filter need \"square roots\" \\(\\Pi_{1|0}^{1/2}\\) \\(\\Sigma^{1/2}\\), .e. matrices \\(\\Pi_{1|0} = \\Pi_{1|0}^{1/2} (\\Pi_{1|0}^{1/2})'\\) \\(\\Sigma = \\Sigma^{1/2}(\\Sigma^{1/2})'\\). addition, define \\(H=(D',B')'\\Sigma^{1/2}\\). (scaled) Gaussian log Likelihood model may expressed $$\\frac{-1}{2N}\\sum_{t=1}^{N}\\left(m\\log(2\\pi) + \\log\\det\\Sigma_{t|t-1} +           (y_t - y_{t|t-1})' \\Sigma_{t|t-1}^{-1} (y_t - y_{t|t-1}) \\right).$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"","code":"ll_kf_cpp(A, C, Q, R, S, y_t, P1, a1, tol)  ll_kf2_cpp(A, C, H_t, y_t, P1_R, a1, tol)  ll_kf(model, y, method = c(\"kf\", \"kf2\"), P1 = NULL, a1 = NULL, tol = 0)"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"\\((s,s)\\) dimensional state transition matrix \\(\\). C \\((m,s)\\) dimensional matrix \\(C\\). Q, R, S variance, covariance matrices \"state disturbances\" (\\(Bu_t\\)) \"measurement disturbances\" (\\(Du_t\\)) described . matrices must dimension \\((s,s)\\),  \\((m,m)\\) \\((s,m)\\) respectively. y_t \\((m,N)\\) transposed data matrix y_t = t(y). P1 \\((s,s)\\) dimensional covariance matrix error initial state estimate, .e. \\(\\Pi_{1|0}\\). NULL, state covariance \\(P = APA'+B\\Sigma B'\\) used. Note scheme assumes state space model stable, .e. state transition matrix \\(\\) stable. a1 \\(s\\) dimensional vector, holds initial estimate \\(a_{1|0}\\) state time \\(t=1\\).  a1=NULL, zero vector used. tol (small) tolerance value (zero). order speed computations, algorithm(s) switch constant Kalman gain significant change state error covariance. behavior controlled parameter tol may switched setting tol=0. H_t \\((n,s+m)\\) dimensional matrix. parameter corresponds transpose \\(H'\\) \\(H=(D',B')'\\Sigma^{1/2}\\). P1_R (right) square root P1, .e. P1 = t(P1_R) \\%*\\% P1_R. model stspmod() object, represents state space model. y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. method Character string. method=\"kf\" ll_kf calls ll_kf_cpp (\"standard form\" Kalman filter) method=\"kf2\" \"square root\" form Kalman filter used, .e. ll_kf2_cpp called. numerical errors outputs depend chosen method.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"(double) Gaussian log Likelihood model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"core routines  ll_kf_cpp ll_kf2_cpp RcppArmadillo implementations standard square root Kalman filter. function ll_kf wrapper function, extracts necessary parameters stspmod() object, computes initial covariance matrix P1 initial state estimate a1 (provided) calls ll_kf_cpp ll2_kf_cpp. Square root Kalman filter: square root \\(\\Pi_{1|0}^{1/2}\\) procedure first tries Cholesky decomposition. fails (since \\(\\Pi_{1|0}^{1/2}\\) (close ) singular), ll_kf tries compute symmetric square root via eigenvalue decomposition \\(\\Pi_{1|0}^{1/2}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"procedures accept \"wide\" state space systems (\\(m \\leq n\\)), since \"tall\" systems (\\(m > n\\)) variance prediction errors (\\(\\Sigma_{t+1|t}\\)) singular \\(t\\) larger threshold.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"","code":"s = 4  # state dimension m = 2  # number of outputs n = m  # number of inputs (square case m=n) n.obs = 100 # sample size  # generate a (stable) state space model (in innovation form) tmpl = tmpl_stsp_full(m, n, s, sigma_L = \"chol\") model = r_model(tmpl, bpoles = 1, sd = 0.5) # generate a sample data = sim(model, n.obs = n.obs, a1 = NA)  # compute Q, R, S and P1 sigma_L = model$sigma_L sigma = tcrossprod(sigma_L) R = model$sys$D %*% sigma %*% t(model$sys$D) S = model$sys$B %*% sigma %*% t(model$sys$D) Q = model$sys$B %*% sigma %*% t(model$sys$B) P1 = lyapunov(model$sys$A, Q)  # compute H and square root of P1 H = rbind(model$sys$D, model$sys$B) %*% sigma_L P1_R = chol(P1)  # compute logLikelihood (via Kalman Filter) ll = ll_kf(model, data$y)  # compute logLikelihood (via square root Kalman Filter) ll_test = ll_kf(model, data$y, method = 'kf2') all.equal(ll, ll_test) #> [1] TRUE  # directly call Rcpp routines, note H_t = t(H) and y_t = t(y) ll_test = ll_kf_cpp(model$sys$A, model$sys$C, Q, R, S,                     t(data$y), P1, a1 = double(s), tol=1e-8) all.equal(ll, ll_test) #> [1] TRUE ll_test = ll_kf2_cpp(model$sys$A, model$sys$C, t(H),                      t(data$y), P1_R, a1 = double(s), tol=1e-8) all.equal(ll, ll_test) #> [1] TRUE  # call the \"full\" kf routines out = kf(model, data$y) all.equal(ll, out$ll) #> [1] TRUE out = kf(model, data$y, method = 'kf2') all.equal(ll, out$ll) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf_theta_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the log likelihood for a statespace system\ndescribed by a model template. — ll_kf_theta_cpp","title":"Compute the log likelihood for a statespace system\ndescribed by a model template. — ll_kf_theta_cpp","text":"internal helper function, used function factory ll_FUN. detailed documentation log Likelihood, see ll_kf.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf_theta_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the log likelihood for a statespace system\ndescribed by a model template. — ll_kf_theta_cpp","text":"","code":"ll_kf_theta_cpp(   theta,   y,   SYS,   H_SYS,   h_SYS,   sigma_L,   H_sigma_L,   h_sigma_L,   VAR,   P1,   tol,   err )"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf_theta_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the log likelihood for a statespace system\ndescribed by a model template. — ll_kf_theta_cpp","text":"theta \\((K)\\) dimensional vector \"deep\" parameters. y \\((m,N)\\) matrix observed outputs: \\((y_1,y_2,\\ldots,y_N)\\). SYS \\((m+s,m+s)\\) matrix, overwritten system matrix \\([,B | C,D]\\). H_SYS \\((m+s)^2, K)\\) matrix. h_SYS \\(((m+s)^2)\\)-dimensional vector. Note vec(SYS) = H_SYS*theta + h_SYS. sigma_L \\((m,m)\\) matrix, overwritten left square root noise covariance matrix. H_sigma_L \\((m^2, K)\\) matrix. h_sigma_L \\((m^2)\\)-dimensional vector. Note vec(sigma_L) = H_sigma_L*theta + h_sigma_L. VAR \\((m+s,m+s)\\) matrix, overwritten covariance matrix \\([Q,S | S',R] = [B | C] sigma_L sigma_L' [B', C']\\) P1 \\((s,s)\\) matrix, overwritten initial state covariance matrix (computed via Lyapunov equation). tol (double) tolerance used ll_kf_cpp. err (double) return err, computation P1 fails.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_theta.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-likelihood Given Deep Parameters — ll_theta","title":"Log-likelihood Given Deep Parameters — ll_theta","text":"See ll_FUN(). template template filled deep parameters th. Subsequently, S3 method ll() called class provided template value scaled log-likelihood function returned, see ll().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_theta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-likelihood Given Deep Parameters — ll_theta","text":"","code":"ll_theta(th, template, y, which, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_theta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-likelihood Given Deep Parameters — ll_theta","text":"th Vector deep parameter template model template, see model structures. y Data sample given \\((N,m)\\) dimensional matrix, \"time series\" object (sense .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. (character) likelihood compute. ... used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_theta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-likelihood Given Deep Parameters — ll_theta","text":"Value log-likelihood given deep/free parameter vector th model structure defined via template. Note function simply calls ll(fill_template(th, template), y, , ...).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":null,"dir":"Reference","previous_headings":"","what":"Local Model Structures — local model structures","title":"Local Model Structures — local model structures","text":"Parametrization \"local\" model classes, particular, \"Data Driven Local Coordinates\" detailed (McKelvey et al. 2004)  (Ribarits et al. 2005) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local Model Structures — local model structures","text":"","code":"tmpl_DDLC(   model,   balance = c(\"none\", \"lyapunov\", \"minimum phase\"),   sigma_L = c(\"chol\", \"symm\", \"identity\") )  tmpl_GRAM(   model,   balance = c(\"lyapunov\", \"minimum phase\"),   sigma_L = c(\"chol\", \"symm\", \"identity\") )"},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local Model Structures — local model structures","text":"model stspmod() object, represents state space model. case \\(m = n > 0\\) implemented, .e. output process noise process must dimension. balance (character string) balance = \"lyapunov\" balance = \"minimum phase\" reference model first balanced respective scheme. sigma_L (character string) determines form (left) square root noise covariance \\(\\Sigma\\). choice \"chol\" gives lower triangular matrix, \"symm\" gives symmetric matrix \"identity\" corresponds (fixed) identity matrix.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local Model Structures — local model structures","text":"Model template, .e. list slots h \\(((m+s)^2 + m^2)\\)-dimensional vector, H \\(((m+s)^2 + m^2, k)\\)-dimensional matrix, class = \"stspmod\"  order = c(m,m,s) n.par number free parameters \\(=k\\). See also model structures() details.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Local Model Structures — local model structures","text":"function tmpl_DDLC tmpl_GRAM construct model templates describe models neighborhood given reference model. first step reference state space model transformed \\(D=\\) eventually (depending parameter \"balance\") balanced. state space models described quadruple \\((,B,C,D=)\\) matrices may embedded \\((s^2+2ms)\\)-dimensional euclidean space. Note parameter matrices uniqely determined ACF spectral density process, .e. inherent non identifiablity problem. minimal models \"equivalence class\" models, represent ACF given set models may obtained state transformation \\((,B,C,D) \\rightarrow (TAT^{-1}, TB, CT^{-1}, D)\\). DDLC parametrization now considers models, \\((,B,C,D=)\\), contained \\(2ms\\)-dimensional subspace, orthogonal \\(s^2\\)-dimensional tangent space set equivalent models. routine tmpl_GRAM considers \\(2ms\\)-dimensional subspace, models close reference models \"approximately\" balanced. schemes may fail \"non-generic\" models. tmpl_DDLC issues warning message tmpl_GRAM throws error, cases \\(2ms\\)-dimensional subspace well defined. Note also parametrization left square root L=sigma_L noise covariance \"local\", .e. th = 0 corresponds (balanced) reference model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Local Model Structures — local model structures","text":"McKelvey T, Helmersson , Ribarits T (2004). “Data driven local coordinates multivariable linear systems application system identification.” Automatica, 40(9), 1629 - 1635. doi:10.1016/j.automatica.2004.04.015 . Ribarits T, Deistler M, Hanzon B (2005). “analysis separable least squares data driven local coordinates maximum likelihood estimation linear systems.” Automatica, 41(3), 531 - 544. doi:10.1016/j.automatica.2004.11.014 . .","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local Model Structures — local model structures","text":"","code":"# create a random state space model with m outputs and s states m = 3 s = 6 tmpl = tmpl_stsp_full(m, n = m, s, sigma_L = 'symm') model = r_model(tmpl, bpoles = 1.1, bzeroes = 1.1, sd = 1/s) model                              # note that sigma_L is symmetric #> state space model [3,3] with s = 6 states #>              s[1]         s[2]        s[3]        s[4]        s[5]        s[6] #> s[1]  0.089170406 -0.113583007 -0.08534516  0.07345925 -0.32113716 -0.37636204 #> s[2]  0.050617524  0.002597294 -0.23049788 -0.09591797  0.07181313 -0.01964554 #> s[3]  0.137009726  0.028130849 -0.16237488 -0.32976592 -0.34502203 -0.09075780 #> s[4]  0.146741275  0.143457436  0.05988445 -0.33080591 -0.29787476  0.12287870 #> s[5]  0.155693300 -0.026457687 -0.30828497 -0.03214173 -0.20115998  0.22725343 #> s[6]  0.009843577 -0.059517130  0.19287530  0.02157084  0.03784017  0.01545729 #> x[1]  0.156326736  0.043901800  0.26992981 -0.10541464  0.12226969 -0.08441109 #> x[2]  0.022358298  0.024989022 -0.08931110 -0.10472402 -0.08170961  0.13421056 #> x[3] -0.023723847 -0.030429082 -0.16513318  0.22703657  0.02073049  0.12747639 #>             u[1]         u[2]         u[3] #> s[1] -0.11083757  0.006480965  0.015798248 #> s[2]  0.05345173  0.030511370  0.204877246 #> s[3] -0.38665976  0.336508384 -0.226351502 #> s[4] -0.08547036 -0.181845694 -0.002862948 #> s[5]  0.41167787  0.004484637 -0.228938906 #> s[6] -0.05318243  0.266320573 -0.092821093 #> x[1]  1.00000000  0.000000000  0.000000000 #> x[2]  0.00000000  1.000000000  0.000000000 #> x[3]  0.00000000  0.000000000  1.000000000 #> Left square root of noise covariance Sigma: #>            u[1]      u[2]       u[3] #> u[1] 0.03788468 0.1260367  0.0159517 #> u[2] 0.12603666 0.1124376  0.1815486 #> u[3] 0.01595170 0.1815486 -0.2035826 model$sigma_L %*% t(model$sigma_L) # noise covariance Sigma #>            [,1]        [,2]        [,3] #> [1,] 0.01757495  0.02184213  0.02023862 #> [2,] 0.02184213  0.06148736 -0.01453675 #> [3,] 0.02023862 -0.01453675  0.07466024  # tmpl_DDLC #############################################  # create a DDLC parametrization of a neighborhood of this model tmpl = tmpl_DDLC(model, balance = 'lyapunov', sigma_L = 'chol') # for th = 0, we get the original model (in balanced form) model = fill_template(numeric(tmpl$n.par), tmpl) model                                # note that sigma_L is lower triangular #> state space model [3,3] with s = 6 states #>             s[1]        s[2]        s[3]        s[4]        s[5]          s[6] #> s[1] -0.42078466  0.31842083 -0.33132621 -0.00312448  0.09373145  0.0317003753 #> s[2] -0.05564299 -0.60140383 -0.14988692  0.24285315  0.05876830  0.0785105762 #> s[3]  0.30364690 -0.08528275  0.27785879 -0.07130312 -0.02243955  0.1801709987 #> s[4] -0.16351607 -0.18406463  0.17892100  0.40904913  0.39083510 -0.1077564826 #> s[5] -0.08071526 -0.03318397 -0.31481124 -0.34436618 -0.27009481  0.1699509894 #> s[6]  0.02000633 -0.11557636 -0.03853533 -0.07993842 -0.12447276  0.0182596088 #> x[1] -0.34854902 -0.00256313  0.06135984  0.03777278 -0.06290516 -0.0008967098 #> x[2]  0.03784979 -0.15235143 -0.12086595 -0.01740589 -0.05146352 -0.0193669451 #> x[3]  0.18329171  0.15421846 -0.03470489  0.09362047 -0.05679321  0.0033448529 #>             u[1]         u[2]        u[3] #> s[1]  0.14940109 -0.279007117  0.21341150 #> s[2]  0.12499489 -0.122522035 -0.18544529 #> s[3] -0.08361661 -0.136989844  0.03256161 #> s[4] -0.07093163  0.003021427  0.03058354 #> s[5] -0.07468612 -0.018548239 -0.02062510 #> s[6]  0.01190673  0.015066660  0.03545149 #> x[1]  1.00000000  0.000000000  0.00000000 #> x[2]  0.00000000  1.000000000  0.00000000 #> x[3]  0.00000000  0.000000000  1.00000000 #> Left square root of noise covariance Sigma: #>           u[1]       u[2]      u[3] #> u[1] 0.1325705  0.0000000 0.0000000 #> u[2] 0.1647586  0.1853159 0.0000000 #> u[3] 0.1526630 -0.2141710 0.0740609 model$sigma_L %*% t(model$sigma_L)  # however Sigma is the same as above #>            [,1]        [,2]        [,3] #> [1,] 0.01757495  0.02184213  0.02023862 #> [2,] 0.02184213  0.06148736 -0.01453675 #> [3,] 0.02023862 -0.01453675  0.07466024  #' apply a \"small\" state transformation T = (diag(s)+eps*X) eps = sqrt(.Machine$double.eps) sys = model$sys d_sys = state_trafo(sys, diag(s) + matrix(rnorm(s^2, sd = eps), nrow = s, ncol = s)) d_pi = (as.vector(unclass(d_sys) - unclass(sys)))/eps # The vector d_pi is (close to) an element of the tangent space # of the set of models, which are generated by a state transformation # of the reference model  # by construction d_pi is (close to) orthogonal to tmpl$H max(abs(d_pi %*% tmpl$H[1:((m+s)^2), , drop = FALSE])) #> [1] 5.590316e-08  # the tmpl_DDLC routine may fail in some exceptional cases m = 1 s = 3 model = stspmod(sys = stsp(A = matrix(0, nrow = s, ncol = s),                            B = matrix(rnorm(m*s), nrow = s, ncol = m),                            C = matrix(rnorm(m*s), nrow = m, ncol = s),                            D = diag(m)),                 sigma_L = diag(m))  # For this model \"tmpl_DLLC\" issues a warning. junk = tmpl_DDLC(model, sigma_L = 'chol', balance = 'none') #> Warning: The tangent space of the equivalence class does not have dimension s^2=9 (sv[1]=2.86391673114514, sv[9]=1.90928224295154e-17)  # tmpl_GRAM ############################################# model = fill_template(numeric(tmpl$n.par), tmpl)  tmpl = tmpl_GRAM(model, sigma_L = 'chol') model = fill_template(numeric(tmpl$n.par), tmpl)  # check grammians gr = grammians(model$sys, 'lyapunov') P = gr$P Q = gr$Q # P=Q=diag() should hold! print(round(cbind(P, P-Q), 6)) #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6] [,7] [,8] [,9] [,10] #> [1,] 0.197055 0.000000 0.000000 0.000000 0.000000 0.000000    0    0    0     0 #> [2,] 0.000000 0.106821 0.000000 0.000000 0.000000 0.000000    0    0    0     0 #> [3,] 0.000000 0.000000 0.049855 0.000000 0.000000 0.000000    0    0    0     0 #> [4,] 0.000000 0.000000 0.000000 0.022886 0.000000 0.000000    0    0    0     0 #> [5,] 0.000000 0.000000 0.000000 0.000000 0.016729 0.000000    0    0    0     0 #> [6,] 0.000000 0.000000 0.000000 0.000000 0.000000 0.003612    0    0    0     0 #>      [,11] [,12] #> [1,]     0     0 #> [2,]     0     0 #> [3,]     0     0 #> [4,]     0     0 #> [5,]     0     0 #> [6,]     0     0  # now consider a model close to the reference model d_th = rnorm(tmpl$n.par, sd = eps) d_model = fill_template(d_th, tmpl) d_sys = d_model$sys gr = grammians(d_sys, 'lyapunov') d_P = gr$P - P d_Q = gr$Q - Q  # the \"disturbed\" system should still be approximately balanced! print(round(cbind(d_P, d_P - d_Q)/eps, 6) ) #>          [,1]    [,2]     [,3]     [,4]     [,5]     [,6] [,7] [,8] [,9] [,10] #> [1,] 0.578336 0.00000 0.000000 0.000000 0.000000 0.000000    0    0    0     0 #> [2,] 0.000000 0.52786 0.000000 0.000000 0.000000 0.000000    0    0    0     0 #> [3,] 0.000000 0.00000 0.218888 0.000000 0.000000 0.000000    0    0    0     0 #> [4,] 0.000000 0.00000 0.000000 0.050486 0.000000 0.000000    0    0    0     0 #> [5,] 0.000000 0.00000 0.000000 0.000000 0.185068 0.000000    0    0    0     0 #> [6,] 0.000000 0.00000 0.000000 0.000000 0.000000 0.052806    0    0    0     0 #>      [,11] [,12] #> [1,]     0     0 #> [2,]     0     0 #> [3,]     0     0 #> [4,]     0     0 #> [5,]     0     0 #> [6,]     0     0"},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Structures — model structures","title":"Model Structures — model structures","text":"tools define implement model structures model parameters represented affine function free (deep) parameters. example consider multivariate ARMA models. AR coefficients \\(a_k\\), MA coefficients \\(b_k\\) (left) square root noise covariance matrix, \\(L\\) say, vectorized stacked (long) parameter vector $$\\pi = (\\mbox{vec}(a_1)',\\ldots,\\mbox{vec}(a_p)',              \\mbox{vec}(b_1)',\\ldots,\\mbox{vec}(b_q)',\\mbox{vec}(L)')'$$ parameter vector written $$\\pi = h + H\\theta$$ \\(\\theta\\) represents free parameters. course matrix \\(H\\) assumed full column rank. parameterization scheme quite flexible. particular, ARMA state space models echelon form may represented scheme.  Templates related tools mainly used estimation generation (random) models simulations testing.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Structures — model structures","text":"","code":"model2template(   model,   sigma_L = c(\"as_given\", \"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_arma_pq(   m,   n,   p,   q,   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_arma_echelon(   nu,   n = length(nu),   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_rmfd_pq(   m,   n,   p,   q,   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_rmfd_echelon(   nu,   m = length(nu),   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_stsp_full(   m,   n,   s,   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_stsp_ar(m, p, sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\"))  tmpl_stsp_echelon(   nu,   n = length(nu),   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )"},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Structures — model structures","text":"model armamod(), rmfdmod() stspmod() object. sigma_L (character string) determines form (left) square root noise covariance \\(\\Sigma\\). choice \"chol\" gives lower triangular matrix, \"symm\" gives symmetric matrix \"identity\" corresponds fixed (identity) matrix.  procedure model2template additional option \"as_given\" means structure square root sigma_L completely determined sigma_L slot given model. m output dimension n input dimension (= number shocks = dimension noise process) p order AR polynomial ARMA models, respectively order right factor polynomial \\(c(z)\\) RMFD model. q order MA polynomial ARMA models, respectively order left factor polynomial \\(d(z)\\) RMFD model. nu vector Kronecker indices. ARMA models Kronecker indices describe basis rows RMFD models basis columns Hankel matrix impulse response coefficients. s state dimension state space models.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Structures — model structures","text":"functions model2template tmpl_*** return model template.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Structures — model structures","text":"functions model2template tmpl_*** generate model \"templates\" represent certain model structures, model parameters affine functions free, respectively deep, parameters. template contains information model structure following slots h, H represent vector \\(h\\) marix \\(H\\) described . (vector \\(\\pi\\) stacked model parameters represented \\(\\pi = h +H \\theta\\) \\(\\theta\\) vector deep parameters.) class=[\"armamod\"|\"rmfdmod\"|\"stspmod\"]: determines whether template parametrizes ARMA, RMFD state space models. order: integer vector contains dimensions orders model. ARMA RMFD models order = c(m,n,p,q) state space models order = c(m,n,s). n.par: number free parameters, .e. dimension vector \\(\\theta\\). nu: optional slot contains Kronecker indices \\(\\nu\\). model2template: function model2template() takes armamod(), rmfdmod(), stspmod() object free parameters coded NA's, NaN's Inf's constructs corresponding model template. parametrization (left) square root, \\(L\\) say, noise covariance \\(\\Sigma = LL'\\) following choices possible: case sigma_L = \"as_given\" slot model$sigma_L given model used construct template: NA entries considered free entries fixed. choice sigma_L = \"chol\" first entries model$sigma_L diagonal set zero template constructed . case sigma_L = \"symm\" matrix  model$sigma_L first replaced symmetric one template constructed (according NA's) square root L=sigma_L always symmetric. choice sigma_L = \"identity\" sets matrix L = sigma_L identity matrix. Finally, choice sigma_L = \"full_normalized\" sets diagonal elements equal ones elements NAs L = sigma_L. tmpl_:* functions tmpl_*** implement following model structures: tmpl_arma_pq ARMA models (armamod()) prescribed orders \\((p,q\\)). tmpl_arma_echelon ARMA models (armamod()) echelon form, given Kronecker indices \\(\\nu\\). tmpl_rmfd_pq RMFD models (rmfdmod()) prescribed orders \\((p,q\\)). tmpl_rmfd_echelon RMFD models (rmfdmod()) echelon form, Kronecker indices \\(\\nu\\). Note RMFD models Kronecker indices refer basis column space Hankel matrix impulse response coefficients. tmpl_stsp_full Fully parametrized state space models (stspmod()) given state space dimension \\(s\\), .e. models entry matrices \\(,B,C\\) considered non-fixed. tmpl_stsp_echelon State space models (stspmod()) echelon form, given Kronecker indices \\(\\nu\\). tmpl_state space_ar State space model representations (stspmod()) AR models given order \\(p\\). \"square\" case \\(m=n\\) implemented. model structures impulse response (transfer function) scaled \\((m,n)\\)-dimensional lag zero coefficient, \\(k_0\\) say, form \\(m=n\\) \\(k_0\\) \\(m\\)-dimensional identity matrix. \\(m<n\\) first \\(m\\) columns \\(k_0\\) form \\(m\\)-dimensional identity matrix remaining columns zero. \\(m>n\\) first \\(n\\) rows \\(k_0\\) form \\(n\\)-dimensional identity matrix remaining rows free. parametrization (left) square root \\(L\\) noise covariance \\(\\Sigma = LL'\\) following choices possible: sigma_L=\"chol\" matrix \\(L\\) lower triangular (entries main diagonal considered free entries diagonal zero). sigma_L=\"symm\" matrix \\(L\\) symmetric (entries main diagonal considered free entries diagonal \\(L=L'\\) holds). sigma_L=\"identity\" matrix \\(L\\) fixed \\(n\\)-dimensional identity matrix. sigma_L=\"full_normalized\" diagonal elements matrix \\(L\\) fixed ones elements free.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Structures — model structures","text":"","code":"# ###################################################### # construct a template from a model # ######################################################  # Let us consider scalar ARMA(5,1) models # for quarterly data with a strong seasonal component. # In order to have parsimonious models we want a[2]=a[3]=0: model = armamod(lmfd(a = c(1,NA,0,0,NA,NA), b = c(1,NA))) tmpl = model2template(model)  # Let's see how the \"free\" parameters are mapped to the model parameters print(cbind(tmpl$h, tmpl$H)) #>       [,1] [,2] [,3] [,4] [,5] #>  [1,]    1    0    0    0    0 #>  [2,]    0    1    0    0    0 #>  [3,]    0    0    0    0    0 #>  [4,]    0    0    0    0    0 #>  [5,]    0    0    1    0    0 #>  [6,]    0    0    0    1    0 #>  [7,]    1    0    0    0    0 #>  [8,]    0    0    0    0    1 #>  [9,]    1    0    0    0    0 th = -(1:tmpl$n.par) fill_template(th, tmpl) #> ARMA model [1,1] with orders p = 5 and q = 1 #> AR polynomial a(z): #>      z^0 [,1] z^1 [,1] z^2 [,1] z^3 [,1] z^4 [,1] z^5 [,1] #> [1,]        1       -1        0        0       -2       -3 #> MA polynomial b(z): #>      z^0 [,1] z^1 [,1] #> [1,]        1       -4 #> Left square root of noise covariance Sigma: #>      u[1] #> u[1]    1  # Generate a random model with this structure th0 = rnorm(tmpl$n.par, sd = 0.1) model = fill_template(th0, tmpl)  # Extract the \"free\" parameters from the model th = extract_theta(model, tmpl) all.equal(th, th0) #> [1] TRUE  # This model structure fixes sigma_L = 1. # If we change sigma_L = 2 then the model does not fit to the template. model$sigma_L = 2 # the default choice on_error = 'ignore', tells # extract_theta to ignore this misfit: th = extract_theta(model, tmpl, on_error = 'ignore') # with on_error = 'warn' we get a warning and # with on_error = 'stop' would throw an error. th = extract_theta(model, tmpl, on_error = 'warn') #> Warning: model does not match template. max(abs(res)) = 1 # We may also \"ignore\" sigma_L th = extract_theta(model, tmpl, on_error = 'stop', ignore_sigma_L=TRUE)  # If the orders/class of template and model does not fit if (FALSE) { model = armamod(lmfd(a = c(1,1), b = c(1,1))) extract_theta(model, tmpl) model = stspmod(stsp(D = 1)) extract_theta(model, tmpl) }  # ###################################################### # the parameter \"sigma_L\" # ######################################################  # consider a state space model (with 1 state) for a 3-dimensional process model = stspmod(stsp(A = 1, B = c(1,0,0), C = c(1,1,1), D = diag(3)))  # We may specify an arbitrary structure for the left square root (L = sigma_L) # of the noise covariance Sigma. Any NA entry is considered as a \"free\" parameter. L = matrix(c(0, NA, 1, 0, 2, 3, NA, 1, 1), nrow = 3, ncol = 3) L #>      [,1] [,2] [,3] #> [1,]    0    0   NA #> [2,]   NA    2    1 #> [3,]    1    3    1 # L has 2 NA entries and thus we get a model structure with 2 free parameters. model$sigma_L = L  tmpl = model2template(model, sigma_L = 'as_given') th = -(1:tmpl$n.par) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    0    0   -2 #> u[2]   -1    2    1 #> u[3]    1    3    1  # The choice sigma_L = 'chol' forces L to be lower triangular. # In the case considered here, we get a model structure with 1 free parameter. tmpl = model2template(model, sigma_L = 'chol') th = -(1:tmpl$n.par) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    0    0    0 #> u[2]   -1    2    0 #> u[3]    1    3    1  # The choice sigma_L = 'symm' forces L = sigma_L to be symmetric. # In the case considered here we thus get a model structure with 2 free parameters. tmpl = model2template(model, sigma_L = 'symm') th = -(1:tmpl$n.par) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    0   -1   -2 #> u[2]   -1    2    2 #> u[3]   -2    2    1  # The choice sigma_L = 'identity' set L equal to the identity matrix, # i.e. sigma_L is fixed. tmpl = model2template(model, sigma_L = 'identity') th = numeric(0) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    1    0    0 #> u[2]    0    1    0 #> u[3]    0    0    1 tmpl$n.par # there are no free parameters: tmpl$n.par = 0 #> [1] 0  # The choice sigma_L = 'full_normalized' sets the diagonal elements of L equal to ones, # and leaves all other elements free. tmpl = model2template(model, sigma_L = 'full_normalized') th = -(1:tmpl$n.par) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    1   -3   -5 #> u[2]   -1    1   -6 #> u[3]   -2   -4    1   # ###################################################### # ARMA(p,q) models # ######################################################  m = 2 # output dimension p = 1 # AR order q = 1 # MA order  # model structure with lower triangular sigma_L tmpl = tmpl_arma_pq(m, n = m, p, q, sigma_L = \"chol\") th = rnorm(tmpl$n.par) th = -(1:tmpl$n.par) fill_template(th, tmpl) #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -3 #> [2,]        0     1       -2    -4 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -5    -7 #> [2,]        0     1       -6    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]   -9    0 #> u[2]  -10  -11  # model structure with symmetric sigma_L tmpl = tmpl_arma_pq(m, n = m, p, q, sigma_L = \"symm\") fill_template(th, tmpl) #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -3 #> [2,]        0     1       -2    -4 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -5    -7 #> [2,]        0     1       -6    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]   -9  -10 #> u[2]  -10  -11  # model structure with sigma_L = I tmpl = tmpl_arma_pq(m, n = m, p, q, sigma_L = \"identity\") # here the number of free paramaters is of course (by 3) smaller # than for the above model structures! fill_template(th[1:(length(th)-3)], tmpl) #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -3 #> [2,]        0     1       -2    -4 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -5    -7 #> [2,]        0     1       -6    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1   # ###################################################### # RMFD(p,q) models y[t] = d(z) c(z)^-1 e[t] # ######################################################  m = 2 # output dimension p = 1 # order of c(z) q = 1 # order of d(z)  # model structure with lower triangular sigma_L tmpl = tmpl_rmfd_pq(m, n = m, p, q, sigma_L = \"chol\") th = rnorm(tmpl$n.par) th = -(1:tmpl$n.par) fill_template(th, tmpl) #> RMFD model [2,2] with orders p = 1 and q = 1 #> right factor polynomial c(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -5 #> [2,]        0     1       -2    -6 #> left factor polynomial d(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -3    -7 #> [2,]        0     1       -4    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]   -9    0 #> u[2]  -10  -11  # model structure with symmetric sigma_L tmpl = tmpl_rmfd_pq(m, n = m, p, q, sigma_L = \"symm\") fill_template(th, tmpl) #> RMFD model [2,2] with orders p = 1 and q = 1 #> right factor polynomial c(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -5 #> [2,]        0     1       -2    -6 #> left factor polynomial d(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -3    -7 #> [2,]        0     1       -4    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]   -9  -10 #> u[2]  -10  -11  # model structure with sigma_L = I tmpl = tmpl_rmfd_pq(m, n = m, p, q, sigma_L = \"identity\") # here the number of free paramaters is of course (by 3) smaller # than for the above model structures! fill_template(th[1:(length(th)-3)], tmpl) #> RMFD model [2,2] with orders p = 1 and q = 1 #> right factor polynomial c(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -5 #> [2,]        0     1       -2    -6 #> left factor polynomial d(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -3    -7 #> [2,]        0     1       -4    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1   # ###################################################### # state space models in echelon form # ###################################################### nu = c(3,2,4)   # Kronecker indices m = length(nu)  # number of outputs/inputs tmpl = tmpl_stsp_echelon(nu = nu)  # generate a random vector of parameters. # Note that \"tmpl$n.par\" contains the number free parameters. th = rnorm(tmpl$n.par)  # generate a model according to this structure with the parameters th model = fill_template(th, tmpl) print(model) #> state space model [3,3] with s = 9 states #>            s[1]       s[2]       s[3]       s[4]       s[5]        s[6] #> s[1]  0.0000000  0.0000000  0.0000000  1.0000000  0.0000000  0.00000000 #> s[2]  0.0000000  0.0000000  0.0000000  0.0000000  1.0000000  0.00000000 #> s[3]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  1.00000000 #> s[4]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> s[5] -0.5069741 -1.3185389  0.9299314 -1.3305402  1.2756387 -0.96206144 #> s[6]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> s[7]  0.2586699  0.4423506  0.9330060 -1.0971973 -1.0225456 -0.04201451 #> s[8]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> s[9] -0.4879223 -2.1404942 -1.1126130 -0.6344114 -0.7314033 -0.18941483 #> x[1]  1.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> x[2]  0.0000000  1.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> x[3]  0.0000000  0.0000000  1.0000000  0.0000000  0.0000000  0.00000000 #>             s[7]       s[8]      s[9]        u[1]       u[2]        u[3] #> s[1]  0.00000000  0.0000000  0.000000 -0.53626878  0.3245287 -0.01816759 #> s[2]  0.00000000  0.0000000  0.000000  0.81296025  0.8422520 -0.66184729 #> s[3]  0.00000000  0.0000000  0.000000 -0.05875453 -0.7313609 -0.52633598 #> s[4]  1.00000000  0.0000000  0.000000  1.50472574 -0.2703538  0.81328773 #> s[5] -0.46374199  0.0000000  0.000000 -0.77001544 -0.4788250 -1.49799882 #> s[6]  0.00000000  1.0000000  0.000000 -0.56025398  0.1951220  0.28004366 #> s[7] -0.68082415  0.5038279  0.000000  0.83989411 -2.1737331  0.31048708 #> s[8]  0.00000000  0.0000000  1.000000  1.14563594 -0.4292933  0.19716398 #> s[9]  0.07047471 -0.9537194 -1.201023  1.22944828 -0.7564283 -0.28276271 #> x[1]  0.00000000  0.0000000  0.000000  1.00000000  0.0000000  0.00000000 #> x[2]  0.00000000  0.0000000  0.000000  0.00000000  1.0000000  0.00000000 #> x[3]  0.00000000  0.0000000  0.000000  0.00000000  0.0000000  1.00000000 #> Left square root of noise covariance Sigma: #>            u[1]       u[2]      u[3] #> u[1]  1.0163770  0.0000000  0.000000 #> u[2]  0.4342113  0.5560351  0.000000 #> u[3] -1.5971272 -0.1438752 -0.471006  # we can extract the free parameters from this given model all.equal(th, extract_theta(model, tmpl, on_error = 'stop')) #> [1] TRUE  # check the impulse response k = impresp(model, lag.max = 2*sum(nu) + 1)  # the lag zero coeffcient k[0] is equal to the identity all.equal(unclass(k$irf)[,,1], diag(m)) #> [1] TRUE  # check the Kronecker indices all.equal(rationalmatrices::pseries2nu(k$irf), nu) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Outputs of an ARMA systems — outputs_ARMA_cpp","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"internal helper function computes outputs ARMA system $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + \\cdots + b_q u_{t-q}$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"","code":"outputs_ARMA_cpp(A1, B, t0, u, y)"},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"A1 \\((m, mp)\\) matrix \\(-a_0^{-1}(a_p,...,a_1)\\). B \\((m, n(q+1))\\) matrix \\(a_0^{-1}(b_0,...,b_q\\). t0 integer, start iteration t = t0. u \\((n, N)\\) matrix inputs \\((u_1,...,u_N\\). y \\((m, N)\\) matrix outputs \\((y_1,...,y_N\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"RcppArmadillo routine returns NULL overwrites input argument y computed outputs!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitly set zero. However, starting iteration \\(t_0>1\\) can enforce non-zero initial values.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"Use procedure care! procedure check input arguments. require \\(m > 0\\), \\(p \\geq 0\\), \\(n(q+1) \\geq 0\\) \\(1 \\leq t_0 \\leq N\\). procedure overwrites input argument y. data matrices organized columnwise (avoid memory shuffling)! Note also non standard representation coefficient matrices.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"","code":"# generate a random ARMA(2,1) model (3 outputs, 2 inputs) p = 2 q = 1 m = 3 n = 2 model = test_armamod(dim = c(m, n), degrees = c(p,q), digits = 2) A = unclass(model$sys$a) a0 = A[,,1] A1 = -A[,,(p+1):2] dim(A1) = c(m, m*p) A1 = solve(a0, A1) B = unclass(model$sys$b) dim(B) = c(m, n*(q+1)) B = solve(a0, B)  # generate random noise sequence (sample size N = 10) n.obs = 10 u = matrix(rnorm(n.obs*n), nrow = n, ncol = n.obs) print(u) #>            [,1]      [,2]      [,3]      [,4]       [,5]      [,6]      [,7] #> [1,] -0.6727197 -3.015827 0.3596626 -2.088264  0.2455572 0.9480790 2.1220845 #> [2,]  1.2258696  1.271059 0.6153130  1.785277 -1.3224404 0.5920432 0.6148116 #>            [,8]       [,9]      [,10] #> [1,] 0.63043010 -1.2634735  1.5776279 #> [2,] 0.03644486 -0.4022728 -0.7037822  # generate matrix for the outputs y = matrix(0, nrow = m, ncol = n.obs)  # call outputs_ARMA_cpp() outputs_ARMA_cpp(A1, B, t0 = 2, u, y) # start with t>=2 print(u) #>            [,1]      [,2]      [,3]      [,4]       [,5]      [,6]      [,7] #> [1,] -0.6727197 -3.015827 0.3596626 -2.088264  0.2455572 0.9480790 2.1220845 #> [2,]  1.2258696  1.271059 0.6153130  1.785277 -1.3224404 0.5920432 0.6148116 #>            [,8]       [,9]      [,10] #> [1,] 0.63043010 -1.2634735  1.5776279 #> [2,] 0.03644486 -0.4022728 -0.7037822 print(y)  # y is overwritten with the computed outputs #>      [,1]       [,2]      [,3]      [,4]      [,5]       [,6]       [,7] #> [1,]    0 -2.0820766  3.020609 -8.863051 10.482240 -16.297199  27.933818 #> [2,]    0  1.7555846  0.750899  2.920361 -5.302189   6.870707 -11.521045 #> [3,]    0 -0.8398604 -3.843394 -2.204348 -2.866299  13.129438   2.798567 #>           [,8]      [,9]      [,10] #> [1,] -39.19313  57.52580 -91.812319 #> [2,]  20.07121 -22.93972  42.908171 #> [3,]  13.97290 -29.83315   8.190574"},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Outputs of a statespace system — outputs_STSP_cpp","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"internal helper function computes outputs states statespace system form $$a_{t+1} = a_t + B u_t, \\; y_t   = C a_t + D u_t$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"\\((s,s)\\) matrix. B \\((s,n)\\) matrix. C \\((m,s)\\) matrix. D \\((m,n)\\) matrix. u \\((n,N)\\) matrix inputs/disturbances: \\((u_1,u_2,\\ldots,u_N)\\). \\((s,N+1)\\) matrix. matrix overwritten (computed) states: \\((a_1,a_2,\\ldots,a_N,a_{N+1})\\). input [,1] must hold initial state \\(a_1\\). y \\((m,N)\\) matrix. matrix overwritten (computed) outputs: \\((y_1,y_2,\\ldots,y_N)\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"RcppArmadillo routine returns NULL overwrites input arguments u!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"Use procedure care! procedure check input arguments. procedure overwrites input arguments u. data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"","code":"# generate a random statespace model (3 outputs, 2 inputs and 4 states) m = 3 n = 2 s = 4 model = test_stspmod(dim = c(m, n), s = s, digits = 2)  # generate random noise sequence (sample size N = 10) n.obs = 10 u = matrix(rnorm(n.obs*n), nrow = n, ncol = n.obs) print(u) #>              [,1]      [,2]       [,3]       [,4]       [,5]       [,6] #> [1,] -0.008161641 0.4151075 -2.5076274 -1.1354969 -0.6171516 -0.6986756 #> [2,]  0.675443061 0.7733806 -0.9724242  0.2943615 -0.2111856  0.7124553 #>             [,7]       [,8]       [,9]       [,10] #> [1,] -0.07804087  1.0509301  0.7876608  0.02725284 #> [2,]  1.09116552 -0.1836981 -0.4505679 -0.39597250  # generate matrix for the state sequence a = matrix(0, nrow = s, ncol = n.obs+1) a[,1] = rnorm(s) # random initial state a[1] print(a) #>             [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] #> [1,]  0.82440488    0    0    0    0    0    0    0    0     0     0 #> [2,]  2.46481445    0    0    0    0    0    0    0    0     0     0 #> [3,] -0.09118371    0    0    0    0    0    0    0    0     0     0 #> [4,]  0.37613488    0    0    0    0    0    0    0    0     0     0  # generate matrix for the outputs y = matrix(0, nrow = m, ncol = n.obs)  # call outputs_STSP_cpp() outputs_STSP_cpp(model$sys$A, model$sys$B, model$sys$C, model$sys$D, u, a, y) print(u) #>              [,1]      [,2]       [,3]       [,4]       [,5]       [,6] #> [1,] -0.008161641 0.4151075 -2.5076274 -1.1354969 -0.6171516 -0.6986756 #> [2,]  0.675443061 0.7733806 -0.9724242  0.2943615 -0.2111856  0.7124553 #>             [,7]       [,8]       [,9]       [,10] #> [1,] -0.07804087  1.0509301  0.7876608  0.02725284 #> [2,]  1.09116552 -0.1836981 -0.4505679 -0.39597250 print(a)  # a is overwritten with the computed states #>             [,1]      [,2]      [,3]       [,4]      [,5]       [,6] #> [1,]  0.82440488 -2.293077  0.318788  -4.357114   2.67933  -16.13106 #> [2,]  2.46481445  3.987800  9.394199  16.745636  35.95045   83.80753 #> [3,] -0.09118371 -4.031825  4.759263  -9.383869  34.57869  -16.25677 #> [4,]  0.37613488 -2.471480 -6.150455 -25.503015 -39.91524 -122.74637 #>             [,7]        [,8]        [,9]      [,10]      [,11] #> [1,]    3.704392  -66.068773   -17.05783  -280.9372  -215.8645 #> [2,]  189.927389  441.826741  1008.66844  2327.1169  5312.8353 #> [3,]  132.125047   -2.799223   531.20666   245.7235  2287.6675 #> [4,] -221.973413 -608.763961 -1211.59866 -3099.6949 -6528.2644 print(y)  # y is overwritten with the computed outputs #>            [,1]       [,2]      [,3]      [,4]       [,5]      [,6]       [,7] #> [1,] -2.3197032 -4.3081398 -6.460507 -21.35190  -6.501508 -80.62249  -65.86759 #> [2,]  4.9021958  2.8863811 36.229599  47.38768 200.519845 296.89768  966.01247 #> [3,] -0.4349683  0.8935802 -8.737062  10.33498 -44.407720  14.70241 -173.58398 #>            [,8]      [,9]     [,10] #> [1,] -361.30857 -463.7478 -1730.969 #> [2,] 1690.28234 4795.0816  9329.061 #> [3,]  -31.58329 -721.1775  -489.352"},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Forecast Error Variance Decomposition — plot.fevardec","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"Plot Forecast Error Variance Decomposition","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"","code":"# S3 method for fevardec plot(   x,   main = NA,   xlab = NA,   col = NA,   y_names = x$names,   u_names = y_names,   parse_names = FALSE,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"x fevardec() object. main (character string) overall title plot. main=NULL omits title main = NA sets default title. xlab (character string) title x-axis. xlab=NULL omits title xlab = NA sets default x-axis title. col (m)-dimensional vector colors. NA default colormap chosen. y_names optional (m)-dimensional character vector names components time-series/process. u_names optional (m)-dimensional character vector names orthogonalized shocks. parse_names boolean. TRUE series- shock- names parsed expression() plotting. See also grDevices::plotmath() usage expressions plot annotations. ... used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"plot routine returns (invisibly) function, subfig say, may used add additional graphic elements subfigures. call opar = subfig() creates new (sub) plot ()-th position suitable margins axis limits. See example .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"","code":"# set seed for reproducible results set.seed(1995)  model = test_stspmod(dim = c(2,2), s = 3, bpoles = 1, bzeroes = 1) model$names = c('x[t]', 'y[t]')  # impulse response irf = impresp(model, lag.max = 11, H = 'eigen')  # forecast error variance decomposition fevd = fevardec(irf) # plot it subfig = plot(fevd, col = c('lightgray','darkgray'),               u_names = c('epsilon[t]', 'eta[t]'), parse_names = TRUE)  opar = subfig(1) graphics::text(x = 1, y = 0.5, 'EXAMPLE PLOT', col = 'blue', adj = c(0, 0.5))  graphics::par(opar)  # reset seed set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Methods — plot methods","title":"Plot Methods — plot methods","text":"Plot methods impulse response functions (impresp() objects), autocovariance functions (autocov() objects), frequency response functions (freqresp() objects) spectral densities (spectrald() objects).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Methods — plot methods","text":"","code":"# S3 method for impresp plot(   x,   x_list = NULL,   xlim = c(\"global\", \"column\", \"subfig\"),   ylim = c(\"row\", \"subfig\", \"global\"),   main = NA,   xlab = NA,   ylab = NULL,   subfigure_main = NA,   parse_subfigure_main = FALSE,   style = c(\"gray\", \"bw\", \"bw2\", \"colored\"),   col = NA,   type = \"l\",   lty = \"solid\",   lwd = 1,   pch = 16,   cex.points = 1,   bg.points = \"black\",   legend = NULL,   legend_args = NA,   ... )  # S3 method for autocov plot(   x,   x_list = NULL,   xlim = c(\"global\", \"column\", \"subfig\"),   ylim = c(\"row\", \"subfig\", \"global\"),   main = NA,   xlab = NA,   ylab = NULL,   subfigure_main = NA,   parse_subfigure_main = FALSE,   style = c(\"gray\", \"bw\", \"bw2\", \"colored\"),   col = NA,   type = \"l\",   lty = \"solid\",   lwd = 1,   pch = 16,   cex.points = 1,   bg.points = \"black\",   legend = NULL,   legend_args = NA,   ... )  # S3 method for freqresp plot(   x,   x_list = NULL,   sampling_rate = 1,   unit = \"\",   which = c(\"gain\", \"phase\", \"nyquist\"),   xlim = NA,   ylim = NA,   log = \"\",   main = NA,   xlab = NA,   ylab = NA,   subfigure_main = NA,   parse_subfigure_main = FALSE,   style = c(\"gray\", \"bw\", \"bw2\", \"colored\"),   col = NA,   type = \"l\",   lty = \"solid\",   lwd = 1,   pch = 16,   cex.points = 1,   bg.points = \"black\",   legend = NULL,   legend_args = NA,   ... )  # S3 method for spectrald plot(   x,   x_list = NULL,   sampling_rate = 1,   unit = \"\",   which = c(\"modulus\", \"phase\", \"coherence\"),   xlim = c(0, 0.5) * sampling_rate,   ylim = \"row\",   log = \"\",   main = NA,   xlab = NA,   ylab = NA,   subfigure_main = NA,   parse_subfigure_main = FALSE,   style = c(\"gray\", \"bw\", \"bw2\", \"colored\"),   col = NA,   type = \"l\",   lty = \"solid\",   lwd = 1,   pch = 16,   cex.points = 1,   bg.points = \"black\",   legend = NULL,   legend_args = NA,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Methods — plot methods","text":"x impresp(), autocov(), freqresp() spectrald()  object. x_list (optional) list additional objects (class \"x\"). xlim, ylim determine axis limits subfigures. E.g. xlim = 'column' means subfigures column use x-axis limits. Analogously y = 'row' implies subfigures row share limits y-axis.  \"freqresp\" \"spectrald\" plots parameter xlim may also numeric 2-dimensional vector xlim = c(x1,x2). case sub-figures use given limits x-axis. Furthermore limits y-axis computed based corresponding data subset. option may used \"zoom\" certain range frequencies. main (character expression) main title plot xlab (character string expression) label x-axis ylab (character expression) label y-axis subfigure_main scalar (m x n) matrix type \"character\" titles subfigures. subfigure_main scalar character string procedures creates matrix respective titles replacing \"place holders\" 'i_' 'j_' respective row column number. parse_subfigure_main boolean. TRUE titles subfigures parsed expression plotting. See also plotmath usage expressions plot annotations. style (character string) determines appearance plot (background color plot regions, color line style grid lines, axis color, ...) See also style_parameters. col vector line colors type vector plot types. following values possible:  \"p\" points, \"l\" lines,  \"b\" points lines,  \"c\" empty points joined lines, \"o\" overplotted points lines,  \"s\" \"S\" stair steps \"h\" histogram-like vertical lines.  'n' suppresses plotting. lty vector line types. Line types can either specified integers (0=blank, 1=solid (default), 2=dashed, 3=dotted, 4=dotdash, 5=longdash, 6=twodash) one character strings \"blank\", \"solid\", \"dashed\", \"dotted\", \"dotdash\", \"longdash\", \"twodash\", \"blank\" uses ‘invisible lines’ (.e., draw ). lwd vector line widths. pch vector plotting character symbols. See points possible values. cex.points vector scales plotting symbols. bg.points vector fill color open plot symbols. legend (character expression vector). NULL legend produced. legend_args (optional) list parameters legend.  legend title can included legend_args = list(title = my_legend_title). Note slots x, y ignored legend always put right hand side plot.  See also legend. ... used. sampling_rate (number) sampling rate. unit (character string) time frequency unit. (character string) plot. parameter used plotting frequency response objects spectral densities. See details . log character string contains \"x\" x axis logarithmic, \"y\" y axis logarithmic \"xy\" \"yx\" axes logarithmic.  parameter used plotting frequency response objects spectral densities. Note logarithmic y-axis makes sense plotting moduli frequency response spectral density.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Methods — plot methods","text":"plot methods return (invisibly) \"closure()\", subfig say, may used add additional graphic elements subfigures. call opar = subfig(,j) creates new (sub) plot (,j)-th position suitable margins axis limits. See examples .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Methods — plot methods","text":"x \\((m,n)\\) dimensional object plot divided \\((m,n)\\) array subfigures. subfigures respective \\((,j)\\)-th element object x displayed. methods allow simultaneous plotting several objects, passing list x_list additional objects procedure. following assume x_list contains \\(k-1\\) objects, .e. total \\(k\\) objects plotted. parameter \"xlim\" determines x-limits subfigures: xlim='global' uses x-limits subfigures (limits determined data). case frequency response spectral density objects one may also pass two-dimensional vector xlim = c(x1,x2) plot method. case subfigures use values common x-limits. xlim='column' means sub figures \"column\" x-limits. limits determined data. Finally xlim='subfigure' means subfigure gets x-limits (determined data). Quite analogously parameter ylim determines limits y-axes. (Just replace 'column' 'row'). plot methods quite number optional design parameters. cases parameters interpreted follows. NA values mean methods use suitable defaults. E.g. labels x- y-axis chosen according class object(s) plotted parameter \"\". NULL values (optional) parameters mean respective graphic element omitted. E.g. subfigure_main = NULL skips titles subfigures. titles (m,n) subfigures determined parameter subfigure_main. One may pass \\((m,n)\\) character matrix scalar character (string) procedure. subfigure_main scalar (character string) procedures creates respective titles replacing \"place holders\" i_ j_ respective row column number. See examples . \"style\" parameters col, type, ..., bg.points determine appearance \"lines\" k objects. (necessary values \"recycled\".) See also graphics::lines() graphics::points() detailed explanation parameters. one object plotted (optional parameter x_list empty) suitable legend may added parameters legend legend_args. Note legend character (expression) vector length k. parameter \"\" determines plot case \"freqresp\" \"spectrald\" objects. gain,modulus plot moduli abs(x[,j]) versus frequencies. phase plot arguments Arg(x[,j]) versus frequencies. nyquist plot imaginary part Im(x[,j]) versus real part Re(x[,j]). coherence plot coherence. plot somewhat special. \"coherence matrix\" symmetric diagonal entries equal one (frequencies). Therefore entries diagonal contain additional information. reason subfigures diagonal display coherence, subfigures show \"scaled arguments\" Arg(x[,j])/(2*pi)+0.5 subfigures diagonal display scaled auto spectra \\(m\\) component processes. plot methods use internal helper function rationalmatrices::plot_3D().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Methods — plot methods","text":"","code":"set.seed(1995)  # set seed to get reproducible results n.obs = 2^8 m = 2 s = 3  # generate a random, stable and minimum phase state space model # for a bivariate process (x[t], y[t]) model = test_stspmod(dim = c(m,m), s = s, bpoles = 1, bzeroes = 1) model$names = c('x[t]', 'y[t]')  # simulate data data = sim(model, n.obs = n.obs)  #### plot impulse response # overlay three different \"orthogonalization\" schemes plot(impresp(model), list(impresp(model, H = 'eigen'),                           impresp(model, H = 'chol')),      legend = c('none','chol','eigen'),      legend_args = list(title = 'orthogonalization', fill = NA, border = NA, bty = 'n'),      style = 'colored', ylim = 'subfig', xlab = NA)   #### plot partial autocorrelation function # overlay with the corresponding sample partial ACF  par(lend = 1) # in order to get a \"barplot\" plot(autocov(data$y, lag.max = 12, type = 'partial'),      list(autocov(model, lag.max = 12, type = 'partial')),      subfigure_main = 'delta[i_*j_](k)', parse_subfigure_main = TRUE,      style = 'bw', type = c('h','l'), pch = 19, lwd = c(15,2),      legend = c('sample', 'true'))  par(lend = 0) # reset 'lend=0'  # frequency response of the model n.f = 2^11 frr = freqresp(model, n.f = n.f)  #### plot \"gain\" subfig = plot(frr, which = 'gain',               sampling_rate = 60, unit = 'Hz',               ylim = 'row', log = 'y',               subfigure_main = 'k[i_*j_](lambda)', parse_subfigure_main = TRUE)  # mark the frequencies with the max gain! junk = unclass(frr$frr) i_max = apply(Mod(junk), MARGIN = c(1,2), FUN = which.max) f_max = matrix(60*((0:(n.f-1))/n.f)[i_max], nrow = 2, ncol = 2) for (i in (1:2)) {   for (j in (1:2)) {     subfig(i,j)     abline(v = f_max[i,j], col = 'steelblue')   } }   #### create a \"Nyquist\" plot of the frequency response plot(frr, which = 'nyquist',      xlim = 'subfig', ylim = 'subfig',      subfigure_main = 'k[i_*j_](lambda)', parse_subfigure_main = TRUE)    # compute spectral density spd = spectrald(model, n.f = 256)  #### plot the coherence # the subfigure above the diagonal shows the coherenec between # the two component proceses x[t] and y[t] # the sub figures on the diagonal show the scaled autospectra # of the two component processes x[t] and y[t]. # and the subfigure below the diagonal shows the # phase/argument of the cross spectral density between the # two component processes x[t] and y[t] plot(spd, sampling_rate = 60, unit=\"Hz\",      main = expression(spectral~density~~Gamma[i*j] == kappa[i*j]*exp(i*Phi[i*j])),      which = 'coherence',      style = 'bw')   # periodogram per = spectrald(data$y)  # smoothed periodogram sacf = autocov(data$y, lag.max = floor(sqrt(n.obs))) per2 = spectrald(sacf, n.f = 256)   #### make a plot of the absolute value of the spectral density, # of the periodogram and the smoothed periogram. # with a logarithmic y-axis # skip zero frequency, since the periodogram is zero at lambda=0 plot(spd, list(per, per2), sampling_rate = 12, unit = '/year', which = 'modulus',      log = 'y', xlim = c(1/n.obs, 0.5) * 12,  # skip zero frequency      legend = c('true','periodogram', 'smoothed per.'),      legend_args = list(bty = 'n', col = NA, lty = NA, pch = NA, lwd = 4),      style = 'colored', ylim = 'subfig',      subfigure_main = 'kappa[i_*j_] == group(\"|\", Gamma[i_*j_], \"|\")',      parse_subfigure_main = TRUE,      col = c('red', 'black', 'blue'), type = 'o', lty = c(1,0,1),      pch = c(NA, 19, NA), cex.points = 0.1)   set.seed(NULL) # reset seed"},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Forecasts — plot_prediction","title":"Plot Forecasts — plot_prediction","text":"function plot_prediction generates standard plots forecasts forecast errors.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Forecasts — plot_prediction","text":"","code":"plot_prediction(   pred,   which = c(\"prediction\", \"error\", \"cusum\", \"cusum2\", \"y0\", \"u0\"),   qu = stats::qnorm(0.95),   col = NULL,   lty = NULL,   style = c(\"gray\", \"colored\", \"bw\", \"bw2\"),   parse_names = FALSE,   plot = TRUE,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Forecasts — plot_prediction","text":"pred list true data forecasts, produced predict(). One may also add slot \"date\" numeric vector indices vector type Date POSIXct contains date/time values. (character string) selects type plot. qu (numeric scalar vector) determines width plotted confidence intervalls. entry NA equal zero confidence band plotted. col, lty optional (vectors ) colors line styles. style character string determines general style plot (background color, grid style, axis axis-labels colors, ...). See also style_parameters(). parse_names parse series names predictor names expression(). See grDevices::plotmath(). plot (boolean) produce plot just return \"closure\" produces plot. ... used","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Forecasts — plot_prediction","text":"plot=TRUE plot_prediction returns (invisibly) function, subfig(= 1) say, may used add additional graphic elements subfigures. call opar = subfig() creates new (sub) plot ()-th position suitable margins axis limits. output opar contains original graphics parameters, see graphics::par(). plot=FALSE function, plotfun(xlim = NULL) say, returned produces desired plot. optional parameter xlim = c(x1,x2) may used zoom certain time range. function plotfun returns  function/closure add graphical elements plot described . See also examples .","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Forecasts — plot_prediction","text":"","code":"# set seed for random number generation, to get reproducable results set.seed(1609)  # generate a random state space model with three outputs and 4 states model = test_stspmod(dim = c(3,3), s = 4, bpoles = 1, bzeroes = 1)  # create a vector \"date\" with date/time info date = seq(as.POSIXct('2017-01-01'), by = 15*60, length.out = 768) n.obs = sum(date < as.POSIXct('2017-01-08')) n.ahead = length(date) - n.obs  # generate random data data = sim(model, n.obs = n.obs, s1 = NA)  # compute predictions pred = predict(model, data$y, h = c(1, 5), n.ahead = n.ahead) # add the date/time information to the list \"pred\" pred$date = date  # the default \"predictor names\" h=1, h=2, ... # don't look well, when plotted as expressions dimnames(pred$yhat)[[3]] = gsub('=','==',dimnames(pred$yhat)[[3]])  # generate some plots ####################  # a simple/compressed plot of the data p.y0 = plot_prediction(pred, which = 'y0', style = 'bw',                        parse_names = TRUE, plot = FALSE) # p.y0()  # a simple/compressed plot of the prediction errors plot_prediction(pred, which = 'u0', parse_names = TRUE)   # plot of the prediction errors (with 95% confidence intervalls) # plot_prediction(pred, which = 'error', qu = c(2,2,2), #                 parse_names = TRUE)  # plot of the true vales and the predicted values (+ 50% confidence region # for the 1-step ahead prediction and the \"out of sample\" predictions) p.y = plot_prediction(pred, qu = c(qnorm(0.75), NA, qnorm(0.75)),                       parse_names = TRUE, plot = FALSE) # subfig = p.y(xlim = date[c(n.obs-20, n.obs+20)]) # opar = subfig(1) # abline(v = mean(as.numeric(date[c(n.obs, n.obs+1)])), col = 'red') # mtext(paste(' example plot:', date()), side = 1, outer = TRUE, #       cex = 0.5, col = 'gray', adj = 0) # graphics::par(opar) # reset the graphical parameters  # CUSUM plot of the prediction errors # plot_prediction(pred, which = 'cusum', #                 style = 'gray', parse_names = TRUE)  # CUSUM2 plot of the prediction errors # plot_prediction(pred, which = 'cusum2', parse_names = TRUE)  set.seed(NULL) # reset seed  if (FALSE) { # open a 'shiny-App' window, where we can zoom # into the plot with the prediction(s) require(shiny) zoom_plot(p.y, p.y0, 'Test zoom & scroll') }"},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Portmanteau Test for Serial Correlation — pm_test","title":"Portmanteau Test for Serial Correlation — pm_test","text":"Test whether residuals estimated model serially correlated. test statistic $$Q = N^2\\sum_{k=1}^{K} (N-k)^{-1}\\mbox{tr} (G_k G_0^{-1} G_k' G_0^{-1})$$ \\(G_k\\) sample covariances residuals. Null correctly specified estimated model test statistic asmyptotically Chi-squared distributed \\(Km^2-\\kappa\\) degrees freedom, \\(\\kappa\\) number (free) parameters model (class).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Portmanteau Test for Serial Correlation — pm_test","text":"","code":"pm_test(u, lag.max, n.par)"},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Portmanteau Test for Serial Correlation — pm_test","text":"u (N--m) matrix residuals (object may coerced matrix .matrix(u)). lag.max (integer) maximum number lags. n.par (integer) number parameters estimated model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Portmanteau Test for Serial Correlation — pm_test","text":"Matrix four columns (\"lags\" number lags, \"df\" degrees freedom, \"Q\" test statistics  \"p\" p values).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Portmanteau Test for Serial Correlation — pm_test","text":"","code":"u = matrix(rnorm(100*3), nrow = 100, ncol = 3) pm_test(u, 4, 0) #>      lags        Q df          p #> [1,]    1 15.30629  9 0.08285910 #> [2,]    2 28.74652 18 0.05156637 #> [3,]    3 43.03334 27 0.02595701 #> [4,]    4 48.99381 36 0.07286598"},{"path":"https://bfunovits.github.io/RLDM/reference/poles_and_zeroes.html","id":null,"dir":"Reference","previous_headings":"","what":"Poles and Zeroes — poles and zeroes","title":"Poles and Zeroes — poles and zeroes","text":"Compute poles zeroes VARMA Statespace models. Note models describe corresponding processes $$x_t = k(B) u_t$$ \\((u_t)\\) white noise process \\(k(B)\\) rational filter (\\(B\\) denotes lag- backward shift operator). poles zeroes poles zeroes rational transfer function \\(k(z)\\) filter.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/poles_and_zeroes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poles and Zeroes — poles and zeroes","text":"","code":"# S3 method for armamod zeroes(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for armamod poles(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for rmfdmod zeroes(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for rmfdmod poles(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for stspmod zeroes(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for stspmod poles(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/poles_and_zeroes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poles and Zeroes — poles and zeroes","text":"x object represents VARMA, RMFD statespace model (.e. armamod(), rmfdmod() stspmod() object). tol Double. Default set sqrt(.Machine$double.eps). Required decide root considered \"infinity\". print_message Boolean. Default set TRUE. Prints message roots \"infinity \" discarded. ... used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/poles_and_zeroes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poles and Zeroes — poles and zeroes","text":"Vector poles, respectively zeroes.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Predictions — predict","title":"Model Predictions — predict","text":"Compute forecasts based VARMA state space model. procedure implements simplified approach. uses formulas prediction infinite past sets unknown initial values (prior \\(t < 1\\)) simply zero. simple approach assumes model stable strictly miniphase thus disturbances \\(u_t\\) innovations process. Note also forecasts known exogenous inputs calculated, .e. \"conditional forecasts\". honest prediction, forecasts exogenous inputs used.  forecast error covariance matrix computed assumes true model used. error stems estimation model taken account.  utility function evaluate_prediction may used assess quality predictions.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Predictions — predict","text":"","code":"# S3 method for armamod predict(object, y, h = 1, n.ahead = 0, ...)  # S3 method for stspmod predict(object, y, x, h = 1, n.ahead = 0, ...)  evaluate_prediction(   y,   yhat,   h,   criteria = list(\"RMSE\"),   benchmark = NULL,   samples = list(1:nrow(y)) )"},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Predictions — predict","text":"object rldm_varma rldm_ss object represents model. y \\((T,n)\\) matrix observed outputs (\\(y_t\\), \\(t=1,...,T\\)). h (integer) vector forecast horizons. n.ahead (integer) number time steps look ahead (sample). number also denoted \\(T_0\\). ... used. x \\((T+T_0,r)\\) matrix exogenous inputs (\\(x_t\\), \\(t=1,...,T+T_0\\)). input parameter ignored, model exogenous inputs. Note condition forecasts computed hence (model exogenous inputs) need values inputs time \\(t=T+T_0\\). yhat \\((T,n,l)\\) dimensional array forecasts. entries yhat[t,,] contain prediction \\(y_t\\). criteria list \"evaluation criteria\". See details. benchmark \\((T,n,l)\\) dimensional array \"benchmark\" forecasts. NULL naive (\\(h\\)-step ahead) forecasts used benchmark. samples list \"(sub) samples\". See details.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Predictions — predict","text":"function predict returns list components yhat \\((T,n,l)\\) dimensional array h-step ahead forecast. \\(T\\) sample size, \\(n\\) dimension outputs \\(y_t\\) \\(l\\) number forecasts made, .e. length vector h. entries yhat[t,,] h[]-step ahead forecast \\(y_t\\). sigmahat \\((n,n,l)\\) dimensional array, sigmahat[,,] contains theoretical covariance matrix \\(h\\)-step ahead prediction error h=h[]. h (integer) vector forecasts horizons considered. yhat.ahead \\((T_0,n)\\) dimensional matrix, contains \"--sample\" forecasts \\(t=T+1, t=T+2,...,t=T+T_0\\). sigmahat.ahead \\((n,n,T_0)\\) dimensional array, sigmahat.ahead[,,h] contains theoretical covariance matrix \\(h\\)-step ahead prediction error. y,x original data. function evaluate_prediction  returns 4-dimensional array dimensions refer evaluation criteria, (sub) samples, predictors components output \\(y_t\\). Note evaluation criteria applied (\\(n\\)) individual components well joint vector hence 4-th dimension array size \\(n+1\\). E.g. consider \"RMSE\" \"MAE\" forecast errors, two samples (training sample test sample), 5 forecast horizons \\(h=1,\\ldots,5\\) process \\((y_t)\\) 2 components, result \\((2,2,5,3)\\)-dimensional array.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Predictions — predict","text":"utility function evaluate_prediction may used asses quality given predictions. (E.g. computed predict). evaluation criteria used passed parameter criteria function. parameter list components either character strings (selection one implemented quality measures) user defined function. function takes three arguments fun(uhat, y, utilde) uhat matrix prediction errors, y matrix (corresponding) true values ytilde matrix predictions benchmark prediction procedures. allows compute relative error measures. benchmark predictions passed via parameter benchmark procedure. input parameter missing naive \\(h\\)-step ahead predictions used benchmark. (Therefore user also specify respective forecast horizons via paramater h.) following evaluation criteria implemented (\\(\\hat{y}_{}\\) denotes prediction error \\(y_{}\\) \\(\\tilde{u}_{}\\) corresponding error benchmark procedure.) MSE Mean Square Error RMSE Root Mean Square Error MAE Mean Absolute Error MdAE Median Absolute Error MAPE Mean Absolute Percentage Error \\(100 mean(|\\hat{u}_{}/y_{}|)\\) MdAPE Median Absolute Percentage Error \\(100 median(|\\hat{u}_{}/y_{}|)\\) RMdSPE Root Median Square Percentage Error \\(100 \\sqrt{median(\\hat{u}^2_{}/y^2_{})}\\) RelRMSE Relative Root Mean Square Error \\(\\sqrt{mean(\\hat{u}^2_{})}/\\sqrt{mean(\\tilde{u}^2_{})}\\) RelMAE Relative Mean Absolute Error \\(mean(|\\hat{u}_{}|)/mean(|\\tilde{u}^2_{}|)\\) PB Percentage better \\(mean(100 (|\\hat{u}_{}|< |\\tilde{u}_{}|))\\) HR Hit Rate \\(100 mean( ((\\tilde{u}_{} - \\hat{u}_{})\\tilde{u}_{} \\geq 0))\\). precise measure computes hit rate naive prediction benchmark. procedure also supports evaluation different (sub) samples. parameter samples simply list integer vectors, vector defines sub sample. E.g. daily data, one evaluate predictions different weekdays.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Predictions — predict","text":"","code":"# create a \"random\" ARMA(1,1) model (stable and miniphase) model = test_armamod(dim = c(2,2), degrees = c(1,1), bpoles = 1, bzeroes = 1)  # generate data (sample size n.obs = 200, \"burn_in\" phase has length 100.) data = sim(model, n.obs = 200, n.burn_in = 100)  # predict with true model pred_true = predict(model, data$y, h = c(1,5))  # estimate AR model, order selection by AIC n.train = 110   # use the first 110 observation for estimation n.test = 90     # the last 90 observations are used for (a fair) comparison model_ar = est_ar(data$y[1:n.train,],  mean_estimate = \"zero\",                   ic = 'AIC', method = 'ols')$model  # predict with AR model pred_ar = predict(model_ar, data$y, h = c(1,5))  # estimate AR1 model (Yule-Walker) model_ar1 = est_ar(data$y[1:n.train,],  mean_estimate = \"zero\",                   penalty = -1, p.max = 1, method = 'yule-walker')$model  # predict with AR1 model pred_ar1 = predict(model_ar1, data$y, h = c(1,5))  # evaluate prediction of the AR model (with the AR1 prediction as benchmark) stats = evaluate_prediction(data$y, pred_ar$yhat, h = pred_ar$h,                             criteria = list('RMSE', 'MAE', 'PB'),                             samples = list(train = 21:n.train, test = (n.train+1):(n.train+n.test)),                             benchmark = pred_ar1$yhat)  # use array2data.frame for \"tabular\" display of the results print(array2data.frame(stats, rows = 1:3, cols = 4)) #>    criterion sample predictor       y[1]       y[2]      total #> 1       RMSE  train       h=1  0.4507930  1.2479183  0.9382202 #> 2        MAE  train       h=1  0.3619205  1.0389882  0.7004544 #> 3         PB  train       h=1 57.7777778 64.4444444 61.1111111 #> 4       RMSE   test       h=1  0.4918756  1.2492269  0.9493444 #> 5        MAE   test       h=1  0.3620219  0.9466281  0.6543250 #> 6         PB   test       h=1 58.8888889 62.2222222 60.5555556 #> 7       RMSE  train       h=5  0.4910659  1.6517061  1.2184578 #> 8        MAE  train       h=5  0.3968138  1.3510779  0.8739459 #> 9         PB  train       h=5 46.6666667 43.3333333 45.0000000 #> 10      RMSE   test       h=5  0.5173099  1.6975118  1.2548218 #> 11       MAE   test       h=5  0.3916004  1.3378322  0.8647163 #> 12        PB   test       h=5 56.6666667 48.8888889 52.7777778  # evaluate all predictions # join predictions yhat  = dbind(3, pred_true$yhat, pred_ar1$yhat, pred_ar$yhat)  # define a function to compute the \"Median Relative Absolute Error\" MdRAE_ = function(u.hat, y, u.bench){    stats::median(abs(u.hat/u.bench), na.rm = TRUE) } stats = evaluate_prediction(data$y, yhat,                             h = c(pred_true$h, pred_ar1$h, pred_ar$h),                             criteria = list('RMSE', 'MAE', MdRAE = MdRAE_),                             samples = list(train = 21:n.train, test = (n.train+1):(n.train+n.test)))  # split prediction method and forecast horizon dimnames.stats = dimnames(stats) stats = stats[,,c(1,3,5,2,4,6),] dim(stats) = c(3,2,3,2,3) dimnames(stats) = list(criterion = dimnames.stats[[1]], sample = dimnames.stats[[2]],                       model = c('true','AR1','AR'), h = paste('h=',c(1,5),sep=''),                       data = dimnames.stats[[4]])  # use array2data.frame for \"tabular\" display of the results print(array2data.frame(stats, cols = 5, rows = c(3,4,1,2))) #>    model   h criterion sample      y[1]      y[2]     total #> 1   true h=1      RMSE  train 0.4578629 1.2660007 0.9519444 #> 2    AR1 h=1      RMSE  train 0.4828464 1.3622769 1.0219929 #> 3     AR h=1      RMSE  train 0.4507930 1.2479183 0.9382202 #> 4   true h=5      RMSE  train 0.4922236 1.6426081 1.2125274 #> 5    AR1 h=5      RMSE  train 0.4922191 1.6396106 1.2104963 #> 6     AR h=5      RMSE  train 0.4910659 1.6517061 1.2184578 #> 7   true h=1       MAE  train 0.3667778 1.0555714 0.7111746 #> 8    AR1 h=1       MAE  train 0.3881432 1.1484860 0.7683146 #> 9     AR h=1       MAE  train 0.3619205 1.0389882 0.7004544 #> 10  true h=5       MAE  train 0.3972814 1.3306377 0.8639595 #> 11   AR1 h=5       MAE  train 0.3972854 1.3291199 0.8632027 #> 12    AR h=5       MAE  train 0.3968138 1.3510779 0.8739459 #> 13  true h=1     MdRAE  train 0.7118385 0.4678256 0.5795242 #> 14   AR1 h=1     MdRAE  train 0.7062178 0.5118335 0.6145320 #> 15    AR h=1     MdRAE  train 0.6883639 0.4660858 0.5887966 #> 16  true h=5     MdRAE  train 0.6914304 0.7140706 0.7067163 #> 17   AR1 h=5     MdRAE  train 0.6905843 0.7138620 0.7083828 #> 18    AR h=5     MdRAE  train 0.6762183 0.7416613 0.6963163 #> 19  true h=1      RMSE   test 0.4760285 1.1779300 0.8983658 #> 20   AR1 h=1      RMSE   test 0.5138117 1.3190180 1.0009523 #> 21    AR h=1      RMSE   test 0.4918756 1.2492269 0.9493444 #> 22  true h=5      RMSE   test 0.5193767 1.7161105 1.2678303 #> 23   AR1 h=5      RMSE   test 0.5192816 1.7136416 1.2661400 #> 24    AR h=5      RMSE   test 0.5173099 1.6975118 1.2548218 #> 25  true h=1       MAE   test 0.3530498 0.9035949 0.6283224 #> 26   AR1 h=1       MAE   test 0.3875639 1.0437082 0.7156360 #> 27    AR h=1       MAE   test 0.3620219 0.9466281 0.6543250 #> 28  true h=5       MAE   test 0.3948289 1.3544309 0.8746299 #> 29   AR1 h=5       MAE   test 0.3947725 1.3512557 0.8730141 #> 30    AR h=5       MAE   test 0.3916004 1.3378322 0.8647163 #> 31  true h=1     MdRAE   test 0.6537800 0.3989324 0.5358819 #> 32   AR1 h=1     MdRAE   test 0.7460778 0.4117077 0.5637452 #> 33    AR h=1     MdRAE   test 0.6721339 0.3325342 0.5138319 #> 34  true h=5     MdRAE   test 0.7864302 0.6608992 0.6758500 #> 35   AR1 h=5     MdRAE   test 0.7866374 0.6570918 0.6757038 #> 36    AR h=5     MdRAE   test 0.7770797 0.6716709 0.6763418"},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Methods — print methods","title":"Print Methods — print methods","text":"Print Methods","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Methods — print methods","text":"","code":"# S3 method for armamod print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\", \"character\"),   ... )  # S3 method for rmfdmod print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\", \"character\"),   ... )  # S3 method for stspmod print(x, digits = NULL, ...)  # S3 method for impresp print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )  # S3 method for autocov print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )  # S3 method for fevardec print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )  # S3 method for freqresp print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )  # S3 method for spectrald print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Methods — print methods","text":"x RLDM object, .e. armamod(), rmfdmod(), stspmod(), impresp(), autocov(), freqresp(), spectrum() fevardec() object. digits (integer) non NULL correspondingly rounded numbers printed, see round(). format (character string) selects specific output formats. Note stsp() fevardec() objects format option. option 'character' implemented (V)ARMA models. ... parameters ignored.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Methods — print methods","text":"invisible(x)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Methods — print methods","text":"","code":"# for VARMA models six different print formats are implemented ################### m = armamod(test_lmfd(dim = c(2,2), degrees = c(1,1)), sigma_L = diag(2)) print(m, digits = 2, format = \"i|jz\") #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0     0.98 -2.22 #> [2,]        0     1     0.15  1.15 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]    -1.73 -0.97     1.52 -0.17 #> [2,]    -0.11 -0.52     1.40  2.10 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a Random Model — r_model","title":"Generate a Random Model — r_model","text":"function may used generate random state space VARMA models. main argument model template, defines type model generate, see e.g. model structures(). bounds poles /zeroes given, procedure simply generates random models model satisfies constraint found. course crude method may need large number randomly generated model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a Random Model — r_model","text":"","code":"r_model(   template,   ntrials.max = 100,   bpoles = NULL,   bzeroes = NULL,   rand.gen = stats::rnorm,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a Random Model — r_model","text":"template model template computed e.g. model2template(). ntrials.max Maximum number trials. bpoles, bzeroes Lower bounds poles zeroes model (stability invertibility assumptions satisfied). set NA, corresponding test skipped. rand.gen (optional) function generate random, \"free\" parameters. ... Additional parameters, passed rand.gen. particular, \"free\" paramameters generated rnorm(), standard deviation sd may set. Choosing small values sd makes easier find stable miniphase model. course \"trick\" works reference model, obtained zero parameter vector, satisfies constraints.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a Random Model — r_model","text":"Model object whose class depends template.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a Random Model — r_model","text":"","code":"# Generate a random VARMA model in echelon form ############  # Compute the appropriate model template tmpl = tmpl_arma_echelon(nu = c(1,2,1))  # Create a random model, which is stable but not necessarily miniphase model = r_model(tmpl, bpoles = 1, sd = 0.5) model #> ARMA model [3,3] with orders p = 2 and q = 2 #> AR polynomial a(z): #>      z^0 [,1]     [,2]  [,3]   z^1 [,1]        [,2]       [,3]  z^2 [,1] #> [1,]        1 0.000000     0  0.6803075 -0.13479012 -0.6523242 0.0000000 #> [2,]        0 1.000000     0  0.0000000 -0.06167765  0.0000000 0.4238262 #> [3,]        0 1.165454     1 -0.5598287 -0.41613770  0.1706450 0.0000000 #>           [,2]       [,3] #> [1,]  0.000000  0.0000000 #> [2,] -0.435083 -0.1727459 #> [3,]  0.000000  0.0000000 #> MA polynomial b(z): #>      z^0 [,1]     [,2]  [,3]   z^1 [,1]       [,2]        [,3] z^2 [,1] #> [1,]        1 0.000000     0  0.2495484  0.5894979  0.01492170  0.00000 #> [2,]        0 1.000000     0 -0.1131153  0.2163622  0.14250981 -1.12312 #> [3,]        0 1.165454     1  0.4422474 -0.2945865 -0.01840261  0.00000 #>            [,2]      [,3] #> [1,]  0.0000000 0.0000000 #> [2,] -0.4346585 0.0179878 #> [3,]  0.0000000 0.0000000 #> Left square root of noise covariance Sigma: #>            u[1]       u[2]        u[3] #> u[1]  0.5573692  0.0000000  0.00000000 #> u[2] -0.2871459 -0.3276322  0.00000000 #> u[3] -0.3516938  0.1433624 -0.05685043  # Check whether the poles satisfy the constraint min(abs(poles(model))) #> There are determinantal roots at (or close to) infinity. #> Roots close to infinity got discarded. #> [1] 1.039752 min(abs(zeroes(model))) #> There are determinantal roots at (or close to) infinity. #> Roots close to infinity got discarded. #> [1] 0.9155559"},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Residuals of an ARMA system — residuals_ARMA_cpp","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"internal helper function computes residuals directional derivatives residuals ARMA system form $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + \\cdots + b_q u_{t-q}$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"ib0 \\((m, m)\\) matrix, inverse coefficient matrix \\(b[0]\\). B1 \\((m, mq)\\) matrix, \\(-b_0^{-1}(b_q,...,b_1)\\). \\((m, n(q+1))\\) matrix \\(b_0^{-1}(a_0,...,a_p\\). t0 integer, start iteration t = t0. y \\((m, N)\\) matrix observed outputs \\((y_1,...,y_N\\). u \\((m, N)\\) matrix. matrix overwritten computed residuals \\((u_1,...,u_N\\). dU \\((mN, m^2(p+q+2))\\) matrix empty matrix. non empty matrix overwritten directional derivatives vectorized residuals. \\(j\\)-th column dU derivative \\(vec(u)\\) respect \\(j\\)-th entry \\(\\mathrm{vec}(a_0,a_1,\\ldots,a_p,b_0,\\ldots,b_q)\\)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"RcppArmadillo routine returns NULL overwrites input arguments u (dU)!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitly set zero. However, starting iteration \\(t_0>1\\) can enforce non-zero initial values.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"Use procedure care! procedure check input arguments. require \\(m = n > 0\\), \\(p,q \\geq 0\\) \\(1 \\leq t_0 \\leq N\\). procedure overwrites input argument u (dU). data matrices organized columnwise (avoid memory shuffling)! Note also non standard representation coefficient matrices.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"","code":"# generate a random ARMA(2,1) model (3 outputs, 2 inputs) p = 2 q = 1 m = 2 model = test_armamod(dim = c(m, m), degrees = c(p,q), digits = 2)  # prepare parameters for \"outputs_ARMA_cpp\" A = unclass(model$sys$a) a0 = A[,,1] A1 = -A[,,(p+1):2] dim(A1) = c(m, m*p) A1 = solve(a0, A1)  B = unclass(model$sys$b) dim(B) = c(m, m*(q+1)) B = solve(a0, B)  # generate random noise sequence (sample size N = 10) n.obs = 10 u = matrix(rnorm(n.obs*m), nrow = m, ncol = n.obs)  # generate matrix for the outputs y = matrix(0, nrow = m, ncol = n.obs)  # compute outputs t0 = 2   # start iterations from t>=t0=2 outputs_ARMA_cpp(A1, B, t0, u, y)  # recompute the disturbances/residuals from the given outputs: B = unclass(model$sys$b) ib0 = B[,,1] B1 = -B[,,(q+1):2] dim(B1) = c(m, m*q) B1 = solve(ib0, B1)  A = unclass(model$sys$a) dim(A) = c(m, m*(p+1)) A = solve(ib0, A)  ib0 = solve(ib0)  uu = u + 0 # \"deep copy\" of the disturbances uu[, t0:(n.obs)] = 0 # clear values for t >= t0 residuals_ARMA_cpp(ib0, B1, A, t0 = 2, y, uu, diag(0)) all.equal(u, uu) # check #> [1] TRUE  # compute directional derivatives of residuals dU = matrix(0, nrow = n.obs*m, ncol = (m^2)*(p+q+2)) residuals_ARMA_cpp(ib0, B1, A, t0 = 2, y, uu, dU)"},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Residuals of a statespace system — residuals_STSP_cpp","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"internal helper function computes residuals (directional derivatives residuals) statespace system form $$a_{t+1} = a_t + B u_t, \\; y_t = C a_t + D u_t$$ system must square non-empty, .e. \\(m=n>0\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"","code":"residuals_STSP_cpp(A, B, C, D, y, a, u, dPI, dU)"},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"\\((s,s)\\) matrix. B \\((s,m)\\) matrix. C \\((m,s)\\) matrix. D \\((m,m)\\) matrix, must regular. y \\((m,N)\\) matrix outputs: \\((y_1,y_2,\\ldots,y_N)\\). \\((s,N+1)\\) matrix. matrix overwritten (computed) states: \\((a_1,a_2,\\ldots,a_N,a_{N+1})\\). input [,1] must hold initial state \\(a_1\\). u \\((m,N)\\) matrix. matrix overwritten (computed) residuals: \\((u_1,u_2,\\ldots,u_N)\\). dPI \\(((m+s)^2,K)\\) matrix. dU \\((mN,K)\\) matrix \\((0,0)\\) matrix. matrix overwritten directional derivatives residuals. However, matrix empty derivatives computed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"RcppArmadillo implementation returns NULL overwrites input arguments , u dU!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"Use procedure care! procedure check input arguments. procedure overwrites input arguments , u dU. data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"","code":"# generate a random statespace model (3 outputs, 3 inputs and 4 states) m = 2 s = 3 model = test_stspmod(dim = c(m, m), s = s, digits = 2)  # generate random noise sequence (sample size N = 10) n.obs = 10 u = matrix(rnorm(n.obs*m), nrow = m, ncol = n.obs)  # generate matrix for the state sequence a = matrix(0, nrow = s, ncol = n.obs+1) a[,1] = rnorm(s) # random initial state a[1]  # generate matrix for the outputs y = matrix(0, nrow = m, ncol = n.obs)  # compute outputs and states outputs_STSP_cpp(model$sys$A, model$sys$B, model$sys$C, model$sys$D, u, a, y)  # recompute the states and disturbances/residuals from the given outputs: uu = u + 0 # \"deep copy\" of the disturbances aa = a + 0 # and the states aa[, 2:(n.obs+1)] = 0 # clear all states a[t], t > 1 residuals_STSP_cpp(model$sys$A, model$sys$B, model$sys$C, model$sys$D,                    y, aa, uu, diag(0), diag(0)) all.equal(u, uu) # check #> [1] TRUE all.equal(a, aa) # check #> [1] TRUE  # compute directional derivatives of residuals dPI = diag((m+s)^2) dU = matrix(0, nrow = n.obs*m, ncol = ncol(dPI)) residuals_STSP_cpp(model$sys$A, model$sys$B, model$sys$C, model$sys$D,                    y, aa, uu, dPI, dU)  # check the directional derivatives eps = 1e-8 dU_num = matrix(0, nrow = m*n.obs, ncol = (m+s)^2) dPI = matrix(0, nrow = (m+s), ncol = (m+s)) for (k in (1:((m+s)^2))) {   dPI[] = 0   dPI[k] = eps   uu = u + 0 # \"deep copy\" of the disturbances   aa = a + 0 # and the states   residuals_STSP_cpp(model$sys$A + dPI[1:s,1:s],                      model$sys$B + dPI[1:s,(s+1):(s+m)],                      model$sys$C + dPI[(s+1):(s+m),1:s],                      model$sys$D + dPI[(s+1):(s+m),(s+1):(s+m)],                      y, aa, uu, diag(0), diag(0))   dU_num[, k] = c(uu - u )/eps  # num. approx. of the derivative in direction \"dPI\" } # relative error of the numerical approximation junk = (abs(dU)+abs(dU_num)) junk[junk == 0] = 1 2*abs(dU_num - dU)/junk #>               [,1]         [,2]         [,3]         [,4]         [,5] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 7.541302e-08 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.512189e-07 #>  [3,] 5.537114e-07 5.537114e-07 2.676424e-09 2.032178e-09 2.621642e-06 #>  [4,] 2.179601e-07 7.541302e-08 3.728088e-05 2.293017e-07 1.974448e-08 #>  [5,] 1.811568e-08 2.954163e-07 1.091681e-08 8.109284e-09 5.134353e-07 #>  [6,] 3.423031e-08 2.951619e-08 2.915995e-07 1.317547e-08 4.330242e-08 #>  [7,] 5.019084e-09 1.387382e-07 1.776977e-08 6.999309e-08 1.141285e-08 #>  [8,] 1.938550e-08 6.946138e-09 2.674533e-08 1.453575e-09 6.537369e-08 #>  [9,] 2.903470e-08 8.383051e-09 6.434611e-08 1.480881e-08 5.598863e-08 #> [10,] 1.947922e-08 9.166698e-09 2.413596e-09 3.965126e-09 5.330606e-08 #> [11,] 2.702881e-08 4.245254e-08 2.077651e-08 2.228964e-08 7.452535e-08 #> [12,] 2.507449e-08 3.385148e-09 1.954482e-08 8.608057e-09 5.164622e-08 #> [13,] 2.113865e-08 3.555413e-08 6.623681e-09 2.486770e-08 3.963942e-08 #> [14,] 2.830204e-08 1.273564e-08 2.198359e-08 1.385138e-08 6.634338e-08 #> [15,] 3.055999e-08 2.116895e-09 3.376252e-08 2.048368e-08 6.102622e-08 #> [16,] 2.796527e-08 1.973632e-10 1.459109e-08 1.532650e-08 5.975420e-08 #> [17,] 3.057029e-08 1.207316e-08 2.396657e-08 2.763126e-08 5.766367e-08 #> [18,] 3.202323e-08 1.822568e-09 2.153310e-08 1.667397e-08 6.585037e-08 #> [19,] 3.262685e-08 3.546798e-09 2.530194e-08 2.796586e-08 5.746206e-08 #> [20,] 3.491511e-08 7.589383e-09 2.262995e-08 1.873646e-08 6.799233e-08 #>               [,6]         [,7]         [,8]         [,9]        [,10] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 1.685504e-09 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.685504e-09 #>  [3,] 2.132590e-08 7.301116e-08 6.017265e-09 7.279933e-08 1.073378e-07 #>  [4,] 4.038075e-09 3.242676e-08 4.026941e-06 8.325475e-08 2.791033e-08 #>  [5,] 2.932180e-08 5.414750e-08 8.626853e-08 1.529946e-08 2.092764e-08 #>  [6,] 4.077864e-08 4.740797e-08 1.056957e-08 9.004997e-08 5.778495e-10 #>  [7,] 8.036903e-08 8.439012e-09 1.565863e-08 4.426614e-08 6.199977e-09 #>  [8,] 1.874849e-08 4.217002e-08 6.225643e-08 7.935698e-08 2.814229e-09 #>  [9,] 2.037161e-08 1.198043e-09 1.654431e-08 5.527089e-07 1.218381e-08 #> [10,] 3.463673e-08 3.608452e-08 3.753393e-08 5.472012e-08 5.025085e-09 #> [11,] 1.846105e-08 1.530989e-08 5.343636e-08 2.886411e-08 6.429349e-10 #> [12,] 3.164751e-08 5.560075e-08 2.846666e-08 9.424942e-08 4.873728e-09 #> [13,] 4.314299e-08 5.293614e-08 2.398946e-08 9.519836e-08 1.430285e-08 #> [14,] 2.474508e-08 2.349083e-08 3.311969e-08 5.890630e-08 1.868146e-09 #> [15,] 2.288670e-08 4.745084e-08 2.978096e-08 6.933383e-08 1.435862e-10 #> [16,] 3.289420e-08 3.693839e-08 3.014315e-08 6.907298e-08 6.678617e-09 #> [17,] 2.999475e-08 2.372476e-08 3.256330e-08 5.584392e-08 5.793610e-09 #> [18,] 2.914068e-08 3.950803e-08 2.946585e-08 7.242526e-08 5.056713e-09 #> [19,] 3.189973e-08 4.768904e-08 2.763463e-08 8.037439e-08 6.230194e-09 #> [20,] 2.968729e-08 3.309481e-08 3.113709e-08 6.398588e-08 5.692828e-09 #>              [,11]        [,12]        [,13]        [,14]        [,15] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 2.538750e-09 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.189380e-07 #>  [3,] 6.249424e-08 1.851980e-07 3.795349e-08 5.478398e-08 2.277336e-07 #>  [4,] 1.356934e-07 3.795349e-08 3.669688e-07 2.106852e-07 9.077329e-08 #>  [5,] 1.651849e-07 3.598335e-08 1.911158e-08 2.076630e-08 1.119812e-07 #>  [6,] 6.649377e-08 2.344801e-08 8.824695e-08 1.635169e-07 3.497775e-08 #>  [7,] 2.829365e-08 3.359021e-07 6.581808e-08 5.602484e-08 5.849284e-09 #>  [8,] 5.680053e-08 1.238124e-07 7.855955e-08 1.097120e-07 2.451679e-08 #>  [9,] 3.075447e-08 2.207328e-07 2.281855e-08 1.242984e-07 4.314673e-08 #> [10,] 3.866730e-08 1.351697e-07 8.916849e-08 7.947266e-08 1.114497e-08 #> [11,] 5.600408e-08 1.086064e-07 3.874532e-08 6.428063e-08 3.437982e-08 #> [12,] 3.098703e-08 1.811942e-07 4.954006e-08 9.024279e-08 1.692288e-08 #> [13,] 2.247289e-08 1.768030e-07 5.881578e-08 7.148902e-08 7.943529e-09 #> [14,] 4.211179e-08 1.384533e-07 4.465179e-08 8.142140e-08 2.474474e-08 #> [15,] 4.057582e-08 1.928531e-07 3.485782e-08 8.940872e-08 2.417333e-08 #> [16,] 3.348460e-08 1.530801e-07 5.141448e-08 7.992083e-08 1.803798e-08 #> [17,] 3.923100e-08 1.437130e-07 4.363413e-08 7.114815e-08 1.969439e-08 #> [18,] 3.699978e-08 1.639348e-07 4.429055e-08 8.287307e-08 2.166142e-08 #> [19,] 3.470603e-08 1.608612e-07 4.444047e-08 7.756789e-08 1.774942e-08 #> [20,] 3.886814e-08 1.535266e-07 4.371219e-08 7.967705e-08 2.288454e-08 #>              [,16]        [,17]        [,18]        [,19]        [,20] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 1.716944e-08 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.778091e-09 #>  [3,] 8.226985e-08 1.518078e-07 1.624338e-09 5.191187e-08 8.805216e-08 #>  [4,] 2.160397e-08 4.011697e-08 5.054221e-06 9.287650e-08 6.378359e-08 #>  [5,] 3.583101e-08 3.234838e-08 9.675629e-09 6.044504e-08 2.806960e-08 #>  [6,] 3.041460e-08 4.454446e-08 4.878713e-08 3.836573e-08 2.756922e-08 #>  [7,] 8.575717e-09 6.119331e-08 7.101747e-09 1.013912e-07 9.399165e-08 #>  [8,] 1.657452e-08 2.052179e-08 4.630897e-08 9.448991e-08 5.934323e-08 #>  [9,] 2.059572e-08 1.074056e-06 7.093363e-08 1.444218e-07 4.142544e-08 #> [10,] 1.054747e-08 1.410494e-08 3.984726e-08 9.203834e-08 8.119711e-08 #> [11,] 2.163893e-08 3.249235e-08 3.308344e-08 8.134366e-08 4.217595e-08 #> [12,] 5.897578e-09 4.089319e-08 5.231153e-08 1.028511e-07 7.933372e-08 #> [13,] 6.325533e-09 4.162871e-08 6.203561e-08 1.229781e-07 9.250400e-08 #> [14,] 1.121894e-08 4.105076e-08 4.655336e-08 8.889634e-08 6.630172e-08 #> [15,] 1.134672e-08 4.108469e-08 6.032661e-08 9.913148e-08 5.956132e-08 #> [16,] 1.194861e-09 3.789185e-08 5.298110e-08 9.994594e-08 8.215824e-08 #> [17,] 3.593631e-09 4.440502e-08 5.115070e-08 1.011692e-07 7.134803e-08 #> [18,] 2.355649e-09 3.894059e-08 5.651595e-08 9.867892e-08 7.823893e-08 #> [19,] 1.018312e-09 3.975705e-08 6.296279e-08 1.110469e-07 7.743917e-08 #> [20,] 4.701496e-11 3.897191e-08 5.489946e-08 9.803419e-08 7.986635e-08 #>              [,21]        [,22]        [,23]        [,24]        [,25] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 7.856062e-10 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.466820e-08 #>  [3,] 6.618237e-10 6.618238e-10 2.840023e-09 5.316584e-08 2.673149e-08 #>  [4,] 2.783058e-09 7.856062e-10 3.431029e-07 1.691970e-08 3.899175e-08 #>  [5,] 1.670098e-09 5.583576e-09 9.503593e-09 4.012493e-08 3.564890e-08 #>  [6,] 7.856363e-09 5.163275e-09 3.216018e-09 2.767652e-09 6.859526e-08 #>  [7,] 1.378998e-08 4.843441e-10 6.322617e-09 1.552729e-09 3.207572e-08 #>  [8,] 8.664833e-09 7.751424e-09 6.692164e-09 4.074404e-09 5.467467e-08 #>  [9,] 1.261562e-08 9.544264e-09 1.431512e-09 3.415255e-08 5.604734e-08 #> [10,] 1.350890e-08 1.881494e-09 8.673477e-09 2.767161e-09 5.223409e-08 #> [11,] 1.641408e-08 1.108465e-08 5.835675e-09 2.151118e-08 4.496565e-08 #> [12,] 1.891895e-08 1.289209e-09 3.470060e-09 2.156589e-09 6.212765e-08 #> [13,] 2.137854e-08 9.754557e-09 3.689691e-09 9.763260e-09 4.726096e-08 #> [14,] 2.319715e-08 9.352113e-09 3.302315e-10 8.030287e-09 6.403163e-08 #> [15,] 2.569503e-08 7.750128e-09 8.598895e-09 2.858314e-08 5.696541e-08 #> [16,] 2.776660e-08 1.973434e-10 7.105715e-10 6.932401e-09 6.568005e-08 #> [17,] 2.992085e-08 1.415781e-09 1.172204e-08 2.287066e-08 5.558973e-08 #> [18,] 3.221886e-08 4.285553e-09 3.961384e-09 1.164391e-08 7.043936e-08 #> [19,] 3.487611e-08 8.155228e-10 1.329008e-08 2.514738e-08 6.050406e-08 #> [20,] 3.642492e-08 5.281759e-09 6.784107e-09 1.445970e-08 7.286672e-08"},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve a discrete time, algebraic Riccati equation — riccati","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"function solves discrete time, algebraic Riccati equation $$X = AXA' + (M -AXC')(G-CXC')^{-1}(M-AXC')'$$ square (s--s) matrix, M C' matrices dimension (s--m) G square (positive definite) matrix dimension (m--m). Given certain regularity conditions (see discussion ) solution X computed riccati positive definite matrix (size (s--s)).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"","code":"riccati(A, M, C, G, only.X = TRUE)"},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"(s--s) matrix M (s--m) matrix C (m--s) matrix G (m--m) matrix .X boolean","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"(.X) TRUE riccati just returns solution X, otherwise list slots X solution Ricatti equation B matrix \\(B = (M- AXC')\\Sigma^{-1}\\) sigma matrix \\(\\Sigma=G-CXC'\\) lambda (2m) vector eigenvalues associated generalized eigenvalue problem. first \\(m\\) entries eigenvalues \\(-BC\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"(within package) function mainly used construct state space model given autocovariance function process \\((y_t)\\) rational spectral density. ACF represented four matrices (,M,C,G) \\(\\gamma(0)=G\\) \\(\\gamma(k) = CA^{k-1}M\\) \\(k>0\\). realization problem related called spectral factorization problem. matrix \\(\\) stable, pair \\((,C)\\) controllable, pair \\((,M)\\) controllable (.e. (,M,C,G) \"minimal\" realization ACF) spectral density positive definite (.e. zeros) Riccati equation (unique) solution \\(X\\) positive definite matrix \\(- (M-AXC')(G-CXC')^{-1}C\\) stable. process  \\((y_t)\\) state space representation parameters \\((,B,C,D=)\\), \\(B=(M-AXC')\\Sigma^{-1}\\) \\(\\Sigma=(G-CXC')\\) innovation covariance. solution computed via (2m--2m) dimensional generalized eigenvalue problem, turn solved QZ decomposition. See QZ::qz.dgges() QZ::qz.dtgsen(). eigenvalues modulus less one eigenvalues matrix \\(-BC\\). addition riccati also used compute stochastically balanced realization state space model, see rationalmatrices::grammians() rationalmatrices::balance(). Note function mainly used utility function therefore checks given input parameters performed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"","code":"# create a \"random\" state space model, which satisfies the # stability and the (strict) miniphase assumption m = 2 # number of outputs s = 4 # number of states  model = r_model(template = tmpl_stsp_full(m, m, s),                 bpoles = 1, bzeroes = 1, sd = 0.25) # scale sigma model$sigma_L = model$sigma_L / sqrt(sum(diag(model$sigma_L %*% t(model$sigma_L))))  # extract the model parameter matrices A = model$sys$A B = model$sys$B C = model$sys$C sigma = model$sigma_L %*% t(model$sigma_L)  # compute the variance of the state P = A P A' + B sigma B' P = lyapunov(A, B %*% sigma %*% t(B))  # variance of the output y[t]: G = C P C' + sigma G = C %*% P %*% t(C) + sigma # covariance between s[t+1] and y[t]: M = A P C' + B sigma M = A %*% P %*% t(C) + B %*% sigma  # check that P solves the Riccati equation P = APA' + (M -APC')(G-CPC')^{-1}(M-APC')' all.equal(P,           A %*% P %*% t(A) +             (M - A %*% P %*% t(C)) %*% solve(G - C%*% P %*% t(C), t(M - A %*% P %*% t(C)))) #> [1] TRUE  # compute P from the Riccati equation: P = APA' + (M -APC')(G-CPC')^{-1}(M-APC')' out = riccati(A, M, C, G, only.X=FALSE)  # check the solution all.equal(P, out$X) #> [1] TRUE all.equal(B, out$B) #> [1] TRUE all.equal(sigma, out$sigma) #> [1] TRUE  # eigenvalues of (A-BC) ( <=> reciprocals of the zeroes of the system) lambda = eigen(A - B %*% C, only.values=TRUE)$values all.equal(sort(lambda), sort(out$lambda[1:s])) #> [1] TRUE"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor for RMFD Models — rmfdmod","text":"","code":"rmfdmod(sys, sigma_L = NULL, names = NULL, label = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor for RMFD Models — rmfdmod","text":"sys rationalmatrices::rmfd() object sigma_L Left-factor noise covariance, .e. covariance \\(\\sigma\\) obtained sigma_L * t(sigma_L). sigma_L vector dimension \\(n\\), \\(n\\) input dimension, diagonal elements parametrized. vector dimension \\(n^2\\), elements sigma_L filled column column. names optional vector character strings label optional character string","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor for RMFD Models — rmfdmod","text":"Object class rmfdmod.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Constructor for RMFD Models — rmfdmod","text":"right-matrix fraction description (RMFD) plus parameterisation noise covariance. (Hannan Deistler 2012) , RMFDs also called dynamic adjustment forms. Internally, MFDs lists slots sys, sigma_L, names, label. Many generic functions construct derived objects like autocovariance autocov() yet implemented rmfdmod objects.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Constructor for RMFD Models — rmfdmod","text":"Hannan EJ, Deistler M (2012). Statistical Theory Linear Systems,  Classics Applied Mathematics. SIAM, Philadelphia. Originally published: John Wiley & Sons, New York, 1988.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructor for RMFD Models — rmfdmod","text":"","code":"y = rmfdmod(sys = test_rmfd(dim = c(3,2), degrees = c(2,2))) y #> RMFD model [3,2] with orders p = 2 and q = 2 #> right factor polynomial c(z): #>      z^0 [,1]  [,2]  z^1 [,1]       [,2]  z^2 [,1]      [,2] #> [1,]        1     0  1.063776  0.7091924 0.7258066 2.1139358 #> [2,]        0     1 -0.121247 -0.3125334 2.0459464 0.3300832 #> left factor polynomial d(z): #>        z^0 [,1]       [,2]   z^1 [,1]       [,2]   z^2 [,1]       [,2] #> [1,] -0.4955241  0.7986806  0.2957552  0.5955532 -0.4058819 -0.4583619 #> [2,]  1.0333531  1.7221005 -0.3370352 -1.5470602  0.7109523  0.0409395 #> [3,]  0.4165378 -0.3344506 -1.2398965 -0.1183625  0.6463519  0.8976081 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from a State Space or VARMA Model — sim","title":"Simulate from a State Space or VARMA Model — sim","text":"Generate time series given process model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from a State Space or VARMA Model — sim","text":"","code":"sim(model, n.obs, rand.gen, n.burnin, ...)  # S3 method for armamod sim(model, n.obs, rand.gen = stats::rnorm, n.burnin = 0, ...)  # S3 method for stspmod sim(model, n.obs, rand.gen = stats::rnorm, n.burnin = 0, a1 = NULL, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from a State Space or VARMA Model — sim","text":"model either armamod() stspmod() object. n.obs sample size (\\(N\\)). rand.gen (optional) function generate disturbances \\(u_t\\). Note rand.gen() generate iid sample random variable mean zero variance one. n.burnin length initial \"burn-\" phase (denoted \\(N_0\\)). ... used. a1 (otional) vector initial state (start \"burn--phase\"). default a1 = NULL means zero initial state used. a1 = NA random initial state according state covariance generated. rand.gen used. model stable covariance defined procedure break .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from a State Space or VARMA Model — sim","text":"List slots y \\((N,m)\\) matrix generated outputs. u \\((N,n)\\) matrix noise. \\((N+1,s)\\) matrix generated states (\\(a_t\\), \\(t=1,...,N+1\\)). Note matrix (\\(N+1\\)) rows! slot present state space models.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate from a State Space or VARMA Model — sim","text":"order generate \"stationary\" trajectory (stable model) one chose suitable initial starting values. quite easy, particular VARMA models. simple remedy, procedure offers option \"burn-\" phase. length phase chosen user. state space model, value state first time point may passed procedure parameter a1. a1 = NULL (default value) zero vector used. a1 = NA random initial state according state covariance generated. model stable, covariance defined procedure break . rand.gen used. user like control disturbances initial values, solve_de() may used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from a State Space or VARMA Model — sim","text":"","code":"# Random Walk ############################################################################ model = armamod(lmfd(a = c(1,-1), b = 1)) # generate outputs \"y\" n.obs = 100 data = sim(model, n.obs = n.obs, y0 = 1) plot(data$y, type = 'l')   # bivariate ARMA(2,1) model ############################################################## model = test_armamod(dim = c(2,2), degrees = c(2,1), bpoles = 1, bzeroes = 1) # generate outputs \"y\" with zero initial conditions n.obs = 50 data =  sim(model, n.obs = n.obs) # reconstruct noise \"u\" from given outputs \"y\" data1 = solve_inverse_de(model$sys, y = data$y) all.equal(data$u, data1$u) #> [1] TRUE  # bivariate state space model with 5 states ############################################## model = test_stspmod(dim = c(2,2), s = 5, bpoles = 1, bzeroes = 1) # generate outputs \"y\" with random initial state a[1] n.obs = 50 data =  sim(model, n.obs = n.obs, a1 = NA) # reconstruct noise \"u\" from given outputs \"y\" data1 = solve_inverse_de(model$sys, y = data$y, a1 = data$a[1,]) all.equal(data$u, data1$u) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve ARMA system — solve_ARMA","title":"Solve ARMA system — solve_ARMA","text":"Compute outputs ARMA(p, q) systems form $$y_t = a_1 y_{t-1} + ... + a_p y_{t-p} + b_0 u_t + \\cdots + b_q u_{t-q}$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve ARMA system — solve_ARMA","text":"","code":"solve_ARMA_R(a, b, u, y, t0)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve ARMA system — solve_ARMA","text":"\\((m, mp)\\) matrix \\((a_p,...,a_1)\\). b \\((m, n(q+1))\\) matrix \\((b_0,...,b_q\\). u \\((n, N)\\) matrix inputs \\((u_1,...,u_N\\). y \\((m, N)\\) matrix outputs \\((y_1,...,y_N\\). t0 integer, start iteration t=t0.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve ARMA system — solve_ARMA","text":"R implementation solve_ARMA_R returns matrix y computed outputs. RcppArmadillo implementation returns NULL overwrites input argument y!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve ARMA system — solve_ARMA","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitly set zero. However, start iteration \\(t_0>1\\) can enforce non-zero initial values. routines used internally hence check arguments. require \\(m > 0\\), \\(p \\geq 0\\), \\(n \\geq 0\\), \\((q+1) \\geq 0\\) \\(1 \\leq t_0 \\leq N\\). Note also RcppArmadillo implementation overwrites input argument y. Use procedure care! Note non standard arguments: order AR coefficients reversed. data matrices organized column-wise (avoid memory shuffling)!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve RMFD system for given inputs — solve_RMFD_R","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"Compute outputs \\(y_t\\) RMFD(p, q) systems form $$y_t = d_0 v_t + d_1 v_{t-1} + \\cdots + d_q v_{t-q}$$ $$v_t + c_1 v_{t-1} + \\cdots + c_p v_{t-p} = u_t$$ given inputs \\(u_t\\) contained column-wis data matrix data_input, see .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"","code":"solve_RMFD_R(polm_c, polm_d, data_input, t0 = 1)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"polm_c, polm_d polm objects. Describe jointly RMFD. \\(c(z)\\) square, identity zero-lag coefficient, coefficients reversed procedure: \\((c_p,...,c_1)\\). \\(d(z)\\) might tall, zero-lag coefficient matrix general free. data_input \\((n, N)\\) matrix inputs \\((u_1,...,u_N\\). t0 integer, start iteration t=t0.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"R implementation solve_RMFD_R() returns matrix y computed outputs. $$y_t = d(z) c(z)^{-1} u_t$$ RcppArmadillo implementation solve_rmfd_cpp() returns NULL overwrites input argument. Note RcppArmadillo implementation different user interface (intended internal use ).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitely set zero. However, start iteration \\(t_0>1\\) can enforce non-zero initial values. routines used internally hence check arguments. require number outputs positive \\(m > 0\\), number inputs non-negative \\(n \\geq 0\\), degree \\(c(z)\\) %>%  non-negative \\(p \\geq 0\\), degree \\(d(z)\\) unrestricted, .e. \\((q+1) \\geq 0\\), starting value sample size \\(1 \\leq t_0 \\leq N\\) holds. Note also RcppArmadillo implementation overwrites input argument y. Use procedure care! Note non standard arguments: polynomial matrices \\(c(z)\\) \\(d(z)\\) saved \"wide\" matrices. order coefficients \\(c(z)\\) reversed \\(c_0\\) coefficient (required identity matrix). order coefficients \\(d(z)\\) usual, \\(d_0\\) available . data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve (linear) Difference Equations — solve_de","title":"Solve (linear) Difference Equations — solve_de","text":"procedure solve_de() solves difference equations associated (V)ARMA models $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t  + b_1 u_{t-1} + ... b_1 u_{t-q}$$ state space models $$a_{t+1} = a_t + B u_t \\mbox{ } y_t = C a_t + D u_t.$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve (linear) Difference Equations — solve_de","text":"","code":"solve_de(sys, u, ...)  # S3 method for stsp solve_de(sys, u, a1 = NULL, ...)  # S3 method for lmfd solve_de(sys, u, u0 = NULL, y0 = NULL, ...)  # S3 method for rmfd solve_de(sys, u, u0 = NULL, y0 = NULL, ...)  solve_inverse_de(sys, y, ...)  # S3 method for stsp solve_inverse_de(sys, y, a1 = NULL, ...)  # S3 method for lmfd solve_inverse_de(sys, y, u0 = NULL, y0 = NULL, ...)  # S3 method for rmfd solve_inverse_de(sys, y, u0 = NULL, y0 = NULL, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve (linear) Difference Equations — solve_de","text":"sys rationalmatrices::lmfd() rationalmatrices::stsp() object describes difference equation. u \\((N,n)\\) matrix noise (\\(u_t\\), \\(t=1,...,N\\)). ... used. a1 \\(m\\) dimensional vector initial state \\(a_1\\). a1=NULL zero vector used. u0 \\((h,n)\\) dimensional matrix starting values disturbances \\((u_{1-h}, \\ldots, u_{-1}, u_0)\\). Note last row corresponds \\(u_0\\), last one row \\(u_{-1}\\) . \\(h>q\\) last \\(q\\) rows u0 used. case \\(h<q\\) \"missing\" initial values set zero vectors.  default value u0=NULL sets initial values \\(u_t\\), \\(t \\leq 0\\) equal zero vectors. y0 \\((h,m)\\) dimensional matrix starting values outputs \\((y_{1-h}, \\ldots, y_{-1}, y_0)\\). (optional) parameter interpreted analogously u0. y \\((N,m)\\) matrix outputs (\\(y_t\\), \\(t=1,...,N\\)).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve (linear) Difference Equations — solve_de","text":"List slots y \\((N,n)\\) matrix (computed) outputs. u \\((N,n)\\) matrix (computed) noise. \\((N+1,n)\\) matrix (computed) states (\\(a_t\\), \\(t=1,...,N+1\\)). Note matrix (\\(N+1\\)) rows! slot present state space models.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve (linear) Difference Equations — solve_de","text":"solve_de() computes outputs \\(y_t\\) \\(t=1,\\ldots,N\\) given disturbances \\(u_t\\) \\(t=1,\\ldots,N\\). starting values  (\\(u_t\\) \\(y_t\\) \\(t\\leq 0\\) VARMA models \\(a_1\\) state space models) may given optional arguments. default use zero vectors. reverse direction, .e. reconstruct disturbances outputs given, function solve_inverse_de may used. case system must square matrix \\(D\\) respectively \\(b_0\\) must invertible. functions mainly intended internal use hence basic checks input parameters performed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve (linear) Difference Equations — solve_de","text":"","code":"### generate a random ARMA(2,1) model (with two outputs) ######### model = test_armamod(dim = c(2,2), degrees = c(2,1),                      digits = 2, bpoles = 1, bzeroes = 1)  # generate random noise sequence (sample size N = 100) u = matrix(rnorm(100*2), nrow = 100, ncol = 2)  # generate random initial values u0 = matrix(rnorm(2), nrow = 1, ncol = 2) # u[0] y0 = matrix(rnorm(2), nrow = 1, ncol = 2) # y[0]  # compute outputs \"y[t]\" # note that y0 has only one row, thus y[-1] is set to zero! data = solve_de(model$sys, u = u, y0 = y0, u0 = u0)  # we can reconstruct the noise \"u\" from given outputs \"y\" data1 = solve_inverse_de(model$sys, y = data$y, u0 = u0, y0 = y0) all.equal(data$u, data1$u) #> [1] TRUE  ### generate a random state space model (3 outputs and 4 states) ## model = test_stspmod(dim = c(3,3), s = 4,                      digits = 2, bpoles = 1, bzeroes = 1)  # generate random noise sequence (sample size N = 100) u = matrix(rnorm(100*3), nrow = 100, ncol = 3)  # generate random initial state a[1] a1 = rnorm(4)  # compute outputs \"y[t]\" data = solve_de(model$sys, u = u, a1 = a1)  # we can reconstruct the noise \"u\" from given outputs \"y\" data1 = solve_inverse_de(model$sys, y = data$y, a1 = data$a[1,]) all.equal(data$u, data1$u) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"Compute inputs \\(u_t\\) RMFD(p, q) systems form $$y_t = d_0 v_t + d_1 v_{t-1} + \\cdots + d_q v_{t-q}$$ $$v_t + c_1 v_{t-1} + \\cdots + c_p v_{t-p} = u_t$$ given data \\(y_t\\) contained column-wise matrix data_output, see .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"","code":"solve_inverse_RMFD_R(polm_c, polm_d, data_output, t0 = 1)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"polm_c, polm_d polm objects. Jointly, reprsent RMFD. \\(c(z)\\) square, identity zero-lag coefficient. \\(d(z)\\) might tall, zero-lag coefficient matrix general free. data_output \\((m, N)\\) matrix outputs \\((y_1,...,y_N\\). t0 integer, start iteration t=t0.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"R implementation solve_inverse_RMFD_R returns matrix u computed inputs $$u_t = d^{+}(z) c(z) y_t$$ columns. RcppArmadillo implementation solve_rmfd_cpp() returns NULL overwrites input argument! Note RcppArmadillo implementation different user interface (intended internal use ).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitely set zero. However, start iteration \\(t_0>1\\) can enforce non-zero initial values. routines used internally hence check arguments. require number outputs positive \\(m > 0\\), number inputs non-negative \\(n \\geq 0\\), degree \\(c(z)\\) non-negative \\(p \\geq 0\\), degree \\(d(z)\\) unrestricted, .e. \\((q+1) \\geq 0\\), starting value sample size \\(1 \\leq t_0 \\leq N\\) holds. Note also RcppArmadillo implementation overwrites input argument y. Use procedure care! Note non standard arguments: polynomial matrices \\(c(z)\\) \\(d(z)\\) saved \"wide\" matrices. order coefficients \\(c(z)\\) reversed \\(c_0\\) coefficient (required identity matrix). order coefficients \\(d(z)\\) usual, \\(d_0\\) available . data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/solve_rmfd_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","title":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","text":"RcppArmadillo function calculates given inputs data_in dimension \\((n \\times nobs)\\),  \\(nobs\\) sample size, outputs dimension \\(m\\). Note data matrices \"transposed\" sense every column corresponds one observation memory management. data_out thus dimension \\((m x nobs)\\). function intended internal use thus arguments checked.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_rmfd_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","text":"poly_inv Matrix dimension \\((n \\times n p)\\), representing square matrix polynomial \\(c(z)\\) \\(c_0\\) equal identity matrix (therefore stored). coefficients need reverse direction, .e. \\((c_p, ... , c_1)\\), \\(p\\) denotes degree \\(c(z)\\). poly_fwd Matrix dimensions \\((m \\times n(q+1))\\), representing (possibly tall) matrix polynomial \\(d(z)\\) dimension \\((m \\times n)\\), \\(m \\geq n\\). coefficient stored \"usual\" including \\(d_0\\), .e. \\((d_0, d_1, ... , d_{q-1}, d_{q})\\), \\(q\\) denotes degree \\(d(z)\\). data_in Matrix dimension \\((n \\times n_obs)\\), .e. \\((u_1, ..., u_T)\\). Inputs RMFD system. data_out Matrix dimension \\((m \\times n_obs)\\), .e. \\((y_1, ..., y_T)\\). Outputs RMFD system. Initially zero overwritten. t0 Integer. Time index start calculating solution. Usually equal 1.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_rmfd_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","text":"data_out overwritten outputs RMFD system.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":null,"dir":"Reference","previous_headings":"","what":"Spectral Density — spectrald","title":"Spectral Density — spectrald","text":"Compute spectral density ARMA process process defined state space model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spectral Density — spectrald","text":"","code":"spectrald(obj, n.f, ...)  # S3 method for armamod spectrald(obj, n.f = 128, ...)  # S3 method for stspmod spectrald(obj, n.f = 128, ...)  # S3 method for autocov spectrald(obj, n.f = 128, ...)  # S3 method for impresp spectrald(obj, n.f = 128, ...)  # S3 method for default spectrald(obj, n.f = NULL, demean = TRUE, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spectral Density — spectrald","text":"obj armamod(), stspmod(), autocov(), impresp() object \"time series\" object, .e. object may coerced data matrix y = .matrix(obj). n.f number frequencies. ... used. demean (logical) data demeaned computing periodogram?","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spectral Density — spectrald","text":"freqresp object, .e. list slots spd rationalmatrices::zvalues() object. names (m)-dimensional character vector NULL. optional slot stores names components time series/process. label character string NULL. n.obs (optional) integer NULL.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Spectral Density — spectrald","text":"spectral density stationary process absolutely summable autocovariance function \\((\\gamma_j)\\) given $$ \\Gamma(\\lambda) = \\frac{1}{2\\pi}\\sum_{j=-\\infty}^{\\infty} \\gamma_j e^{-\\lambda j}. $$ ARMA process, process defined state space model spectral density equal $$ \\Gamma(\\lambda) = \\frac{1}{2\\pi} K(\\lambda) \\Sigma K^*(\\lambda) $$ \\(\\Sigma\\) noise covariance, \\(K()\\) frequency response model \\(K^*(\\lambda)\\) Hermitean transpose \\(K(\\lambda)\\). See also autocov() freqresp(). Note \\(\\Gamma()\\) (factor \\(2\\pi\\)) discrete-time Fourier transform (DTFT) autocovariance function therefore ACF \\(\\gamma_j\\) may reconstructed spectral density via inverse DTFT $$ \\gamma_j = \\int_{-\\pi}^{\\pi} \\Gamma(\\lambda) e^{\\lambda j} d\\lambda $$ S3 methods spectrald.* evaluate spectral density function grid angular frequencies \\(\\lambda_j = 2\\pi j/N\\), \\(j=0,\\ldots,N-1\\) store result spectrald object. several possible ways specify process. One may provide ARMA (armamod) respectively state space model (stspmod), autocovariance function (autocov) impulse response function (impresp) maps noise outputs. Note however, given autocov impresp object computed spectral density approximation true spectral density since finite number covariances respectively impulse response coefficients given. type autocovariance function (\"covariances\", \"correlations\" \"partial correlations\") irrelevenat since procedure alwayas uses slot \"gamma\" contains covariances. default method spectrald.default assumes obj \"time series\" object tries coerce object data matrix via y = .matrix(obj). case procedure computes periodogram simple estimate spectral density. periodgram may also computed call spectrald(autocov(obj, max.lag = n.obs-1)), .e. first computing sample auto covariance function computing corresponding spectral density. Note use different scaling stats::[spectrum][stats::spectrum] routine.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spectral Density — spectrald","text":"","code":"#' ### generate random 3-dimensional ARMA(1,1) model # \"bpoles = 1.1\" implies that the poles have moduli larger than 1.1 # and therefore the impulse response coefficients decay with a rate (1.1)^k arma_model = test_armamod(dim = c(3,3), degrees = c(1,1), bpoles = 1.1)  # spectral density spd = spectrald(arma_model)  # compute the spectral density via the impulse response spd1 = spectrald(impresp(arma_model, lag.max = 100))  # since the impulse response quickly decays # the \"truncated\" spectral density should be close to the true one all.equal(spd, spd1) #> [1] TRUE  # compute the spectral density via the autocovariance function spd1 = spectrald(autocov(arma_model, lag.max = 100))  # since the ACF quickly decays # the \"truncated\" spectral density should be close to the true one all.equal(spd, spd1) #> [1] TRUE  # create an equivalent state space model stsp_model = as.stspmod(arma_model)  # of course the state space model gives the same spectrum # as the original ARMA model spd1 = spectrald(stsp_model) all.equal(spd, spd1) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/str.html","id":null,"dir":"Reference","previous_headings":"","what":"Display the Structure of Objects — str methods","title":"Display the Structure of Objects — str methods","text":"Display Structure Objects","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display the Structure of Objects — str methods","text":"","code":"# S3 method for armamod str(object, ...)  # S3 method for stspmod str(object, ...)  # S3 method for impresp str(object, ...)  # S3 method for autocov str(object, ...)  # S3 method for fevardec str(object, ...)  # S3 method for freqresp str(object, ...)  # S3 method for spectrald str(object, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/str.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display the Structure of Objects — str methods","text":"object object ... used","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/str.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display the Structure of Objects — str methods","text":"invisible(NULL)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":null,"dir":"Reference","previous_headings":"","what":"Creator for stspmod class — stspmod","title":"Creator for stspmod class — stspmod","text":"Creator stspmod class","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creator for stspmod class — stspmod","text":"","code":"stspmod(sys, sigma_L = NULL, names = NULL, label = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creator for stspmod class — stspmod","text":"sys rationalmatrices::stsp() object sigma_L noise covariance left names optional vector character strings label optional chracter string","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creator for stspmod class — stspmod","text":"Object class stspmod.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creator for stspmod class — stspmod","text":"","code":"x = stspmod(sys = test_stsp(dim = c(2,2), s = 2), sigma_L = diag(2)) x #> state space model [2,2] with s = 2 states #>            s[1]       s[2]       u[1]      u[2] #> s[1]  0.5105671  1.6823183 -0.2925323 -2.166980 #> s[2] -1.1836676  1.7890167  1.1578473 -1.680253 #> x[1]  0.9410797  1.3583102  1.0000000  0.000000 #> x[2] -1.2673354 -0.3776806  0.0000000  1.000000 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Subspace Helper Methods — subspace helpers","title":"Subspace Helper Methods — subspace helpers","text":"procedure implement two subspace algorithms estimation state space models, AOKI method, described (Aoki 1990)  CCA algorithm (see e.g. (Dahlen Scherrer 2004)  (Bauer 2001) ). subspace algorithms center weighted Hankel matrix $$(R_f')^{-T} H_{fp} R_p^{-1}$$ block Hankel matrix \\(H_{fp}\\) covariance \"past\" \\((y_{t-1}',\\cdots,y_{t-p}')'\\) \"future\" \\((y_{t}',\\cdots,y_{t+f-1}')'\\) \\(R_f\\) \\(R_p\\) cholesky factors covariance matrices \"future\" \"past\" respectively. singular values weighted Hankel matrix canonical correlation coefficients past future. Note implementation always sets \\(f = p+1\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subspace Helper Methods — subspace helpers","text":"","code":"est_stsp_aoki(   gamma,   s.max,   p,   estorder = estorder_SVC,   keep_models = FALSE,   n.obs = NULL,   ... )  est_stsp_cca(   gamma,   s.max,   p,   estorder = estorder_SVC,   keep_models = FALSE,   n.obs = NULL,   ... )  est_stsp_cca_sample(   y,   s.max,   p,   estorder = estorder_SVC,   keep_models = FALSE,   mean_estimate = c(\"sample.mean\", \"zero\"),   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subspace Helper Methods — subspace helpers","text":"gamma \\((m,m,L+1)\\)-dimensional array (sample) autocovariance function. s.max (integer) maximum possible order. p (integer) number block columns Hankel matrix (size \"past\") estorder function, estimate order system. keep_models (boolean) function return list estimated system order 0:s.max? n.obs sample size \\(N\\). ... additional parameters, passed order estimation routine. y \\((N,m)\\)-dimensional matrix object, may coerced matrix .matrix{y}. mean_estimate Character string giving method used estimate mean \\(\\mu = E y_t\\). Default use sample mean.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subspace Helper Methods — subspace helpers","text":"List slots: model stsp() object, represents estimated state space model. models either NULL (!keep_models) list parameters estimated models orders (s=0:s.max+1). slot may e.g. used estimate model order user defined model selection procedure. s (integer) estimate model order. info list information data design parameters estimation procedure. stats ((s.max+1)--5)-dimensional matrix statistics (estimated) state space models.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subspace Helper Methods — subspace helpers","text":"AOKIs method realization algorithm, .e. reconstructs underlying state space model (population) autocovariance function. end Riccati equation solved, see riccati(). estimated ACF fed algorithm one obtains estimate state space model. However note may fail (particular Riccati equation may positive definite solution) estimate ACF positive definite, Hankel matrix small state dimension correct. CCA method estimates state space model first constructing estimate states. parameter matrices estimated via simple LS regressions. procedure give \"true\" model, even case population ACF used. However, \"distance\" true model estimated model converges zero, estimate ACF converges population ACF size \\(p\\) Hankel matrix converges infinity. two implementations CCA method: routine est_stsp_cca_sample() operates directly supplied data. routine est_stsp_cca() uses (estimated) autocovariance function. algorithms may also used simple \"model reduction algorithms\". want approximate high dimensional state space model model lower order, may proceed follows. First compute ACF high dimensional model fed ACF subspace routines est_stsp_cca est_stsp_aoki, however setting maximum order s.max value less true order. Order Estimation order estimation based Hankel singular values \\(\\sigma_s\\) /log det values estimated noise covariance matrices \\(\\ln\\det \\hat{\\Sigma}_s\\). Using Hankel singular values advantage one model estimated, whereas otherwise estimates models orders \\(s=0,\\ldots,s_{\\max}\\) computed. order exploit (small) advantage singular values based criteria order estimation runs follows: First procedures call  estorder(s.max, Hsv, n.par, m, n.obs, Hsize=c(f,p), ...)  Hsv \\(pm\\) dimensional vector Hankel singular values n.par \\((s_{\\max}+1)\\) dimensional vector respective number parameters models orders \\(s=0,\\ldots,s_{\\max}\\). call returns estimate order procedures estimate corresonding state space model. call fails (.e returns NULL) procedures estimate models orders \\(s_{\\max}\\) corresponding noise covariance matrices. order estimated calling  estorder(s.max = s.max, Hsv, lndetSigma, n.par, m, n.obs, Hsize, ...)  lndetSigma vector log det values estimated noise covariance matrices (\\(\\ln\\det \\hat{\\Sigma}_s\\)). package offers predefined order selection procedures (see also subspace order estimates): estorder_max(s.max, ...) simply returns maximum order s.max considered. estorder_rkH(s.max, Hsv, tol, ...) estimates order estimate rank Hankel matrix. estorder_MOE(s.max, Hsv, ...) estimates order searching \"gap\" singular values. estorder_SVC(s.max, Hsv, n.par, n.obs, Hsize, penalty, ...) implements called Singular Value Criteria, see (Bauer 2001) : $$svc(s) = \\sigma_{s+1}^2 + c(N)d(s)/N$$ \\(\\sigma_s\\) \\(s\\)-th singular value weighted Hankel marix, \\(N\\) sample size, \\(d(s) = 2ms\\) denotes number parameters state space model \\(s\\) states (\\(m\\) outputs) \\(c(N)\\)) \"penalty\" (depending sample size). order estimation procedures use Hankel singular values, whereas following procedure based estimated noise covariances. estorder_IVC(s.max, lndetSigma, n.par, n.obs, penalty, ...) estimates order via information criterion form $$ivc(s) = \\ln\\det\\hat\\Sigma_{s} + c(N)d(s)/N$$ \\(\\hat\\Sigma_s\\) estimate noise covariace matrix obtained model order \\(s\\), \\(d(s)\\) denotes number parameters \\(c(N)\\) \"penalty\" (depending sample size). estorder_SVC estorder_IVC (optional) parameter penalty controls penalty term \\(c(N)\\). Note also  keep_models==TRUE estimation procedures compute models even case Hankel singular value based selection criterion.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Subspace Helper Methods — subspace helpers","text":"Bauer D (2001). “Order estimation subspace methods.” Automatica, 37(10), 1561 - 1573. doi:10.1016/S0005-1098(01)00118-2 .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate State Space Models with Subspace Methods — subspace methods","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"Estimate (respectively construct) state space model given sample given (sample) autocovariance function.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"","code":"est_stsp_ss(   obj,   method = c(\"cca\", \"aoki\"),   s.max = NULL,   p = NULL,   p.ar.max = NULL,   p.factor = 2,   extend_acf = FALSE,   sample2acf = TRUE,   estorder = estorder_SVC,   keep_models = FALSE,   mean_estimate = c(\"sample.mean\", \"zero\"),   n.obs = NULL,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"obj Either \"time series\" object (.e .matrix(obj) returns \\((N,m)\\)-dimensional numeric matrix) autocov() object (\\(L\\) lags) represents (estimated) autocovariance function. type autocov object irrelevant since est_stsp_ss always uses slot obj$gamma contains autocovariance function. method Character string giving method used fit model. s.max (integer) maximum order state space model. NULL default value chosen based sample size \\(N\\), respectively based number lags \\(L\\) ACF. p (integer) number block columns Hankel matrix (size \"past\"). NULL p chosen fitting \"long\" AR model. p.ar.max (integer) maximum order \"long\" AR model. NULL default choice made. parameter needed case p=NULL. p.factor (integer) p=NULL, number block columns Hankel matrix set \\(p = p_f\\hat{p}_{AIC}\\) \\(p_f\\) parameter p.factor \\(\\hat{p}_{AIC}\\) (AIC) estimate order \"long\" AR model. See also est_ar(). extend_acf (boolean) TRUE ACF extended via AR(p) model (MEST). sample2acf (boolean) obj data object sample2acf TRUE, first sample autocovariance function computed used actual computations. estorder function, used select order state space model. keep_models (boolean) function return list estimated system order 0:s.max? mean_estimate Character string giving method used estimate mean \\(\\mu = E y_t\\). Default use sample mean. See details . n.obs Optional integer gives sample size \\(N\\). parameter used, obj autocov() object. n.obs=NULL slot obj$n.obs used. Note obj$n.obs=NULL obj$n.obs=Inf refers case population autocovariance function, .e. \\(N=\\infty\\). \"time series\" object sample size course set number observations, .e. n.obs = nrow(.matrix(obj)). sample size \\(N\\) controls computation default (maximum) orders estimation order state space model. ... additional parameters, passed order estimation routine.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"list slots model stsp() object, represents estimated state space model. models either NULL (!keep_models) list parameters estimated models orders (s=0:s.max+1). slot may e.g. used estimate model order user defined model selection procedure. s (integer) estimate model order. info list information data design parameters estimation procedure. stats ((s.max+1)--5)-dimensional matrix statistics (estimated) state space models. y.mean estimate mean \\(\\mu\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"procedure implements three subspace algorithms estimation state space models, AOKI method, described (Aoki 1990)  CCA MEST algorithms (see e.g. (Dahlen Scherrer 2004) ). three algorithms center weighted Hankel matrix $$(R_f')^{-T} H_{fp} R_p^{-1}$$ block Hankel matrix \\(H_{fp}\\) covariance \"past\" \\((y_{t-1}',\\cdots,y_{t-p}')'\\) \"future\" \\((y_{t}',\\cdots,y_{t+f-1}')'\\) \\(R_f\\) \\(R_p\\) cholesky factors covariance matrices \"future\" \"past\" respectively. singular values weighted Hankel matrix canonical correlation coefficients past future. Note implementation always sets \\(f = p+1\\). AOKIs method realization algorithm, .e. reconstructs underlying state space model (population) autocovariance function. end Riccati equation solved, see riccati(). estimated ACF fed algorithm one obtains estimate state space model. However note may fail (particular Riccati equation may positive definite solution) estimate ACF positive definite, Hankel matrix small state dimension correct. CCA method estimates state space model first constructing estimate states. parameter matrices estimated via simple LS regressions. procedure give \"true\" model, even case population ACF used. However, \"distance\" true model estimated model converges zero, estimate ACF converges population ACF size \\(p\\) Hankel matrix converges infinity. two implementations CCA method: obj \"time series\" object sample2acf==FALSE helper function est_stsp_cca_sample() called. implementation CCA operates directly supplied data. obj autocov() object obj \"time series\" object sample2acf==TRUE helper function est_stsp_cca() called. implementation uses (estimated) autocovariance function. time series object, first sample autocovariance function computed fed helper function. key idea MEST algorithm first estimate \"long\" AR model, convert AR model state space model use \"balancing truncation\" method obtain final estimate state space model. scheme may obtained calling est_stsp_ss option extend_acf=TRUE: option instructs procedure first estimate AR(p) model use model \"extend\" ACF, .e. compute values ACF lags \\(p+1,\\ldots,2p\\). extended ACF fed helper function  est_stsp_cca(). Note MEST uses autocovariance function. \"time series\" object one set sample2acf=TRUE. algorithms may used model reduction (.e. find model smaller state space dimension true model) estimation (feeding sample autocovariance function ). algorithms may also used simple \"model reduction algorithms\". want approximate high dimensional state space model model lower order, may proceed follows. First compute ACF high dimensional model fed ACF subspace routine est_stsp_ss, however setting maximum order s.max value less true order. Note thet AOKI procedure however, may break , since guaranteed Riccati equation, needs solved, positive semidefinite solution. Size Hankel matrix input parameter p=NULL \\(p\\) chosen follows. procedure estimates order \"long\" AR model AIC criterion. size \"past\" \\(p\\) set \\(p = p_f\\hat{p}_{AIC}\\) \\(p_f\\) factor (defaults \\(2\\)) \\(\\hat{p}_{AIC}\\) (AIC) estimate order \"long\" AR model. See also est_ar(). Estimation Mean input parameter obj autocov() object (contains info mean \\(\\mu=E y_t\\)) \"estimate\" mean simply set vector NA's. input parameter obj \"time series\" object, two options. mean_estimate == 'zero' procedure assumes process centered (\\(\\mu=E y_t=0\\)) thus sets estimate zero vector. case mean_estimate == 'sample.mean'  sample mean data used. Order Estimation input parameter s.max defines maximum order considered. order estimation based Hankel singular values \\(\\sigma_s\\) /log det values estimated noise covariance matrices \\(\\ln\\det \\hat{\\Sigma}_s\\). Using Hankel singular values advantage one model estimated, whereas otherwise estimates models orders \\(s=0,\\ldots,s_{\\max}\\) computed. order exploit (small) advantage singular values based criteria order estimation runs follows: First procedures call  estorder(s.max, Hsv, n.par, m, n.obs, Hsize=c(f,p), ...)  Hsv \\(pm\\) dimensional vector Hankel singular values n.par \\((s_{\\max}+1)\\) dimensional vector respective number parameters models orders \\(s=0,\\ldots,s_{\\max}\\). call returns estimate order procedures estimate corresonding state space model. call fails (.e returns NULL) procedures estimate models orders \\(s_{\\max}\\) corresponding noise covariance matrices. order estimated calling  estorder(s.max = s.max, Hsv, lndetSigma, n.par, m, n.obs, Hsize, ...)  lndetSigma vector log det values estimated noise covariance matrices (\\(\\ln\\det \\hat{\\Sigma}_s\\)). package offers predefined order selection procedures (see also subspace order estimates): estorder_max(s.max, ...) simply returns maximum order s.max considered. estorder_rkH(s.max, Hsv, tol, ...) estimates order estimate rank Hankel matrix. estorder_MOE(s.max, Hsv, ...) estimates order searching \"gap\" singular values. estorder_SVC(s.max, Hsv, n.par, n.obs, Hsize, penalty, ...) implements called Singular Value Criteria, see (Bauer 2001) : $$svc(s) = \\sigma_{s+1}^2 + c(N)d(s)/N$$ \\(\\sigma_s\\) \\(s\\)-th singular value weighted Hankel marix, \\(N\\) sample size, \\(d(s) = 2ms\\) denotes number parameters state space model \\(s\\) states (\\(m\\) outputs) \\(c(N)\\)) \"penalty\" (depending sample size).  order estimation procedures use Hankel singular values, whereas following procedure based estimated noise covariances. estorder_IVC(s.max, lndetSigma, n.par, n.obs, penalty, ...) estimates order via information criterion form $$ivc(s) = \\ln\\det\\hat\\Sigma_{s} + c(N)d(s)/N$$ \\(\\hat\\Sigma_s\\) estimate noise covariace matrix obtained model order \\(s\\), \\(d(s)\\) denotes number parameters \\(c(N)\\) \"penalty\" (depending sample size). estorder_SVC estorder_IVC (optional) parameter penalty controls penalty term \\(c(N)\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"further-notes","dir":"Reference","previous_headings":"","what":"Further Notes","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"actual computations done helper routines detailed subspace helpers. type autocov() object irrelevenat since function always uses slot obj$gamma.  keep_models==TRUE estimation procedure compute models even case Hankel singular value based selection criterion.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"Aoki M (1990). State Space Modeling Time Series. Springer Verlag, New York. Bauer D (2001). “Order estimation subspace methods.” Automatica, 37(10), 1561 - 1573. doi:10.1016/S0005-1098(01)00118-2 . Dahlen , Scherrer W (2004). “relation CCA subspace method balanced reduction autoregressive model.” Journal Econometrics, 118, 293--312. doi:10.1016/S0304-4076(03)00144-1 .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"","code":"set.seed(3421) # in order to get reproducible results  # create a \"random\", stable and miniphase state space model m = 2 # number of outputs s = 3 # number of states s.max = 2*s lag.max = max(4*s, 25) n.obs = 1000  model = r_model(tmpl_stsp_full(m, m, s),                 bpoles = 1, bzeroes = 1,  sd = 0.5) # scale sigma_L diag(model$sigma_L) = 1  # compute ACF gam = autocov(model, lag.max = lag.max)  # simulate data data = sim(model, n.obs)  # sample ACF gam.sample = autocov(data$y, lag.max = lag.max, demean = FALSE)  # AOKIs method ############################################################## # reconstruct the true model from the population ACF # \"estimate\" the order by the rank of the Hankel matrix out = est_stsp_ss(gam, method = 'aoki', s.max = 2*s, estorder = estorder_rkH)  # compute the ACF of the constructed model. gam.hat = autocov(out$model, lag.max = lag.max)  # check that the constructed model is equivalent to the original model all.equal(dim(model$sys), dim(out$model$sys)) #> [1] TRUE all.equal(gam, gam.hat) #> [1] TRUE   # CCA based on the sample ################################################### # estimate the order by a \"singular value criterion\" out = est_stsp_ss(data$y, method = 'cca', sample2acf = FALSE, s.max = 2*s,                   estorder = estorder_SVC)  # compute the ACF of the constructed model. gam.hat = autocov(out$model, lag.max = lag.max)  all.equal(dim(model$sys), dim(out$model$sys)) # the estimated order is correct #> [1] TRUE all.equal(gam$gamma, gam.hat$gamma)           # but of course the estimated model is not perfect #> [1] \"Mean relative difference: 0.1680467\"  # CCA based on the sample ACF ############################################### # estimate the order by an \"information criterion\" out = est_stsp_ss(gam.sample, method = 'cca', s.max = 2*s,                   estorder = estorder_IVC)  # compute the ACF of the constructed model. gam.hat = autocov(out$model, lag.max = lag.max)  cat('s.hat=', dim(out$model$sys)[3], '\\n') # the estimated order is s.hat=2, the true order is s=3! #> s.hat= 2  all.equal(gam$gamma, gam.hat$gamma)        # relative error of the TRUE and the estimated ACF #> [1] \"Mean relative difference: 0.1966654\"  # alternatively, we may also use out2 = est_stsp_ss(data$y, sample2acf = TRUE, mean_estimate = 'zero',                    method = 'cca', s.max = 2*s, estorder = estorder_IVC) all.equal(out$model, out2$model) #> [1] TRUE  # MEST algorithm ############################################################# # estimate the order by an \"information criterion\" out = est_stsp_ss(gam.sample, method = 'cca', extend_acf = TRUE, s.max = 2*s,                   estorder = estorder_IVC)  # compute the ACF of the constructed model. gam.hat = autocov(out$model, lag.max = lag.max)  cat('s.hat=', dim(out$model$sys)[3], '\\n') # the estimated order is s.hat=2, the true order is s=3! #> s.hat= 2  all.equal(gam$gamma, gam.hat$gamma)        # relative error of the TRUE and the estimated ACF #> [1] \"Mean relative difference: 0.196599\"  # make a plot of the ACFs plot(gam, list(gam.sample, gam.hat), legend = c('TRUE', 'sample', 'subspace'))   # reset seed set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Functions for Order Estimation — subspace order estimates","title":"Helper Functions for Order Estimation — subspace order estimates","text":"helper function used subspace estimation routine subspace methods estimation order state space model. discussion order estimation context subspace methods see e.g (Bauer 2001) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Functions for Order Estimation — subspace order estimates","text":"","code":"estorder_SVC(s.max, Hsv = NULL, n.par, n.obs, Hsize, penalty = \"lnN\", ...)  estorder_IVC(s.max, lndetSigma = NULL, n.par, n.obs, penalty = \"BIC\", ...)  estorder_max(s.max, ...)  estorder_rkH(s.max, Hsv = NULL, tol = sqrt(.Machine$double.eps), ...)  estorder_MOE(s.max, Hsv = NULL, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper Functions for Order Estimation — subspace order estimates","text":"s.max (integer) maximum order (maximum state space dimension). Hsv vector Hankel singular values (must least s.max entries). n.par (s.max+1) dimensional vector respective number parameters. n.obs (integer) sample size \\(N\\) (Inf). Hsize two dimensional integer vector number block rows block columns Hankel matrix (Hsize = c(f,p)). penalty determines penalty term. See details . ... optional additional parameters. lndetSigma (s.max+1) dimensional vector logarithms determinants respective estimated noise covariance matrices. tol (small) tolarenace used determine rank Hankel matrix.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Functions for Order Estimation — subspace order estimates","text":"Either NULL list slots $s (selected/estimated order) $criterion ((s.max+1) dimensional vector).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helper Functions for Order Estimation — subspace order estimates","text":"estorder_max simply returns maximum order s.max considered. estorder_rkH estimates order estimate rank Hankel matrix. maximum singular value smaller equal .Machine$double.eps estimate set s=0. Otherwise estimated order equal number singular values larger equal tol times maximum singular value. function estorder_MOE searches \"gap\" singular values. order set maximum \\(s\\) satisfies $$\\ln(\\sigma_s) > (\\ln(\\sigma_1)+\\ln(\\sigma_m))/2$$ \\(\\sigma_m\\) minimum, non zero singular value. scheme also implemented N4SID procedure system identification toolbox MATLAB (Ljung, 1991). function estorder_SVC implements called Singular Value Criterion $$svc(s) = \\sigma_{s+1}^2 + c(N)d(s)/N$$ (see e.g. (Bauer 2001) ). \\(\\sigma_s\\) \\(s\\)-th singular value weighted Hankel marix, \\(N\\) sample size, \\(d(s) = 2ms\\) denotes number parameters state space model \\(s\\) states (\\(m\\) outputs) \\(c(N)\\) \"penalty\" term. term \\(c(N)=\\ln(N)\\) penalty = \"lnN\" \\(c(N)=fp\\ln(N)\\) penalty = \"fplnN\". estimate order minimizer criterion. estorder_IVC estimates order via information criterion form $$ivc(s) = \\ln\\det\\hat\\Sigma_{s} + c(N)d(s)/N$$ \\(\\hat\\Sigma_s\\) estimate noise covariace matrix obtained model order \\(s\\). term \\(c(N)\\) chosen \\(c(N)=2\\) penalty = \"AIC\" \\(c(N)=\\ln(N)\\) penalty = \"BIC\". Note also routines estorder_SVC estorder_IVC one may also set penalty arbitrary numeric value! E.g. setting penalty=-1 ensure  estorder_SVC  always choses maximum possible order s=s.max.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Helper Functions for Order Estimation — subspace order estimates","text":"Bauer D (2001). “Order estimation subspace methods.” Automatica, 37(10), 1561 - 1573. doi:10.1016/S0005-1098(01)00118-2 .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Test ARMA model — test_armamod","title":"Create Test ARMA model — test_armamod","text":"simple tool may used create random ARMA model $$y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + b_1 u_{t-1} + \\cdots + b_q u_{t-q}$$ given order \\((p,q)\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Test ARMA model — test_armamod","text":"","code":"test_armamod(   dim = c(1, 1),   degrees = c(1, 1),   b0 = NULL,   sigma_L = NULL,   digits = NULL,   bpoles = NULL,   bzeroes = NULL,   n.trials = 100 )"},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Test ARMA model — test_armamod","text":"dim integer vector c(m,n). degrees integer vector c(p,q). b0 \\((m,n)\\) dimensional matrix (NULL). See details . sigma_L \\((n,n)\\) dimensional matrix (NULL). See details . digits integer, non NULL randomly generated numbers rounded \"digits\" number decimal places. bpoles lower bound moduli poles corresponding transfer function (NULL). bzeroes lower bound moduli zeroes corresponding tranmsfer function (NULL). parameter ignored non-square matrices (m != n). n.trials maximum number trials.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Test ARMA model — test_armamod","text":"armamod() object, represents generated ARMA model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Test ARMA model — test_armamod","text":"require \\(m>0\\) \\(p\\geq 0\\). \\(b_0\\) matrix defaults \\((m,n)\\)-dimensional diagonal matrix ones diagonal (diag(x=1, nrow = m, ncol = n)). However, one may also pass arbitray (compatible) matrix procedure. matrix may contain NA's, replaced random numbers. \\(sigma_L\\) matrix defaults \\((n,n)\\)-dimensional lower, triangular matrix However, one may also pass arbitrary (compatible) \\(sigma_L\\) matrix procedure. user may prescribe lower bounds moduli zeroes /poles transfer function $$k(z) = ^{-1}(z) b(z).$$ case procedure simply generates (n.trials) random models model found satisfies constraint. standard deviation normal distribution, used generate random entries, decreased step. course crude method may fail need large number randomly generated matrices.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Test ARMA model — test_armamod","text":"","code":"### generate a random ARMA(1,1) model (with two outputs) ### we require that the model is stable and minimum phase model = try(test_armamod(dim = c(2,2), degrees = c(1,1), digits = 2, bpoles = 1, bzeroes = 1)) if (!inherits(model, 'try-error')) {    print(model)    print(abs(poles(model$sys)))    print(abs(zeroes(model$sys))) } #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0    -0.35  0.62 #> [2,]        0     1    -1.16 -0.78 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0    -0.37  0.32 #> [2,]        0     1     0.24  0.26 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1] 1.43 0.00 #> u[2] 0.05 0.14 #> [1] 1.003923 1.003923 #> [1] 2.107245 2.743083"},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Test state space Model — test_stspmod","title":"Create Test state space Model — test_stspmod","text":"simple tool may used create random, state space model $$a_{t+1} = a_t + B u_t \\mbox{ } y_t = C a_t + D u_t.$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Test state space Model — test_stspmod","text":"","code":"test_stspmod(   dim = c(1, 1),   s = NULL,   nu = NULL,   D = NULL,   sigma_L = NULL,   digits = NULL,   bpoles = NULL,   bzeroes = NULL,   n.trials = 100 )"},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Test state space Model — test_stspmod","text":"dim integer vector c(m,n). s state dimension (NULL). nu vector Kronecker indices (NULL). Either state space dimension s Kronecker indices nu must non NULL. parameters given, parameter s ignored. D \\((m,n)\\) dimensional matrix (NULL). See details . sigma_L \\((n,n)\\) dimensional matrix (NULL). See details . digits integer, non NULL randomly generated numbers rounded \"digits\" number decimal places. bpoles lower bound moduli poles corresponding transfer function (NULL). bzeroes lower bound moduli zeroes corresponding tranmsfer function (NULL). parameter ignored non-square matrices (m != n). n.trials maximum number trials.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Test state space Model — test_stspmod","text":"stspmod() object, represents generated model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Test state space Model — test_stspmod","text":"Kronecker indices (parameter nu) given, state space model echelon canonical form generated. means entries \\(,B,C\\) matrices fixed one zero others considerd \"free\". See also rationalmatrices::Kronecker-Indices(). entries \\(, B, C\\) matrices, priori fixed randomly generated. state dimension \\(s\\) (parameter s) given, entries \\(, B, C\\) matrices considered \"free\". \\(D\\) matrix defaults \\((m,n)\\)-dimensional diagonal matrix ones diagonal (diag(x=1, nrow = m, ncol = n)). However, one may also pass arbitray (compatible) \\(D\\) matrix procedure. matrix may contain NA's, replaced random numbers. \\(sigma_L\\) matrix defaults \\((n,n)\\)-dimensional lower, triangular matrix However, one may also pass arbitray (compatible) \\(sigma_L\\) matrix procedure. user may prescribe lower bounds moduli zeroes /poles transfer function $$k(z) = C(I_m z{-1} - )^{-1} B + D.$$ case procedure simply generates (n.trials) random models model found satisfies constraint. standard deviation normal distribution, used generate random entries, decreased step. course crude method may fail need large number randomly generated matrices. Note also, generated model may non-minimal.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Test state space Model — test_stspmod","text":"","code":"### random state space model with two outputs and state dimension s = 3 ### The model is required to be stable and minimum phase model = try(test_stspmod(dim = c(2,2), s = 3, digits = 2, bpoles = 1, bzeroes = 1)) if (!inherits(model, 'try-error')) {    print(model)    print(min(abs(poles(model$sys))) > 1)    print(min(abs(zeroes(model$sys))) > 1)    print(pseries2nu(pseries(model$sys, lag.max = 10))) # Kronecker indices } #> state space model [2,2] with s = 3 states #>       s[1]  s[2]  s[3]  u[1]  u[2] #> s[1] -0.43 -0.99 -0.22  1.05  0.76 #> s[2]  0.54 -0.41 -0.21 -0.09 -0.52 #> s[3] -0.11  0.03  0.79 -0.26 -0.04 #> x[1] -1.00 -0.38  0.13  1.00  0.00 #> x[2]  0.55 -0.07 -0.22  0.00  1.00 #> Left square root of noise covariance Sigma: #>       u[1] u[2] #> u[1]  0.41    0 #> u[2] -0.16    1 #> [1] TRUE #> [1] TRUE #> [1] 2 1  ### random state space model with three outputs and 2 inputs in echelon canonical form ### D is lower triangular (with ones on the diagonal) ### the model is required to stable (the transfer function has no poles within the unit circle) model = try(test_stspmod(dim = c(3, 2), nu = c(2,3,0),                          D = matrix(c(1,NA,NA,0,1,NA), nrow = 3, ncol = 2),                          digits = 2, bpoles = 1))  if (!inherits(model, 'try-error')) {    print(model)    print(min(abs(poles(model$sys))) > 1)    print(pseries2nu(pseries(model$sys, lag.max = 10))) # Kronecker indices } #> state space model [3,2] with s = 5 states #>       s[1] s[2]  s[3] s[4]  s[5]  u[1]  u[2] #> s[1]  0.00 0.00  1.00 0.00  0.00  0.22  0.04 #> s[2]  0.00 0.00  0.00 1.00  0.00 -0.20  0.62 #> s[3] -0.18 0.00 -1.05 0.04  0.00  0.12  0.19 #> s[4]  0.00 0.00  0.00 0.00  1.00  1.11  0.01 #> s[5] -0.60 0.33  0.76 0.20 -0.01  0.14 -0.50 #> x[1]  1.00 0.00  0.00 0.00  0.00  1.00  0.00 #> x[2]  0.00 1.00  0.00 0.00  0.00 -0.37  1.00 #> x[3]  0.08 0.56  0.00 0.00  0.00 -0.92 -1.39 #> Left square root of noise covariance Sigma: #>       u[1] u[2] #> u[1]  1.94 0.00 #> u[2] -0.66 1.19 #> [1] TRUE #> [1] 2 3 0"},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":null,"dir":"Reference","previous_headings":"","what":"sigma_L Structure — tmpl_sigma_L","title":"sigma_L Structure — tmpl_sigma_L","text":"Create templates left square root \\(L\\) noise covariance matrix \\(\\Sigma = LL'\\). means \\(L\\) parametrized $$\\mbox{vec}(L) = h + H \\theta$$ (\\(k\\)-dimensional) parameter vector \\(\\theta\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"sigma_L Structure — tmpl_sigma_L","text":"","code":"tmpl_sigma_L(   sigma_L,   structure = c(\"as_given\", \"chol\", \"symm\", \"identity\", \"full_normalized\") )"},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"sigma_L Structure — tmpl_sigma_L","text":"sigma_L numeric (n x n) matrix, free entries coded NAs structure character string, determines \"structure\" sigma_L, see examples.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"sigma_L Structure — tmpl_sigma_L","text":"List slots h (\\(n^2\\)-dimensional vector), H (\\((n^2, k)\\)-dimensional matrix, \\(k\\) denotes number  free/deep parameters) n.par (integer) number free/deep parameters (\\(=k\\)).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"sigma_L Structure — tmpl_sigma_L","text":"parameter structure following meaning as_given Use given parameter sigma_L construct template: NA entries considered free entries fixed. chol Set entries sigma_L diagonal zero proceed . symm First make sigma_L symmetric (sigma_L = (sigma_L + t(sigma_L))/2) use sigma_L template. However, h, H constructed \\(h + H\\theta\\) gives symmetric matrix! Note NAs overwrite fixed values, see examples. identity Use identity matrix template. case free parameters, .e. \\(\\theta\\) empty vector (vector zero length). full_normalized Ones diagonal, otherwise parameters free.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"sigma_L Structure — tmpl_sigma_L","text":"","code":"sigma_L = matrix(c(0, NA, 1, 0, 2, 3, NA, 1, 1), nrow = 3, ncol = 3) sigma_L #>      [,1] [,2] [,3] #> [1,]    0    0   NA #> [2,]   NA    2    1 #> [3,]    1    3    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'as_given') th = -(1:tmpl$n.par) matrix(tmpl$h + tmpl$H %*% th, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    0    0   -2 #> [2,]   -1    2    1 #> [3,]    1    3    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'chol') th = -(1:tmpl$n.par) matrix(tmpl$h + tmpl$H %*% th, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    0    0    0 #> [2,]   -1    2    0 #> [3,]    1    3    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'symm') th = -(1:tmpl$n.par) matrix(tmpl$h + tmpl$H %*% th, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    0   -1   -2 #> [2,]   -1    2    2 #> [3,]   -2    2    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'identity') tmpl$n.par # = 0 #> [1] 0 matrix(tmpl$h, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    0 #> [3,]    0    0    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'full_normalized') th = -(1:tmpl$n.par) matrix(tmpl$h + tmpl$H %*% th, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    1   -3   -5 #> [2,]   -1    1   -6 #> [3,]   -2   -4    1"},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":null,"dir":"Reference","previous_headings":"","what":"Toeplitz Calculations — toepl_fwd","title":"Toeplitz Calculations — toepl_fwd","text":"Multiplication stacked data vector block Toeplitz matrix (toepl_fwd() MA calculations) \"inversion\" block Toeplitz matrix order perform calculations equivalent multiplying given stacked data vector inverse lower-triangular banded block Toeplitz matrix (toepl_inv() AR calculations). Note matrix polynomials can mapped one--one banded lower-triangular block Toeplitz matrices.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Toeplitz Calculations — toepl_fwd","text":"","code":"toepl_fwd(polm_wide, data_in, t0 = 1)  toepl_inv(polm_rev, data_in, t0 = 1)"},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Toeplitz Calculations — toepl_fwd","text":"polm_wide Wide matrix \\(( d_0, d_1, \\ldots, d_q )\\) dimension \\((m \\times (q+1) n)\\) represents matrix polynomial \\(d(z)\\) degree \\(q\\). data_in Data matrix dimension \\((dim(inputs) x nobs)\\). Every column corresponds one observation. t0 Integer. Time index calculations start. Default set 1. AR calculations, \\(degree + 1\\) another smart option. polm_rev Wide matrix \\((c_p, ... , c_1)\\) dimension \\((n \\times (q+1) n)\\) coefficients ordered reverse direction, zero-lag coefficient matrix included. represents square polynomial matrix \\(c(z)\\) \\(c_0\\) equal identity matrix degree \\(p\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Toeplitz Calculations — toepl_fwd","text":"data_out Data matrix dimension \\((dim_out x n_obs)\\)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"ma-type-toeplitz-calculations","dir":"Reference","previous_headings":"","what":"MA-type Toeplitz calculations","title":"Toeplitz Calculations — toepl_fwd","text":"Given polynomial matrix degree \\(q\\) dimension \\((m \\times n)\\), \\(m \\geq n\\), given \"wide\" input data matrix dimension \\((n \\times nobs)\\), \\(nobs\\) number observations column corresponds one observation number columns equal number observations, calculate \"wide\" output data matrix dimension \\((m \\times nobs)\\). function name toepl_fwd stems multiplication \"stacked\" input data vector \\((u_1', \\ldots , u_{nobs}')'\\) banded lower-triangular block Toeplitz matrix \\(T\\) dimension \\((nobs m \\times nobs n)\\) whose block elements depend difference row- column-index  \\(T_{,j} = d_{-j}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"ar-type-toeplitz-calcuations","dir":"Reference","previous_headings":"","what":"AR-type Toeplitz calcuations","title":"Toeplitz Calculations — toepl_fwd","text":"Given square polynomial matrix \\(c(z)\\) \\(c_0\\) identity matrix given wide data matrix y = data_in, obtain solution u, wide data matrix, Toeplitz equation $$T (y_1', \\ldots , y_{nobs}')' =  (u_1', ... , u_{nobs}')'$$ Note zero-lag coefficient discarded coefficients reversed order since simplifies computations implementation.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Toeplitz Calculations — toepl_fwd","text":"","code":"p = test_polm(dim = c(2,2), degree = 2) %>% unclass() dim(p) = c(2,2*3) data = matrix(rnorm(2*100), 2, 100) toepl_fwd(p, data) #>           [,1]      [,2]     [,3]      [,4]     [,5]      [,6]      [,7] #> [1,]  77.88936 -141.7628 145.1943 -100.9090  86.6346 -327.4640 -161.8148 #> [2,] 151.12709 -246.9925 299.7344 -159.5419 166.9235 -611.6294 -312.3931 #>           [,8]      [,9]      [,10]     [,11]     [,12]     [,13]    [,14] #> [1,] -122.2955 -117.6364  -82.15673 -199.9383 -192.9253 -109.3355 21.19757 #> [2,] -232.5138 -236.5170 -164.31963 -383.3160 -364.9630 -213.8007 14.69428 #>         [,15]     [,16]     [,17]      [,18]    [,19]     [,20]     [,21] #> [1,] 14.74409 -159.3111 -126.7744  -84.50766 184.4034 -17.82726 -114.0374 #> [2,] 13.31315 -307.4891 -227.0016 -155.71573 347.8717 -35.51716 -224.6815 #>          [,22]     [,23]     [,24]     [,25]     [,26]    [,27]    [,28] #> [1,] -503.8494 -324.5687 -160.9731  80.85545 -62.59665 34.80536 47.63224 #> [2,] -951.0216 -614.2522 -296.6608 161.43446 -90.88371 77.15831 84.14289 #>         [,29]    [,30]    [,31]    [,32]      [,33]     [,34]     [,35] #> [1,] 239.3154 397.2031 513.1338 459.5870  -68.69651 -378.6913 -228.7658 #> [2,] 430.7602 726.5041 960.0394 851.9137 -128.20735 -700.4899 -421.1819 #>         [,36]    [,37]      [,38]     [,39]    [,40]     [,41]    [,42] #> [1,] 28.19113 20.06021  -91.16675 -32.44854 101.4258  95.15421 114.0035 #> [2,] 64.74845 47.13291 -165.10154 -69.85698 171.4146 171.28522 211.6225 #>         [,43]    [,44]    [,45]    [,46]    [,47]    [,48]    [,49]    [,50] #> [1,] 132.0305 190.7212 352.5188 541.2942 461.5141 320.0934 218.2515 298.9156 #> [2,] 241.6069 344.3757 645.2971 987.7103 825.7957 562.3157 389.7961 566.0852 #>         [,51]    [,52]     [,53]     [,54]    [,55]    [,56]    [,57]    [,58] #> [1,] 390.2281 199.7450  74.57167  4.908045 230.9796 478.5157 413.8979 43.84532 #> [2,] 737.7278 391.4046 166.36878 37.112500 439.5847 884.1896 763.1475 78.26082 #>          [,59]     [,60]     [,61]    [,62]     [,63]    [,64]    [,65] #> [1,] -246.3377 -301.4791 -154.6170 44.41441  89.52473 201.5594 130.0858 #> [2,] -459.7251 -551.6215 -279.5503 91.20776 168.38790 386.4406 253.9928 #>         [,66]     [,67]     [,68]    [,69]    [,70]    [,71]      [,72] #> [1,] 201.4582 -38.20403  3.467639 23.75060 433.8254 149.8919  -75.02994 #> [2,] 371.2796 -88.80823 -1.339687 54.97751 822.2681 288.1637 -142.56871 #>           [,73]    [,74]    [,75]    [,76]    [,77]     [,78]     [,79] #> [1,] -1.4489556 154.6870 462.4494 207.6014 207.0852 -190.6689 -276.8920 #> [2,]  0.6115891 274.5521 861.9501 390.5182 404.4998 -346.6210 -517.7392 #>          [,80]    [,81]     [,82]     [,83]      [,84]    [,85]    [,86] #> [1,] -348.5044 11.44899 -33.07494 -38.59866  -80.15798 215.7784 226.3083 #> [2,] -653.1656 21.09577 -63.10823 -87.14130 -151.63902 401.5095 430.7965 #>          [,87]      [,88]     [,89]      [,90]    [,91]    [,92]     [,93] #> [1,] -226.3582  -818.0346  -859.661  -543.4951 16.67412 103.7158  72.47077 #> [2,] -428.6238 -1515.1996 -1582.392 -1006.1654 26.66353 175.6057 133.84706 #>          [,94]      [,95]     [,96]    [,97]     [,98]     [,99]    [,100] #> [1,] -197.7723  -87.75489  99.08135 148.6724  57.39691 -190.3617 -233.9043 #> [2,] -363.2818 -146.76630 201.76647 289.8853 105.65634 -370.1016 -452.2675 p = test_polm(dim = c(2,2), degree = 2) %>% unclass() dim(p) = c(2,2*3) data = matrix(rnorm(2*100), 2, 100) toepl_inv(p, data) #>            [,1]     [,2]       [,3]     [,4]         [,5]         [,6] #> [1,]  0.2487596 200.9781  -66541.11 22359602  -7512220066 2.523907e+12 #> [2,] -1.8659559 362.5346 -122729.31 41230454 -13852354938 4.654025e+12 #>               [,7]         [,8]          [,9]        [,10]         [,11] #> [1,] -8.479660e+14 2.848941e+17 -9.571689e+19 3.215834e+22 -1.080435e+25 #> [2,] -1.563629e+15 5.253380e+17 -1.764997e+20 5.929922e+22 -1.992297e+25 #>             [,12]         [,13]        [,14]         [,15]        [,16] #> [1,] 3.629976e+27 -1.219576e+30 4.097453e+32 -1.376636e+35 4.625131e+37 #> [2,] 6.693590e+27 -2.248869e+30 7.555605e+32 -2.538483e+35 8.528632e+37 #>              [,17]        [,18]         [,19]        [,20]         [,21] #> [1,] -1.553922e+40 5.220766e+42 -1.754039e+45 5.893108e+47 -1.979928e+50 #> [2,] -2.865395e+40 9.626968e+42 -3.234406e+45 1.086675e+48 -3.650940e+50 #>             [,22]         [,23]        [,24]         [,25]        [,26] #> [1,] 6.652035e+52 -2.234908e+55 7.508698e+57 -2.522724e+60 8.475685e+62 #> [2,] 1.226619e+53 -4.121116e+55 1.384586e+58 -4.651843e+60 1.562896e+63 #>              [,27]        [,28]         [,29]        [,30]         [,31] #> [1,] -2.847606e+65 9.567202e+67 -3.214327e+70 1.079929e+73 -3.628275e+75 #> [2,] -5.250917e+65 1.764169e+68 -5.927141e+70 1.991363e+73 -6.690452e+75 #>             [,32]         [,33]        [,34]         [,35]        [,36] #> [1,] 1.219004e+78 -4.095532e+80 1.375990e+83 -4.622963e+85 1.553193e+88 #> [2,] 2.247815e+78 -7.552062e+80 2.537293e+83 -8.524633e+85 2.864051e+88 #>              [,37]        [,38]         [,39]        [,40]          [,41] #> [1,] -5.218318e+90 1.753217e+93 -5.890345e+95 1.979000e+98 -6.648916e+100 #> [2,] -9.622454e+90 3.232890e+93 -1.086165e+96 3.649229e+98 -1.226044e+101 #>              [,42]          [,43]         [,44]          [,45]         [,46] #> [1,] 2.233860e+103 -7.505178e+105 2.521541e+108 -8.471711e+110 2.846271e+113 #> [2,] 4.119184e+103 -1.383937e+106 4.649662e+108 -1.562163e+111 5.248455e+113 #>               [,47]         [,48]          [,49]         [,50]          [,51] #> [1,] -9.562716e+115 3.212820e+118 -1.079422e+121 3.626573e+123 -1.218433e+126 #> [2,] -1.763342e+116 5.924363e+118 -1.990429e+121 6.687315e+123 -2.246761e+126 #>              [,52]          [,53]         [,54]          [,55]         [,56] #> [1,] 4.093611e+128 -1.375345e+131 4.620796e+133 -1.552465e+136 5.215872e+138 #> [2,] 7.548522e+128 -2.536104e+131 8.520637e+133 -2.862708e+136 9.617943e+138 #>               [,57]         [,58]          [,59]         [,60]          [,61] #> [1,] -1.752395e+141 5.887583e+143 -1.978072e+146 6.645799e+148 -2.232812e+151 #> [2,] -3.231374e+141 1.085656e+144 -3.647518e+146 1.225469e+149 -4.117253e+151 #>              [,62]          [,63]         [,64]          [,65]         [,66] #> [1,] 7.501659e+153 -2.520359e+156 8.467739e+158 -2.844936e+161 9.558233e+163 #> [2,] 1.383288e+154 -4.647482e+156 1.561431e+159 -5.245994e+161 1.762515e+164 #>               [,67]         [,68]          [,69]         [,70]          [,71] #> [1,] -3.211313e+166 1.078916e+169 -3.624873e+171 1.217861e+174 -4.091692e+176 #> [2,] -5.921585e+166 1.989496e+169 -6.684180e+171 2.245707e+174 -7.544983e+176 #>              [,72]          [,73]         [,74]          [,75]         [,76] #> [1,] 1.374700e+179 -4.618629e+181 1.551737e+184 -5.213426e+186 1.751573e+189 #> [2,] 2.534914e+179 -8.516642e+181 2.861366e+184 -9.613433e+186 3.229859e+189 #>               [,77]         [,78]          [,79]         [,80]          [,81] #> [1,] -5.884823e+191 1.977145e+194 -6.642683e+196 2.231766e+199 -7.498142e+201 #> [2,] -1.085147e+192 3.645808e+194 -1.224895e+197 4.115323e+199 -1.382639e+202 #>              [,82]          [,83]         [,84]          [,85]         [,86] #> [1,] 2.519177e+204 -8.463769e+206 2.843602e+209 -9.553751e+211 3.209808e+214 #> [2,] 4.645303e+204 -1.560699e+207 5.243535e+209 -1.761689e+212 5.918809e+214 #>               [,87]         [,88]          [,89]         [,90]          [,91] #> [1,] -1.078410e+217 3.623174e+219 -1.217290e+222 4.089774e+224 -1.374056e+227 #> [2,] -1.988563e+217 6.681046e+219 -2.244655e+222 7.541445e+224 -2.533726e+227 #>              [,92]          [,93]         [,94]          [,95]         [,96] #> [1,] 4.616464e+229 -1.551010e+232 5.210982e+234 -1.750752e+237 5.882063e+239 #> [2,] 8.512649e+229 -2.860025e+232 9.608926e+234 -3.228345e+237 1.084638e+240 #>               [,97]         [,98]          [,99]        [,100] #> [1,] -1.976218e+242 6.639568e+244 -2.230719e+247 7.494626e+249 #> [2,] -3.644098e+242 1.224321e+245 -4.113393e+247 1.381991e+250"}]
