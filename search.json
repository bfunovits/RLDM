[{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"project-overview","dir":"","previous_headings":"","what":"Project Overview","title":"CLAUDE.md","text":"RLDM (Rational Linear Dynamic Models) R package modeling stationary processes rational spectral density. uses Rcpp/RcppArmadillo performance-critical computations including Kalman filtering recursive least squares. Dependencies: Requires sister package rationalmatrices (installed GitHub via remotes::install_github(\"bfunovits/rationalmatrices\")).","code":""},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"build-commands","dir":"","previous_headings":"","what":"Build Commands","title":"CLAUDE.md","text":"","code":"# Development workflow devtools::load_all()           # Load package in dev mode devtools::document()           # Generate Roxygen docs devtools::test()               # Run testthat tests devtools::check()              # Full package check devtools::build()              # Build source package  # Run a single test file testthat::test_file(\"tests/testthat/test-templates.R\")  # Rcpp workflow (after modifying C++ code) Rcpp::compileAttributes()      # Regenerate RcppExports.cpp/R devtools::load_all()           # Reload with new compiled code"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"model-classes-s3","dir":"","previous_headings":"Architecture","what":"Model Classes (S3)","title":"CLAUDE.md","text":"Three main model classes, inheriting rldm: - armamod - VARMA models (left matrix fraction description) - stspmod - State space models - rmfdmod - Right matrix fraction description (experimental, many methods yet implemented)","code":""},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"processing-pipeline","dir":"","previous_headings":"Architecture","what":"Processing Pipeline","title":"CLAUDE.md","text":"","code":"Model Construction (armamod/stspmod/rmfdmod)     ↓ Parameter Templates (tmpl_* functions) - maps deep parameters to linear parameters     ↓ Derived Objects (autocov, freqresp, impresp, spectrald)     ↓ Estimation (moment-based or likelihood)     ↓ Model Comparison & Diagnostics"},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"key-file-organization-numeric-functional-system","dir":"","previous_headings":"Architecture","what":"Key File Organization (Numeric Functional System)","title":"CLAUDE.md","text":"R files use numeric prefix system organized purpose/workflow: Key principle: Files organized code (operations), object type operates (S3 dispatch handles representation differences). numeric convention ensures files load dependency order groups related functionality together. See R/README.md detailed organization documentation.","code":""},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"c-code-src","dir":"","previous_headings":"Architecture","what":"C++ Code (src/)","title":"CLAUDE.md","text":"kf.cpp - Kalman filter implementation solve_fwd_bwd_cll.cpp - Forward-backward solving conditional log-likelihood rls_core.cpp - Recursive least squares (exponential forgetting windowed variants) Makevars - Links OpenMP, LAPACK, BLAS","code":""},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"key-entry-points","dir":"","previous_headings":"","what":"Key Entry Points","title":"CLAUDE.md","text":"Model construction: armamod(), stspmod(), rmfdmod() Estimation: est_ML(), est_ar(), est_arma_hrk3(), est_stsp_cca() Analysis: autocov(), spectrald(), impresp(), freqresp() Solving: solve_de(), solve_inverse_de() Comparison: KL_divergence(), pm_test(), compare_estimates()","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"vignettes","dir":"","previous_headings":"Documentation","what":"Vignettes","title":"CLAUDE.md","text":"RLDM three main vignettes organized different user levels: Beginner-friendly introduction Simple univariate bivariate examples ~10-15 minute read executable code Best starting point new users Practical end--end workflow Blanchard-Quah economic data analysis Comparing multiple estimation methods Model diagnostics, prediction, interpretation Comprehensive class method documentation Mathematical foundations Method selection guidance Reference material advanced users Developer Documentation: - inst/doc/technical_notes.Rmd - Deep mathematical derivations algorithm details - Durbin-Levinson-Whittle recursions - HRK Stage 3 algorithm specifications - ARMA ACF computation - built vignette included package","code":""},{"path":"https://bfunovits.github.io/RLDM/CLAUDE.html","id":"documentation-tools","dir":"","previous_headings":"Documentation","what":"Documentation Tools","title":"CLAUDE.md","text":"Uses Roxygen2 markdown support References managed via Rdpack Online docs: https://bfunovits.github.io/RLDM/","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"numeric-functional-system","dir":"","previous_headings":"","what":"Numeric Functional System","title":"R/ Folder Organization","text":"RLDM uses numeric prefix system organized purpose/workflow, object type. organization scheme emphasizes mathematical operations (estimation, properties, visualization) conceptually independent model representation.","code":""},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"core-philosophy","dir":"","previous_headings":"Numeric Functional System","what":"Core Philosophy","title":"R/ Folder Organization","text":"Representations (lmfd/armamod, stsp/stspmod, rmfd/rmfdmod) just different encodings rational process Operations (estimation, properties, prediction) work representations via S3 dispatch Templates map deep (free) parameters model parameters using affine transformations Users think terms workflow (“want estimate”) representation","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"load-order","dir":"","previous_headings":"Numeric Functional System","what":"Load Order","title":"R/ Folder Organization","text":"Files load alphabetically. Dependencies must come dependents: 01 - Core classes (needed everything) 02 - Templates (needed estimation model creation) 03-04 - Properties operations (use classes) 05-07 - Higher-level functionality (use estimation/properties) 08 - Utilities (minimal dependencies) 99 - Auto-generated (loaded last)","code":""},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"file-naming-convention","dir":"","previous_headings":"Numeric Functional System","what":"File Naming Convention","title":"R/ Folder Organization","text":"NN_category_subcategory.R : NN = Two-digit numeric prefix category = Functional area (single word: representations, templates, properties, etc.) subcategory = Specific aspect (method name, model type, descriptor) Examples: - 02_templates.R - template-related functions - 03_properties_autocov.R - Autocovariance computation - 04_timeseries_solve.R - Difference equation solving - 05_estimation_ar.R - AR model estimation - 06_visualization_plot.R - General plotting methods","code":""},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"s3-method-organization","dir":"","previous_headings":"Numeric Functional System","what":"S3 Method Organization","title":"R/ Folder Organization","text":"Key principle: Methods grouped operation (noun), class. Example: 03_properties_autocov.R contains: - autocov() generic - autocov.armamod() - via Yule-Walker equations - autocov.stspmod() - via Lyapunov equation - autocov.rmfdmod() - experimental - autocov.default() - time series data emphasizes: Operation primary, representation implementation detail.","code":""},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"roxygen2-integration","dir":"","previous_headings":"Numeric Functional System","what":"Roxygen2 Integration","title":"R/ Folder Organization","text":"file header comment block (see example ) Cross-references via @rdname related functions @include directives specify file loading order documentation Roxygen tags group documentation functional area (@name model_structures, etc.)","code":""},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"template-header-format","dir":"","previous_headings":"Numeric Functional System","what":"Template Header Format","title":"R/ Folder Organization","text":"file begin structured header comment:","code":"# ==================================================================== # Category Name # # Purpose: [Clear, single-sentence description] #   - Function 1 (brief role) #   - Function 2 (brief role) # # Key Operations: [What this file does in the workflow] # Representations: [Which model types, if relevant] # Dependencies: [Which files this imports/depends on] # Related Files: [Cross-references to related functionality] # ===================================================================="},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"transition-from-alphabetical-system","dir":"","previous_headings":"Numeric Functional System","what":"Transition from Alphabetical System","title":"R/ Folder Organization","text":"previous alphabetical prefix system (aa_, ab_, aca_, etc.) reorganized: Old → New: - aa_* → 01_representations_* - ab_* → 02_templates - aca_*, acb_*, ... → 03_properties_* - ada_*, adb_* → 03_properties_poles, 04_timeseries_* - aeb_*, aec_* → 08_utilities_* - aeaa_* → 06_visualization_* - afa* → 05_estimation_* - ag_* → 07_comparison_*","code":""},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"verification-commands","dir":"","previous_headings":"Numeric Functional System","what":"Verification Commands","title":"R/ Folder Organization","text":"reorganization, verify everything still works:","code":"# Load package in development mode devtools::load_all()  # Generate documentation (respects new file organization) devtools::document()  # Check for any warnings/errors devtools::check()  # Run test suite devtools::test()"},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"guidelines-for-adding-new-files","dir":"","previous_headings":"Numeric Functional System","what":"Guidelines for Adding New Files","title":"R/ Folder Organization","text":"Choose right prefix based code Use descriptive names - subcategory clarify function Add header comment explaining purpose dependencies Check load order - ensure dependencies load first (automatic via naming) Use @rdname related functions documentation Add tests implementing new functionality","code":""},{"path":"https://bfunovits.github.io/RLDM/CONTRIBUTING.html","id":"notes","dir":"","previous_headings":"Numeric Functional System","what":"Notes","title":"R/ Folder Organization","text":"23 R files (excluding RcppExports.R) fit within categories 01-08 Load order automatically handled via alphabetical sorting filenames subdirectories used (R package requirement) Documentation unified across files via Roxygen2 tags","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"what-is-rldm","dir":"Articles","previous_headings":"","what":"What is RLDM?","title":"Getting Started with RLDM","text":"RLDM (Rational Linear Dynamic Models) R package modeling analyzing stationary time series using linear systems theory. implements powerful methods : Autoregressive (AR) models - Simple, interpretable baseline models ARMA (VARMA) models - Flexible models combining AR Moving Average terms State Space models - Compact representations complex dynamics Impulse response analysis - Understanding shocks propagate system Spectral analysis - Analyzing behavior different frequencies Model comparison - Selecting best model data RLDM particularly useful multivariate time series data want go beyond simple AR(1) models capture complex dependencies.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started with RLDM","text":"RLDM depends companion package rationalmatrices matrix fraction computations. Install GitHub: load package:","code":"# Install dependencies first remotes::install_github(\"bfunovits/rationalmatrices\")  # Then install RLDM remotes::install_github(\"bfunovits/RLDM\") library(RLDM)"},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"simple-ar-model-univariate-example","dir":"Articles","previous_headings":"","what":"Simple AR Model: Univariate Example","title":"Getting Started with RLDM","text":"Let’s start simple univariate time series. ’ll generate synthetic data AR(2) process estimate model.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"generate-ar2-data","dir":"Articles","previous_headings":"Simple AR Model: Univariate Example","what":"Generate AR(2) Data","title":"Getting Started with RLDM","text":"","code":"# Simulate an AR(1) process: y_t = 0.8*y_{t-1} + u_t # # In RLDM convention: y_t - 0.8*y_{t-1} = u_t a_coef <- matrix(-0.8)  # AR coefficient with sign convention b_coef <- matrix(1)     # MA term (just white noise) sys <- lmfd(a_coef, b_coef)  # Create ARMA model with noise variance = 1 model_true <- armamod(sys, sigma_L = matrix(1), label = \"AR(1)\")  # Simulate 200 observations y_list <- sim(model_true, n.obs = 200) y <- y_list$y  # Plot the simulated data plot(y, main = \"Simulated AR(1) Process\", ylab = \"y_t\", type = 'l')"},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"estimate-the-model","dir":"Articles","previous_headings":"Simple AR Model: Univariate Example","what":"Estimate the Model","title":"Getting Started with RLDM","text":"Now let’s estimate AR model data using Yule-Walker method. RLDM uses information criteria (AIC) automatically select order:","code":"# Estimate AR model with automatic order selection result <- est_ar(y, p.max = 10)  # Display basic information cat(\"Selected AR order:\", result$p, \"\\n\") #> Selected AR order: 0 cat(\"Number of parameters:\", result$p, \"\\n\") #> Number of parameters: 0 cat(\"Information Criterion:\", result$stats[result$p + 1, \"ic\"], \"\\n\\n\") #> Information Criterion: 0.3897879  # View the estimated model result$model #> ARMA model [1,1] with orders p = 0 and q = 0 #> AR polynomial a(z): #>      z^0 [,1] #> [1,]        1 #> MA polynomial b(z): #>      z^0 [,1] #> [1,]        1 #> Left square root of noise covariance Sigma: #>          u[1] #> u[1] 1.215182"},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"model-diagnostics","dir":"Articles","previous_headings":"Simple AR Model: Univariate Example","what":"Model Diagnostics","title":"Getting Started with RLDM","text":"Check model adequately captures dynamics:","code":"# Compute residuals residuals <- solve_inverse_de(result$model$sys, y)$u  # Plot residuals par(mfrow = c(2, 1)) plot(residuals, main = \"Residuals\", type = 'l', ylab = \"Residuals\") abline(h = 0, col = 'red', lty = 2)  # ACF of residuals (should show no significant correlations) acf(residuals, main = \"ACF of Residuals\") par(mfrow = c(1, 1))"},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"make-predictions","dir":"Articles","previous_headings":"Simple AR Model: Univariate Example","what":"Make Predictions","title":"Getting Started with RLDM","text":"Forecast future values:","code":"# Predict 10 steps ahead n.ahead <- 10 pred <- predict(result$model, y, h = 1, n.ahead = n.ahead)  # Combine data and predictions n_obs <- length(y) plot_range <- max(1, n_obs - 40):n_obs plot(plot_range, y[plot_range], type = 'l',      xlab = \"Time\", ylab = \"Value\",      main = \"Data and Predictions\")  # Add predictions pred_time <- (n_obs+1):(n_obs+n.ahead) lines(pred_time, pred$yhat.ahead[, 1], col = 'blue', lwd = 2)  # Add confidence bands (approximate, assuming normality) # Extract the variance for each step ahead (the variance increases with horizon) variance_ahead <- as.vector(pred$sigmahat.ahead[1, 1, ]) se <- sqrt(variance_ahead) lines(pred_time, pred$yhat.ahead[, 1] + 1.96*se, col = 'blue', lty = 2) lines(pred_time, pred$yhat.ahead[, 1] - 1.96*se, col = 'blue', lty = 2)  legend(\"topleft\", c(\"Data\", \"Forecast\", \"95% CI\"),        col = c(\"black\", \"blue\", \"blue\"), lty = c(1, 1, 2))"},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"multivariate-example-bivariate-var","dir":"Articles","previous_headings":"","what":"Multivariate Example: Bivariate VAR","title":"Getting Started with RLDM","text":"Now let’s work multivariate system - 2-dimensional VAR(1) model.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"generate-bivariate-data","dir":"Articles","previous_headings":"Multivariate Example: Bivariate VAR","what":"Generate Bivariate Data","title":"Getting Started with RLDM","text":"","code":"# Define a 2D VAR(1) model # # [ y1_t ]   [ 0.8  0.1 ] [ y1_{t-1} ]   [ u1_t ] # [ y2_t ] = [ 0.2  0.7 ] [ y2_{t-1} ] + [ u2_t ]  # AR matrices (note sign convention) A1 <- matrix(c(-0.8, -0.2, -0.1, -0.7), nrow = 2, byrow = TRUE) B0 <- diag(2)  # Create VARMA system sys_var <- lmfd(A1, B0)  # Noise covariance (correlation between u1 and u2) rho <- 0.5 Sigma_L <- matrix(c(1, rho, 0, sqrt(1 - rho^2)), nrow = 2)  # Create model and simulate model_var <- armamod(sys_var, sigma_L = Sigma_L,                      names = c(\"Series 1\", \"Series 2\"))  y_var_list <- sim(model_var, n.obs = 300) y_var <- y_var_list$y  # Plot both series plot.ts(y_var, main = \"Bivariate VAR(1) Process\")"},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"estimate-the-multivariate-model","dir":"Articles","previous_headings":"Multivariate Example: Bivariate VAR","what":"Estimate the Multivariate Model","title":"Getting Started with RLDM","text":"","code":"# Estimate VAR model result_var <- est_ar(y_var, p.max = 5)  cat(\"Selected VAR order:\", result_var$p, \"\\n\") #> Selected VAR order: 0 cat(\"Total parameters:\", result_var$p * 2^2, \"\\n\\n\") #> Total parameters: 0  # View estimated model result_var$model #> ARMA model [2,2] with orders p = 0 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>           u[1]     u[2] #> u[1] 1.1841356 0.000000 #> u[2] 0.1760054 1.273754"},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"analyze-the-system","dir":"Articles","previous_headings":"Multivariate Example: Bivariate VAR","what":"Analyze the System","title":"Getting Started with RLDM","text":"Impulse Response Function: system respond shocks?  Spectral Density: Understand frequency domain behavior:  Autocovariance Structure:","code":"# Compute impulse responses irf <- impresp(result_var$model, lag.max = 20)  # Plot impulse responses plot(irf,      main = \"Impulse Response Functions\",      legend = c(\"shock to Series 1\", \"shock to Series 2\")) # Compute and plot spectral density spec <- spectrald(result_var$model, n.f = 128)  plot(spec,      main = \"Spectral Density\",      legend = c(\"Series 1\", \"Series 2\")) # Compute autocovariances acov <- autocov(result_var$model, lag.max = 10, type = \"correlation\")  # Plot correlations plot(acov, main = \"Sample and Model ACF\")"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"for-real-world-applications","dir":"Articles","previous_headings":"Where to Go Next","what":"For Real-World Applications","title":"Getting Started with RLDM","text":"Check Case Study vignette (vignette(\"1_case_study\")) walks : - Economic data analysis (GDP growth unemployment) - Comparing multiple estimation methods - Selecting best model - Forecasting model diagnostics","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"for-more-details","dir":"Articles","previous_headings":"Where to Go Next","what":"For More Details","title":"Getting Started with RLDM","text":"Technical Reference vignette (vignette(\"2_technical_reference\")) provides: - Detailed explanation model class - Mathematical foundations - Guidance method selection - Parameter templates estimation algorithms","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"quick-tips","dir":"Articles","previous_headings":"","what":"Quick Tips","title":"Getting Started with RLDM","text":"Start simple: Begin est_ar() understand data moving complex models Check diagnostics: Always plot residuals ACF verify model Use AIC: automatic order selection est_ar() est_arma_hrk() works well cases Compare models: Use compare_estimates() systematically compare methods Multivariate: RLDM really shines multivariate data relationships matter","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/0_getting_started.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Getting Started with RLDM","text":"(Scherrer Deistler 2019)","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"the-blanchard-quah-dataset","dir":"Articles","previous_headings":"Introduction and Research Question","what":"The Blanchard-Quah Dataset","title":"Case Study: Economic Data Analysis with RLDM","text":"case study analyzes quarterly US economic data real GDP growth rates detrended unemployment rates Blanchard-Quah (1989) study. research question : underlying shocks drive GDP growth unemployment, interact? classic question macroeconomics: separating supply shocks (permanently affect output) demand shocks (temporarily affect unemployment growth).","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"methods-overview","dir":"Articles","previous_headings":"Introduction and Research Question","what":"Methods Overview","title":"Case Study: Economic Data Analysis with RLDM","text":"analysis, ’ll compare several estimation approaches find model best captures relationships: AR Models (baseline) - Simple autoregressive models State Space Models - Flexible representations different estimation algorithms ARMA Models - Parsimonious alternatives combining AR MA terms method different strengths, ’ll compare performance systematically.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"data-preparation-and-visualization","dir":"Articles","previous_headings":"","what":"Data Preparation and Visualization","title":"Case Study: Economic Data Analysis with RLDM","text":"Data Summary: - Total observations: 159 quarters 1948-04-01 1987-10-01 - Training set: 87 observations (model estimation) - Test set: 72 observations (--sample validation) - Variables: GDP growth rate unemployment rate (standardized unit variance)","code":"# Load the Blanchard-Quah dataset y = BQdata_xts  # Define split point for train/test break_date = as_date(\"1970-01-01\")  y_train = BQdata_xts[index(BQdata_xts) < break_date] y_test  = BQdata_xts[index(BQdata_xts) >= break_date] dim_out = ncol(y_train)  # Visualize the data plot(y) addLegend('topleft', c('GDP growth rate', 'Unemployment rate'),           col = c('black', 'red'), lwd = 2, bty = 'n') addEventLines(xts(\"Train/Test Split\", break_date), col = 'blue', on = NA)"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"what-are-ar-models","dir":"Articles","previous_headings":"Baseline: AR Models","what":"What are AR Models?","title":"Case Study: Economic Data Analysis with RLDM","text":"Autoregressive (AR) models form simplest baseline comparison. AR(p) model expresses variable linear combination past p values plus white noise: yt=a1yt−1+⋯+apyt−p+uty_t = a_1 y_{t-1} + \\cdots + a_p y_{t-p} + u_t use: - Understanding basic dynamics lag structure - Quick baseline model comparison - need interpretable, simple models - Automatic order selection via AIC multivariate data, estimate VAR(p) model treats variable AR cross-variable dependencies.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"estimation","dir":"Articles","previous_headings":"Baseline: AR Models","what":"Estimation","title":"Case Study: Economic Data Analysis with RLDM","text":"est_ar() function uses Yule-Walker estimation (statistically efficient) automatic order selection: Selected AR order: 1","code":"# Estimate AR model with automatic order selection out = est_ar(y_train, mean_estimate = 'zero')  # View available outputs cat(\"Output components:\\n\") #> Output components: cat(paste(names(out), collapse = \", \"), \"\\n\\n\") #> model, p, stats, y.mean, ll  # Display statistics for different orders cat(\"Model selection statistics:\\n\") #> Model selection statistics: print(out$stats) #>        p n.par lndetSigma        ic #>  [1,]  0     0   1.013188  1.013188 #>  [2,]  1     4  -2.193313 -2.101359 #>  [3,]  2     8  -2.231092 -2.047184 #>  [4,]  3    12  -2.257910 -1.982048 #>  [5,]  4    16  -2.317073 -1.949257 #>  [6,]  5    20  -2.336830 -1.877060 #>  [7,]  6    24  -2.362950 -1.811226 #>  [8,]  7    28  -2.380498 -1.736819 #>  [9,]  8    32  -2.452787 -1.717155 #> [10,]  9    36  -2.461676 -1.634090 #> [11,] 10    40  -2.522346 -1.602806 #> [12,] 11    44  -2.539423 -1.527929 #> [13,] 12    48  -2.565177 -1.461729"},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"interpretation","dir":"Articles","previous_headings":"Baseline: AR Models","what":"Interpretation","title":"Case Study: Economic Data Analysis with RLDM","text":"estimated AR model captures first-order dynamics data:","code":"# View the model print(out$model) #> ARMA model [2,2] with orders p = 1 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2] #> [1,]        1     0 -0.4579266 -0.1795184 #> [2,]        0     1  0.3098179 -0.9328347 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] #> u[1]  0.9567816 0.0000000 #> u[2] -0.2050479 0.3490723  # Store for later comparison models    = list(AR1 = out$model) estimates = list(AR1 = list(model = out$model, n.par = out$p * dim_out^2))"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"what-are-state-space-models","dir":"Articles","previous_headings":"State Space Models","what":"What are State Space Models?","title":"Case Study: Economic Data Analysis with RLDM","text":"State space models provide flexible framework capturing complex dynamics: st+1=Ast+Buts_{t+1} = s_t + B u_tyt=Cst+Duty_t = C s_t + D u_t sts_t hidden state variables matrices , B, C, D define system dynamics. use: - Complex systems hidden variables - need interpretable latent factors - Flexible different specifications (CCA, DDLC, echelon form) ’ll estimate state space models using three different parameterizations:","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"cca-estimate-canonical-correlation-analysis","dir":"Articles","previous_headings":"State Space Models > What are State Space Models?","what":"CCA Estimate (Canonical Correlation Analysis)","title":"Case Study: Economic Data Analysis with RLDM","text":"CCA data-driven method finding informative state representation. ’s good don’t priori knowledge system structure.","code":"out = est_stsp_ss(y_train, method = 'cca', mean_estimate = 'zero')  cat(\"CCA estimation output components:\\n\") #> CCA estimation output components: print(names(out)) #> [1] \"model\"  \"models\" \"s\"      \"stats\"  \"info\"   \"y.mean\"  cat(\"\\n\\nModel selection statistics (order selection):\\n\") #>  #>  #> Model selection statistics (order selection): print(out$stats) #>      s n.par       Hsv lndetSigma criterion #> [1,] 0     0        NA         NA 0.9480826 #> [2,] 1     4 0.9736953         NA 0.5022205 #> [3,] 2     8 0.5448774  -2.229582 0.4863466 #> [4,] 3    12 0.2751153         NA 0.6217772 #> [5,] 4    16 0.0760915         NA 0.8213164  cat(\"\\n\\nSelected model:\\n\") #>  #>  #> Selected model: print(out$model) #> state space model [2,2] with s = 2 states #>            s[1]       s[2]       u[1]      u[2] #> s[1]  0.9191263  0.1912447 -0.1103757 0.7043585 #> s[2] -0.3340845  0.6472138 -0.6742802 0.2083379 #> x[1]  0.1800227 -0.5626354  1.0000000 0.0000000 #> x[2]  1.4254461  0.1339044  0.0000000 1.0000000 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] #> u[1]  0.9477920 0.0000000 #> u[2] -0.1968541 0.3460504  models$CCA    = out$model estimates$CCA = list(model = out$model, n.par = 2*dim_out*out$s)"},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"ddlc-estimate-ml-with-diagonal-direct-lead-coefficient","dir":"Articles","previous_headings":"State Space Models > What are State Space Models?","what":"DDLC Estimate (ML with Diagonal Direct-Lead Coefficient)","title":"Case Study: Economic Data Analysis with RLDM","text":"DDLC uses maximum likelihood estimation specific parameterization ’s often numerically stable. refine CCA estimate iterative ML optimization:","code":"# Create template for ML estimation tmpl = tmpl_DDLC(models$CCA, balance = 'minimum phase', sigma_L = 'identity') th0 = numeric(tmpl$n.par)  # Define likelihood function llfun = ll_FUN(tmpl, y_train, skip = 0, which = \"concentrated\")  # Optimization with increasing iterations for (maxit in c(10, 20, 200)) {   control = list(trace = 0, fnscale = -1, maxit = maxit)   out = optim(th0, llfun, method = 'BFGS', control = control)   th = out$par   model = fill_template(th, tmpl)    # Reparametrize for next iteration   if (maxit < 200) {     tmpl = tmpl_DDLC(model, balance = 'minimum phase', sigma_L = 'identity')     th0 = numeric(tmpl$n.par)   } }  # Ensure Cholesky factor is lower triangular model$sigma_L = t(chol(model$sigma_L))  models$DDLC    = model estimates$DDLC = list(model = model, n.par = tmpl$n.par)  cat(\"DDLC Model (ML refined from CCA):\\n\") #> DDLC Model (ML refined from CCA): print(model) #> state space model [2,2] with s = 2 states #>            s[1]       s[2]       u[1]       u[2] #> s[1]  0.9314125 -0.5174226 0.05086557 -0.8108537 #> s[2]  0.3158625  0.5107108 0.01463569  1.2381876 #> x[1] -0.2628945 -1.3907238 1.00000000  0.0000000 #> x[2] -1.2551652  0.4318004 0.00000000  1.0000000 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"echelon-form-ml-estimate","dir":"Articles","previous_headings":"State Space Models > What are State Space Models?","what":"Echelon Form ML Estimate","title":"Case Study: Economic Data Analysis with RLDM","text":"Echelon form canonical representation provides parsimony structural restrictions. First, compute Kronecker indices impulse response:","code":"lag.max = 20 ir = impresp(models$CCA, lag.max = lag.max)$irf     # Impulse response nu = pseries2nu(ir)                                  # Kronecker indices  cat(\"Kronecker indices (system order structure):\\n\") #> Kronecker indices (system order structure): print(nu) #> [1] 1 1  # Transform CCA estimate into echelon form model = stspmod(sys = pseries2stsp(ir, method = 'echelon')$Xs,                 sigma_L = models$CCA$sigma_L)  # Verify the conversion preserves the system cat(\"\\nVerifying echelon form preserves autocovariance:\\n\") #>  #> Verifying echelon form preserves autocovariance: print(all.equal(autocov(model, lag.max = lag.max),                 autocov(models$CCA, lag.max = lag.max))) #> [1] TRUE  # ML refinement of echelon form tmpl = tmpl_stsp_echelon(nu, sigma_L = 'identity') th0 = extract_theta(model, tmpl, on_error = 'stop', ignore_sigma_L = TRUE)  llfun = ll_FUN(tmpl, y_train, skip = 0, which = \"concentrated\") control = list(trace = 0, fnscale = -1, maxit = 500)  out = optim(th0, llfun, method = 'BFGS', control = control) th = out$par model = fill_template(th, tmpl)  models$SSECF    = model estimates$SSECF = list(model = model, n.par = tmpl$n.par)  cat(\"Echelon Form State Space Model (ML):\\n\") #> Echelon Form State Space Model (ML): print(model) #> state space model [2,2] with s = 2 states #>            s[1]      s[2]       u[1]       u[2] #> s[1]  0.5316189 0.2011516  0.3138400 -0.4001788 #> s[2] -0.3600091 0.9572035 -0.1629595  1.3478205 #> x[1]  1.0000000 0.0000000  1.0000000  0.0000000 #> x[2]  0.0000000 1.0000000  0.0000000  1.0000000 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"what-are-arma-models","dir":"Articles","previous_headings":"ARMA Models","what":"What are ARMA Models?","title":"Case Study: Economic Data Analysis with RLDM","text":"ARMA (VARMA multivariate) models combine autoregressive moving average components: a0yt+a1yt−1+⋯+apyt−p=b0ut+b1ut−1+⋯+bqut−qa_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + b_1 u_{t-1} + \\cdots + b_q u_{t-q} use: - want parsimony (fewer parameters AR) - Capturing short-term longer-term dependencies - MA-type features data Hannan-Rissanen-Kavalieris (HRK) procedure provides good initial estimates, refine ML.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"hrk-estimate","dir":"Articles","previous_headings":"ARMA Models > What are ARMA Models?","what":"HRK Estimate","title":"Case Study: Economic Data Analysis with RLDM","text":"HRK three-stage procedure provides consistent ARMA estimates without requiring nonlinear optimization:","code":"# Define echelon form template for ARMA tmpl = tmpl_arma_echelon(nu, sigma_L = 'chol')  # HRK estimation out = est_arma_hrk(y_train, tmpl = tmpl, mean_estimate = 'zero') #> HRK estimation of ARMA model: m=2, n.obs=87, p=1, q=1 #> initial AR estimate of noise p.max=9, p=8, ll=-1.085391 #> iter |th - th0|  n.val      MSE       ll  #>    1      0.967     78    0.846   -1.282  models$HRK = out$model estimates$HRK = list(model = out$model, n.par = tmpl$n.par - dim_out*(dim_out+1)/2)  cat(\"ARMA HRK Estimate:\\n\") #> ARMA HRK Estimate: print(out$model) #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2] #> [1,]        1     0 -0.6039963 -0.1627991 #> [2,]        0     1  0.3696634 -0.9673143 #> MA polynomial b(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2] #> [1,]        1     0 -0.2239565 -0.1928248 #> [2,]        0     1  0.1675349  0.2200974 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] #> u[1]  0.8698782 0.0000000 #> u[2] -0.1746577 0.2425972"},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"ml-refinement-of-arma","dir":"Articles","previous_headings":"ARMA Models > What are ARMA Models?","what":"ML Refinement of ARMA","title":"Case Study: Economic Data Analysis with RLDM","text":"optimize HRK estimate using maximum likelihood:","code":"tmpl = tmpl_arma_echelon(nu, sigma_L = 'identity') th0 = extract_theta(models$HRK, tmpl, on_error = 'stop', ignore_sigma_L = TRUE)  llfun = ll_FUN(tmpl, y_train, skip = 0, which = \"concentrated\") control = list(trace = 0, fnscale = -1, maxit = 200)  out = optim(th0, llfun, method = 'BFGS', control = control) th = out$par model = fill_template(th, tmpl)  models$ARMAECF = model estimates$ARMAECF = list(model = model, n.par = tmpl$n.par)  cat(\"ARMA ML (Echelon Form):\\n\") #> ARMA ML (Echelon Form): print(model) #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2] #> [1,]        1     0 -0.5316187 -0.2011493 #> [2,]        0     1  0.3600104 -0.9572044 #> MA polynomial b(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2] #> [1,]        1     0 -0.2177798 -0.6013328 #> [2,]        0     1  0.1970517  0.3906198 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"equivalence-of-ml-estimates","dir":"Articles","previous_headings":"Model Comparison and Selection","what":"Equivalence of ML Estimates","title":"Case Study: Economic Data Analysis with RLDM","text":"dataset, three ML-refined state space ARMA models essentially equivalent (data generating process):","code":"# Compare impulse responses eq_ddlc_ssecf = all.equal(impresp(models$DDLC, lag.max = lag.max),                           impresp(models$SSECF, lag.max = lag.max)) eq_ssecf_arma = all.equal(impresp(models$SSECF, lag.max = lag.max),                           impresp(models$ARMAECF, lag.max = lag.max))  cat(\"DDLC ≈ SSECF:\", isTRUE(eq_ddlc_ssecf), \"\\n\") #> DDLC ≈ SSECF: FALSE cat(\"SSECF ≈ ARMAECF:\", isTRUE(eq_ssecf_arma), \"\\n\\n\") #> SSECF ≈ ARMAECF: FALSE  # Keep only the unique models for further analysis models    = models[c('AR1', 'CCA', 'HRK', 'SSECF')] estimates = estimates[c('AR1', 'CCA', 'HRK', 'SSECF')]  cat(\"Models selected for comparison:\\n\") #> Models selected for comparison: print(names(models)) #> [1] \"AR1\"   \"CCA\"   \"HRK\"   \"SSECF\""},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"systematic-model-comparison","dir":"Articles","previous_headings":"Model Comparison and Selection","what":"Systematic Model Comparison","title":"Case Study: Economic Data Analysis with RLDM","text":"Compare models using multiple criteria: Interpretation: - Log-Likelihood: Higher better (fit quality) - AIC/BIC: Lower better (penalizes complexity) - Portmanteau Test p-value: Higher better (residuals white noise) - RMSE: Lower better (prediction accuracy)","code":"# Residual diagnostics u = solve_inverse_de(models$AR1$sys, as.matrix(y_train))$u pm_result = pm_test(u, 8, dim_out^2)  cat(\"Portmanteau Test for AR1 Model:\\n\") #> Portmanteau Test for AR1 Model: print(pm_result) #>      lags        Q df          p #> [1,]    2 11.22127  4 0.02418664 #> [2,]    3 12.63544  8 0.12502364 #> [3,]    4 16.29370 12 0.17815125 #> [4,]    5 19.35190 16 0.25083795 #> [5,]    6 20.69316 20 0.41538642 #> [6,]    7 31.86943 24 0.13026383 #> [7,]    8 33.88714 28 0.20461367  # Comprehensive comparison stats = compare_estimates(estimates, y_train, n.lags = 8)  if (requireNamespace(\"kableExtra\", quietly = TRUE)) {   kable(stats) %>%     kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%     kableExtra::column_spec(1, bold = TRUE) } else {   print(stats) }"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"autocorrelation-analysis","dir":"Articles","previous_headings":"Model Diagnostics","what":"Autocorrelation Analysis","title":"Case Study: Economic Data Analysis with RLDM","text":"models capture autocorrelation structure data?  look : - Model ACF track data ACF - Large deviations indicate missing dynamics - ARMAECF SSECF match data closely","code":"plot(autocov(y, lag.max = lag.max),      lapply(models, FUN = autocov, lag.max = lag.max),      legend = c('Data', names(models)),      col = c('black', default_colmap(length(models))))"},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"spectral-density","dir":"Articles","previous_headings":"Model Diagnostics","what":"Spectral Density","title":"Case Study: Economic Data Analysis with RLDM","text":"Frequency domain analysis - model fit different frequencies?  Interpretation: - Peaks show dominant frequencies data - Model spectral densities follow data pattern - Good fit across frequencies indicates good model","code":"plot(spectrald(models[[1]], n.f = 2^10),      lapply(models[-1], FUN = spectrald, n.f = 2^10),      legend = names(models))"},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"impulse-response-functions","dir":"Articles","previous_headings":"Model Diagnostics","what":"Impulse Response Functions","title":"Case Study: Economic Data Analysis with RLDM","text":"system respond shocks?  Economic interpretation: - Top-left: GDP shock effect GDP - Top-right: unemployment shock effect GDP - Bottom-left: GDP shock effect unemployment - Bottom-right: unemployment shock effect unemployment","code":"plot(impresp(models[[1]], lag.max = lag.max),      lapply(models[-1], FUN = impresp, lag.max = lag.max),      legend = names(models))"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"out-of-sample-predictions","dir":"Articles","previous_headings":"Prediction and Forecasting","what":"Out-of-Sample Predictions","title":"Case Study: Economic Data Analysis with RLDM","text":"Forecast test set using model fit training data:","code":"n.ahead = 8 n.obs = nrow(y) pred = predict(models$SSECF, y, h = c(1, 4), n.ahead = n.ahead)  # Clean up prediction names for plotting dimnames(pred$yhat)[[3]] = gsub('=', '==', dimnames(pred$yhat)[[3]])  # Plot predictions p.y0 = plot_prediction(pred, which = 'y0', style = 'bw',                        parse_names = TRUE, plot = FALSE) p.y0() # Plot prediction errors plot_prediction(pred, which = 'error', qu = c(2, 2, 2),                 parse_names = TRUE) # CUSUM plot for error accumulation plot_prediction(pred, which = 'cusum', style = 'gray',                 parse_names = TRUE)"},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"compare-prediction-performance","dir":"Articles","previous_headings":"Prediction and Forecasting","what":"Compare Prediction Performance","title":"Case Study: Economic Data Analysis with RLDM","text":"","code":"# Generate predictions from all models out = lapply(models, FUN = function(model) {   predict(model, y, h = c(1, 4))$yhat }) yhat = do.call(dbind, c(3, out)) dimnames(yhat)[[3]] = kronecker(names(models), c(1, 4), FUN = paste, sep = ':')  # Evaluate using multiple criteria stats = evaluate_prediction(y, yhat,                            h = rep(c(1, 4), length(models)),                            criteria = list('RMSE', 'MAE', 'MdAPE'),                            samples = list(                              in.sample = 1:nrow(y_train),                              out.of.sample = (nrow(y_train)+1):nrow(y)                            ))  # Format for display stats.df = array2data.frame(stats, cols = 4) stats.df$h = sub(\"^.*:\", \"\", as.character(stats.df$predictor)) stats.df$predictor = sub(\":.$\", \"\", as.character(stats.df$predictor)) stats.df = stats.df[c('sample', 'h', 'criterion', 'predictor',                       'rGDPgrowth_demeaned', 'unemp_detrended', 'total')] stats.df = stats.df[order(stats.df$sample, stats.df$h,                           stats.df$criterion, stats.df$predictor), ] rownames(stats.df) = NULL  if (requireNamespace(\"kableExtra\", quietly = TRUE)) {   kable(stats.df) %>%     kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%     kableExtra::collapse_rows(columns = 1:3, valign = \"top\") } else {   print(stats.df) }"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"key-findings","dir":"Articles","previous_headings":"Conclusions","what":"Key Findings","title":"Case Study: Economic Data Analysis with RLDM","text":"Model Selection: SSECF ARMAECF models perform best, capturing complex dynamics GDP growth unemployment interactions Baseline Performance: simple AR1 model provides useful baseline misses important multivariate dependencies State Space vs ARMA: approaches competitive; choice depends interpretability needs computational constraints Forecast Accuracy: advanced models show improved --sample prediction compared baseline AR","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"practical-recommendations","dir":"Articles","previous_headings":"Conclusions","what":"Practical Recommendations","title":"Case Study: Economic Data Analysis with RLDM","text":"interpretability: Use state space models CCA initialization parsimony: Use ARMA/VARMA models echelon form quick analysis: Start AR, compare state space production: Validate model assumptions monitor forecast performance time","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/1_case_study.html","id":"references","dir":"Articles","previous_headings":"Conclusions","what":"References","title":"Case Study: Economic Data Analysis with RLDM","text":"(Scherrer Deistler 2019)","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"notation","dir":"Articles","previous_headings":"Preliminaries","what":"Notation","title":"Technical Reference: RLDM Classes and Methods","text":"following notation used throughout RLDM:","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"sign-convention","dir":"Articles","previous_headings":"Preliminaries","what":"Sign Convention","title":"Technical Reference: RLDM Classes and Methods","text":"RLDM uses non-standard sign convention AR coefficients maintain consistency matrix fraction descriptions. Standard form (often seen time series textbooks): yt=a1yt−1+a2yt−2+⋯+apyt−p+uty_t = a_1 y_{t-1} + a_2 y_{t-2} + \\cdots + a_p y_{t-p} + u_t RLDM form (matrix fraction description): yt+a1yt−1+a2yt−2+⋯+apyt−p=uty_t + a_1 y_{t-1} + a_2 y_{t-2} + \\cdots + a_p y_{t-p} = u_t Notice opposite signs AR coefficients. ensures consistency working rational matrix fractions : a0yt+a1yt−1+⋯+apyt−p=b0ut+b1ut−1+⋯+bqut−qa_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + b_1 u_{t-1} + \\cdots + b_q u_{t-q} a0=Ima_0 = I_m (identity matrix).","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"overview-model-representations","dir":"Articles","previous_headings":"Model Classes","what":"Overview: Model Representations","title":"Technical Reference: RLDM Classes and Methods","text":"RLDM supports three equivalent ways represent rational linear dynamic models:","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"left-matrix-fraction-description-lmfd-armamod","dir":"Articles","previous_headings":"Model Classes > Overview: Model Representations","what":"1. Left Matrix Fraction Description (LMFD): armamod","title":"Technical Reference: RLDM Classes and Methods","text":"ARMA/VARMA representation: (z)yt=b(z)uta(z) y_t = b(z) u_t (z)(z) b(z)b(z) polynomial matrices lag operator zz.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"state-space-form-stspmod","dir":"Articles","previous_headings":"Model Classes > Overview: Model Representations","what":"2. State Space Form: stspmod","title":"Technical Reference: RLDM Classes and Methods","text":"canonical state space representation: st+1=Ast+Butyt=Cst+Dut\\begin{aligned} s_{t+1} &= s_t + B u_t \\\\ y_t &= C s_t + D u_t \\end{aligned} sts_t state vector dimension ss.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"right-matrix-fraction-description-rmfd-rmfdmod","dir":"Articles","previous_headings":"Model Classes > Overview: Model Representations","what":"3. Right Matrix Fraction Description (RMFD): rmfdmod","title":"Technical Reference: RLDM Classes and Methods","text":"alternative ARMA representation (experimental): wt=c(z)utyt=d(z)wt\\begin{aligned} w_t &= c(z) u_{t} \\\\ y_t &= d(z) w_t \\end{aligned}","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"varmaarma-models-armamod-class","dir":"Articles","previous_headings":"Model Classes","what":"VARMA/ARMA Models: armamod Class","title":"Technical Reference: RLDM Classes and Methods","text":"armamod class represents VARMA (multivariate ARMA) processes left matrix fraction form.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"structure","dir":"Articles","previous_headings":"Model Classes > VARMA/ARMA Models: armamod Class","what":"Structure","title":"Technical Reference: RLDM Classes and Methods","text":"armamod object S3 list following slots: Class attribute: c(\"armamod\", \"rldm\")","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"constructor","dir":"Articles","previous_headings":"Model Classes > VARMA/ARMA Models: armamod Class","what":"Constructor","title":"Technical Reference: RLDM Classes and Methods","text":"Example:","code":"armamod(sys, sigma_L, names = NULL, label = NULL) # Create a simple AR(1) model: y_t = 0.8*y_{t-1} + u_t # In RLDM convention: y_t - 0.8*y_{t-1} = u_t a_coef <- matrix(-0.8)  # negative sign for standard convention b_coef <- matrix(1) sys <- lmfd(a_coef, b_coef)  model <- armamod(sys, sigma_L = matrix(1), names = \"Output\", label = \"AR(1)\") model #> AR(1): ARMA model [1,1] with orders p = 0 and q = 0 #> AR polynomial a(z): #>      z^0 [,1] #> [1,]     -0.8 #> MA polynomial b(z): #>      z^0 [,1] #> [1,]        1 #> Left square root of noise covariance Sigma: #>      u[1] #> u[1]    1"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"available-methods","dir":"Articles","previous_headings":"Model Classes > VARMA/ARMA Models: armamod Class","what":"Available Methods","title":"Technical Reference: RLDM Classes and Methods","text":"Key methods: - autocov() - Compute autocovariance function - impresp() - Impulse response functions - spectrald() - Spectral density - freqresp() - Frequency response - predict() - Forecasting - solve_de() - Simulate model - print() / plot() - Visualization","code":"methods(class = 'armamod') #>  [1] as.stspmod autocov    freqresp   impresp    ll         poles      #>  [7] predict    print      sim        spectrald  str        zeroes     #> see '?methods' for accessing help and source code"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"state-space-models-stspmod-class","dir":"Articles","previous_headings":"Model Classes","what":"State Space Models: stspmod Class","title":"Technical Reference: RLDM Classes and Methods","text":"stspmod class represents processes canonical state space form.","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"structure-1","dir":"Articles","previous_headings":"Model Classes > State Space Models: stspmod Class","what":"Structure","title":"Technical Reference: RLDM Classes and Methods","text":"stspmod object S3 list slots: Class attribute: c(\"stspmod\", \"rldm\")","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"constructor-1","dir":"Articles","previous_headings":"Model Classes > State Space Models: stspmod Class","what":"Constructor","title":"Technical Reference: RLDM Classes and Methods","text":"Example:","code":"stspmod(sys, sigma_L, names = NULL, label = NULL) # Create a simple state space model # s_{t+1} = 0.8*s_t + u_t # y_t = s_t  A_matrix <- matrix(0.8) B_matrix <- matrix(1) C_matrix <- matrix(1) D_matrix <- matrix(0)  sys <- stsp(A_matrix, B_matrix, C_matrix, D_matrix) model_ss <- stspmod(sys, sigma_L = matrix(1)) model_ss #> state space model [1,1] with s = 1 states #>      s[1] u[1] #> s[1]  0.8    1 #> x[1]  1.0    0 #> Left square root of noise covariance Sigma: #>      u[1] #> u[1]    1"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"available-methods-1","dir":"Articles","previous_headings":"Model Classes > State Space Models: stspmod Class","what":"Available Methods","title":"Technical Reference: RLDM Classes and Methods","text":"Similar armamod, state space models support: - Autocovariance, impulse responses, spectral density computation - Forecasting simulation - Conversion impulse response representation","code":"methods(class = 'stspmod') #>  [1] autocov   freqresp  impresp   ll        poles     predict   print     #>  [8] sim       spectrald str       zeroes    #> see '?methods' for accessing help and source code"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"state-space-parameterizations","dir":"Articles","previous_headings":"Model Classes > State Space Models: stspmod Class","what":"State Space Parameterizations","title":"Technical Reference: RLDM Classes and Methods","text":"RLDM supports several standard state space canonical forms template functions: tmpl_DDLC() - Diagonal-Direct-Lead-Coefficient form tmpl_stsp_echelon() - Echelon canonical form tmpl_stsp_innovation() - Innovation form","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"right-matrix-fraction-description-rmfdmod-class","dir":"Articles","previous_headings":"Model Classes","what":"Right Matrix Fraction Description: rmfdmod Class","title":"Technical Reference: RLDM Classes and Methods","text":"rmfdmod class represents processes right matrix fraction form (experimental, limited methods): estimation analysis methods yet implemented class.","code":"rmfdmod(sys, sigma_L, names = NULL, label = NULL)"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"derived-objects","dir":"Articles","previous_headings":"","what":"Derived Objects","title":"Technical Reference: RLDM Classes and Methods","text":"classes represent computed properties process models, model specifications .","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"autocovariance-autocov-class","dir":"Articles","previous_headings":"Derived Objects","what":"Autocovariance: autocov Class","title":"Technical Reference: RLDM Classes and Methods","text":"Stores autocovariances, autocorrelations, partial autocorrelations.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"computation","dir":"Articles","previous_headings":"Derived Objects > Autocovariance: autocov Class","what":"Computation","title":"Technical Reference: RLDM Classes and Methods","text":"Example:","code":"# From data autocov.default(obj, lag.max = 20, type = \"correlation\")  # From model autocov.armamod(obj, lag.max = 20, type = \"correlation\") autocov.stspmod(obj, lag.max = 20, type = \"correlation\") # Generate AR model and compute ACF y <- sim(model, n.obs = 500) acov <- autocov(model, lag.max = 15, type = \"correlation\") plot(acov)"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"impulse-response-impresp-class","dir":"Articles","previous_headings":"Derived Objects","what":"Impulse Response: impresp Class","title":"Technical Reference: RLDM Classes and Methods","text":"Stores impulse response coefficients: kjk_j yt=∑j≥0kjut−jy_t = \\sum_{j \\geq 0} k_j u_{t-j}.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"computation-1","dir":"Articles","previous_headings":"Derived Objects > Impulse Response: impresp Class","what":"Computation","title":"Technical Reference: RLDM Classes and Methods","text":"Example:  H parameter allows custom orthogonalization (default: Cholesky).","code":"impresp.armamod(obj, lag.max = 40, H = NULL) impresp.stspmod(obj, lag.max = 40, H = NULL) irf <- impresp(model, lag.max = 20) plot(irf, main = \"Impulse Response\")"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"spectral-density-spectrald-class","dir":"Articles","previous_headings":"Derived Objects","what":"Spectral Density: spectrald Class","title":"Technical Reference: RLDM Classes and Methods","text":"Frequency-domain representation: Γ(λ)=K(λ)ΣK*(λ)\\Gamma(\\lambda) = K(\\lambda) \\Sigma K^*(\\lambda) K(λ)K(\\lambda) frequency response.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"computation-2","dir":"Articles","previous_headings":"Derived Objects > Spectral Density: spectrald Class","what":"Computation","title":"Technical Reference: RLDM Classes and Methods","text":"Example:","code":"spectrald(obj, n.f = 128, ...) spec <- spectrald(model, n.f = 256) plot(spec)"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"frequency-response-freqresp-class","dir":"Articles","previous_headings":"Derived Objects","what":"Frequency Response: freqresp Class","title":"Technical Reference: RLDM Classes and Methods","text":"frequency transfer function K(λ)=∑jkje−iλjK(\\lambda) = \\sum_j k_j e^{-\\lambda j}.","code":"freqresp.armamod(obj, n.f = 256)"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"forecast-error-variance-decomposition-fevardec-class","dir":"Articles","previous_headings":"Derived Objects","what":"Forecast Error Variance Decomposition: fevardec Class","title":"Technical Reference: RLDM Classes and Methods","text":"Decomposes forecast error variance contributions shock.","code":"fevardec(obj, h.max = 40)"},{"path":[]},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"yule-walker-method-est_ar_yw","dir":"Articles","previous_headings":"Estimation Methods > AR Model Estimation","what":"Yule-Walker Method: est_ar_yw()","title":"Technical Reference: RLDM Classes and Methods","text":"Theory: Solves Yule-Walker equations using Cholesky decomposition: γk=a1γk−1+⋯+apγk−p\\gamma_k = a_1 \\gamma_{k-1} + \\cdots + a_p \\gamma_{k-p} Advantages: - Statistically efficient (minimum variance) - Produces AR orders simultaneously - Automatic log-determinant sequence model selection Example:","code":"est_ar_yw(gamma, p.max = 10, penalty = -1)"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"durbin-levinson-whittle-method-est_ar_dlw","dir":"Articles","previous_headings":"Estimation Methods > AR Model Estimation","what":"Durbin-Levinson-Whittle Method: est_ar_dlw()","title":"Technical Reference: RLDM Classes and Methods","text":"Theory: Recursive algorithm AR parameter partial autocorrelation computation. Advantages: - Numerically stable - Computes partial ACF - Efficient recursions Example:","code":"est_ar_dlw(gamma, p.max = 10, penalty = -1)"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"wrapper-function-est_ar","dir":"Articles","previous_headings":"Estimation Methods > AR Model Estimation","what":"Wrapper Function: est_ar()","title":"Technical Reference: RLDM Classes and Methods","text":"Primary interface AR estimation automatic order selection: Parameters: - ic: Information criterion (“AIC”, “BIC”, “HQ”) - mean_estimate: estimate mean (“sample.mean”, “zero”, vector) - method: “yw” (Yule-Walker), “dlw” (Durbin-Levinson-Whittle), “auto” Returns: List components: - model: Estimated armamod object - p: Selected order - stats: Criterion values order - ll: Log-likelihood values","code":"est_ar(data, p.max = NULL, method = \"auto\",        ic = \"AIC\", mean_estimate = \"sample.mean\")"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"hannan-rissanen-kavalieris-hrk-est_arma_hrk","dir":"Articles","previous_headings":"Estimation Methods > ARMA Model Estimation","what":"Hannan-Rissanen-Kavalieris (HRK): est_arma_hrk()","title":"Technical Reference: RLDM Classes and Methods","text":"Three-stage procedure VARMA estimation without nonlinear optimization: Stage 1: Estimate long AR model Stage 2: Compute initial ARMA estimates Stage 3: Refine using feasible GLS Advantages: - Provides consistent initial estimates - nonlinear optimization required - Suitable maximum likelihood refinement use: - Initial estimates multivariate ARMA - Moderate high-dimensional systems - want avoid local optima","code":"est_arma_hrk(data, tmpl = NULL, p = NULL, q = NULL,              mean_estimate = \"zero\")"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"cca-method-est_stsp_ssmethod-cca","dir":"Articles","previous_headings":"Estimation Methods > State Space Estimation","what":"CCA Method: est_stsp_ss(method = \"cca\")","title":"Technical Reference: RLDM Classes and Methods","text":"Canonical Correlation Analysis determining state space order initial estimates. Advantages: - Data-driven order selection - Suitable prior knowledge system structure - Good numerical properties","code":"est_stsp_ss(data, method = \"cca\", s = NULL,             keep_models = FALSE, ...)"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"subspace-methods-est_stsp_ssmethod-ccahomoesp","dir":"Articles","previous_headings":"Estimation Methods > State Space Estimation","what":"Subspace Methods: est_stsp_ss(method = \"cca\"/\"ho\"/\"moesp\")","title":"Technical Reference: RLDM Classes and Methods","text":"Multiple subspace identification methods available matrix fraction estimation.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"general-ml-framework-ll_fun","dir":"Articles","previous_headings":"Estimation Methods > Maximum Likelihood Estimation","what":"General ML Framework: ll_FUN()","title":"Technical Reference: RLDM Classes and Methods","text":"Create likelihood functions structured parameter templates: optimize using standard R optimizers:","code":"llfun <- ll_FUN(tmpl, data, skip = 0, which = \"concentrated\") out <- optim(theta0, llfun, method = \"BFGS\", control = list(fnscale = -1))"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"parameter-templates","dir":"Articles","previous_headings":"Estimation Methods > Maximum Likelihood Estimation","what":"Parameter Templates","title":"Technical Reference: RLDM Classes and Methods","text":"Templates map deep model parameters linear parameters optimization: tmpl_DDLC() - Diagonal-Direct-Lead-Coefficient tmpl_arma_echelon() - ARMA echelon form tmpl_stsp_echelon() - State space echelon form Workflow:","code":"# Create template from initial estimate tmpl <- tmpl_DDLC(model_initial, sigma_L = 'identity')  # Extract starting parameter vector theta0 <- extract_theta(model_initial, tmpl)  # Create and optimize likelihood llfun <- ll_FUN(tmpl, data, which = \"concentrated\") opt <- optim(theta0, llfun, method = \"BFGS\", control = list(fnscale = -1, maxit = 500))  # Reconstruct model from optimized parameters model_ml <- fill_template(opt$par, tmpl)"},{"path":[]},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"forward-solution-solve_de","dir":"Articles","previous_headings":"Solution and Simulation > Solving Difference Equations","what":"Forward Solution: solve_de()","title":"Technical Reference: RLDM Classes and Methods","text":"Simulate forward initial conditions: yt=k0ut+k1ut−1+k2ut−2+⋯y_t = k_0 u_t + k_1 u_{t-1} + k_2 u_{t-2} + \\cdots","code":"y <- solve_de(sys, u, y_init = NULL)"},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"inverse-solution-solve_inverse_de","dir":"Articles","previous_headings":"Solution and Simulation > Solving Difference Equations","what":"Inverse Solution: solve_inverse_de()","title":"Technical Reference: RLDM Classes and Methods","text":"Extract residuals given data (solve backwards): ut=(z)−1b(z)−1ytu_t = (z)^{-1} b(z)^{-1} y_t","code":"u <- solve_inverse_de(sys, y)$u"},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"stationary-arma-processes","dir":"Articles","previous_headings":"Mathematical Foundations","what":"Stationary ARMA Processes","title":"Technical Reference: RLDM Classes and Methods","text":"ARMA process described : (z)yt=b(z)uta(z) y_t = b(z) u_t : - (z)=Im+a1z+⋯+apzpa(z) = I_m + a_1 z + \\cdots + a_p z^p (AR polynomial) - b(z)=b0+b1z+⋯+bqzqb(z) = b_0 + b_1 z + \\cdots + b_q z^q (MA polynomial) - (ut)(u_t) white noise 𝔼(utut′)=Σ\\mathbb{E}(u_t u_t') = \\Sigma process stationary roots det((z))=0\\det((z)) = 0 lie outside unit circle. stationary solution : yt=∑j≥0kjut−jy_t = \\sum_{j \\geq 0} k_j u_{t-j} kjk_j satisfy: (z)k(z)=b(z)(z) k(z) = b(z).","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"autocovariance-function","dir":"Articles","previous_headings":"Mathematical Foundations","what":"Autocovariance Function","title":"Technical Reference: RLDM Classes and Methods","text":"stationary ARMA processes, autocovariance function γk=𝔼(yt+kyt′)\\gamma_k = \\mathbb{E}(y_{t+k} y_t') satisfies generalized Yule-Walker equations: a0γk+a1γk−1+⋯+apγk−p={b0Σk0′+⋯+bqΣkq−k′0≤k≤q0k>qa_0 \\gamma_k + a_1 \\gamma_{k-1} + \\cdots + a_p \\gamma_{k-p} = \\begin{cases} b_0 \\Sigma k_0' + \\cdots + b_q \\Sigma k_{q-k}' & 0 \\leq k \\leq q \\\\ 0 & k > q \\end{cases}","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"spectral-factorization","dir":"Articles","previous_headings":"Mathematical Foundations","what":"Spectral Factorization","title":"Technical Reference: RLDM Classes and Methods","text":"spectral density can written : Γ(λ)=12πK(λ)ΣK*(λ)\\Gamma(\\lambda) = \\frac{1}{2\\pi} K(\\lambda) \\Sigma K^*(\\lambda) K(λ)K(\\lambda) frequency response K*K^* denotes conjugate transpose. enables: - Frequency domain analysis - Filter design - Whitening transformations","code":""},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"kronecker-indices","dir":"Articles","previous_headings":"Mathematical Foundations","what":"Kronecker Indices","title":"Technical Reference: RLDM Classes and Methods","text":"VARMA models canonical form, Kronecker indices (n1,…,nm)(n_1, \\ldots, n_m) define minimal orders required output: - Total state dimension: s=n1+⋯+nms = n_1 + \\cdots + n_m - specify echelon structure","code":""},{"path":[]},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"model-comparison-workflow","dir":"Articles","previous_headings":"Method Selection Guide","what":"Model Comparison Workflow","title":"Technical Reference: RLDM Classes and Methods","text":"Start AR using est_ar() Try state space est_stsp_ss() dimensionality reduction Compare ARMA using HRK initial estimates + ML refinement Refine best model parameter templates optimization Validate using residual diagnostics, ACF, spectral plots","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/articles/2_technical_reference.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Technical Reference: RLDM Classes and Methods","text":"(Scherrer Deistler 2019)","code":""},{"path":"https://bfunovits.github.io/RLDM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Wolfgang Scherrer. Author. Bernd Funovits. Author, maintainer.","code":""},{"path":"https://bfunovits.github.io/RLDM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Scherrer W, Funovits B (2026). RLDM: Rational Linear Dynamic (Time Series) Models. R package version 0.0.0.9006, https://bfunovits.github.io/RLDM.","code":"@Manual{,   title = {RLDM: Rational Linear Dynamic (Time Series) Models},   author = {Wolfgang Scherrer and Bernd Funovits},   year = {2026},   note = {R package version 0.0.0.9006},   url = {https://bfunovits.github.io/RLDM}, }"},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"rational-linear-dynamic-models-rldm","dir":"","previous_headings":"","what":"Rational Linear Dynamic (Time Series) Models","title":"Rational Linear Dynamic (Time Series) Models","text":"RLDM (Rational Linear Dynamic Models) R package provides models stationary processes rational spectral density methods estimation. refer rational models. builds heavily sister R package rationalmatrices, see https://bfunovits.github.io/rationalmatrices/.","code":""},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Rational Linear Dynamic (Time Series) Models","text":"can install latest version code using remotes R package.","code":"remotes::install_github(\"bfunovits/RLDM\")"},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"content","dir":"","previous_headings":"","what":"Content","title":"Rational Linear Dynamic (Time Series) Models","text":"package provides following sets functions whose documentation can found reference page https://bfunovits.github.io/RLDM/reference website https://bfunovits.github.io/RLDM/ (created https://pkgdown.r-lib.org/): VARMA models armamod() State space models stspmod() Right matrix fraction description (RMFD) models rmfdmod() (experimental) matrix HH number rows number linear parameters given model number columns number deep parameters given model column vector hh appropriate dimension See help(\"model structures\") help(\"local model structures\") details. Generic functions create objects derived rational models autocovariance sequence, see autocov() Spectral density, see spectrald() Forecast error variance decomposition, see fevardec(), given IRF Frequency response (transfer function evaluated unit circle), see freqresp() Several generic functions extend R’s generic functions plot(), print(), str(), predict() helpers estimation methods: solve_de(), solve_inverse_de(), Moment estimation methods AR models, see e.g. est_ar() ARMA models, see Hannan-Rissannen-Kavalieris algorithm est_arma_hrk3() state space models, see e.g. est_stsp_cca() Likelihood estimation methods ll() ll_theta() ll_FUN() estimation deep parameters rational model ll_kf() tooling like simulation sim() model comparison KL_divergence(), pm_test(), compare_estimates()","code":""},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Rational Linear Dynamic (Time Series) Models","text":"RLDM includes comprehensive documentation organized user level: Practical introduction simple examples AR models multivariate VAR/VARMA systems ~10-15 minute read executable code Blanchard-Quah economic data analysis Comparing AR, state space, ARMA models Model selection, diagnostics, forecasting Complete class method documentation Mathematical foundations Method selection guidance","code":""},{"path":"https://bfunovits.github.io/RLDM/index.html","id":"installation-notes","dir":"","previous_headings":"","what":"Installation Notes","title":"Rational Linear Dynamic (Time Series) Models","text":"package depends rationalmatrices. Install : load explore:","code":"remotes::install_github(\"bfunovits/rationalmatrices\") remotes::install_github(\"bfunovits/RLDM\") library(RLDM) browseVignettes(\"RLDM\")  # View all vignettes"},{"path":"https://bfunovits.github.io/RLDM/reference/BQdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Blanchard/Quah (1989) dataset — BQdata","title":"Blanchard/Quah (1989) dataset — BQdata","text":"dataset contains (159 x 2)-dimensional matrix quarterly data real GDP growth rates (first column) unemployment rate USA. starts second quarter 1948 ends last quarter 1987. script transforming raw data (csv-file) matrix BQdata available data-raw directory. dataset used Gourieroux, Monfort, Renne (2019)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/BQdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Blanchard/Quah (1989) dataset — BQdata","text":"","code":"BQdata  BQdata_ts  BQdata_xts"},{"path":"https://bfunovits.github.io/RLDM/reference/BQdata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Blanchard/Quah (1989) dataset — BQdata","text":"tibble (BQdata), ts-object (BQdata_ts), xts-object (BQdata_xts) 159 rows 2 variables (plus timestamp, total 3): date Timestamp column type dttm tibble, index ts xts object. rGDPgrowth_demeaned real GDP growth series demeaned respect two different subperiods: Till last quarter 1973 first quarter 1974 unemp_detrended unemployment rate detrended respect linear trend (intercept). object class mts (inherits ts, matrix) 159 rows 2 columns. object class xts (inherits zoo) 159 rows 2 columns.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/BQdata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Blanchard/Quah (1989) dataset — BQdata","text":"https://academic.oup.com/restud/advance-article/doi/10.1093/restud/rdz028/5490841#supplementary-data","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Kullback–Leibler divergence — KL_divergence","title":"Kullback–Leibler divergence — KL_divergence","text":"Compute Kullback-Leibler divergence \"true\" state space model estimated state space model. function works square systems, \"true\" model stable estimate (strictly) miniphase.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kullback–Leibler divergence — KL_divergence","text":"","code":"KL_divergence(model, model_hat)"},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kullback–Leibler divergence — KL_divergence","text":"model stspmod() object, true model model_hat stspmod() object, estimated model","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kullback–Leibler divergence — KL_divergence","text":"KL divergence.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/KL_divergence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kullback–Leibler divergence — KL_divergence","text":"KL divergence computed follows. Suppose \\(y_t = k(z) u_t\\), \\(\\mathbf{E} u_t u_t' = \\Sigma\\) true model, let \\(y_t = h(z) u_t\\), \\(\\mathbf{E} u_t u_t'=\\Omega\\) denote estimate. W.l.o.g. assume models innovation form, .e. \\(k(0) = h(0) = \\). procedure computes covariance matrix, \\(\\Delta = \\mathbf{E} e_t e_t'\\) say, one-step-ahead prediction errors \\(e_t = h^{-1}(z) k(z) u_t\\) KL divergence $$ \\mathrm{KL} = (1/2)(\\mathrm{tr}(\\Omega^{-1}\\Delta) - m - \\ln\\det(\\Omega^{-1}\\Delta))) $$ Note procedure breaks transfer function \\(h^{-1}(z) k(z)\\) stable. Therefore true models stable estimated model strictly miniphase.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RLDM-package.html","id":null,"dir":"Reference","previous_headings":"","what":"A Collection of Tools for VARMA and State Space Processes — RLDM-package","title":"A Collection of Tools for VARMA and State Space Processes — RLDM-package","text":"package provides models stationary processes rational spectral density methods estimation.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RLDM-package.html","id":"author-s-","dir":"Reference","previous_headings":"","what":"Author(s)","title":"A Collection of Tools for VARMA and State Space Processes — RLDM-package","text":"Wolfgang Scherrer Bernd Funovits Maintainer: bernd.funovits@gmail.com","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/RLDM-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A Collection of Tools for VARMA and State Space Processes — RLDM-package","text":"Maintainer: Bernd Funovits bernd.funovits@gmail.com (ORCID) Authors: Wolfgang Scherrer wolfgang.scherrer@tuwien.ac.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RSdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Ramey/Shapiro dataset — RSdata","title":"Ramey/Shapiro dataset — RSdata","text":"dataset contains (248 x 7)-dimensional matrix quarterly US data first quarter 1947 till last quarter 2008. script transforming raw data (csv-file) matrix RSdata available data-raw directory. data set used identify government spending shocks particular investigate response consumption real wages respect shocks. variables orthogonalized respect intercept linear trend. See https://doi.org/10.1093/qje/qjq008 details.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RSdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ramey/Shapiro dataset — RSdata","text":"","code":"RSdata  RSdata_ts  RSdata_xts"},{"path":"https://bfunovits.github.io/RLDM/reference/RSdata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Ramey/Shapiro dataset — RSdata","text":"matrix 248 rows 7 variables (plus timestamp, total 8 variables). Versions tibble (RSdata), ts (RSdata_ts), xts (RSdata_xts) object available: Date column logarithm real per capita quantities total government spending real GDP total hours worked nondurable plus services consumption private fixed investment real wage (precisely nominal compensation private business divided deflator private business) tax rate object class mts (inherits ts, matrix) 248 rows 7 columns. object class xts (inherits zoo) 248 rows 7 columns.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/RSdata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Ramey/Shapiro dataset — RSdata","text":"https://econweb.ucsd.edu/~vramey/research.html","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Structural Time Series Models — STSmodels","title":"Structural Time Series Models — STSmodels","text":"Tools Structural Time Series Models, described e.g. (Harvey 1994) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Structural Time Series Models — STSmodels","text":"","code":"tmpl_llm()  tmpl_lltm()  tmpl_cycle(fr, rho)  tmpl_season(s)  cbind_templates(...)"},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Structural Time Series Models — STSmodels","text":"fr, rho frequency damping factor cyclical components s (integer > 1) period seasonal component. ... compatible (state space model) templates. output dimensions state space models must templates.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Structural Time Series Models — STSmodels","text":"Model template, .e. list slots h \\(((m+s)(n+s) + m^2)\\)-dimensional vector, H \\(((m+s)(n+s) + m^2, k)\\)-dimensional matrix, class class = \"stspmod\", state space models implemented order order = c(m,n,s) (output, noise state dimensions), n.par number free parameters \\(=k\\) idx list slots state, noise par. indices code states, noise components parameters associated respective components. See example(s) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Structural Time Series Models — STSmodels","text":"Local Level Model (LLM): tmpl_llm() $$a_{t+1} = a_t + u_t,\\quad y_t = a_t$$ \\((u_t)\\) white noise variance \\(\\sigma_u^2\\). model one free parameter \\(\\theta = \\sigma_u\\). output process \\((y_t)\\) random walk. Local Linear Trend Model (LLTM): tmpl_lltm() $$a_{t+1} = a_t + b_t + u_t,\\quad b_{t+1} = b_t + v_t,\\quad y_t = a_t$$ \\((u_t)\\), \\((v_t)\\) two independent white noise processes variance  \\(\\sigma_u^2\\)  \\(\\sigma_v^2\\). model two free parameter \\(\\theta_1 = \\sigma_u\\)  \\(\\theta_2 = \\sigma_v\\). general output process integrated order two (\\((2)\\)). \\(sigma[v]^2=0\\) model generates random walk drift \\(sigma[u]^2=0\\) one gets integrated random walk. Cyclical Models: tmpl_cycle(fr, rho) tmpl_cycl(fr. rho) generates template scalar AR(2) models, AR polynomial two roots $$z = \\rho^{-1}\\exp((\\pm 2\\pi f)$$ \"damping factor\" \\(\\rho\\) close one model generates processes strong \"cyclical component\" frequency \\(f\\). \\(\\rho <1\\) AR(2) model satisfies stability condition, .e. forward solution converges stationary process. \\(\\rho > 1\\) trajectories forward solution diverge exponentially. template one free parameter, standard deviation driving white noise: \\(\\theta = \\sigma_u\\). Seasonal Models: tmpl_season(s) tmpl_season(s) generates template scalar seasonal models, .e. models generate trajectories \"almost\" periodic given period, \\(s\\) say. template one free parameter, standard deviation driving white noise: \\(\\theta = \\sigma_u\\). Combine Models cbind_templates(...) utility cbind_templates(...) may used construct models simple \"bulding blocks\". Suppose e.g. observed process described sum two (unobserved) components $$y_t = k_1(z) u_t + k_2(z) v_t$$ \\((u_t)\\), \\((v_t)\\) two independent white noise processes. components described templates tmpl1 tmpl2 may construct template combined model simply cbind_templates(tmpl1, tmpl2). function cbind_templates deals state space models course templates must describe outputs dimension. functions tmpl_llm(), ..., tmpl_season() generate templates scalar time series. However, utility cbind_templates(...) also handles multivariate case.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Structural Time Series Models — STSmodels","text":"Harvey AC (1994). Forecasting, Structural Time Series Models Kalman Filter. Cambridge University Press, Cambridge.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/STSmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Structural Time Series Models — STSmodels","text":"","code":"# build a structural times series model (see Harve 94) with #   a \"local linear trend component\", #   a cyclical component with period 50 (frequency 1/50), #   a seasonal component with period 6 and #   an AR(1) component. tmpl = cbind_templates(tmpl_lltm(), tmpl_cycle(1/50,1), tmpl_season(6),                        tmpl_stsp_ar(1, 1, sigma_L = 'identity')) # set some \"reasonable\" values for the standard deviations # of the respective noise and for the AR(1) coefficient. model = fill_template(c(0.0, 0.1,  # parameters for trend (lltm) component                             0.1,       # parameter for cyclical component                             0.1,       # parameter for seasonal component                            -0.5        # AR(1) coefficient                            ), tmpl) print(model) #> state space model [1,5] with s = 10 states #>       s[1] s[2]     s[3] s[4] s[5] s[6] s[7] s[8] s[9] s[10] u[1] u[2] u[3] #> s[1]     1    1 0.000000    0    0    0    0    0    0   0.0    1    0    0 #> s[2]     0    1 0.000000    0    0    0    0    0    0   0.0    0    1    0 #> s[3]     0    0 1.984229   -1    0    0    0    0    0   0.0    0    0    1 #> s[4]     0    0 1.000000    0    0    0    0    0    0   0.0    0    0    0 #> s[5]     0    0 0.000000    0   -1   -1   -1   -1   -1   0.0    0    0    0 #> s[6]     0    0 0.000000    0    1    0    0    0    0   0.0    0    0    0 #> s[7]     0    0 0.000000    0    0    1    0    0    0   0.0    0    0    0 #> s[8]     0    0 0.000000    0    0    0    1    0    0   0.0    0    0    0 #> s[9]     0    0 0.000000    0    0    0    0    1    0   0.0    0    0    0 #> s[10]    0    0 0.000000    0    0    0    0    0    0  -0.5    0    0    0 #> x[1]     1    0 1.984229   -1   -1   -1   -1   -1   -1  -0.5    0    0    1 #>       u[4] u[5] #> s[1]     0    0 #> s[2]     0    0 #> s[3]     0    0 #> s[4]     0    0 #> s[5]     1    0 #> s[6]     0    0 #> s[7]     0    0 #> s[8]     0    0 #> s[9]     0    0 #> s[10]    0    1 #> x[1]     1    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] u[4] u[5] #> u[1]    0  0.0  0.0  0.0    0 #> u[2]    0  0.1  0.0  0.0    0 #> u[3]    0  0.0  0.1  0.0    0 #> u[4]    0  0.0  0.0  0.1    0 #> u[5]    0  0.0  0.0  0.0    1  # simulate the time series (with initial states) out = sim(model, n.obs = 100,           a1 = c(100, 1,     # initial states for the trend component                  3, 0,       # initial states for the cyclical component                  5, 10, 10, -10, -10,   # ... for the seasonal component                  0           # initial state for the AR(1) component           ))  # extract the contribution of the respective components X = cbind(out$y,  out$a[1:100,tmpl$idx$state == 1, drop = FALSE] %*% model$sys$C[1, tmpl$idx$state == 1] +   out$u[,tmpl$idx$noise == 1, drop = FALSE] %*% model$sys$D[1, tmpl$idx$noise == 1],  out$a[1:100,tmpl$idx$state == 2, drop = FALSE] %*% model$sys$C[1, tmpl$idx$state == 2] +   out$u[,tmpl$idx$noise == 2, drop = FALSE] %*% model$sys$D[1, tmpl$idx$noise == 2],  out$a[1:100,tmpl$idx$state == 3, drop = FALSE] %*% model$sys$C[1, tmpl$idx$state == 3] +   out$u[,tmpl$idx$noise == 3, drop = FALSE] %*% model$sys$D[1, tmpl$idx$noise == 3],  out$a[1:100,tmpl$idx$state == 4, drop = FALSE] %*% model$sys$C[1, tmpl$idx$state == 4] +   out$u[,tmpl$idx$noise == 4, drop = FALSE] %*% model$sys$D[1, tmpl$idx$noise == 4])  matplot(X, ylab = 'y', xlab = 't',         type = 'l', lty = 1, col = 1:5) grid() legend('topleft', legend = c('y','trend','cycle','season','AR(1) noise'),        lwd = 2, col = 1:5, bty = 'n')   if (FALSE) { # \\dontrun{ # the following examples throw errors # 1 is not a template cbind_templates(1, tmpl_season(4)) # the respective output dimensions are not equal cbind_templates(tmpl_season(4), tmpl_stsp_ar(2, 2)) # the third argument is a \"VARMA template\" cbind_templates(tmpl_lltm(), tmpl_cycle(1/20,1), tmpl_arma_pq(1, 1, 1, 1)) } # }"},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructor for LMFD (ARMA) Models — armamod","title":"Constructor for LMFD (ARMA) Models — armamod","text":"left-matrix fraction description (LMFD) plus parameterisation noise covariance.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor for LMFD (ARMA) Models — armamod","text":"","code":"armamod(sys, sigma_L = NULL, names = NULL, label = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor for LMFD (ARMA) Models — armamod","text":"sys rationalmatrices::lmfd() rationalmatrices::rmfd() object sigma_L Left-factor noise covariance, .e. covariance \\(\\sigma\\) obtained sigma_L * t(sigma_L). sigma_L vector dimension \\(n\\), \\(n\\) input dimension, diagonal elements parametrized. vector dimension \\(n^2\\), elements sigma_L filled column column. names optional vector character strings label optional character string","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor for LMFD (ARMA) Models — armamod","text":"Object class armamod.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Constructor for LMFD (ARMA) Models — armamod","text":"Hannan, Deistler (2012, page 7), RMFDs also called dynamic adjustment forms. Internally, MFDs lists slots sys, sigma_L, names, label.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/armamod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructor for LMFD (ARMA) Models — armamod","text":"","code":"x = armamod(sys = lmfd(c(1, 0.5), 1), sigma_L = diag(1)) x #> ARMA model [1,1] with orders p = 1 and q = 0 #> AR polynomial a(z): #>      z^0 [,1] z^1 [,1] #> [1,]        1      0.5 #> MA polynomial b(z): #>      z^0 [,1] #> [1,]        1 #> Left square root of noise covariance Sigma: #>      u[1] #> u[1]    1"},{"path":"https://bfunovits.github.io/RLDM/reference/arx_rls_core.html","id":null,"dir":"Reference","previous_headings":"","what":"RLS function — arx_rls_core","title":"RLS function — arx_rls_core","text":"function implements Recursive Least Squares (RLS) algorithm exponentially -weighted past.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/arx_rls_core.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RLS function — arx_rls_core","text":"","code":"arx_rls_core(   y,   X,   r = matrix(c(0.9, 0.95, 0.975, 0.9875, 0.99375, 0.996875, 0.9984375, 1), ncol = 1),   n_init = NULL,   start_of_eval = NULL,   end_of_train = NULL,   enhance_conv = TRUE )"},{"path":"https://bfunovits.github.io/RLDM/reference/arx_rls_core.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RLS function — arx_rls_core","text":"y Vector doubles. Response variable regression. must NAs vector. X Matrix doubles. Dimension = (length(y) x maximal number regressors). NAs handled separately (.e. must checked function called). r Matrix doubles (column vector dimension \\( (#forgetting_factors \\times 1) \\) containing forgetting factors. n_init Integer. Number observations used initial estimate beta. value provided, least 21 observations (3 weeks) 3 times number regressors used. start_of_eval Integer. Starting value evaluation period honest prediction error (start early, bad initial estimations involved) end_of_train Integer. Index specifying end training set. (Afterwards forecasting period starts.) Important calculating honest prediction error (otherwise --sample...). comment_bf: one wants use arx_rls_core() outside automated forecasting framework, set end_of_train length(y). enhance_conv Boolean. Indicates whether convergence enhancing factor described Young (2011) page 55.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/arx_rls_core.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"RLS function — arx_rls_core","text":"List containing y_pred: vector predictions (vector length input y) fev_honest: double. honest prediction error (calculated end_of_train - start_of_eval + 1 observations) forgetting: double. forgetting factor produced minimal honest prediction error","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/as.stspmod.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce to State Space Model — as.stspmod","title":"Coerce to State Space Model — as.stspmod","text":"function .stsp.pseries() calls pseries2stsp() default parameters. course pseries() object must contain sufficiently many lags. YET implemented","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/as.stspmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce to State Space Model — as.stspmod","text":"","code":"as.stspmod(obj, ...)  # S3 method for class 'armamod' as.stspmod(obj, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/as.stspmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce to State Space Model — as.stspmod","text":"obj object ... optional additional parameters method character string","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/as.stspmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce to State Space Model — as.stspmod","text":"object class stspmod().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":null,"dir":"Reference","previous_headings":"","what":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"Compute respectively estimate autocovariance, autocorrelation partial autocorrelation function stationary process.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"","code":"autocov(obj, type, ...)  # Default S3 method autocov(   obj,   type = c(\"covariance\", \"correlation\", \"partial\"),   lag.max = NULL,   na.action = stats::na.fail,   demean = TRUE,   ... )  # S3 method for class 'autocov' autocov(obj, type = c(\"covariance\", \"correlation\", \"partial\"), ...)  # S3 method for class 'armamod' autocov(   obj,   type = c(\"covariance\", \"correlation\", \"partial\"),   lag.max = 12,   ... )  # S3 method for class 'stspmod' autocov(   obj,   type = c(\"covariance\", \"correlation\", \"partial\"),   lag.max = 12,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"obj either armamod(), stspmod(), autocov() object \"data\" object. type character string giving type acf computed. Allowed values \"covariance\" (default), \"correlation\", \"partial\". partially matched. Note default value \"covariance\" whereas stats::acf() uses \"correlation\" default. ... used. lag.max (integer) maximum lag. na.action function called handle missing values. stats::na.pass() can used. demean logical. covariances sample means?","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"autocov object, .e. list slots acf rationalmatrices::pseries() object, stores covariances (correlations). type character string indicates type ACF. gamma (m,m,lag.max+1) dimensional array stores autocovariance function. names (m)-dimensional character vector NULL. optional slot stores names components time series/process. label character string NULL. n.obs integer NULL. slot stores sample size.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"class input parameter \"obj\" determines S3 method called hence actually computed. Population ACF: \"obj\" armamod() stspmod() object autocov(obj, ...) computes ACF corresponding stationary process. Note however, function returns nonsense, model satisfy stability condition. Change type ACF: Calling autocov(obj, type), \"obj\" autocov object returns ACF desired type. E.g. \"obj\" holds partial autocorrelation function autocov(obj, type = 'covariance') may used retrieve corresponding autocovariance function. possible since autocov object stores \"original\" autocovariances slot named gamma. Sample ACF: default S3 method estimates ACF given data. assumes \"obj\" univariate multivariate numeric time series object, (numeric) data frame (numeric) vector, respectively matrix simply calls function stats::acf() stats package compute sample autocovariance function. needed, corresponding sample autocorrelation, respectively sample partial autocorrelation function computed (returned). syntax quite analogous stats::acf(), please consider documentation stats::acf() details. Note stats stores autocovariance/autocorrelation functions (lag.max+1,m,m) dimensional arrays, whereas RLDM uses (m,m,lag.max+1) dimensional arrays. definition partial autocorrelations used stats::acf() differs definition used , see e.g. (Reinsel 1997) . Furthermore stats::acf() skips lag zero partial autocorrelation coefficient thus pacf computed  stats::acf() (lag.max,n,n) dimensional. default choice number lags \\(10*log10(N/m)\\) \\(N\\) number observations \\(m\\) number series. number automatically limited one less number observations series.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"Reinsel GC (1997). Elements Multivariate Time Series Analysis. Springer.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/autocov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Autocovariance, Autocorelation and Partial Autocorrelation Function — autocov","text":"","code":"model = stspmod(sys = stsp(A = c(0,0.2,1,-0.5), B = c(1,1,1,-1),                            C = c(1,0,0,1)), sigma_L = diag(c(4,1)),                 names = c('y1','y2'), label = 'test model') g = autocov(model, lag.max=10)       # ACF r = autocov(model, lag.max=10, type = 'correlation')  # autocorrelation function r = autocov(g, type = 'correlation')                  # this gives the same result! c = autocov(r, type = 'partial')     # partial autocorrelation function  if (FALSE) { # \\dontrun{ # consider an equivalent VARMA model model2 = impresp2varma(irf(model, lag.max = 20))$model g2 = autocov(model2, lag.max = 10) all.equal(g,g2) # of course both return the same ACF  autocov(matrix(rnorm(100*2), nrow = 100)) autocov(stspmod(test_stsp(dim = c(2,2), s = 2), sigma_L = diag(2)))  # generate a random sample with 100 observations and 3 outputs/series. x = matrix(rnorm(100*3), nrow = 100, ncol = 3)  # the covariance estimates are of course identical stats_acfobj = stats::acf(x, type = 'covariance', demean = TRUE, plot = FALSE) rldm_acfobj  = acf_estimate(x, type = 'covariance', demean = TRUE) testthat::expect_equivalent(rldm_acfobj$gamma, aperm(stats_acfobj$acf,c(2,3,1)))  # also the correlation estimates are identical stats_acfobj = stats::acf(x, type = 'correlation', demean = TRUE, plot = FALSE) rldm_acfobj  = acf_estimate(x, type = 'correlation', demean = TRUE) testthat::expect_equivalent(rldm_acfobj$gamma, aperm(stats_acfobj$acf,c(2,3,1)))  # However, the partial correlations dont match! stats_acfobj = stats::acf(x, type = 'partial', demean = TRUE, plot = FALSE) rldm_acfobj  = acf_estimate(x, type = 'partial', demean = TRUE) testthat::expect_equivalent(rldm_acfobj$gamma[,,-1,drop=FALSE], aperm(stats_acfobj$acf,c(2,3,1))) } # }"},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the (concentrated) conditional log likelihood for ARMA models described by a model template. — cll_theta_ARMA_cpp","title":"Compute the (concentrated) conditional log likelihood for ARMA models described by a model template. — cll_theta_ARMA_cpp","text":"internal helper function computes (concentrated) conditional log Likelihood ARMA systems form $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + \\cdots + b_q u_{t-q}$$ conditional likelihood computed zero initial values \\(u_s=y_s=0\\) \\(s\\leq 0\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the (concentrated) conditional log likelihood for ARMA models described by a model template. — cll_theta_ARMA_cpp","text":"","code":"cll_theta_ARMA_cpp(   th,   y,   skip,   concentrated,   ib0,   H_b,   h_b,   B1,   H_B,   h_B,   a0,   A,   H_A,   h_A,   L,   H_L,   h_L,   u,   dU )"},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the (concentrated) conditional log likelihood for ARMA models described by a model template. — cll_theta_ARMA_cpp","text":"th \\((K)\\) dimensional vector \"deep\" parameters. y \\((m,N)\\) matrix observed outputs: \\((y_1,y_2,\\ldots,y_N)\\). skip (integer), omit first \"skip\" residuals, computing likelihood. concentrated (bool), TRUE concentrated, conditional log Likelihood computed ib0 \\((m, m)\\) matrix, overwritten matrix \\(b_0^{-1}a_0\\). H_b \\((m^2, K)\\) matrix. h_b \\(((m^2)\\)-dimensional vector. Note vec(b[0]) = H_b*th + h_b. B1 \\((m, mq)\\) matrix, overwritten \\(-b_0^{-1}(b_q,...,b_1)\\). H_B \\(((m^2)*q, K)\\) matrix. h_B \\(((m^2)*q)\\)-dimensional vector. Note vec(-(b[q],...,b[1])) = H_B*th + h_B. a0 \\((m, m)\\) matrix, overwritten \\(a_0\\). \\((m, m(q+1))\\) matrix, overwritten \\(b_0^{-1}(a_0,...,a_p\\). H_A \\(((m^2)*(p+1), K)\\) matrix. h_A \\(((m^2)*(p+1))\\)-dimensional vector. Note vec(([0],[1],...,[p])) = H_A*th + h_A. L \\((m,m)\\) matrix. (concentrated==FALSE) L overwritten left square \\(L\\) noise covariance matrix \\(\\Sigma=LL'\\) corresponding deep parameters th. However, (concentrated==TRUE) L overwritten sample covariance matrix computed residuals! H_L \\((m^2, K)\\) matrix. h_L \\((m^2)\\)-dimensional vector. Note vec(L) = H_L*th + h_L. u \\((m,N)\\) matrix. matrix overwritten (computed) residuals: \\((u_1,u_2,\\ldots,u_N)\\). dU \\((mN,(m^2)(p+q+2))\\) matrix \\((0,0)\\) matrix. non empty matrix overwritten directional derivatives residuals. However, matrix empty derivatives computed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the (concentrated) conditional log likelihood for ARMA models described by a model template. — cll_theta_ARMA_cpp","text":"(double) log Likelihood","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the (concentrated) conditional log likelihood for ARMA models described by a model template. — cll_theta_ARMA_cpp","text":"function mainly used function factory ll_FUN. detailed documentation (concentrated) conditional log Likelihood, see ll. procedure first constructs ARMA parameter matrices given vector th \"deep\" parameters. AR parameters vec(([0],[1],...,[p])) = h_A + H_A * th. MA parameters vec(b[0]) = h_b + H_b * th vec(-(b[q],...,b[1])) = h_B + H_B * th Left square root noise covariance matrix \\(\\Sigma = LL'\\) vec(L) = h_L + H_L * th. residuals (directional derivatives) computed residuals_ARMA_cpp.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_ARMA_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the (concentrated) conditional log likelihood for ARMA models described by a model template. — cll_theta_ARMA_cpp","text":"Use procedure care! procedure check input arguments. procedure overwrites input arguments data matrices organized columnwise (avoid memory shuffling)! Note also non standard representation coefficient matrices.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_STSP_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the (concentrated) conditional log likelihood for a statespace system described by a model template. — cll_theta_STSP_cpp","title":"Compute the (concentrated) conditional log likelihood for a statespace system described by a model template. — cll_theta_STSP_cpp","text":"internal helper function, used function factory ll_FUN. detailed documentation conditional log Likelihood, see ll. conditional likelihood computed initial state \\(a_1\\) given first column [,1] matrix .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_STSP_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the (concentrated) conditional log likelihood for a statespace system described by a model template. — cll_theta_STSP_cpp","text":"","code":"cll_theta_STSP_cpp(   th,   y,   skip,   concentrated,   pi,   H_pi,   h_pi,   L,   H_L,   h_L,   a,   u,   dU )"},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_STSP_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the (concentrated) conditional log likelihood for a statespace system described by a model template. — cll_theta_STSP_cpp","text":"th \\((K)\\) dimensional vector \"deep\" parameters. y \\((m,N)\\) matrix observed outputs: \\((y_1,y_2,\\ldots,y_N)\\). skip (integer), skip first residuals, computing sample covariance residuals. concentrated (bool), TRUE concentrated, conditional log Likelihood computed pi \\((m+s,m+s)\\) matrix, overwritten system matrix \\([,B | C,D]\\). H_pi \\((m+s)^2, K)\\) matrix. h_pi \\(((m+s)^2)\\)-dimensional vector. Note vec(pi) = H_pi*th + h_pi. L \\((m,m)\\) matrix. (concentrated==FALSE) L overwritten left square noise covariance matrix L corresponding deep parameters th. However, (concentrated==TRUE) L overwritten sample covariance matrix computed residuals! H_L \\((m^2, K)\\) matrix. h_L \\((m^2)\\)-dimensional vector. Note vec(L) = H_L*th + h_L. \\((s,N+1)\\) matrix. matrix overwritten (computed) states: \\((a_1,a_2,\\ldots,a_N,a_{N+1})\\). input [,1] must hold initial state \\(a_1\\). u \\((m,N)\\) matrix. matrix overwritten (computed) residuals: \\((u_1,u_2,\\ldots,u_N)\\). dU \\((mN,K)\\) matrix \\((0,0)\\) matrix. matrix overwritten directional derivatives residuals. However, matrix empty derivatives computed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/cll_theta_STSP_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the (concentrated) conditional log likelihood for a statespace system described by a model template. — cll_theta_STSP_cpp","text":"(double) log Likelihood","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Estimated Models — compare_estimates","title":"Compare Estimated Models — compare_estimates","text":"utility function computes number statistics may used compare/evaluate set estimated models. particular function returns log Likelihood (ll), Akaike Information Criterion (AIC), Bayes Information Criterion (BIC), Final Prediction Error (FPE) p-values Portmanteau test serial correlation residuals.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Estimated Models — compare_estimates","text":"","code":"compare_estimates(estimates, y, n.lags = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Estimated Models — compare_estimates","text":"estimates (named) list estimates. slot contain list slots $model (estimated model) $n.par corresponding number (free) parameters model (class). y (N--m)-dimensional matrix observed data (object may coerced matrix .matrix(y)). n.lags number lags Portmantaeu test serial correlation residuals, see also pm_test().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Estimated Models — compare_estimates","text":"Matrix computed statistics estimated models. matrix attributes m, n.obs n.lags.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/compare_estimates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare Estimated Models — compare_estimates","text":"concentrated, conditional (scaled) log Likelihood $$ll = -(1/2)(m \\ln(2\\pi) + m + \\ln\\det S + 2 \\ln\\det (k_0)$$ computed ll(model, y, skip = 0, concentrated = TRUE), see ll(). \\(S\\) denotes sample covariance residuals model. information criteria $$AIC = -2 ll + (2/N) \\kappa$$ $$BIC = -2 ll + (\\ln(N)/N) \\kappa$$ \\(\\kappa\\) denotes respective number free parameters. Final Prediction Error $$FPE = \\det(S)\\frac{N+\\kappa}{N-\\kappa}$$ portmanteau test, see pm_test(). number lags specified procedure choses default value based sample size. (values attached output attribute). Note procedure (re)evaulates measures, even estimates contain information (e.g. residuals log likelihood may stored corresponding list). reason common data set common evaluation procedure estimates. Typically data y \"estimation data set\", .e. data used estimate models. However, one may also pass new data set procedure.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/dft_3D.html","id":null,"dir":"Reference","previous_headings":"","what":"Discrete Time Fourier Transform — dft_3D","title":"Discrete Time Fourier Transform — dft_3D","text":"Compute Discrete Time Fourier Transform data stored 3-dimensional array.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/dft_3D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discrete Time Fourier Transform — dft_3D","text":"","code":"dft_3D(a, n.f = dim(a)[3])"},{"path":"https://bfunovits.github.io/RLDM/reference/dft_3D.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Discrete Time Fourier Transform — dft_3D","text":"\\((m,n,k)\\) dimensional (numeric) array n.f (integer) number frequencies","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/dft_3D.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Discrete Time Fourier Transform — dft_3D","text":"rationalmatrices::zvalues() object.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Likelihood Estimation — est_ML","title":"Maximum Likelihood Estimation — est_ML","text":"naive implementation Maximum Likelihood Estimation. Rather use ll() ll_FUN().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Likelihood Estimation — est_ML","text":"","code":"est_ML(   y,   tmpl,   th,   which = c(\"concentrated\", \"conditional\", \"kf\"),   method = c(\"BFGS\", \"Nelder-Mead\", \"CG\", \"L-BFGS-B\", \"SANN\", \"Brent\"),   hessian = FALSE,   control = list() )"},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Likelihood Estimation — est_ML","text":"y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. tmpl model template describes model class, see model structures(). Note case (non-empty, square) state space ARMA models implemented. th Initial parameter estimate. (character string) determines \"likelihood\" used, see also ll(). option \"kf\"  supported state space models. method, hessian, control passed optimization routine stats::optim().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Likelihood Estimation — est_ML","text":"list components model estimated model. th corresponding vector deep parameters. ll log likelihood estimated model. type likelihood used. counts, convergence, message, hessian returned  stats::optim().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Maximum Likelihood Estimation — est_ML","text":"optimization computed general-purpose routine stats::optim(). initial estimate needed. procedure respect constraints like stability minimum phase. case conditional, concentrated likelihood somewhat special. case model template must particular structure: (1) noise covariance parametrized via left cholesky factor. (2) last \\(m(m+1)/2\\) components parameter vector \\(\\theta\\) parametrize left cholesky factor components describe system. (implies overlap/dependency betweeen \"system parameters\" \"noise parameters\".)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ML.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum Likelihood Estimation — est_ML","text":"","code":"# Generate a random model in echelon form model (m = 3) tmpl = tmpl_stsp_echelon(nu = c(2,1,1)) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> state space model [3,3] with s = 4 states #>              s[1]      s[2]       s[3]        s[4]       u[1]        u[2] #> s[1]  0.000000000 0.0000000  0.0000000  1.00000000  0.2260673 -0.18269465 #> s[2] -0.300891527 0.1763168 -0.3097276 -0.10587253  0.0199123 -0.04753638 #> s[3] -0.009954261 0.2478604  0.6637246 -0.04959676 -0.3147068  0.13221617 #> s[4]  0.171745616 0.2860622 -0.0392293 -0.22370060  0.2564213  0.13755263 #> x[1]  1.000000000 0.0000000  0.0000000  0.00000000  1.0000000  0.00000000 #> x[2]  0.000000000 1.0000000  0.0000000  0.00000000  0.0000000  1.00000000 #> x[3]  0.000000000 0.0000000  1.0000000  0.00000000  0.0000000  0.00000000 #>             u[3] #> s[1]  0.13742108 #> s[2] -0.16488559 #> s[3]  0.01435543 #> s[4] -0.70200263 #> x[1]  0.00000000 #> x[2]  0.00000000 #> x[3]  1.00000000 #> Left square root of noise covariance Sigma: #>            u[1]       u[2] u[3] #> u[1]  1.0000000  0.0000000    0 #> u[2] -0.1955948  1.0000000    0 #> u[3] -0.1660262 -0.1268121    1 # extract the corresponding free/deep parameters th = extract_theta(model, tmpl)  # generate a sample with 500 observations y = sim(model, n.obs = 500, n.burn_in = 100)$y  # We are cheating here and use the true model parameters # as starting values for the optimization routine:  # estimate the model with the \"exakt log likelihood\" out = est_ML(y, tmpl, th, which = 'kf') KL_divergence(model, out$model) #> [1] 0.01806206  # estimate the model with \"conditional log likelihood\" out = est_ML(y, tmpl, th, which = 'conditional') KL_divergence(model, out$model) #> [1] 0.01786555  # estimate the model with \"concentrated, conditional log likelihood\" out = est_ML(y, tmpl, th, which = 'concentrated') KL_divergence(model, out$model) #> [1] 0.01786693"},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Autoregressive Models — est_ar","title":"Estimate Autoregressive Models — est_ar","text":"function est_ar estimates (V)AR models $$(y_t - \\mu) = a_1 (y_{t-1} - \\mu) + \\cdots + a_p (y_{t-p} - \\mu) + u_t$$ given sample given (sample) autocovariance function. model order \\(p\\) chosen information criterion, like AIC BIC. \"helper\" functions est_ar_ols, est_ar_yw est_ar_dlw implement three available estimation methods: estimation ordinary least squares, Yule-Walker estimates Durbin-Levinson-Whittle method.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Autoregressive Models — est_ar","text":"","code":"est_ar(   obj,   p.max = NULL,   penalty = NULL,   ic = c(\"AIC\", \"BIC\", \"max\"),   method = c(\"yule-walker\", \"ols\", \"durbin-levinson-whittle\"),   mean_estimate = c(\"sample.mean\", \"intercept\", \"zero\"),   n.obs = NULL )  est_ar_yw(gamma, p.max = (dim(gamma)[3] - 1), penalty = -1)  est_ar_dlw(gamma, p.max = (dim(gamma)[3] - 1), penalty = -1)  est_ar_ols(   y,   p.max = NULL,   penalty = -1,   mean_estimate = c(\"sample.mean\", \"intercept\", \"zero\"),   p.min = 0L )"},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Autoregressive Models — est_ar","text":"obj either \"time series\" object (.e .matrix(obj) returns \\((N,m)\\)-dimensional numeric matrix) autocov() object represents (estimated) autocovariance function. type autocov object irrelevant since est_ar always uses slot obj$gamma contains autocovariance function. p.max (integer NULL) Maximum order candidate AR models. default choice see . penalty scalar (NULL) determines \"penalty\" per parameter model. Note parameter (NULL) overrides paramater ic. ic (character string) information criterion shall used find optimal order. Note ic=\"max\" means AR(p) model p=p.max estimated. Default ic=\"AIC\". method Character string giving method used fit model. Note 'yule-walker' 'durbin-levinson-whittle' (numerical errors) equivalent choice 'ols' available \"time-series\" object obj. mean_estimate Character string giving method used estimate mean \\(\\mu\\). Default mean_estimate = \"sample.mean\". See details . n.obs Optional integer gives sample size \\(N\\). parameter used, obj autocov object. n.obs=NULL slot obj$n.obs used. Note obj$n.obs=NULL obj$n.obs=Inf refers case population autocovariance function, .e. \\(N=\\infty\\).  \"time series\" object sample size course set number observations, .e. n.obs = nrow(.matrix(obj)).  sample size \\(N\\) controls computation default maximum order p.max computation information criterion. gamma \\((m,m,lag.max+1)\\)-dimensional array, contains (sample) autocovariance function. y \\((N,m)\\)-dimensional matrix, contains sample. p.min (non negative integer) Minimum order candidate AR models. used est_ar_ols.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Autoregressive Models — est_ar","text":"function est_ar returns list components model armamod() object represents estimated AR model. p optimal model order. stats (p.max+1,4) dimensional matrix stores \\(\\ln\\det(\\Sigma_p)\\) values, number parameters IC values. See details . y.mean estimate mean \\(\\mu\\). ll log likelihood estimated model. \"helper\" functions est_ar_yw, est_ar_dlw est_ar_ols return list components (m,m,p)-dimensional array estimated AR coefficients \\(a_i\\). sigma (m,m)-dimensional matrix estimated noise covariance \\(\\Sigma\\). p estimate AR order. stats (p.max+1,4) dimensional matrix stores \\(\\ln\\det(\\Sigma_p)\\) values, number parameters IC values. See details . y.mean (est_ar_ols ) estimate mean \\(\\mu\\). residuals (est_ar_ols ) (n.obs,m) dimensional matrix OLS residuals. partial (est_ar_dlw ) (m,m,p.max+1) dimensional array (estimated) partial autocorrelation coefficients.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"ols-method","dir":"Reference","previous_headings":"","what":"OLS method","title":"Estimate Autoregressive Models — est_ar","text":"helper function est_ar_ols implements three schemes estimate mean \\(\\mu\\) AR parameters. choice mean_estimate = \"zero\" assumes \\(\\mu=0\\) thus AR parameters determined regression: $$y_t = a_1 y_{t-1} + \\cdots + a_p y_{t-p} + u_t \\mbox{ } t=p+1,\\ldots,N$$ case mean_estimate = \"sample.mean\" mean \\(\\mu\\) estimated sample mean AR parameters determined LS estimate regression $$(y_t - \\mu) = a_1 (y_{t-1} - \\mu) + \\cdots + a_p (y_{t-p} - \\mu) + u_t \\mbox{ } t=p+1,\\ldots,N$$ last case mean_estimate = \"intercept\", regression intercept $$y_t = d + a_1 y_{t-1} + \\cdots + a_p y_{t-p} + u_t \\mbox{ } t=p+1,\\ldots,N$$ considered. estimate \\(\\mu\\) obtained $$\\mu = (I_m - a_1 - \\cdots - a_p)^{-1} d$$ estimate mean \\(\\mu\\) fails estimated AR model unit root, .e. \\((I_m - a_1 - \\cdots - a_p)\\) singular. sample covariance corresponding residuals (scaled \\(1/(N-p)\\)) serves estimate noise covariance \\(\\Sigma\\). actual computations routine stats::lsfit() stats package used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"yule-walker-estimates","dir":"Reference","previous_headings":"","what":"Yule-Walker estimates","title":"Estimate Autoregressive Models — est_ar","text":" est_ar_yw est_ar_dlw use Yule-Walker equations estimate AR coefficients \\((a_i)\\) noise covariance matrix \\(\\Sigma\\). However, use different numerical scheme solve equations. function est_ar_dlw uses Durbin-Levinson-Whittle recursions addition returns (estimates ) partial autocorrelation coefficients. obj \"time series\" object, first ACF estimated call autocov(). option mean_estimate = \"zero\" implies mean assumed zero (\\(\\mu = 0\\)) therefore autocov called option demean = FALSE. mean_estimate = \"sample.mean\" mean_estimate = \"intercept\" mean \\(\\mu\\) estimated sample mean ACF computed  demean = TRUE.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"estimation-of-the-ar-order","dir":"Reference","previous_headings":"","what":"Estimation of the AR order","title":"Estimate Autoregressive Models — est_ar","text":"order \\(p\\) AR model chosen minimizing information criterion form $$IC(p) = \\ln\\det\\Sigma_p + c(p)r(N) \\mbox{ } p = 0,\\ldots,p_{\\max}$$ \\(\\Sigma_p\\) estimate noise (innovation) covariance, \\(c(p)\\) counts number parameters model, \\(r(N)\\) \"penalty\" per parameter model. Note \\(\\log\\det\\Sigma\\) constant scaling factor \\(-(N-p)/2\\) equal (scaled, approximate) Gaussian log likelihood model $$ll = -(1/2)(m \\ln(2\\pi) + m + \\ln\\det \\Sigma_p)$$ See also ll(). Note value \\(ll\\), returned routine, (approximate) log Likelihood scaled factor \\(1/(N-p)\\). AR(p) model intercept, number parameters \\(c(p) = p m^2 + m\\) AR model without intercept \\(c(p) = p m^2\\). Akaike information criterion (AIC) corresponds \\(r(N)=2/N\\) Bayes information criterion (BIC) uses penatlty \\(r(N)=\\log(N)/N\\). helper routines, user set penalty term \\(r(N)\\) explicitly via input parameter \"penalty\". default choice penalty = -1 means maximum possible order p=p.max chosen. function est_ar offers parameter \"ic\" tells routine set penalty accordingly. Note choice ic=\"max\" sets \\(r(N) = -1\\) thus model maximum possible order fitted. default maximum order p.max chosen follows. helper functions est_ar_yw est_ar_dlw simply chose maximum accordng maximum lag given autocovariances, p.max = dim(gamma)[3] - 1. routine est_ar_ols uses minimum \\(12\\), \\((N-1)/(m+1)\\) \\(10*log10(N)\\) default. function est_ar uses value. However, \"obj\" autocov object p.max addition bounded number lags contained object.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Estimate Autoregressive Models — est_ar","text":"Yule-Walker estimates offer easy way reconstruct \"true\" model population autocovariance function given. noise covariance (thus likelihood values) improve model order larger true model order \"estimated\". However due numerical errors may true. simple trick one may call est_ar (est_ar_yw est_ar_dlw) small positive penalty. See example . functions essentially equivalent stats routines. (re) implemented convenience, input output parameters (models) fit RLDM conventions. AIC values RLDM routines equivalent AIC values computed stats routines constant scaling \\(N\\). seems Yule-Walker estimate stats::[ar.yw][stats::ar.yw] uses scaling factor \\((N - m(p+1))/N\\) noise covariance \\(\\Sigma\\). Finally note est_ar_ols, est_ar_yw est_ar_dlw mainly intended \"internal helper\" functions. Therefore, functions check validity input parameters.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_ar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Autoregressive Models — est_ar","text":"","code":"# set seed, to get reproducable results set.seed(5436)  ############################################################### # generate a (bivariate) random, stable AR(3) model  m = 2 p = 3 n.obs = 100 p.max = 10 tmpl = tmpl_arma_pq(m = m, n = m, p = p, q = 0) model = r_model(tmpl, bpoles = 1, sd = 0.25) # make sure that the diagonal entries of sigma_L are non negative model$sigma_L = model$sigma_L %*% diag(sign(diag(model$sigma_L)))  ############################################################### # reconstruct the true AR model from the population ACF  true_acf = autocov(model, lag.max = 12, type = 'covariance') ARest = est_ar(true_acf, p.max = p.max, method = 'yule-walker', penalty = 1e-6) all.equal(model, ARest$model) #> [1] TRUE  ############################################################### # simulate a sample  y = sim(model, n.obs = n.obs, start = list(s1 = NA))$y  ############################################################### # estimate the AR(p) model with the true order p  # OLS ARest = est_ar(y, ic = 'max', p.max = p, method = 'ols', mean_estimate = \"zero\") # check the log Likelihood p.opt = ARest$p all.equal(ll(ARest$model, y, 'conditional', skip = p.opt), ARest$ll) #> [1] TRUE  # Yule-Walker and Durbin-Levinson-Whittle are equivalent (up to numerical errors) ARest = est_ar(y, ic = 'max', p.max = p, method = 'yule-walker', mean_estimate = \"zero\") junk = est_ar(y, ic = 'max', p.max = p, method = 'durbin-levinson-whittle', mean_estimate = \"zero\") all.equal(ARest$model, junk$model) #> [1] TRUE  # alternatively we may first estimate the sample autocovariance function # note that the 'type' of the ACF is irrelevant sample_acf = autocov(y, type = 'correlation', demean = FALSE) junk = est_ar(sample_acf, ic = 'max', p.max = p, method = 'yule-walker') all.equal(ARest$model, junk$model) #> [1] TRUE  ############################################################### # estimate the order of the AR model with 'AIC', estimate a model with intercept ARest = est_ar(y, ic = 'AIC', p.max = p.max, method = 'ols', mean_estimate = \"intercept\") print(ARest$model) #> ARMA model [2,2] with orders p = 3 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  z^1 [,1]       [,2]  z^2 [,1]       [,2]  z^3 [,1] #> [1,]        1     0 0.1758752 -0.2469383 0.4064368 -0.2595963 0.7758289 #> [2,]        0     1 0.3113271 -0.3092643 0.3315128 -0.1661434 0.3077410 #>            [,2] #> [1,] -0.2624946 #> [2,] -0.2492206 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>          u[1]      u[2] #> u[1] 0.144723 0.0000000 #> u[2] 0.188681 0.1501011  # compare with the stats::ar function ARest2 = stats::ar(y, aic = TRUE, order.max = p.max, method = 'ols', intercept = TRUE) # the estimated coefficients are equal all.equal(unclass(ARest$model$sys$a)[,,-1], -aperm(ARest2$ar, c(2,3,1)), check.attributes = FALSE) #> [1] TRUE # also the AIC values are up to scaling equivalent all.equal( ARest$stats[,'ic'] - min(ARest$stats[,'ic']), ARest2$aic/n.obs, check.attributes = FALSE) #> [1] TRUE  # reset seed set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":null,"dir":"Reference","previous_headings":"","what":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"Estimate (V)ARMA models Hannan, Rissanen Kavalieris procedure, see e.g. (Hannan Rissanen 1982)  (Hannan et al. 1986) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"","code":"est_arma_hrk(   y,   e = NULL,   tmpl,   maxit = 1,   tol = 0.001,   trace = TRUE,   p.max = NULL,   ic = c(\"AIC\", \"BIC\", \"max\"),   mean_estimate = c(\"sample.mean\", \"intercept\", \"zero\") )"},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. e (initial) estimate disturbances \\(u_t\\). non NULL e \\((N,m)\\) dimensional matrix, \"time series\" object (.e object may coerced \\((N,m)\\) dimensional matrix .matrix(e)).  NULL procedure computes estimate disturbances fitting \"long\" AR model data, see est_ar_ols().  matrix e may contain missing values (NA, NaN Inf). Note e.g. est_ar_ols returns residuals first \\(p\\) (\\(p\\) refers order fitted AR model) values missing. tmpl model template, see model structures(). Note case implemented, \\(a_0=b_0\\) holds, diagonal entries \\(a_0=b_0\\) equal one fixed elements equal zero. Furthermore square root sigma_L noise covariance matrix asssumed lower triangular matrix without restrictions.  given template coerced template kind. given template comply restrictions, warning message issued. maxit (integer) maximum number iterations tol (numeric) tolerance level trace (boolean) trace=TRUE, tracing information iterations printed. p.max (integer NULL) Maximum order candidate AR models. default choice see . ic (character string) information criterion shall used find optimal AR order. Note ic=\"max\" means AR(p) model p=p.max fitted. Default ic=\"AIC\". mean_estimate Character string giving method used estimate mean \\(\\mu\\). Default mean_estimate = \"sample.mean\". See details .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"List components model estimated (V)ARMA model (.e. armamod() object). th vector (free) parameters estimated (V)ARMA model. tmpl (coerced) model template. y.mean estimate mean \\(\\mu\\). residuals residuals model, computed solve_inverse_de(). sigma sample variance \\(S\\) residuals, .e. estimate noise covariance matrix \\(\\Sigma\\). n.valid number \"valid\" observations, .e. observations needed lagged values \\(y_{t-}\\) \\(e_{t-}\\) availiable. ARMA(p,q) model implies number valid observations less equal n.obs -max(p,q). ll Gaussian log likelihood: $$(-1/2)(m \\ln(2\\pi) + m + \\ln\\det(S))$$ \\(S\\) denotes sample variance residuals. iter number iterations. converged (boolean) indicates whether algorithm converged.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"main idea HRK procedure follows. given estimates, \\(e_t\\) say, disturbances, ARMA model estimated equation $$y_t = -^*_0(y_t+e_t) - a_1 y_{t-1} - \\cdots - a_p y_{t-p} +                 b_1 e_{t-1} + \\cdots + b_q e_{t-q} + v_{t-1}$$ \\(^*_0\\) obtained \\(a_0 = b_0\\) setting diagonal elements equal zero. entries parameter matrices \\(a_i\\) \\(b_i\\) either treated fixed (equal zero) \"free\". Now regression estimated \"componentwise\", .e. component \\(y_t\\) corresponding \"free\" parameters estimated OLS. Given parameter estimates one computes new estimates disturbances, recursively solving ARMA system, see solve_inverse_de(). sample variance residuals used estimate noise covariance matrix \\(\\Sigma\\). procedure may iterated: use \"new\" estimates disturbances (re) estimate ARMA parameters (re) estimate disturbances, ... parameters maxit tol control iterative scheme. iterations stopped maxit iterations \"small\" change estimates. precise, th, th0 denote vector parameter estimates actual round previous round, procedure stops max(abs(th-th0)) <= tol. Note general guarantee iterative scheme converges estimates improved iterating. user may supply \"\" (initial) estimates e disturbances. parameter e missing (NULL) procedure est_arma_hrk computes estimates disturbances fitting \"long\" AR model data. end procedure simply calls est_ar_ols() respective paramaters p.max (controls maximum possible AR order), ic (controls information criterion used select order AR model) mean_estimate (tells est_ar_ols estimate mean \\(\\mu\\)). default maximum order p.max $$\\max(12, 10\\log_{10}(N), (N-1)/(m+1))$$ procedure supports three options estimation mean \\(\\mu = \\mathbf{E} y_t\\). mean_estimate=\"zero\" procedure sets (estimate ) mean equal zero. mean_estimate=\"sample.mean\" procedure simply uses sample mean y estimate. Third option mean_estimate=\"intercept\" uses intercept regression(s) computes estimate mean correspondingly. Note fails estimated AR polynomial unit root, .e. $$\\det \\hat{}(1) = 0.$$ guarantee HRK algorithm returns stable minimum phase ARMA model. particular, estimated model minimum phase recursive computation residuals often yields useless results correspondingly cholesky decomposition sample variance residuals (used estimate noise covariance matrix \\(\\Sigma\\)) fails. case procedure stops error message.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"Hannan EJ, Rissanen J (1982). “Recursive estimation mixed autoregressive-moving average order.” Biometrika, 69, 81–94. Hannan EJ, Kavalieris L, Mackisack M (1986). “Recursive Estimation Linear Systems.” Biometrika, 73(1), 119-133.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hannan, Rissanen, Kavalieris estimation procedure — est_arma_hrk","text":"","code":"# in order to get reproducible results set.seed(4321)  # generate a random VARMA(p=2,q=1) model with m=2 outputs ##################### tmpl = tmpl_arma_pq(m = 2, n = 2, p = 2, q = 1) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> ARMA model [2,2] with orders p = 2 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]    z^1 [,1]      [,2]    z^2 [,1]        [,2] #> [1,]        1     0 -0.10668935 0.1794017 -0.03208932 -0.07429186 #> [2,]        0     1 -0.05590295 0.2103614  0.40233680  0.04900116 #> MA polynomial b(z): #>      z^0 [,1]  [,2]   z^1 [,1]        [,2] #> [1,]        1     0  0.3101866 -0.01680908 #> [2,]        0     1 -0.1796745  0.08609177 #> Left square root of noise covariance Sigma: #>          u[1] u[2] #> u[1] 1.000000    0 #> u[2] 0.284866    1  # generate a sample with 200 observations data = sim(model, n.obs = 200, n.burn_in = 100)  # estimate model with HRK # note: we are cheating here and use the true disturbances! out = est_arma_hrk(data$y, data$u, tmpl) #> HRK estimation of ARMA model: m=2, n.obs=200, p=2, q=1 #> iter |th - th0|  n.val      MSE       ll  #>    1      0.977    198    1.958   -2.754   print(out$model) #> ARMA model [2,2] with orders p = 2 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  z^1 [,1]        [,2]    z^2 [,1]        [,2] #> [1,]        1     0 0.4774058 0.231267694 -0.08031496 -0.05099365 #> [2,]        0     1 0.1309504 0.005178953  0.33292233  0.06794187 #> MA polynomial b(z): #>      z^0 [,1]  [,2]   z^1 [,1]        [,2] #> [1,]        1     0 0.86715882 -0.05585317 #> [2,]        0     1 0.06883826 -0.24833582 #> Left square root of noise covariance Sigma: #>           u[1]      u[2] #> u[1] 0.9772386 0.0000000 #> u[2] 0.3424949 0.9410523 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 2)) #> [1] TRUE  # estimate the model with HRK # use the residuals of a long AR model as estimates for the noise out = est_arma_hrk(data$y, e = NULL, tmpl,                    trace = TRUE, maxit = 10, mean_estimate = 'zero') #> HRK estimation of ARMA model: m=2, n.obs=200, p=2, q=1 #> initial AR estimate of noise p.max=11, p=2, ll=-2.711726 #> iter |th - th0|  n.val      MSE       ll  #>    1      0.939    197    1.865   -2.697   #>    2      0.140    198    1.856   -2.692   #>    3      0.060    198    1.856   -2.692   #>    4      0.018    198    1.856   -2.692   #>    5      0.007    198    1.856   -2.692   #>    6      0.002    198    1.856   -2.692   #>    7      0.002    198    1.856   -2.692   #>    8      0.000    198    1.856   -2.692   #> algorithm converged print(out$model) #> ARMA model [2,2] with orders p = 2 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2]   z^2 [,1]        [,2] #> [1,]        1     0 0.20158389 0.13764630 0.05391753 -0.08392618 #> [2,]        0     1 0.06234842 0.09370431 0.37190127  0.05010730 #> MA polynomial b(z): #>      z^0 [,1]  [,2]     z^1 [,1]       [,2] #> [1,]        1     0  0.615023757 -0.1511000 #> [2,]        0     1 -0.001179974 -0.1500922 #> Left square root of noise covariance Sigma: #>           u[1]      u[2] #> u[1] 0.9230599 0.0000000 #> u[2] 0.3558209 0.9364313 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 2)) #> [1] TRUE  # Generate a random Model in echelon form model (m = 3) ####################### tmpl = tmpl_arma_echelon(nu = c(1,1,1)) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> ARMA model [3,3] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  [,3]   z^1 [,1]        [,2]       [,3] #> [1,]        1     0     0  0.5893418 -0.00553193 -0.2113619 #> [2,]        0     1     0  0.1842932  0.06201503  0.1328532 #> [3,]        0     0     1 -0.1422159  0.23607602  0.3943483 #> MA polynomial b(z): #>      z^0 [,1]  [,2]  [,3]    z^1 [,1]       [,2]      [,3] #> [1,]        1     0     0 -0.07942568 -0.1992309 0.5002033 #> [2,]        0     1     0 -0.29348965  0.1566674 0.1483497 #> [3,]        0     0     1 -0.14925189  0.4185160 0.3153198 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] u[3] #> u[1]  1.0000000 0.0000000    0 #> u[2]  0.2661327 1.0000000    0 #> u[3] -0.4719906 0.1258785    1  # generate a sample with 200 observations data = sim(model, n.obs = 200, n.burn_in = 100) # add mean value(s) data$y = data$y + matrix(1:3, nrow = 200, ncol = 3, byrow = TRUE)  # estimate model with HRK # note: we are cheating here and use the true disturbances! out = est_arma_hrk(data$y, data$u, tmpl,                    trace = FALSE, maxit = 1, mean_estimate = 'sample.mean') print(out$y.mean) #> [1] 0.9511495 1.9436019 2.8487408 print(out$model) #> ARMA model [3,3] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  [,3]   z^1 [,1]        [,2]         [,3] #> [1,]        1     0     0  0.6687489 -0.12600713 -0.154716557 #> [2,]        0     1     0  0.1944165 -0.04965131  0.057462781 #> [3,]        0     0     1 -0.3418481  0.50977514  0.007750021 #> MA polynomial b(z): #>      z^0 [,1]  [,2]  [,3]    z^1 [,1]        [,2]        [,3] #> [1,]        1     0     0  0.05047286 -0.31806802  0.52077685 #> [2,]        0     1     0 -0.21348959 -0.01193928  0.04368415 #> [3,]        0     0     1 -0.45130821  0.70739668 -0.11303414 #> Left square root of noise covariance Sigma: #>            u[1]       u[2]    u[3] #> u[1]  0.9644771 0.00000000 0.00000 #> u[2]  0.1932537 0.98300427 0.00000 #> u[3] -0.4325050 0.06192851 1.05045 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 1)) #> [1] TRUE  # estimate the model with HRK # use the residuals of a long AR model as estimates for the noise out = est_arma_hrk(data$y, e = NULL, tmpl,                    maxit = 10, mean_estimate = 'intercept') #> HRK estimation of ARMA model: m=3, n.obs=200, p=1, q=1 #> initial AR estimate of noise p.max=7, p=2, ll=-4.235502 #> iter |th - th0|  n.val      MSE       ll  #>    1      1.051    197    3.200   -4.235   #>    2      0.135    199    3.220   -4.249   #>    3      0.081    199    3.223   -4.251   #>    4      0.048    199    3.220   -4.250   #>    5      0.035    199    3.222   -4.251   #>    6      0.022    199    3.221   -4.250   #>    7      0.015    199    3.222   -4.250   #>    8      0.010    199    3.221   -4.250   #>    9      0.007    199    3.222   -4.250   #>   10      0.005    199    3.221   -4.250   print(out$y.mean) #> [1] 0.9537144 1.9386421 2.8536800 print(out$model) #> ARMA model [3,3] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  [,3]   z^1 [,1]         [,2]       [,3] #> [1,]        1     0     0  0.6740053 -0.261126479 -0.3217273 #> [2,]        0     1     0  0.1479565  0.008074719 -0.1286455 #> [3,]        0     0     1 -0.2984776  0.523115301  0.1643308 #> MA polynomial b(z): #>      z^0 [,1]  [,2]  [,3]    z^1 [,1]        [,2]        [,3] #> [1,]        1     0     0  0.05225048 -0.45689436  0.35600140 #> [2,]        0     1     0 -0.25603151  0.04533693 -0.14860902 #> [3,]        0     0     1 -0.41217354  0.72060291  0.04411931 #> Left square root of noise covariance Sigma: #>            u[1]       u[2]     u[3] #> u[1]  0.9625622 0.00000000 0.000000 #> u[2]  0.1902924 0.98177314 0.000000 #> u[3] -0.4307534 0.06340989 1.051195 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 1)) #> [1] TRUE  # We may also use this procedure to estimate AR models ##################### # where some coefficients are fixed = 0 a = dbind(d = 3, diag(2), array(NA_real_, dim = c(2,2,2))) a[1,2,] = 0 # all coefficient matrices are lower triangular, i.e. # y[2t] does not Granger cause y[1t] tmpl = model2template(armamod(sys = lmfd(a=a),                               sigma_L = matrix(NA_real_, nrow = 2, ncol = 2)),                       sigma_L = 'chol') model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> ARMA model [2,2] with orders p = 2 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]      [,2]    z^2 [,1]       [,2] #> [1,]        1     0 -0.1836216 0.0000000 -0.04334075 0.00000000 #> [2,]        0     1  0.2345054 0.2220447 -0.54760618 0.04449801 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>             u[1] u[2] #> u[1]  1.00000000    0 #> u[2] -0.07017046    1  # generate a sample with 200 observations data = sim(model, n.obs = 200, n.burn_in = 100)  # estimate model with HRK out = est_arma_hrk(data$y, NULL, tmpl,                    trace = FALSE, maxit = 1, mean_estimate = 'zero') print(out$y.mean) #> [1] 0 0 print(out$model) #> ARMA model [2,2] with orders p = 2 and q = 0 #> AR polynomial a(z): #>      z^0 [,1]  [,2]   z^1 [,1]    [,2]    z^2 [,1]       [,2] #> [1,]        1     0 -0.1045799 0.00000 -0.04138278 0.00000000 #> [2,]        0     1  0.3202084 0.22883 -0.58485638 0.09887707 #> MA polynomial b(z): #>      z^0 [,1]  [,2] #> [1,]        1     0 #> [2,]        0     1 #> Left square root of noise covariance Sigma: #>             u[1]      u[2] #> u[1]  0.91829065 0.0000000 #> u[2] -0.04809834 0.9383795 # ll() returns the same logLik value. However, we have to demean the data all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),                      'conditional', skip = 2)) #> [1] TRUE  # reset the \"seed\" set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":null,"dir":"Reference","previous_headings":"","what":"Different version of HRK Procedure — est_arma_hrk3","title":"Different version of HRK Procedure — est_arma_hrk3","text":"See est_arma_hrk. Stage III Hannan-Rissanen-Kavalieris procedure implemented well. function returns best model (since iterations might always improve log-likelihood value) allows returning results different stages HRK procedure.  One notable differences data needs demeaned use Yule-Walker estimation first stage ensure stability implementation stage III otherwise even cumbersome.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Different version of HRK Procedure — est_arma_hrk3","text":"","code":"est_arma_hrk3(   y,   tmpl,   maxit_stage2 = 5,   tol_stage2 = 0.001,   maxit_stage3 = 5,   tol_stage3 = 0.001,   info = TRUE,   trace = FALSE,   p.max = NULL,   ic = c(\"AIC\", \"BIC\", \"max\"),   mean_estimate = c(\"zero\", \"sample.mean\", \"intercept\"),   tol = sqrt(.Machine$double.eps) )"},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Different version of HRK Procedure — est_arma_hrk3","text":"y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. tmpl model template, see model structures(). Note case implemented, \\(a_0=b_0\\) holds, diagonal entries \\(a_0=b_0\\) equal one fixed elements equal zero. Furthermore square root sigma_L noise covariance matrix asssumed lower triangular matrix without restrictions.  given template coerced template kind. given template comply restrictions, warning message issued. maxit_stage2, maxit_stage3 Integers. Default stages 5. tol_stage2, tol_stage3 Default set 1e-3. Maximal absolute distance deep parameters adjacent iterations info Boolean. Indicates whether slot extra_info returned list contain tibble additional info model different iterations, e.g., min max absolute value zeros, poles, value objective function etc. trace (boolean) trace=TRUE, tracing information iterations printed. p.max (integer NULL) Maximum order candidate AR models. default choice see . ic (character string) information criterion shall used find optimal AR order. Note ic=\"max\" means AR(p) model p=p.max fitted. Default ic=\"AIC\". mean_estimate Character string giving method used estimate mean \\(\\mu\\). Default mean_estimate = \"sample.mean\". See details . tol Small tolerance, used check whether mean supplied data matrix indeed zero.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Different version of HRK Procedure — est_arma_hrk3","text":"See est_arma_hrk(). list contains additional slots stage_opt Since best stable miniphase model returned, also indicate whether happened stage II stage III. info_tibble Tibble containing relevant info outcome different stages iterations. contain slots y.mean (since mean required zero) converged.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/est_arma_hrk3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Different version of HRK Procedure — est_arma_hrk3","text":"","code":"data = BQdata_xts for (pp in 0:2){   for (qq in 0:2){     if (pp + qq == 0){next}     cat(paste0(\"p = \", pp, \" q = \", qq, \"\\n\"))     tmpl = tmpl_arma_pq(m = 2, n = 2,                         p = pp, q = qq)     ff = est_arma_hrk3(data, tmpl = tmpl)   } } #> p = 0 q = 1 #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> p = 0 q = 2 #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> p = 1 q = 0 #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> p = 1 q = 1 #> p = 1 q = 2 #> p = 2 q = 0 #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to max; returning -Inf #> p = 2 q = 1 #> p = 2 q = 2 ff$info_tibble %>% print(n=100) #> # A tibble: 21 × 10 #>    stage iteration flipped min_pole max_pole min_zero max_zero trace log_lik #>    <dbl>     <dbl> <lgl>      <dbl>    <dbl>    <dbl>    <dbl> <dbl>   <dbl> #>  1     1         1 FALSE       1.23     3.13   Inf      Inf    0.945  Inf    #>  2     2         1 FALSE       1.36     2.56     1.49     5.10 0.948   -1.33 #>  3     2         1 TRUE        1.36     2.56     1.49     5.10 0.948   -1.37 #>  4     2         2 FALSE       1.28     1.98     1.51     2.38 0.957   -1.34 #>  5     2         2 TRUE        1.28     1.98     1.51     2.38 0.957   -1.36 #>  6     2         3 FALSE       1.43    25.0      1.37     5.67 0.955   -1.34 #>  7     2         3 TRUE        1.43    25.0      1.37     5.67 0.955   -1.34 #>  8     2         4 FALSE       1.39     2.93     1.40     8.26 0.948   -1.33 #>  9     2         4 TRUE        1.39     2.93     1.40     8.26 0.948   -1.35 #> 10     2         5 FALSE       1.35     2.92     1.17     3.60 0.959   -1.34 #> 11     2         5 TRUE        1.35     2.92     1.17     3.60 0.959   -1.34 #> 12     3         1 FALSE       1.29     2.09     1.47     6.75 0.948   -1.34 #> 13     3         1 TRUE        1.29     2.09     1.47     6.75 0.963   -1.36 #> 14     3         2 FALSE       1.29     4.23     1.65     3.21 0.948   -1.34 #> 15     3         2 TRUE        1.29     4.23     1.65     3.21 0.958   -1.34 #> 16     3         3 FALSE       1.39     2.45     1.64     5.11 0.951   -1.34 #> 17     3         3 TRUE        1.39     2.45     1.64     5.11 0.958   -1.35 #> 18     3         4 FALSE       1.34     5.34     2.02     3.61 0.950   -1.34 #> 19     3         4 TRUE        1.34     5.34     2.02     3.61 0.952   -1.34 #> 20     3         5 FALSE       1.52     3.33     2.91     5.90 0.950   -1.34 #> 21     3         5 TRUE        1.52     3.33     2.91     5.90 0.952   -1.34 #> # ℹ 1 more variable: lndetSigma <dbl>"},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"DEPRECATED? internal helper function computes outputs , general unstable, statespace system $$a_{t+1} = a_t + B u_t, \\; y_t = C a_t + D u_t$$ forward backward recursion. procedure assumes state transition matrix \\(\\) block upper triangular, upper block \\(A_{11}\\) stable (.e. eigenvalues moduli less one) lower block \\(A_{22}\\) unstable (.e. eigenvalues moduli larger one). function mainly used routine innovation_form.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"","code":"fbsolve_STSP_cpp(A, B, C, D, u, au, as, y)"},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"\\((s, s)\\) matrix. B \\((s, n)\\) matrix. C \\((m, s)\\) matrix. D \\((m, n)\\) matrix. u \\((n, N)\\) matrix inputs \\((u_1,...,u_N\\). au \\((su,N+1)\\) matrix. matrix overwritten (computed) states unstable part system. \\((a_{u1},a_{u2},\\ldots,a_{uN},a_{u,N+1})\\). input au[,N+1] must hold \"initial\" state \\(a_{u,N+1}\\). \\((ss,N+1)\\) matrix. matrix overwritten (computed) states stable part system. \\((a_{s1},a_{s2},\\ldots,a_{sN},a_{s,N+1})\\). input [,1] must hold \"initial\" state \\(a_{s1}\\). y \\((m,N)\\) matrix. matrix overwritten (computed) outputs: \\((y_1,y_2,\\ldots,y_N)\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"RcppArmadillo routine returns NULL overwrites input argument y, au computed outputs states!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fbsolve_STSP_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Forward-backward solution of statespace systems — fbsolve_STSP_cpp","text":"Use procedure care! procedure check input arguments. require \\(m > 0\\), \\(n > 0\\). Furthermore assumed state transition matrix \\(\\) block upper triangular, explained . procedure overwrites input arguments y, au. data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":null,"dir":"Reference","previous_headings":"","what":"Forecast Error Variance Decomposition — fevardec","title":"Forecast Error Variance Decomposition — fevardec","text":"Computes Forecast Errors Variance Decomposition given (orthogonalized) impulse response function.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forecast Error Variance Decomposition — fevardec","text":"","code":"fevardec(obj, h.max = NULL, H = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forecast Error Variance Decomposition — fevardec","text":"obj impresp() object represents (orthogonalized) impulse response function. h.max maximum forecast horizon. default one plus number lags impresp object. H (n x n) (non singular) matrix renders impulse response orthogonalized impulse response. noise \\(u_t\\) transformed \\(H^{-1}u_t\\) impulse response coefficients (\\(k_j \\rightarrow k_j H\\)) (left) square root noise covariance matrix (\\(L \\rightarrow H^{-1}L\\)) transformed correspondingly.  default case H=NULL corresponds identity matrix (.e. transformation).  H='chol', transformation matrix H = t(chol(Sigma)) obtained Choleski decomposition noise covariance \\(\\Sigma\\). H='eigen' symmetric square root \\(\\Sigma\\) (obtained eigenvalue decomposition \\(\\Sigma\\)) used. H='sigma_L' left square root noise covariance, stored object obj, used. orthogonalization schemes may obtained setting \\(H\\) suitable square root \\(\\Sigma\\).  procedure checks whether transformation yields orthogonalized impulse response. , error thrown.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forecast Error Variance Decomposition — fevardec","text":"fevardec object, .e. list components vd n--n--h.max array contains forecast error variance decomposition: vd[,j,h] percentage variance h-step ahead forecast error -th component due j-th orthogonalized shock. v n--h.max matrix contains forecast error variances: v[,h] variance h-step ahead forecast error -th component. names (m)-dimensional character vector label character string NULL","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fevardec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forecast Error Variance Decomposition — fevardec","text":"","code":"model = stspmod(sys = stsp(A = c(0,0.2,1,-0.5), B = c(1,1,1,-1),                            C = c(1,0,0,1)),                 sigma_L = t(chol(matrix(c(4,2,2,3),nrow=2))),                 names = c('y1','y2'), label = 'test model') fevardec(impresp(model, lag.max=10), H = 'chol', h.max = 5) %>% print(digits = 2, format = 'iz|j') #> test model: Forecast error variance decompositon [2,2] maximum horizon = 5 #>        u[1] u[2] #> h=1 y1 1.00 0.00 #>     y2 0.33 0.67 #> h=2 y1 0.87 0.13 #>     y2 0.33 0.67 #> h=3 y1 0.78 0.22 #>     y2 0.29 0.71 #> h=4 y1 0.74 0.26 #>     y2 0.27 0.73 #> h=5 y1 0.72 0.28 #>     y2 0.26 0.74 fevardec(impresp(model, lag.max=4, H = 'eigen'))            %>% print(digits = 2, format = 'iz|j') #> test model: Forecast error variance decompositon [2,2] maximum horizon = 5 #>        u[1] u[2] #> h=1 y1 0.92 0.08 #>     y2 0.11 0.89 #> h=2 y1 0.66 0.34 #>     y2 0.36 0.64 #> h=3 y1 0.65 0.35 #>     y2 0.31 0.69 #> h=4 y1 0.62 0.38 #>     y2 0.30 0.70 #> h=5 y1 0.60 0.40 #>     y2 0.30 0.70"},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect Deep Parameters with a Model — fill_template","title":"Connect Deep Parameters with a Model — fill_template","text":"fill_template fills given template, .e. essence affine mapping free parameters linear parameters model class specified template, given free (deep) parameters th returns model (e.g. armamod() stspmod()). procedure can used generate random models, see e.g. r_model(), M-estimates, .e. estimation procedures estimate obtained minimizing (maximizing) criterion (e.g. ML GMM estimation).  \"inverse function\" extract_theta extracts free/deep parameters linear parameters model, using information provided template. end procedure first constructs vector \\(\\pi\\) stacked (linear) model parameters determines deep parameters \\(\\theta\\) least squares solution equation system $$(\\pi - h) =  H\\theta$$ residuals non zero, model (exactly) fit model structure. threshold tol used decide whether model fits template . parameter on_error decides case \"significant\" misfit. \"ignore\" procedure ignores misfit, \"warn\" procedure issues warning, \"stop\" procedure stops appropriate error message.  many cases noise covariance explicitly parametrized, since \\(\\Sigma\\) estimated another route. may accomplished fixing sigma_L identity matrix, option sigma_L = \"identity\" tmpl_*** functions. order extract system parameters (e.g. AR MA parameters ARMA model) model sigma_L equal identity, one may use option ignore_sigma_L = TRUE. ignores possible mismatch sigma_L still checks whether system parameters accordance model structure.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect Deep Parameters with a Model — fill_template","text":"","code":"fill_template(th, template)  extract_theta(   model,   template,   tol = sqrt(.Machine$double.eps),   on_error = c(\"ignore\", \"warn\", \"stop\"),   ignore_sigma_L = FALSE )"},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect Deep Parameters with a Model — fill_template","text":"th Vector containing free (deep) parameters. template template like listed model structures(), template explicitly specified user model2template(). Essentially, template affine mapping parametrised vector h matrix H connect free (deep) parameters linear parameters model. model model object, .e. armamod(), stspmod(), rmfdmod() object, deep parameters extracted. tol extract_theta, small double specifying tolerance acceptable distance linear parameters H times deep parameters. Default st sqrt(.Machine$double.eps). on_error extract_theta, character string possible choices ignore, warn, stop. Specifies happen distance linear parmameters H times deep parameters, larger specified tol. Default ignore ignore_sigma_L Boolean, default set FALSE. TRUE, linear free parameters pertaining left square root sigma_L error covariance matrix ignored. See also tmpl_sigma_L() model structures() detail.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect Deep Parameters with a Model — fill_template","text":"fill_template returns model object, .e. armamod(), stspmod(), rmfdmod() object, according class template (given parameters th). function extract_theta returns vector free parameters given model template.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"connection-to-likelihood-estimation","dir":"Reference","previous_headings":"","what":"Connection to Likelihood Estimation","title":"Connect Deep Parameters with a Model — fill_template","text":"functions important likelihood estimation following instances functionality necessary. initial estimate given model (together template), one may use extract_theta extract deep parameters. vector initial free/deep parameter values needs supplied optimizer. optimized deep parameter values need filled model using structure provided template. done fill_template","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/fill_template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Connect Deep Parameters with a Model — fill_template","text":"","code":"# Extract deep parameter from ARMA object with ARMA(p,q) template ########## (armamod_obj = test_armamod(dim = c(2,2), degree = c(3,1))) #> ARMA model [2,2] with orders p = 3 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2]  z^1 [,1]      [,2]    z^2 [,1]       [,2]  z^3 [,1] #> [1,]        1     0 0.4788278 0.8033552 -0.02115351 -0.3974357 1.5255242 #> [2,]        0     1 0.7681575 0.6468269  1.35827126  1.2689082 0.4007101 #>           [,2] #> [1,]  1.021274 #> [2,] -1.538554 #> MA polynomial b(z): #>      z^0 [,1]  [,2]   z^1 [,1]       [,2] #> [1,]        1     0  1.7449898  0.8355711 #> [2,]        0     1 -0.4705249 -0.8206135 #> Left square root of noise covariance Sigma: #>            u[1]      u[2] #> u[1]  0.3213127 0.0000000 #> u[2] -0.8014435 0.6287823 (tmpl_obj = tmpl_arma_pq(2, 2, 3, 1)) #> $h #>  [1] 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 #>  #> $H #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [2,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [5,]    1    0    0    0    0    0    0    0    0     0     0     0     0 #>  [6,]    0    1    0    0    0    0    0    0    0     0     0     0     0 #>  [7,]    0    0    1    0    0    0    0    0    0     0     0     0     0 #>  [8,]    0    0    0    1    0    0    0    0    0     0     0     0     0 #>  [9,]    0    0    0    0    1    0    0    0    0     0     0     0     0 #> [10,]    0    0    0    0    0    1    0    0    0     0     0     0     0 #> [11,]    0    0    0    0    0    0    1    0    0     0     0     0     0 #> [12,]    0    0    0    0    0    0    0    1    0     0     0     0     0 #> [13,]    0    0    0    0    0    0    0    0    1     0     0     0     0 #> [14,]    0    0    0    0    0    0    0    0    0     1     0     0     0 #> [15,]    0    0    0    0    0    0    0    0    0     0     1     0     0 #> [16,]    0    0    0    0    0    0    0    0    0     0     0     1     0 #> [17,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [18,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [19,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [20,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [21,]    0    0    0    0    0    0    0    0    0     0     0     0     1 #> [22,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [23,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [24,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [25,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [26,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [27,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [28,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] #>  [1,]     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0 #> [14,]     0     0     0     0     0     0 #> [15,]     0     0     0     0     0     0 #> [16,]     0     0     0     0     0     0 #> [17,]     0     0     0     0     0     0 #> [18,]     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0 #> [21,]     0     0     0     0     0     0 #> [22,]     1     0     0     0     0     0 #> [23,]     0     1     0     0     0     0 #> [24,]     0     0     1     0     0     0 #> [25,]     0     0     0     1     0     0 #> [26,]     0     0     0     0     1     0 #> [27,]     0     0     0     0     0     0 #> [28,]     0     0     0     0     0     1 #>  #> $class #> [1] \"armamod\" #>  #> $order #> [1] 2 2 3 1 #>  #> $n.par #> [1] 19 #>   extract_theta(armamod_obj, tmpl_obj) #>  [1]  0.47882776  0.76815751  0.80335524  0.64682691 -0.02115351  1.35827126 #>  [7] -0.39743566  1.26890825  1.52552422  0.40071009  1.02127370 -1.53855420 #> [13]  1.74498984 -0.47052488  0.83557110 -0.82061355  0.32131274 -0.80144349 #> [19]  0.62878228   # Fill template with deep parameters ################# (tmpl_obj = tmpl_arma_echelon(nu = c(3,2))) #> $h #>  [1] 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 #>  #> $H #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #>  [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [2,]    1    0    0    0    0    0    0    0    0     0     0     0     0 #>  [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [5,]    0    1    0    0    0    0    0    0    0     0     0     0     0 #>  [6,]    0    0    1    0    0    0    0    0    0     0     0     0     0 #>  [7,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>  [8,]    0    0    0    1    0    0    0    0    0     0     0     0     0 #>  [9,]    0    0    0    0    1    0    0    0    0     0     0     0     0 #> [10,]    0    0    0    0    0    1    0    0    0     0     0     0     0 #> [11,]    0    0    0    0    0    0    1    0    0     0     0     0     0 #> [12,]    0    0    0    0    0    0    0    1    0     0     0     0     0 #> [13,]    0    0    0    0    0    0    0    0    1     0     0     0     0 #> [14,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [15,]    0    0    0    0    0    0    0    0    0     1     0     0     0 #> [16,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [17,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [18,]    1    0    0    0    0    0    0    0    0     0     0     0     0 #> [19,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [20,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [21,]    0    0    0    0    0    0    0    0    0     0     1     0     0 #> [22,]    0    0    0    0    0    0    0    0    0     0     0     1     0 #> [23,]    0    0    0    0    0    0    0    0    0     0     0     0     1 #> [24,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [25,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [26,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [27,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [28,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [29,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [30,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [31,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [32,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [33,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [34,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [35,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #> [36,]    0    0    0    0    0    0    0    0    0     0     0     0     0 #>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] #>  [1,]     0     0     0     0     0     0     0     0     0     0 #>  [2,]     0     0     0     0     0     0     0     0     0     0 #>  [3,]     0     0     0     0     0     0     0     0     0     0 #>  [4,]     0     0     0     0     0     0     0     0     0     0 #>  [5,]     0     0     0     0     0     0     0     0     0     0 #>  [6,]     0     0     0     0     0     0     0     0     0     0 #>  [7,]     0     0     0     0     0     0     0     0     0     0 #>  [8,]     0     0     0     0     0     0     0     0     0     0 #>  [9,]     0     0     0     0     0     0     0     0     0     0 #> [10,]     0     0     0     0     0     0     0     0     0     0 #> [11,]     0     0     0     0     0     0     0     0     0     0 #> [12,]     0     0     0     0     0     0     0     0     0     0 #> [13,]     0     0     0     0     0     0     0     0     0     0 #> [14,]     0     0     0     0     0     0     0     0     0     0 #> [15,]     0     0     0     0     0     0     0     0     0     0 #> [16,]     0     0     0     0     0     0     0     0     0     0 #> [17,]     0     0     0     0     0     0     0     0     0     0 #> [18,]     0     0     0     0     0     0     0     0     0     0 #> [19,]     0     0     0     0     0     0     0     0     0     0 #> [20,]     0     0     0     0     0     0     0     0     0     0 #> [21,]     0     0     0     0     0     0     0     0     0     0 #> [22,]     0     0     0     0     0     0     0     0     0     0 #> [23,]     0     0     0     0     0     0     0     0     0     0 #> [24,]     1     0     0     0     0     0     0     0     0     0 #> [25,]     0     1     0     0     0     0     0     0     0     0 #> [26,]     0     0     1     0     0     0     0     0     0     0 #> [27,]     0     0     0     1     0     0     0     0     0     0 #> [28,]     0     0     0     0     1     0     0     0     0     0 #> [29,]     0     0     0     0     0     1     0     0     0     0 #> [30,]     0     0     0     0     0     0     0     0     0     0 #> [31,]     0     0     0     0     0     0     1     0     0     0 #> [32,]     0     0     0     0     0     0     0     0     0     0 #> [33,]     0     0     0     0     0     0     0     1     0     0 #> [34,]     0     0     0     0     0     0     0     0     1     0 #> [35,]     0     0     0     0     0     0     0     0     0     0 #> [36,]     0     0     0     0     0     0     0     0     0     1 #>  #> $class #> [1] \"armamod\" #>  #> $order #> [1] 2 2 3 3 #>  #> $n.par #> [1] 23 #>  #> $nu #> [1] 3 2 #>  # Number of columns of matrix H in affine mapping = number of free parameters (n_par_deep = dim(tmpl_obj$H)[2]) #> [1] 23  fill_template(rnorm(n_par_deep), tmpl_obj) #> ARMA model [2,2] with orders p = 3 and q = 3 #> AR polynomial a(z): #>        z^0 [,1]  [,2]  z^1 [,1]       [,2] z^2 [,1]       [,2]   z^3 [,1] #> [1,]  1.0000000     0 0.1586592  0.0000000 1.677256 -0.3179531 -0.3444367 #> [2,] -0.1285962     1 1.7350727 -0.2612972 1.044599 -0.2397774  0.0000000 #>            [,2] #> [1,] -0.4538713 #> [2,]  0.0000000 #> MA polynomial b(z): #>        z^0 [,1]  [,2]   z^1 [,1]      [,2]    z^2 [,1]       [,2]  z^3 [,1] #> [1,]  1.0000000     0  0.9679175 0.1632936 0.433025297 0.07230028 -1.012777 #> [2,] -0.1285962     1 -0.5661814 0.1644222 0.007921939 0.79980420  0.000000 #>           [,2] #> [1,] 0.3808726 #> [2,] 0.0000000 #> Left square root of noise covariance Sigma: #>            u[1]       u[2] #> u[1] -0.4935700  0.0000000 #> u[2]  0.6620541 -0.3514827"},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":null,"dir":"Reference","previous_headings":"","what":"Frequency Response Function — freqresp","title":"Frequency Response Function — freqresp","text":"Compute frequency response function (also called transfer function) associated VARMA state space model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frequency Response Function — freqresp","text":"","code":"freqresp(obj, n.f, ...)  # S3 method for class 'armamod' freqresp(obj, n.f = 128, ...)  # S3 method for class 'stspmod' freqresp(obj, n.f = 128, ...)  # S3 method for class 'impresp' freqresp(obj, n.f = 128, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frequency Response Function — freqresp","text":"obj armamod(), stspmod() impresp() object. Note impulse response object result approximation \"true\" frequency response due finite number coefficients. n.f number frequencies. ... used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Frequency Response Function — freqresp","text":"freqresp object, .e. list slots frr rationalmatrices::zvalues() object. sigma_L (n,n)-dimensional matrix contains left square root noise covariance matrix \\(\\Sigma\\). names (m)-dimensional character vector NULL. optional slot stores names components time series/process. label character string NULL.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Frequency Response Function — freqresp","text":"frequency response function (transfer function) associated ARMA state space model $$ K(\\lambda) = \\sum_{j=0}^{\\infty} k_j e^{-\\lambda j} $$ \\((k_j \\,|\\, j\\geq 0)\\) impulse response model. See also impresp(). ARMA model frequency response equal $$ K(\\lambda) = (a_0 + a_1 e^{-\\lambda} + \\cdots + a_p e^{-\\lambda p})^{-1} (b_0 + b_1 e^{-\\lambda} + \\cdots + b_q e^{-\\lambda q}) $$ state space model $$ K(\\lambda) = C(e^{\\lambda}I_s - )^{-1}B+D $$ Note \\(K()\\) discrete-time Fourier transform (DTFT) impulse response. impulse response absolutely summable coefficents \\(k_j\\) may reconstructed frequency response via inverse DTFT $$ k_j = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} K(\\lambda) e^{\\lambda j} d\\lambda $$ S3 methods freqresp.* evaluate function grid angular frequencies \\(\\lambda_j = 2\\pi j/N\\), \\(j=0,\\ldots,N-1\\) store result (together sigma_L) freqresp object.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/freqresp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frequency Response Function — freqresp","text":"","code":"set.seed(3451) # set seed in order to get reproducible results  ### generate random bivariate ARMA(1,1) model # \"bpoles = 1.1\" implies that the poles have moduli larger than 1.1 # and therefore the impulse response coefficients decay with a rate (1.1)^k arma_model = test_armamod(dim = c(2,2), degrees = c(1,1), bpoles = 1.1) # frequency response frr = freqresp(arma_model) # compute the frequency response via the impulse response irf = impresp(arma_model, lag.max = 100) frr1 = freqresp(irf) # since the impulse response quickly decays # the \"truncated\" frequency response should be close to the true frequency response all.equal(frr, frr1) #> [1] TRUE # create an equivalent state space model stsp_model = as.stspmod(arma_model) # of course the state space model has the same frequency response # as the original ARMA model frr1 = freqresp(stsp_model) all.equal(frr, frr1) #> [1] TRUE  # we can also reconstruct the impulse response from the # frequency response, provided the frequency grid is \"fine enough\" n.f = 2^6 frr = freqresp(arma_model, n.f = n.f) # compute the impulse response via the inverse DTFT K = unclass(frr$frr) k1 = Re(apply(K, MARGIN = c(1,2), FUN = fft, inverse = TRUE)) / n.f k1 = aperm(k1, c(2,3,1)) # impulse response irf = impresp(arma_model, lag.max = n.f-1) k = unclass(irf$irf) # compare all.equal(k, k1) #> [1] TRUE  set.seed(NULL) # reset seed"},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":null,"dir":"Reference","previous_headings":"","what":"Impulse Response Function — impresp","title":"Impulse Response Function — impresp","text":"Compute (orthogonalized) impulse response function VARMA model state space model. impulse response coefficients also called Power series parameters system.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impulse Response Function — impresp","text":"","code":"impresp(obj, lag.max, H)  # S3 method for class 'armamod' impresp(obj, lag.max = 12, H = NULL)  # S3 method for class 'rmfdmod' impresp(obj, lag.max = 12, H = NULL)  # S3 method for class 'stspmod' impresp(obj, lag.max = 12, H = NULL)  # S3 method for class 'impresp' impresp(obj, lag.max = NULL, H = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impulse Response Function — impresp","text":"obj armamod(), stspmod() object impresp() object. last case may used transform impulse response function different orthogonalization scheme. lag.max Maximum lag impulse response coefficients. parameter ignored case obj impresp object. H (n x n) (non singular) matrix specifies transformation noise. noise \\(u_t\\) transformed \\(H^{-1}u_t\\) impulse response coefficients (\\(k_j \\rightarrow k_j H\\)) (left) square root noise covariance matrix (\\(L \\rightarrow H^{-1}L\\)) transformed correspondingly.  default case H=NULL corresponds identity matrix (.e. transformation).  H='chol', transformation matrix H = t(chol(Sigma)) determined Choleski decomposition noise covariance \\(\\Sigma\\). H='eigen' symmetric square root \\(\\Sigma\\) (obtained eigenvalue decomposition \\(\\Sigma\\)) used. H='sigma_L' left square root noise covariance, stored object obj, used. cases one obtains orthogonalized impulse response function. orthogonalization schemes may obtained setting \\(H\\) suitable square root \\(\\Sigma\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impulse Response Function — impresp","text":"impresp object, .e. list components irf pseries object. sigma_L (n,n)-dimensional matrix contains left square noise covariance matrix. names (n)-dimensional character vector NULL label character string NULL","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Impulse Response Function — impresp","text":"impulse response coefficients \\((k_j \\,|\\, j \\geq 0)\\) define map noise output process. model stable stationary solution ARMA system, respectively state space system, given $$ y_t = \\sum_{j \\geq 0} k_j u_{t-j}. $$ state space system impulse response coefficients $$k_0 = D \\mbox{ }$$ $$k_j = CA^{j-1}B \\mbox{ }j >0.$$ ARMA model coefficients (recursively) computed comparison coefficients equation $$ (a_0 + a_1 z + \\cdots + a_p z^p)(k_0 + k_1 z + k_2 z^2 + \\cdots ) = b_0 + b_1 z + \\cdots + b_q z^q $$ S3 methods impresp.* compute coefficients \\(k_j\\) \\(j = 0,\\cdots,N\\) store result, together left square root (sigma_L) noise covariance \\(\\Sigma\\), impresp object. impresp objects contain complete information underlying model, provided maximum lag \\(N\\) large enough. means one may reconstruct underlying model impulse response object.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Impulse Response Function — impresp","text":"Lütkepohl H (2005). New Introduction Multiple Time Series Analysis. Springer Berlin.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/impresp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impulse Response Function — impresp","text":"","code":"# IRF from state space model ################################################ model = stspmod(stsp(A = c(0,0.2,1,-0.5), B = c(1,1,1,-1),                      C = c(1,0,0,1)),                 sigma_L = matrix(c(4, 1, 1, 3), 2, 2),                 names = c('y1','y2'), label = 'test model')  # IRF irf = impresp(model, lag.max=10) irf #> test model: Impulse response [2,2] with 10 lags #>      lag=0 [,1]  [,2] lag=1 [,1]  [,2] lag=2 [,1]  [,2] lag=3 [,1]  [,2] #> [1,]          1     0          1     1        1.0  -1.0      -0.30  0.70 #> [2,]          0     1          1    -1       -0.3   0.7       0.35 -0.55 #>      lag=4 [,1]   [,2] lag=5 [,1]    [,2] lag=6 [,1]     [,2] lag=7 [,1] #> [1,]      0.350 -0.550    -0.2350  0.4150    0.18750 -0.31750  -0.140750 #> [2,]     -0.235  0.415     0.1875 -0.3175   -0.14075  0.24175   0.107875 #>           [,2] lag=8 [,1]       [,2]  lag=9 [,1]       [,2] lag=10 [,1] #> [1,]  0.241750  0.1078750 -0.1843750 -0.08208750  0.1405375  0.06261875 #> [2,] -0.184375 -0.0820875  0.1405375  0.06261875 -0.1071438 -0.04772688 #>             [,2] #> [1,] -0.10714375 #> [2,]  0.08167938  # Orthogonalized IRF: Cholesky irf_chol = impresp(model, lag.max = 10, H = 'chol') irf_chol #> test model: Impulse response [2,2] with 10 lags #>      lag=0 [,1]     [,2] lag=1 [,1]      [,2]  lag=2 [,1]      [,2]  lag=3 [,1] #> [1,]   4.123106 0.000000   5.820855  2.667892  2.42535625 -2.667892 -0.04850713 #> [2,]   1.697749 2.667892   2.425356 -2.667892 -0.04850713  1.867524  0.50932481 #>           [,2] lag=4 [,1]      [,2] lag=5 [,1]       [,2] lag=6 [,1]       [,2] #> [1,]  1.867524  0.5093248 -1.467341 -0.2643638  1.1071751  0.2340469 -0.8470557 #> [2,] -1.467341 -0.2643638  1.107175  0.2340469 -0.8470557 -0.1698962  0.6449629 #>      lag=7 [,1]       [,2]  lag=8 [,1]       [,2]  lag=9 [,1]       [,2] #> [1,] -0.1698962  0.6449629  0.13175748 -0.4918926 -0.09985798  0.3749389 #> [2,]  0.1317575 -0.4918926 -0.09985798  0.3749389  0.07628049 -0.2858479 #>      lag=10 [,1]       [,2] #> [1,]  0.07628049 -0.2858479 #> [2,] -0.05811184  0.2179117 print(irf_chol$sigma_L) # Sigma is (approximately equal to) the identity matrix #>            [,1]      [,2] #> [1,]  0.9701425 0.2425356 #> [2,] -0.2425356 0.9701425   # IRF from VARMA model ################################################ model = armamod(sys = test_lmfd(dim = c(2,2), degrees = c(2,1)))  irf = impresp(model) print(irf, digits = 2, format = 'iz|j') #> Orthogonalized impulse response [2,2] with 12 lags #>              [,1]   [,2] #>  lag=0 [1,] -1.15  -2.34 #>        [2,]  0.46   1.59 #>  lag=1 [1,] -1.10  -1.61 #>        [2,]  0.69  -1.98 #>  lag=2 [1,] -0.45   0.74 #>        [2,] -1.94  -1.74 #>  lag=3 [1,]  0.65  -1.28 #>        [2,] -0.11  -0.26 #>  lag=4 [1,] -1.61  -3.63 #>        [2,] -0.03   1.36 #>  lag=5 [1,] -1.97  -4.05 #>        [2,]  0.76  -2.48 #>  lag=6 [1,] -1.91  -1.92 #>        [2,] -2.45  -2.94 #>  lag=7 [1,] -0.65  -4.26 #>        [2,] -0.83  -2.27 #>  lag=8 [1,] -3.34  -7.75 #>        [2,] -1.18  -0.22 #>  lag=9 [1,] -4.44 -10.35 #>        [2,]  0.11  -4.60 #> lag=10 [1,] -5.63  -9.79 #>        [2,] -3.87  -6.16 #> lag=11 [1,] -4.94 -14.06 #>        [2,] -2.72  -7.21 #> lag=12 [1,] -8.95 -20.60 #>        [2,] -4.07  -5.66"},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":null,"dir":"Reference","previous_headings":"","what":"Innovation Form state space Model — innovation_form","title":"Innovation Form state space Model — innovation_form","text":"Convert given state space model innovation form, .e. transformed model satisfies \\(D=\\) model stable minimum phase. procedure \"flips\" bad poles zeroes helper functions reflect_zeroes() reflect_poles(). transformed model equivalent description process terms second order moments. means spectral density changed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Innovation Form state space Model — innovation_form","text":"","code":"innovation_form(model, echelon_form = TRUE, y = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Innovation Form state space Model — innovation_form","text":"model state space model, .e. object type stspmod(). echelon_form boolean, TRUE innovation form model addition transformed echelon form. y NULL data sample. .matrix(y) return (N,m)-dimensional numeric matrix. NULL noise covariance matrix estimated sample.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Innovation Form state space Model — innovation_form","text":"List slots model state space model innovation form. z (complex) vector zeroes innovation form model. z_flipped (boolean) vector indicates zeroes flipped. p (complex) vector poles innovation form model. p_flipped (boolean) vector indicates poles flipped.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/innovation_form.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Innovation Form state space Model — innovation_form","text":"","code":"# in order to get reproducable results set.seed(342)  model = r_model(tmpl_stsp_full(3, 3, 5)) print(model, digits = 4) #> state space model [3,3] with s = 5 states #>         s[1]    s[2]    s[3]    s[4]    s[5]    u[1]    u[2]    u[3] #> s[1] -0.7701 -0.7534  0.4933 -1.2629  0.3608  0.0149  0.8278 -1.1295 #> s[2] -0.9100  2.2148 -0.4970 -2.2051 -1.0721 -0.9960  0.5980 -1.5275 #> s[3]  1.2751  0.9052 -0.7475 -0.5919 -1.6086 -1.1893  0.0486 -1.6221 #> s[4] -0.1740 -1.3902  1.4165  0.8076  0.5328 -0.9149 -0.2580 -0.4574 #> s[5]  0.5116 -0.0054 -0.6111  0.5597 -0.0738  0.0839 -0.3527 -0.6538 #> x[1]  0.1336  1.7917  0.5724  0.5907  0.1006  1.0000  0.0000  0.0000 #> x[2]  1.1534  1.2193  1.4340 -0.4257  0.6177  0.0000  1.0000  0.0000 #> x[3] -1.2113 -0.5287 -1.2432 -0.8186  0.8428  0.0000  0.0000  1.0000 #> Left square root of noise covariance Sigma: #>            u[1]      u[2]     u[3] #> u[1]  0.6968024 0.0000000 0.000000 #> u[2] -0.3246241 0.1801707 0.000000 #> u[3]  0.9493687 0.6805352 1.089781 # the model has two non-minimum phase zeroes and two non-stable poles. z = zeroes(model, print_message = FALSE) abs(z) #> [1] 0.2430920 0.3822571 1.4472231 1.4472231 1.7947154 p = poles(model, print_message = FALSE) abs(p) #> [1] 0.3184163 0.3801766 1.1047541 1.1047541 7.2894009  # convert to innnovation form, by flipping the \"bad\" poles and zeroes. out = innovation_form(model) print(out$model, digits = 4) #> state space model [3,3] with s = 5 states #>         s[1]    s[2]    s[3]    s[4]    s[5]     u[1]     u[2]    u[3] #> s[1]  0.0000  0.0000  0.0000  1.0000  0.0000  -2.1013   0.4187 -3.8366 #> s[2]  0.0000  0.0000  0.0000  0.0000  1.0000  -4.0003  -1.8191 -5.5912 #> s[3]  0.8764 -0.0799  1.0267  0.0449 -0.4833   6.2841   4.3642  4.3778 #> s[4] -1.0675 -0.1793 -2.2047 -2.5517  1.3806 -16.2235 -18.8212 -3.6213 #> s[5] -0.7212 -0.4139 -2.5557 -4.6404  2.3841 -17.7956 -23.0643 -1.8357 #> x[1]  1.0000  0.0000  0.0000  0.0000  0.0000   1.0000   0.0000  0.0000 #> x[2]  0.0000  1.0000  0.0000  0.0000  0.0000   0.0000   1.0000  0.0000 #> x[3]  0.0000  0.0000  1.0000  0.0000  0.0000   0.0000   0.0000  1.0000 #> Left square root of noise covariance Sigma: #>             u[1]       u[2]     u[3] #> u[1]  0.52953545  0.0000000 0.000000 #> u[2] -0.31786378  0.3060925 0.000000 #> u[3]  0.06273688 -1.0192496 1.099613 flip = function(x) {   x[abs(x) < 1] = 1/x[abs(x) < 1]   return(x)} data.frame(poles.inno = out$p, flipped = out$p_flipped,            poles.ori = p[match_vectors(out$p, p)],            zeroes.inno = out$z, flipped = out$z_flipped,            zeroes.ori = z[match_vectors(out$z, flip(z))]) #>              poles.inno flipped             poles.ori          zeroes.inno #> 1  0.6456403-0.8964543i   FALSE  0.6456403-0.8964543i -1.7947154+0.000000i #> 2  0.6456403+0.8964543i   FALSE  0.6456403+0.8964543i  0.8583822-1.165176i #> 3 -7.2894009+0.0000000i   FALSE -7.2894009+0.0000000i  0.8583822+1.165176i #> 4  3.1405429+0.0000000i    TRUE  0.3184163+0.0000000i -4.1136687+0.000000i #> 5 -2.6303566+0.0000000i    TRUE -0.3801766+0.0000000i  2.6160404+0.000000i #>   flipped.1           zeroes.ori #> 1     FALSE -1.7947154+0.000000i #> 2     FALSE  0.8583822-1.165176i #> 3     FALSE  0.8583822+1.165176i #> 4      TRUE -0.2430920+0.000000i #> 5      TRUE  0.3822571+0.000000i  # check that the innovation form model describes the same process, # by checking that the spectral density is not changed! junk = spectrald(model, n.f = 128) junk1 = spectrald(out$model, n.f = 128) all.equal(junk, junk1) #> [1] TRUE  # reset seed set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":null,"dir":"Reference","previous_headings":"","what":"Check templates — is.template","title":"Check templates — is.template","text":"Check templates","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check templates — is.template","text":"","code":"is.template(tmpl, class = c(\"any\", \"stspmod\", \"armamod\", \"rmfdmod\"))"},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check templates — is.template","text":"tmpl object tested class test specific class","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check templates — is.template","text":"TRUE/FALSE","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/is.template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check templates — is.template","text":"","code":"is.template(1) #> [1] FALSE is.template(tmpl_llm(), 'armamod') #> [1] FALSE is.template(tmpl_llm(), 'stspmod') #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":null,"dir":"Reference","previous_headings":"","what":"Kalman Filter — kf","title":"Kalman Filter — kf","text":"functions implement \"standard\" Kalman filter \"square root\" Kalman filter (also called \"square root covariance filter\") time invariant, linear state space systems without exogenous inputs, see e.g. (Anderson Moore 2005) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kalman Filter — kf","text":"","code":"kf(model, y, method = c(\"kf\", \"kf2\"), P1 = NULL, a1 = NULL)  kf_cpp(A, C, Q, R, S, y_t, P1, a1)  kf2_cpp(A, C, H_t, y_t, P1_R, a1)"},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kalman Filter — kf","text":"model stspmod() object, represents state space model. y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. method Character string. method=\"kf\" kf calls kf_cpp (\"standard form\" Kalman filter) method=\"kf2\" \"square root\" form Kalman filter used, .e. kf2_cpp called. numerical errors outputs depend chosen method. P1 \\((s,s)\\) dimensional covariance matrix error initial state estimate, .e. \\(\\Pi_{1|0}\\). NULL, state covariance \\(P = APA'+B\\Sigma B'\\) used. Note scheme assumes state space model stable, .e. state transition matrix \\(\\) stable. a1 \\(s\\) dimensional vector, holds initial estimate \\(a_{1|0}\\) state time \\(t=1\\).  a1=NULL, zero vector used. \\((s,s)\\) dimensional state transition matrix \\(\\). C \\((m,s)\\) dimensional matrix \\(C\\). Q, R, S variance, covariance matrices \"state disturbances\" (\\(Bu_t\\)) \"measurement disturbances\" (\\(Du_t\\)) described . matrices must dimension \\((s,s)\\),  \\((m,m)\\) \\((s,m)\\) respectively. y_t \\((m,N)\\) transposed data matrix y_t = t(y). H_t \\((n,s+m)\\) dimensional matrix. parameter corresponds transpose \\(H'\\) \\(H=(D',B')'\\Sigma^{1/2}\\). P1_R (right) square root P1, .e. P1 = t(P1_R) \\%*\\% P1_R.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kalman Filter — kf","text":"List components e \\((N,m)\\) dimensional matrix standardized one-step ahead prediction errors. \\(t\\)-th row matrix e corresponds $$e_t = \\Sigma_{t|t-1}^{-1/2}\\epsilon_{t|t-1}.$$ model correctly specified standardized residuals white noise unit covariance matrix. may used validaton model. \\((N+1,s)\\) dimensional matrix estimated states. \\(t\\)-th row matrix corresponds \\(a_{t|t-1}\\). Given y , one step ahead predictions \\(y_{t|t-1}\\) may computed yh = \\%*\\% t(C). ll (scaled) Gaussian log likelihood model $$-\\frac{1}{2N}\\sum_{t=1}^{N}\\left(m\\log(2\\pi) + \\log\\det\\Sigma_{t|t-1} +           (y_t - y_{t|t-1})' \\Sigma_{t|t-1}^{-1} (y_t - y_{t|t-1}) \\right).$$ P1 \\((s,s)\\) dimensional covariance matrix error state prediction \\(a_{N+1|N}\\), .e. matrix corresponds \\(\\Pi_{N+1|N}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kalman Filter — kf","text":"model considered $$a_{t+1} = a_t + Bu_t$$ $$y_t = C a_t + Du_t$$ \\(m\\)-dimensional outputs \\(y_t\\), \\(s\\)-dimensional states \\(a_t\\) \\(n\\)-dimensional disturbances \\(u_t\\). disturbances white noise covariance matrix \\(\\mathbf{E} u_tu_t'=\\Sigma\\). Note disturbances outputs may different dimensions, however, \"wide\" systems (\\(m\\leq n\\)) implemented. Kalman filter recursive scheme compute linear, least squares predictions \\(a_{t+1}\\) \\(y_{t+1}\\) given observations \\(y_t,\\ldots,y_1\\) time \\(t\\). predictions notated \\(a_{t+1|t}\\) \\(y_{t+1|t}\\), prediction error output \\(y_{t+1}\\) \\(\\epsilon_{t+1|t}=(y_{t+1}-y_{t+1|t})\\) corresponding variances prediction errors $$\\Pi_{t+1|t}=\\mathbf{E}(a_{t+1}-a_{t+1|t}) (a_{t+1}-a_{t+1|t})',$$ $$\\Sigma_{t+1|t}=\\mathbf{E}(\\epsilon_{t+1|t} \\epsilon_{t+1|t}').$$ standard form Kalman filter based parameter matrices \\(,C\\), variance \"state disturbances\" \\(Q=\\mathbf{E}(Bu_t (Bu_t)')=(B\\Sigma B')\\), variance \"measurement disturbances\" \\(R=\\mathbf{E}(Du_t (Du_t)')=(D\\Sigma D')\\) covariance \\(S=\\mathbf{E}(Bu_t(Du_t)')=(B\\Sigma D')\\). Furthermore need initial prediction \\(a_{1|0}\\) corresponding error variance \\(\\Pi_{1|0}\\). square root form filter need \"square roots\" \\(\\Pi_{1|0}^{1/2}\\) \\(\\Sigma^{1/2}\\), .e. matrices \\(\\Pi_{1|0} = \\Pi_{1|0}^{1/2} (\\Pi_{1|0}^{1/2})'\\) \\(\\Sigma = \\Sigma^{1/2}(\\Sigma^{1/2})'\\). addition, define \\(H=(D',B')'\\Sigma^{1/2}\\). routines kf_cpp, kf2_cpp RcppArmadillo implementations standard form square root form Kalman filter. wrapper function kf takes stspmod() object, describes state space model, calls approriate RcppArmadillo function. Square root Kalman filter: square root \\(\\Pi_{1|0}^{1/2}\\) procedure first tries Cholesky decomposition. fails (since \\(\\Pi_{1|0}^{1/2}\\) (close ) singular), ll_kf tries compute symmetric square root via eigenvalue decomposition \\(\\Pi_{1|0}^{1/2}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Kalman Filter — kf","text":"RcppArmadillo functions (kf_cpp kf2_cpp) check input parameters, function must used care. procedures accept \"wide\" state space systems (\\(m \\leq n\\)), since \"tall\" systems (\\(m > n\\)) variance prediction errors (\\(\\Sigma_{t+1|t}\\)) singular \\(t\\) larger threshold. now, support models exogenous inputs.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kalman Filter — kf","text":"Anderson BDO, Moore JB (2005). Optimal filtering. Dover Publications Inc., London. Originally published: Englewood Cliffs, Prentice-Hall 1979.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/kf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kalman Filter — kf","text":"","code":"s = 4  # state dimension m = 2  # number of outputs n = 3  # number of inputs, n.obs = 100 # sample size  # generate a (stable) state space model tmpl = tmpl_stsp_full(m, n, s, sigma_L = \"chol\") model = r_model(tmpl, bpoles = 1, sd = 0.5) # generate a sample data = sim(model, n.obs = n.obs, a1 = NA)  # compute Q, R, S and P1 sigma_L = model$sigma_L sigma = tcrossprod(sigma_L) R = model$sys$D %*% sigma %*% t(model$sys$D) S = model$sys$B %*% sigma %*% t(model$sys$D) Q = model$sys$B %*% sigma %*% t(model$sys$B) P1 = lyapunov(model$sys$A, Q)  # call Kalman filter. Note y_t = t(y)! out = kf_cpp(model$sys$A, model$sys$C, Q, R, S, t(data$y), P1, double(s)) # use the wrapper function out_test = kf(model, data$y, method = 'kf') all.equal(out, out_test) #> [1] TRUE  # compute H and square root of P1 H = rbind(model$sys$D, model$sys$B) %*% sigma_L P1_R = chol(P1)  # call square root Kalman filter. Note H_t = t(H) and y_t = t(y)! out_test = kf2_cpp(model$sys$A, model$sys$C, t(H), t(data$y), P1_R, double(s)) all.equal(out, out_test) #> [1] TRUE # use the wrapper function out_test = kf(model, data$y, method = 'kf2') all.equal(out, out_test) #> [1] TRUE  # The one step ahead predictions for y[t] may be computed by yh = out$a %*% t(model$sys$C) # and the (non scaled) prediction errors are uh = data$y - out$a[1:n.obs,] %*% t(model$sys$C)"},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Likelihood Methods — ll","title":"Log Likelihood Methods — ll","text":"Tools methods computation (conditional exact) Gaussian log-likelihood ARMA, RMFD, state space models. functions serve input optimizers like optim, see ll_theta ll_FUN (latter function factory generates closure serves input).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Likelihood Methods — ll","text":"","code":"ll(obj, y, which, ...)  # S3 method for class 'armamod' ll(obj, y, which = c(\"concentrated\", \"conditional\"), skip = 0L, ...)  # S3 method for class 'stspmod' ll(   obj,   y,   which = c(\"concentrated\", \"conditional\", \"kf\", \"kf2\"),   skip = 0L,   P1 = NULL,   a1 = NULL,   tol = 1e-08,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Likelihood Methods — ll","text":"obj Object type armamod(), rmfdmod(), stspmod(). y Data sample given \\((N,m)\\) dimensional matrix, \"time series\" object (sense .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. (character) likelihood compute. ... used. skip (integer) skip initial observations. parameter used, (concentrated) conditional likelihood computed. P1 \\((s,s)\\) dimensional covariance matrix error initial state estimate. NULL state covariance \\(P=APA'+B\\Sigma B'\\) used. parameter used, (exact) likelihood computed via Kalman Filter. See ll_kf() details. a1 \\(s\\) dimensional vector, holds initial estimate state time t=1. a1=NULL, zero vector used. parameter used, (exact) likelihood computed via Kalman Filter. See ll_kf() details. tol (small) tolerance value (zero) used Kalman Filter routines, see ll_kf().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Likelihood Methods — ll","text":"(double) (scaled) log Likelihood model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Likelihood Methods — ll","text":"procedure three choices ... ARMA model $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + b_1 u_{t-1} + \\cdots + b_q u_{t-q}$$ Gaussian noise \\(u_t \\sim N(0,\\Sigma)\\) approximation scaled log likelihood $$ll = -(1/2)(m \\ln(2\\pi) + \\mathrm{tr}(S\\Sigma^{-1}) + \\ln\\det \\Sigma + 2 \\ln\\det (a_0^{-1}b_0)$$ \\(S\\) denotes sample covariance residuals model $$S=\\frac{1}{N-s}\\sum_{t=s+1}^N e_t e_t'$$ residuals computed sample \\(y_t, t=1,\\ldots,N\\) solving (inverse) ARMA system $$b_0 e_t = -b_1 e_{t-1} - \\cdots - b_q e_{t-q} + a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p}$$ setting unknown initial values \\(y_t=0\\) \\(e_t=0\\) \\(t\\leq 0\\) equal zero. See e.g. solve_inverse_de(). Note log Likelihood scaled factor \\(1/(N-s)\\) first \\(s\\) observations skipped computing sample covariance matrix. log-likelihood may easily maximized respect noise covariance matrix \\(\\Sigma\\). given \\(S\\), optimal value \\(\\Sigma\\) \\(\\Sigma=S\\). plug maximizer log-likelihood function, obtain \"concentrated\" log likelihood function $$cll = -(1/2)(m \\ln(2\\pi) + m + \\ln\\det S + 2 \\ln\\det (a_0^{-1}b_0)$$ depends sample y ARMA parameter matrices \\(a_i\\) \\(b_i\\). state space models (approximate) log likelihood computed quite analogously.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Log Likelihood Methods — ll","text":"precise, functions returns \\(1/(N-s)\\) times (approximate) log likelihood. routines handle case centered data, .e. assumed output process \\((y_t)\\) mean zero! computation concentrated log likelihood assumes model structure impose restrictions noise covariance matrix.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Likelihood Methods — ll","text":"","code":"# Generate a random model in echelon form model (m = 3) tmpl = tmpl_arma_echelon(nu = c(2,1,1)) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> ARMA model [3,3] with orders p = 2 and q = 2 #> AR polynomial a(z): #>         z^0 [,1]  [,2]  [,3]    z^1 [,1]      [,2]       [,3]   z^2 [,1] #> [1,]  1.00000000     0     0 -0.30971228 0.0000000  0.0000000 -0.2851629 #> [2,] -0.18030565     1     0 -0.07152422 0.2227471 -0.2489370  0.0000000 #> [3,]  0.02886177     0     1 -0.18531607 0.1409678  0.1947942  0.0000000 #>           [,2]       [,3] #> [1,] 0.6455823 0.06594129 #> [2,] 0.0000000 0.00000000 #> [3,] 0.0000000 0.00000000 #> MA polynomial b(z): #>         z^0 [,1]  [,2]  [,3]   z^1 [,1]        [,2]       [,3]    z^2 [,1] #> [1,]  1.00000000     0     0 0.22986530 0.009034977  0.1316557 -0.08972547 #> [2,] -0.18030565     1     0 0.06354289 0.036216677  0.5051050  0.00000000 #> [3,]  0.02886177     0     1 0.20327238 0.068788081 -0.4723335  0.00000000 #>           [,2]       [,3] #> [1,] 0.2853816 0.06148275 #> [2,] 0.0000000 0.00000000 #> [3,] 0.0000000 0.00000000 #> Left square root of noise covariance Sigma: #>           u[1]      u[2] u[3] #> u[1]  1.000000 0.0000000    0 #> u[2] -0.109147 1.0000000    0 #> u[3]  0.157453 0.1977473    1 # extract the corresponding free/deep parameters th = extract_theta(model, tmpl)  # generate a sample with 50 observations y = sim(model, n.obs = 50, n.burn_in = 100)$y  # conditional log likelihood # the following statements return the same ll value! ll(model, y, which = 'conditional', skip = 0) #> [1] -4.405062 ll_theta(th, template= tmpl, y, which = 'conditional', skip = 0) #> [1] -4.405062 llfun = ll_FUN(tmpl, y, which = 'conditional', skip = 0) llfun(th) #> [1] -4.405062  # concentrated, conditional log likelihood # the following statements return the same ll value! ll(model, y, which = 'concentrated', skip = 0) #> [1] -4.365861 ll_theta(th, template= tmpl, y, which = 'concentrated', skip = 0) #> [1] -4.365861 llfun = ll_FUN(tmpl, y, which = 'concentrated', skip = 0) llfun(th) #> [1] -4.365861"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Likelihood Function Factory — ll_FUN","title":"Log Likelihood Function Factory — ll_FUN","text":"Creates function similar ll_theta() faster memory efficient. model structure (template) data (y) encoded within generated closure (function plus enclosing environment). generated function calls compiled C/C++ code (see RcppArmadillo-package) hence much faster calling ll_theta(th, template, y, ...).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Likelihood Function Factory — ll_FUN","text":"","code":"ll_FUN(   template,   y,   which = c(\"concentrated\", \"conditional\", \"kf\", \"gr_concentrated\"),   skip = 0L,   tol = 1e-08,   err = NA_real_ )"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Likelihood Function Factory — ll_FUN","text":"template model template, see model structures. y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. (string) Determines type ll function. skip (integer) skip initial observations. NULL skip set \\(0\\) state space models \\(\\max(p,q)\\) ARMA models. parameter used cases \"concentrated\", \"conditional\" \"gr_concentrated\" tol (double) tolerance used ll_kf_cpp(). err (double) return value case \"kf\", computation initial state covariance fails.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Likelihood Function Factory — ll_FUN","text":"function, llfun(th) say, computes log-likelihood given deep parameters th. function may used ML estimation model. Function fn(th)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_FUN.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Likelihood Function Factory — ll_FUN","text":"","code":"# Generate a random model in echelon form model (m = 3) tmpl = tmpl_stsp_echelon(nu = c(2,1,1)) model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25) diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L print(model) #> state space model [3,3] with s = 4 states #>             s[1]         s[2]        s[3]        s[4]        u[1]       u[2] #> s[1]  0.00000000  0.000000000  0.00000000  1.00000000 -0.47579669  0.1941772 #> s[2]  0.17834782 -0.001085635 -0.28582940 -0.01480361  0.09693782 -0.2800847 #> s[3]  0.09380898  0.013628061 -0.07131278  0.27512558  0.23146018 -0.1110135 #> s[4] -0.10879216 -0.278774721 -0.17177456  0.33897889  0.02478557  0.5165047 #> x[1]  1.00000000  0.000000000  0.00000000  0.00000000  1.00000000  0.0000000 #> x[2]  0.00000000  1.000000000  0.00000000  0.00000000  0.00000000  1.0000000 #> x[3]  0.00000000  0.000000000  1.00000000  0.00000000  0.00000000  0.0000000 #>             u[3] #> s[1]  0.09142169 #> s[2] -0.10341404 #> s[3]  0.04197707 #> s[4]  0.10486197 #> x[1]  0.00000000 #> x[2]  0.00000000 #> x[3]  1.00000000 #> Left square root of noise covariance Sigma: #>             u[1]     u[2] u[3] #> u[1]  1.00000000 0.000000    0 #> u[2] -0.02632044 1.000000    0 #> u[3]  0.06769402 0.110399    1 # extract the corresponding free/deep parameters th = extract_theta(model, tmpl)  # generate a sample with 50 observations y = sim(model, n.obs = 50)$y  # conditional log likelihood # the following statements return the same ll value! ll(model, y, 'conditional') #> [1] -4.283411 ll_theta(th, tmpl, y, 'conditional') #> [1] -4.283411 fn = ll_FUN(tmpl, y, 'conditional') fn(th) #> [1] -4.283411  # concentrated conditional log likelihood # the following statements return the same ll value! ll(model, y, 'concentrated') #> [1] -4.248823 ll_theta(th, tmpl, y, 'concentrated') #> [1] -4.248823 fn = ll_FUN(tmpl, y, 'concentrated') fn(th) #> [1] -4.248823 # for this case, we may also compute the (analytic) gradient gr = ll_FUN(tmpl, y, 'gr_concentrated') gr(th) #>  [1] -6.884443e-01 -3.628422e-02  7.316056e-01  2.632317e-01 -2.791062e-03 #>  [6] -6.040969e-02 -8.197604e-02  3.233422e-05  9.889647e-02 -6.908969e-01 #> [11]  1.347149e-02  3.425038e-01  6.087337e-02  3.500822e-01  1.623533e-01 #> [16] -3.689552e-02 -2.536515e-01 -4.107069e-01  1.207367e-01  7.516551e-02 #> [21] -3.309819e-02 -2.035432e-01 -2.322694e-01  9.862495e-02  0.000000e+00 #> [26]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  # log likelihood (via Kalman filter) # the following statements return the same ll value! ll(model, y, 'kf2') #> [1] -4.283794 ll_theta(th, tmpl, y, 'kf2') #> [1] -4.283794 ll(model, y, 'kf') #> [1] -4.283794 ll_theta(th, tmpl, y, 'kf') #> [1] -4.283794 fn = ll_FUN(tmpl, y, 'kf') fn(th) #> [1] -4.283794"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian log Likelihood of a State Space Model — ll_kf","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"routines compute log Likelihood time invariant, linear state space models form $$a_{t+1} = a_t + Bu_t$$ $$y_t = C a_t + Du_t$$ \\(m\\)-dimensional outputs \\(y_t\\), \\(s\\)-dimensional states \\(a_t\\) \\(n\\)-dimensional disturbances \\(u_t\\). disturbances white noise covariance matrix \\(\\mathbf{E} u_t u_t'=\\Sigma\\). Note disturbances outputs may different dimensions, however, \"wide\" systems (\\(m\\leq n\\)) implemented. Gaussian log likelihood (case Gaussian disturbances \\(u_t\\sim N(0,\\Sigma)\\) \\(a_1\\sim N(a_{1|0},\\Pi_{1|0})\\)) computed standard Kalman Filter square root Kalman filter, see kf(). Kalman filter recursive scheme compute linear, least squares predictions \\(a_{t+1}\\) \\(y_{t+1}\\) given observations \\(y_t,\\ldots,y_1\\) time \\(t\\). predictions notated \\(a_{t+1|t}\\) \\(y_{t+1|t}\\), prediction error output \\(y_{t+1}\\) \\(\\epsilon_{t+1|t}=(y_{t+1}-y_{t+1|t})\\) corresponding variances prediction errors $$\\Pi_{t+1|t}=\\mathbf{E}(a_{t+1}-a_{t+1|t}) (a_{t+1}-a_{t+1|t})',$$ $$\\Sigma_{t+1|t}=\\mathbf{E}(\\epsilon_{t+1|t} \\epsilon_{t+1|t}').$$ standard form Kalman filter based parameter matrices \\(,C\\), variance \"state disturbances\" \\(Q=\\mathbf{E}(Bu_t (Bu_t)')=(B\\Sigma B')\\), variance \"measurement disturbances\" \\(R=\\mathbf{E}(Du_t (Du_t)')=(D\\Sigma D')\\) covariance \\(S=\\mathbf{E}(Bu_t(Du_t)')=(B\\Sigma D')\\). Furthermore need initial prediction \\(a_{1|0}\\) corresponding error variance \\(\\Pi_{1|0}\\). square root form filter need \"square roots\" \\(\\Pi_{1|0}^{1/2}\\) \\(\\Sigma^{1/2}\\), .e. matrices \\(\\Pi_{1|0} = \\Pi_{1|0}^{1/2} (\\Pi_{1|0}^{1/2})'\\) \\(\\Sigma = \\Sigma^{1/2}(\\Sigma^{1/2})'\\). addition, define \\(H=(D',B')'\\Sigma^{1/2}\\). (scaled) Gaussian log Likelihood model may expressed $$\\frac{-1}{2N}\\sum_{t=1}^{N}\\left(m\\log(2\\pi) + \\log\\det\\Sigma_{t|t-1} +           (y_t - y_{t|t-1})' \\Sigma_{t|t-1}^{-1} (y_t - y_{t|t-1}) \\right).$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"","code":"ll_kf(model, y, method = c(\"kf\", \"kf2\"), P1 = NULL, a1 = NULL, tol = 0)  ll_kf_cpp(A, C, Q, R, S, y_t, P1, a1, tol)  ll_kf2_cpp(A, C, H_t, y_t, P1_R, a1, tol)"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"model stspmod() object, represents state space model. y sample, .e. \\((N,m)\\) dimensional matrix, \"time series\" object (.e. .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. method Character string. method=\"kf\" ll_kf calls ll_kf_cpp (\"standard form\" Kalman filter) method=\"kf2\" \"square root\" form Kalman filter used, .e. ll_kf2_cpp called. numerical errors outputs depend chosen method. P1 \\((s,s)\\) dimensional covariance matrix error initial state estimate, .e. \\(\\Pi_{1|0}\\). NULL, state covariance \\(P = APA'+B\\Sigma B'\\) used. Note scheme assumes state space model stable, .e. state transition matrix \\(\\) stable. a1 \\(s\\) dimensional vector, holds initial estimate \\(a_{1|0}\\) state time \\(t=1\\).  a1=NULL, zero vector used. tol (small) tolerance value (zero). order speed computations, algorithm(s) switch constant Kalman gain significant change state error covariance. behavior controlled parameter tol may switched setting tol=0. \\((s,s)\\) dimensional state transition matrix \\(\\). C \\((m,s)\\) dimensional matrix \\(C\\). Q, R, S variance, covariance matrices \"state disturbances\" (\\(Bu_t\\)) \"measurement disturbances\" (\\(Du_t\\)) described . matrices must dimension \\((s,s)\\),  \\((m,m)\\) \\((s,m)\\) respectively. y_t \\((m,N)\\) transposed data matrix y_t = t(y). H_t \\((n,s+m)\\) dimensional matrix. parameter corresponds transpose \\(H'\\) \\(H=(D',B')'\\Sigma^{1/2}\\). P1_R (right) square root P1, .e. P1 = t(P1_R) \\%*\\% P1_R.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"(double) Gaussian log Likelihood model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"core routines  ll_kf_cpp ll_kf2_cpp RcppArmadillo implementations standard square root Kalman filter. function ll_kf wrapper function, extracts necessary parameters stspmod() object, computes initial covariance matrix P1 initial state estimate a1 (provided) calls ll_kf_cpp ll2_kf_cpp. Square root Kalman filter: square root \\(\\Pi_{1|0}^{1/2}\\) procedure first tries Cholesky decomposition. fails (since \\(\\Pi_{1|0}^{1/2}\\) (close ) singular), ll_kf tries compute symmetric square root via eigenvalue decomposition \\(\\Pi_{1|0}^{1/2}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"procedures accept \"wide\" state space systems (\\(m \\leq n\\)), since \"tall\" systems (\\(m > n\\)) variance prediction errors (\\(\\Sigma_{t+1|t}\\)) singular \\(t\\) larger threshold.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian log Likelihood of a State Space Model — ll_kf","text":"","code":"s = 4  # state dimension m = 2  # number of outputs n = m  # number of inputs (square case m=n) n.obs = 100 # sample size  # generate a (stable) state space model (in innovation form) tmpl = tmpl_stsp_full(m, n, s, sigma_L = \"chol\") model = r_model(tmpl, bpoles = 1, sd = 0.5) # generate a sample data = sim(model, n.obs = n.obs, a1 = NA)  # compute Q, R, S and P1 sigma_L = model$sigma_L sigma = tcrossprod(sigma_L) R = model$sys$D %*% sigma %*% t(model$sys$D) S = model$sys$B %*% sigma %*% t(model$sys$D) Q = model$sys$B %*% sigma %*% t(model$sys$B) P1 = lyapunov(model$sys$A, Q)  # compute H and square root of P1 H = rbind(model$sys$D, model$sys$B) %*% sigma_L P1_R = chol(P1)  # compute logLikelihood (via Kalman Filter) ll = ll_kf(model, data$y)  # compute logLikelihood (via square root Kalman Filter) ll_test = ll_kf(model, data$y, method = 'kf2') all.equal(ll, ll_test) #> [1] TRUE  # directly call Rcpp routines, note H_t = t(H) and y_t = t(y) ll_test = ll_kf_cpp(model$sys$A, model$sys$C, Q, R, S,                     t(data$y), P1, a1 = double(s), tol=1e-8) all.equal(ll, ll_test) #> [1] TRUE ll_test = ll_kf2_cpp(model$sys$A, model$sys$C, t(H),                      t(data$y), P1_R, a1 = double(s), tol=1e-8) all.equal(ll, ll_test) #> [1] TRUE  # call the \"full\" kf routines out = kf(model, data$y) all.equal(ll, out$ll) #> [1] TRUE out = kf(model, data$y, method = 'kf2') all.equal(ll, out$ll) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf_theta_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the log likelihood for a statespace system described by a model template. — ll_kf_theta_cpp","title":"Compute the log likelihood for a statespace system described by a model template. — ll_kf_theta_cpp","text":"internal helper function, used function factory ll_FUN. detailed documentation log Likelihood, see ll_kf.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf_theta_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the log likelihood for a statespace system described by a model template. — ll_kf_theta_cpp","text":"","code":"ll_kf_theta_cpp(   theta,   y,   SYS,   H_SYS,   h_SYS,   sigma_L,   H_sigma_L,   h_sigma_L,   VAR,   P1,   tol,   err )"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_kf_theta_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the log likelihood for a statespace system described by a model template. — ll_kf_theta_cpp","text":"theta \\((K)\\) dimensional vector \"deep\" parameters. y \\((m,N)\\) matrix observed outputs: \\((y_1,y_2,\\ldots,y_N)\\). SYS \\((m+s,m+s)\\) matrix, overwritten system matrix \\([,B | C,D]\\). H_SYS \\((m+s)^2, K)\\) matrix. h_SYS \\(((m+s)^2)\\)-dimensional vector. Note vec(SYS) = H_SYS*theta + h_SYS. sigma_L \\((m,m)\\) matrix, overwritten left square root noise covariance matrix. H_sigma_L \\((m^2, K)\\) matrix. h_sigma_L \\((m^2)\\)-dimensional vector. Note vec(sigma_L) = H_sigma_L*theta + h_sigma_L. VAR \\((m+s,m+s)\\) matrix, overwritten covariance matrix \\([Q,S | S',R] = [B | C] sigma_L sigma_L' [B', C']\\) P1 \\((s,s)\\) matrix, overwritten initial state covariance matrix (computed via Lyapunov equation). tol (double) tolerance used ll_kf_cpp. err (double) return err, computation P1 fails.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_theta.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-likelihood Given Deep Parameters — ll_theta","title":"Log-likelihood Given Deep Parameters — ll_theta","text":"See ll_FUN(). template template filled deep parameters th. Subsequently, S3 method ll() called class provided template value scaled log-likelihood function returned, see ll().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_theta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-likelihood Given Deep Parameters — ll_theta","text":"","code":"ll_theta(th, template, y, which, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/ll_theta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-likelihood Given Deep Parameters — ll_theta","text":"th Vector deep parameter template model template, see model structures. y Data sample given \\((N,m)\\) dimensional matrix, \"time series\" object (sense .matrix(y) return \\((N,m)\\)-dimensional numeric matrix). Missing values (NA, NaN Inf) supported. (character) likelihood compute. ... used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/ll_theta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-likelihood Given Deep Parameters — ll_theta","text":"Value log-likelihood given deep/free parameter vector th model structure defined via template. Note function simply calls ll(fill_template(th, template), y, , ...).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":null,"dir":"Reference","previous_headings":"","what":"Local Model Structures — local model structures","title":"Local Model Structures — local model structures","text":"Parametrization \"local\" model classes, particular, \"Data Driven Local Coordinates\" detailed (McKelvey et al. 2004)  (Ribarits et al. 2005) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local Model Structures — local model structures","text":"","code":"tmpl_DDLC(   model,   balance = c(\"none\", \"lyapunov\", \"minimum phase\"),   sigma_L = c(\"chol\", \"symm\", \"identity\") )  tmpl_GRAM(   model,   balance = c(\"lyapunov\", \"minimum phase\"),   sigma_L = c(\"chol\", \"symm\", \"identity\") )"},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local Model Structures — local model structures","text":"model stspmod() object, represents state space model. case \\(m = n > 0\\) implemented, .e. output process noise process must dimension. balance (character string) balance = \"lyapunov\" balance = \"minimum phase\" reference model first balanced respective scheme. sigma_L (character string) determines form (left) square root noise covariance \\(\\Sigma\\). choice \"chol\" gives lower triangular matrix, \"symm\" gives symmetric matrix \"identity\" corresponds (fixed) identity matrix.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local Model Structures — local model structures","text":"Model template, .e. list slots h \\(((m+s)^2 + m^2)\\)-dimensional vector, H \\(((m+s)^2 + m^2, k)\\)-dimensional matrix, class = \"stspmod\"  order = c(m,m,s) n.par number free parameters \\(=k\\). See also model structures() details.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Local Model Structures — local model structures","text":"function tmpl_DDLC tmpl_GRAM construct model templates describe models neighborhood given reference model. first step reference state space model transformed \\(D=\\) eventually (depending parameter \"balance\") balanced. state space models described quadruple \\((,B,C,D=)\\) matrices may embedded \\((s^2+2ms)\\)-dimensional euclidean space. Note parameter matrices uniqely determined ACF spectral density process, .e. inherent non identifiablity problem. minimal models \"equivalence class\" models, represent ACF given set models may obtained state transformation \\((,B,C,D) \\rightarrow (TAT^{-1}, TB, CT^{-1}, D)\\). DDLC parametrization now considers models, \\((,B,C,D=)\\), contained \\(2ms\\)-dimensional subspace, orthogonal \\(s^2\\)-dimensional tangent space set equivalent models. routine tmpl_GRAM considers \\(2ms\\)-dimensional subspace, models close reference models \"approximately\" balanced. schemes may fail \"non-generic\" models. tmpl_DDLC issues warning message tmpl_GRAM throws error, cases \\(2ms\\)-dimensional subspace well defined. Note also parametrization left square root L=sigma_L noise covariance \"local\", .e. th = 0 corresponds (balanced) reference model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Local Model Structures — local model structures","text":"McKelvey T, Helmersson , Ribarits T (2004). “Data driven local coordinates multivariable linear systems application system identification.” Automatica, 40(9), 1629 - 1635. doi:10.1016/j.automatica.2004.04.015 . Ribarits T, Deistler M, Hanzon B (2005). “analysis separable least squares data driven local coordinates maximum likelihood estimation linear systems.” Automatica, 41(3), 531 - 544. doi:10.1016/j.automatica.2004.11.014 . .","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/local_model_structures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local Model Structures — local model structures","text":"","code":"# create a random state space model with m outputs and s states m = 3 s = 6 tmpl = tmpl_stsp_full(m, n = m, s, sigma_L = 'symm') model = r_model(tmpl, bpoles = 1.1, bzeroes = 1.1, sd = 1/s) model                              # note that sigma_L is symmetric #> state space model [3,3] with s = 6 states #>             s[1]        s[2]         s[3]          s[4]        s[5]        s[6] #> s[1] -0.22265095  0.50272019  0.083513362  0.2571544759 -0.15906105 -0.27229490 #> s[2] -0.11927751 -0.16415220  0.001178752  0.0960543961  0.20591719 -0.01219423 #> s[3] -0.11021934  0.05313687  0.091211239 -0.0025940641 -0.03484008  0.12386439 #> s[4] -0.07729205  0.15424939 -0.006312946 -0.2471635357  0.09182998 -0.05297297 #> s[5]  0.18620731  0.54056846 -0.074042125  0.0207133786 -0.11031516 -0.12790172 #> s[6] -0.04158061  0.06799590  0.240351977  0.0582696231  0.09531564 -0.15093084 #> x[1]  0.35927919  0.29838600 -0.086336419  0.1441695219  0.28723100  0.09486512 #> x[2]  0.16698048  0.08323002 -0.063497533 -0.1934404090 -0.08559753  0.03810958 #> x[3] -0.10010093 -0.13964260  0.209183518 -0.0005764036  0.16099128 -0.17881458 #>             u[1]        u[2]        u[3] #> s[1]  0.16462478  0.31937121  0.25967546 #> s[2]  0.15654489  0.18129501  0.04779198 #> s[3] -0.25792220  0.02887677  0.30754427 #> s[4] -0.04657263  0.29725757  0.12495017 #> s[5] -0.15681295  0.19306445 -0.27792576 #> s[6] -0.11656068 -0.13340313  0.04655536 #> x[1]  1.00000000  0.00000000  0.00000000 #> x[2]  0.00000000  1.00000000  0.00000000 #> x[3]  0.00000000  0.00000000  1.00000000 #> Left square root of noise covariance Sigma: #>             u[1]        u[2]        u[3] #> u[1]  0.14463601  0.01497182 -0.28498768 #> u[2]  0.01497182 -0.17696139  0.30163687 #> u[3] -0.28498768  0.30163687  0.08626554 model$sigma_L %*% t(model$sigma_L) # noise covariance Sigma #>             [,1]        [,2]        [,3] #> [1,]  0.10236171 -0.08644676 -0.06128804 #> [2,] -0.08644676  0.12252429 -0.03162400 #> [3,] -0.06128804 -0.03162400  0.17964452  # tmpl_DDLC #############################################  # create a DDLC parametrization of a neighborhood of this model tmpl = tmpl_DDLC(model, balance = 'lyapunov', sigma_L = 'chol') # for th = 0, we get the original model (in balanced form) model = fill_template(numeric(tmpl$n.par), tmpl) model                                # note that sigma_L is lower triangular #> state space model [3,3] with s = 6 states #>             s[1]        s[2]         s[3]          s[4]         s[5] #> s[1]  0.22749707 -0.09706120 -0.376418415 -0.2081900642  0.054668903 #> s[2]  0.13130247 -0.36833737  0.011801937  0.0340802642 -0.067264809 #> s[3]  0.30960298 -0.25986571 -0.555903533  0.5208816630  0.007463684 #> s[4] -0.06039423 -0.07845019 -0.104719211  0.1102402592 -0.142683665 #> s[5] -0.06439903 -0.17966764  0.054101790  0.0178486443 -0.054539103 #> s[6] -0.02066912  0.02215459 -0.005762771  0.1407234833 -0.189952759 #> x[1] -0.51782150 -0.08054127 -0.067977961 -0.0008951252  0.006844787 #> x[2] -0.03901319  0.19629373 -0.125363793 -0.0367534161 -0.056625548 #> x[3]  0.04949881 -0.26791384  0.017674281 -0.0588825594 -0.034572369 #>             s[6]         u[1]          u[2]         u[3] #> s[1]  0.01002193 -0.168232498 -0.4847356383 -0.063645698 #> s[2]  0.07421788  0.315846871 -0.0963310647  0.109632249 #> s[3] -0.02324560 -0.056813276  0.0993283768  0.010965345 #> s[4]  0.05292509  0.060633747  0.0030335678 -0.190016927 #> s[5] -0.10497537 -0.025337571 -0.0001285062  0.006827089 #> s[6] -0.16295878  0.001324394 -0.0071282729  0.005706124 #> x[1]  0.00125503  1.000000000  0.0000000000  0.000000000 #> x[2] -0.00384912  0.000000000  1.0000000000  0.000000000 #> x[3] -0.01732466  0.000000000  0.0000000000  1.000000000 #> Left square root of noise covariance Sigma: #>            u[1]       u[2]       u[3] #> u[1]  0.3199402  0.0000000 0.00000000 #> u[2] -0.2701967  0.2225265 0.00000000 #> u[3] -0.1915610 -0.3747109 0.05040472 model$sigma_L %*% t(model$sigma_L)  # however Sigma is the same as above #>             [,1]        [,2]        [,3] #> [1,]  0.10236171 -0.08644676 -0.06128804 #> [2,] -0.08644676  0.12252429 -0.03162400 #> [3,] -0.06128804 -0.03162400  0.17964452  #' apply a \"small\" state transformation T = (diag(s)+eps*X) eps = sqrt(.Machine$double.eps) sys = model$sys d_sys = state_trafo(sys, diag(s) + matrix(rnorm(s^2, sd = eps), nrow = s, ncol = s)) d_pi = (as.vector(unclass(d_sys) - unclass(sys)))/eps # The vector d_pi is (close to) an element of the tangent space # of the set of models, which are generated by a state transformation # of the reference model  # by construction d_pi is (close to) orthogonal to tmpl$H max(abs(d_pi %*% tmpl$H[1:((m+s)^2), , drop = FALSE])) #> [1] 3.344665e-08  # the tmpl_DDLC routine may fail in some exceptional cases m = 1 s = 3 model = stspmod(sys = stsp(A = matrix(0, nrow = s, ncol = s),                            B = matrix(rnorm(m*s), nrow = s, ncol = m),                            C = matrix(rnorm(m*s), nrow = m, ncol = s),                            D = diag(m)),                 sigma_L = diag(m))  # For this model \"tmpl_DLLC\" issues a warning. junk = tmpl_DDLC(model, sigma_L = 'chol', balance = 'none') #> Warning: The tangent space of the equivalence class does not have dimension s^2=9 (sv[1]=2.11291112328716, sv[9]=4.22480766864052e-18)  # tmpl_GRAM ############################################# model = fill_template(numeric(tmpl$n.par), tmpl)  tmpl = tmpl_GRAM(model, sigma_L = 'chol') model = fill_template(numeric(tmpl$n.par), tmpl)  # check grammians gr = grammians(model$sys, 'lyapunov') P = gr$P Q = gr$Q # P=Q=diag() should hold! print(round(cbind(P, P-Q), 6)) #>          [,1]     [,2]    [,3]     [,4]     [,5]     [,6] [,7] [,8] [,9] [,10] #> [1,] 0.299115 0.000000 0.00000 0.000000 0.000000 0.000000    0    0    0     0 #> [2,] 0.000000 0.146146 0.00000 0.000000 0.000000 0.000000    0    0    0     0 #> [3,] 0.000000 0.000000 0.09197 0.000000 0.000000 0.000000    0    0    0     0 #> [4,] 0.000000 0.000000 0.00000 0.043465 0.000000 0.000000    0    0    0     0 #> [5,] 0.000000 0.000000 0.00000 0.000000 0.006966 0.000000    0    0    0     0 #> [6,] 0.000000 0.000000 0.00000 0.000000 0.000000 0.001438    0    0    0     0 #>      [,11] [,12] #> [1,]     0     0 #> [2,]     0     0 #> [3,]     0     0 #> [4,]     0     0 #> [5,]     0     0 #> [6,]     0     0  # now consider a model close to the reference model d_th = rnorm(tmpl$n.par, sd = eps) d_model = fill_template(d_th, tmpl) d_sys = d_model$sys gr = grammians(d_sys, 'lyapunov') d_P = gr$P - P d_Q = gr$Q - Q  # the \"disturbed\" system should still be approximately balanced! print(round(cbind(d_P, d_P - d_Q)/eps, 6) ) #>           [,1]     [,2]      [,3]    [,4]      [,5]      [,6] [,7] [,8] [,9] #> [1,] -0.174217 0.000000  0.000000  0.0000  0.000000  0.000000    0    0    0 #> [2,]  0.000000 0.062264  0.000000  0.0000  0.000000  0.000000    0    0    0 #> [3,]  0.000000 0.000000 -0.372991  0.0000  0.000000  0.000000    0    0    0 #> [4,]  0.000000 0.000000  0.000000 -0.3011  0.000000  0.000000    0    0    0 #> [5,]  0.000000 0.000000  0.000000  0.0000 -0.037533  0.000000    0    0    0 #> [6,]  0.000000 0.000000  0.000000  0.0000  0.000000 -0.008466    0    0    0 #>      [,10] [,11] [,12] #> [1,]     0     0     0 #> [2,]     0     0     0 #> [3,]     0     0     0 #> [4,]     0     0     0 #> [5,]     0     0     0 #> [6,]     0     0     0"},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Structures — model structures","title":"Model Structures — model structures","text":"tools define implement model structures model parameters represented affine function free (deep) parameters. example consider multivariate ARMA models. AR coefficients \\(a_k\\), MA coefficients \\(b_k\\) (left) square root noise covariance matrix, \\(L\\) say, vectorized stacked (long) parameter vector $$\\pi = (\\mbox{vec}(a_1)',\\ldots,\\mbox{vec}(a_p)',              \\mbox{vec}(b_1)',\\ldots,\\mbox{vec}(b_q)',\\mbox{vec}(L)')'$$ parameter vector written $$\\pi = h + H\\theta$$ \\(\\theta\\) represents free parameters. course matrix \\(H\\) assumed full column rank. parameterization scheme quite flexible. particular, ARMA state space models echelon form may represented scheme.  Templates related tools mainly used estimation generation (random) models simulations testing.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Structures — model structures","text":"","code":"model2template(   model,   sigma_L = c(\"as_given\", \"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_arma_pq(   m,   n,   p,   q,   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_arma_echelon(   nu,   n = length(nu),   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_rmfd_pq(   m,   n,   p,   q,   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_rmfd_echelon(   nu,   m = length(nu),   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_stsp_full(   m,   n,   s,   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )  tmpl_stsp_ar(m, p, sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\"))  tmpl_stsp_echelon(   nu,   n = length(nu),   sigma_L = c(\"chol\", \"symm\", \"identity\", \"full_normalized\") )"},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Structures — model structures","text":"model armamod(), rmfdmod() stspmod() object. sigma_L (character string) determines form (left) square root noise covariance \\(\\Sigma\\). choice \"chol\" gives lower triangular matrix, \"symm\" gives symmetric matrix \"identity\" corresponds fixed (identity) matrix.  procedure model2template additional option \"as_given\" means structure square root sigma_L completely determined sigma_L slot given model. m output dimension n input dimension (= number shocks = dimension noise process) p order AR polynomial ARMA models, respectively order right factor polynomial \\(c(z)\\) RMFD model. q order MA polynomial ARMA models, respectively order left factor polynomial \\(d(z)\\) RMFD model. nu vector Kronecker indices. ARMA models Kronecker indices describe basis rows RMFD models basis columns Hankel matrix impulse response coefficients. s state dimension state space models.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Structures — model structures","text":"functions model2template tmpl_*** return model template.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Structures — model structures","text":"functions model2template tmpl_*** generate model \"templates\" represent certain model structures, model parameters affine functions free, respectively deep, parameters. template contains information model structure following slots h, H represent vector \\(h\\) marix \\(H\\) described . (vector \\(\\pi\\) stacked model parameters represented \\(\\pi = h +H \\theta\\) \\(\\theta\\) vector deep parameters.) class=[\"armamod\"|\"rmfdmod\"|\"stspmod\"]: determines whether template parametrizes ARMA, RMFD state space models. order: integer vector contains dimensions orders model. ARMA RMFD models order = c(m,n,p,q) state space models order = c(m,n,s). n.par: number free parameters, .e. dimension vector \\(\\theta\\). nu: optional slot contains Kronecker indices \\(\\nu\\). model2template: function model2template() takes armamod(), rmfdmod(), stspmod() object free parameters coded NA's, NaN's Inf's constructs corresponding model template. parametrization (left) square root, \\(L\\) say, noise covariance \\(\\Sigma = LL'\\) following choices possible: case sigma_L = \"as_given\" slot model$sigma_L given model used construct template: NA entries considered free entries fixed. choice sigma_L = \"chol\" first entries model$sigma_L diagonal set zero template constructed . case sigma_L = \"symm\" matrix  model$sigma_L first replaced symmetric one template constructed (according NA's) square root L=sigma_L always symmetric. choice sigma_L = \"identity\" sets matrix L = sigma_L identity matrix. Finally, choice sigma_L = \"full_normalized\" sets diagonal elements equal ones elements NAs L = sigma_L. tmpl_:* functions tmpl_*** implement following model structures: tmpl_arma_pq ARMA models (armamod()) prescribed orders \\((p,q\\)). tmpl_arma_echelon ARMA models (armamod()) echelon form, given Kronecker indices \\(\\nu\\). tmpl_rmfd_pq RMFD models (rmfdmod()) prescribed orders \\((p,q\\)). tmpl_rmfd_echelon RMFD models (rmfdmod()) echelon form, Kronecker indices \\(\\nu\\). Note RMFD models Kronecker indices refer basis column space Hankel matrix impulse response coefficients. tmpl_stsp_full Fully parametrized state space models (stspmod()) given state space dimension \\(s\\), .e. models entry matrices \\(,B,C\\) considered non-fixed. tmpl_stsp_echelon State space models (stspmod()) echelon form, given Kronecker indices \\(\\nu\\). tmpl_state space_ar State space model representations (stspmod()) AR models given order \\(p\\). \"square\" case \\(m=n\\) implemented. model structures impulse response (transfer function) scaled \\((m,n)\\)-dimensional lag zero coefficient, \\(k_0\\) say, form \\(m=n\\) \\(k_0\\) \\(m\\)-dimensional identity matrix. \\(m<n\\) first \\(m\\) columns \\(k_0\\) form \\(m\\)-dimensional identity matrix remaining columns zero. \\(m>n\\) first \\(n\\) rows \\(k_0\\) form \\(n\\)-dimensional identity matrix remaining rows free. parametrization (left) square root \\(L\\) noise covariance \\(\\Sigma = LL'\\) following choices possible: sigma_L=\"chol\" matrix \\(L\\) lower triangular (entries main diagonal considered free entries diagonal zero). sigma_L=\"symm\" matrix \\(L\\) symmetric (entries main diagonal considered free entries diagonal \\(L=L'\\) holds). sigma_L=\"identity\" matrix \\(L\\) fixed \\(n\\)-dimensional identity matrix. sigma_L=\"full_normalized\" diagonal elements matrix \\(L\\) fixed ones elements free.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/model_structures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Structures — model structures","text":"","code":"# ###################################################### # construct a template from a model # ######################################################  # Let us consider scalar ARMA(5,1) models # for quarterly data with a strong seasonal component. # In order to have parsimonious models we want a[2]=a[3]=0: model = armamod(lmfd(a = c(1,NA,0,0,NA,NA), b = c(1,NA))) tmpl = model2template(model)  # Let's see how the \"free\" parameters are mapped to the model parameters print(cbind(tmpl$h, tmpl$H)) #>       [,1] [,2] [,3] [,4] [,5] #>  [1,]    1    0    0    0    0 #>  [2,]    0    1    0    0    0 #>  [3,]    0    0    0    0    0 #>  [4,]    0    0    0    0    0 #>  [5,]    0    0    1    0    0 #>  [6,]    0    0    0    1    0 #>  [7,]    1    0    0    0    0 #>  [8,]    0    0    0    0    1 #>  [9,]    1    0    0    0    0 th = -(1:tmpl$n.par) fill_template(th, tmpl) #> ARMA model [1,1] with orders p = 5 and q = 1 #> AR polynomial a(z): #>      z^0 [,1] z^1 [,1] z^2 [,1] z^3 [,1] z^4 [,1] z^5 [,1] #> [1,]        1       -1        0        0       -2       -3 #> MA polynomial b(z): #>      z^0 [,1] z^1 [,1] #> [1,]        1       -4 #> Left square root of noise covariance Sigma: #>      u[1] #> u[1]    1  # Generate a random model with this structure th0 = rnorm(tmpl$n.par, sd = 0.1) model = fill_template(th0, tmpl)  # Extract the \"free\" parameters from the model th = extract_theta(model, tmpl) all.equal(th, th0) #> [1] TRUE  # This model structure fixes sigma_L = 1. # If we change sigma_L = 2 then the model does not fit to the template. model$sigma_L = 2 # the default choice on_error = 'ignore', tells # extract_theta to ignore this misfit: th = extract_theta(model, tmpl, on_error = 'ignore') # with on_error = 'warn' we get a warning and # with on_error = 'stop' would throw an error. th = extract_theta(model, tmpl, on_error = 'warn') #> Warning: model does not match template. max(abs(res)) = 1 # We may also \"ignore\" sigma_L th = extract_theta(model, tmpl, on_error = 'stop', ignore_sigma_L=TRUE)  # If the orders/class of template and model does not fit if (FALSE) { # \\dontrun{ model = armamod(lmfd(a = c(1,1), b = c(1,1))) extract_theta(model, tmpl) model = stspmod(stsp(D = 1)) extract_theta(model, tmpl) } # }  # ###################################################### # the parameter \"sigma_L\" # ######################################################  # consider a state space model (with 1 state) for a 3-dimensional process model = stspmod(stsp(A = 1, B = c(1,0,0), C = c(1,1,1), D = diag(3)))  # We may specify an arbitrary structure for the left square root (L = sigma_L) # of the noise covariance Sigma. Any NA entry is considered as a \"free\" parameter. L = matrix(c(0, NA, 1, 0, 2, 3, NA, 1, 1), nrow = 3, ncol = 3) L #>      [,1] [,2] [,3] #> [1,]    0    0   NA #> [2,]   NA    2    1 #> [3,]    1    3    1 # L has 2 NA entries and thus we get a model structure with 2 free parameters. model$sigma_L = L  tmpl = model2template(model, sigma_L = 'as_given') th = -(1:tmpl$n.par) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    0    0   -2 #> u[2]   -1    2    1 #> u[3]    1    3    1  # The choice sigma_L = 'chol' forces L to be lower triangular. # In the case considered here, we get a model structure with 1 free parameter. tmpl = model2template(model, sigma_L = 'chol') th = -(1:tmpl$n.par) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    0    0    0 #> u[2]   -1    2    0 #> u[3]    1    3    1  # The choice sigma_L = 'symm' forces L = sigma_L to be symmetric. # In the case considered here we thus get a model structure with 2 free parameters. tmpl = model2template(model, sigma_L = 'symm') th = -(1:tmpl$n.par) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    0   -1   -2 #> u[2]   -1    2    2 #> u[3]   -2    2    1  # The choice sigma_L = 'identity' set L equal to the identity matrix, # i.e. sigma_L is fixed. tmpl = model2template(model, sigma_L = 'identity') th = numeric(0) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    1    0    0 #> u[2]    0    1    0 #> u[3]    0    0    1 tmpl$n.par # there are no free parameters: tmpl$n.par = 0 #> [1] 0  # The choice sigma_L = 'full_normalized' sets the diagonal elements of L equal to ones, # and leaves all other elements free. tmpl = model2template(model, sigma_L = 'full_normalized') th = -(1:tmpl$n.par) fill_template(th, tmpl) #> state space model [3,3] with s = 1 states #>      s[1] u[1] u[2] u[3] #> s[1]    1    1    0    0 #> x[1]    1    1    0    0 #> x[2]    1    0    1    0 #> x[3]    1    0    0    1 #> Left square root of noise covariance Sigma: #>      u[1] u[2] u[3] #> u[1]    1   -3   -5 #> u[2]   -1    1   -6 #> u[3]   -2   -4    1   # ###################################################### # ARMA(p,q) models # ######################################################  m = 2 # output dimension p = 1 # AR order q = 1 # MA order  # model structure with lower triangular sigma_L tmpl = tmpl_arma_pq(m, n = m, p, q, sigma_L = \"chol\") th = rnorm(tmpl$n.par) th = -(1:tmpl$n.par) fill_template(th, tmpl) #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -3 #> [2,]        0     1       -2    -4 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -5    -7 #> [2,]        0     1       -6    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]   -9    0 #> u[2]  -10  -11  # model structure with symmetric sigma_L tmpl = tmpl_arma_pq(m, n = m, p, q, sigma_L = \"symm\") fill_template(th, tmpl) #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -3 #> [2,]        0     1       -2    -4 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -5    -7 #> [2,]        0     1       -6    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]   -9  -10 #> u[2]  -10  -11  # model structure with sigma_L = I tmpl = tmpl_arma_pq(m, n = m, p, q, sigma_L = \"identity\") # here the number of free paramaters is of course (by 3) smaller # than for the above model structures! fill_template(th[1:(length(th)-3)], tmpl) #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -3 #> [2,]        0     1       -2    -4 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -5    -7 #> [2,]        0     1       -6    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1   # ###################################################### # RMFD(p,q) models y[t] = d(z) c(z)^-1 e[t] # ######################################################  m = 2 # output dimension p = 1 # order of c(z) q = 1 # order of d(z)  # model structure with lower triangular sigma_L tmpl = tmpl_rmfd_pq(m, n = m, p, q, sigma_L = \"chol\") th = rnorm(tmpl$n.par) th = -(1:tmpl$n.par) fill_template(th, tmpl) #> RMFD model [2,2] with orders p = 1 and q = 1 #> right factor polynomial c(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -5 #> [2,]        0     1       -2    -6 #> left factor polynomial d(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -3    -7 #> [2,]        0     1       -4    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]   -9    0 #> u[2]  -10  -11  # model structure with symmetric sigma_L tmpl = tmpl_rmfd_pq(m, n = m, p, q, sigma_L = \"symm\") fill_template(th, tmpl) #> RMFD model [2,2] with orders p = 1 and q = 1 #> right factor polynomial c(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -5 #> [2,]        0     1       -2    -6 #> left factor polynomial d(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -3    -7 #> [2,]        0     1       -4    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]   -9  -10 #> u[2]  -10  -11  # model structure with sigma_L = I tmpl = tmpl_rmfd_pq(m, n = m, p, q, sigma_L = \"identity\") # here the number of free paramaters is of course (by 3) smaller # than for the above model structures! fill_template(th[1:(length(th)-3)], tmpl) #> RMFD model [2,2] with orders p = 1 and q = 1 #> right factor polynomial c(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -1    -5 #> [2,]        0     1       -2    -6 #> left factor polynomial d(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0       -3    -7 #> [2,]        0     1       -4    -8 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1   # ###################################################### # state space models in echelon form # ###################################################### nu = c(3,2,4)   # Kronecker indices m = length(nu)  # number of outputs/inputs tmpl = tmpl_stsp_echelon(nu = nu)  # generate a random vector of parameters. # Note that \"tmpl$n.par\" contains the number free parameters. th = rnorm(tmpl$n.par)  # generate a model according to this structure with the parameters th model = fill_template(th, tmpl) print(model) #> state space model [3,3] with s = 9 states #>           s[1]       s[2]       s[3]       s[4]       s[5]        s[6] #> s[1]  0.000000  0.0000000  0.0000000  1.0000000  0.0000000  0.00000000 #> s[2]  0.000000  0.0000000  0.0000000  0.0000000  1.0000000  0.00000000 #> s[3]  0.000000  0.0000000  0.0000000  0.0000000  0.0000000  1.00000000 #> s[4]  0.000000  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> s[5] -1.229153  0.2556706  1.0504372 -1.0628182 -0.6775323  1.38303260 #> s[6]  0.000000  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> s[7]  1.754942 -1.8281670 -0.1409875 -0.6164041  1.0829308 -0.04739599 #> s[8]  0.000000  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> s[9]  0.789922  1.1386980 -0.4779014  0.2460182 -0.7205951 -1.04820069 #> x[1]  1.000000  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> x[2]  0.000000  1.0000000  0.0000000  0.0000000  0.0000000  0.00000000 #> x[3]  0.000000  0.0000000  1.0000000  0.0000000  0.0000000  0.00000000 #>            s[7]       s[8]         s[9]        u[1]        u[2]       u[3] #> s[1]  0.0000000  0.0000000  0.000000000 -0.59102707 -1.84756891  2.2379831 #> s[2]  0.0000000  0.0000000  0.000000000 -0.44574410  0.01679591  0.9091784 #> s[3]  0.0000000  0.0000000  0.000000000  0.55427835  0.82874573  1.7200899 #> s[4]  1.0000000  0.0000000  0.000000000 -0.38192322  1.58208478 -0.2087060 #> s[5]  0.4091870  0.0000000  0.000000000  0.20242605  0.31036002  0.6408392 #> s[6]  0.0000000  1.0000000  0.000000000 -0.51279042  0.49153314  0.4987534 #> s[7] -0.3478686 -0.5027389  0.000000000  0.16240910  0.05084881  0.6901537 #> s[8]  0.0000000  0.0000000  1.000000000  0.01816816  1.63516828  1.6480944 #> s[9]  0.1416559  0.7635246 -0.006776399  1.63912365 -1.05083484  0.4031096 #> x[1]  0.0000000  0.0000000  0.000000000  1.00000000  0.00000000  0.0000000 #> x[2]  0.0000000  0.0000000  0.000000000  0.00000000  1.00000000  0.0000000 #> x[3]  0.0000000  0.0000000  0.000000000  0.00000000  0.00000000  1.0000000 #> Left square root of noise covariance Sigma: #>             u[1]        u[2]      u[3] #> u[1] -2.09030869  0.00000000 0.0000000 #> u[2] -0.01272456 -1.03278192 0.0000000 #> u[3]  1.29127069 -0.07057778 0.1253465  # we can extract the free parameters from this given model all.equal(th, extract_theta(model, tmpl, on_error = 'stop')) #> [1] TRUE  # check the impulse response k = impresp(model, lag.max = 2*sum(nu) + 1)  # the lag zero coeffcient k[0] is equal to the identity all.equal(unclass(k$irf)[,,1], diag(m)) #> [1] TRUE  # check the Kronecker indices all.equal(rationalmatrices::pseries2nu(k$irf), nu) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Outputs of an ARMA systems — outputs_ARMA_cpp","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"internal helper function computes outputs ARMA system $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + \\cdots + b_q u_{t-q}$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"","code":"outputs_ARMA_cpp(A1, B, t0, u, y)"},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"A1 \\((m, mp)\\) matrix \\(-a_0^{-1}(a_p,...,a_1)\\). B \\((m, n(q+1))\\) matrix \\(a_0^{-1}(b_0,...,b_q\\). t0 integer, start iteration t = t0. u \\((n, N)\\) matrix inputs \\((u_1,...,u_N\\). y \\((m, N)\\) matrix outputs \\((y_1,...,y_N\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"RcppArmadillo routine returns NULL overwrites input argument y computed outputs!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitly set zero. However, starting iteration \\(t_0>1\\) can enforce non-zero initial values.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"Use procedure care! procedure check input arguments. require \\(m > 0\\), \\(p \\geq 0\\), \\(n(q+1) \\geq 0\\) \\(1 \\leq t_0 \\leq N\\). procedure overwrites input argument y. data matrices organized columnwise (avoid memory shuffling)! Note also non standard representation coefficient matrices.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_ARMA_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outputs of an ARMA systems — outputs_ARMA_cpp","text":"","code":"# generate a random ARMA(2,1) model (3 outputs, 2 inputs) p = 2 q = 1 m = 3 n = 2 model = test_armamod(dim = c(m, n), degrees = c(p,q), digits = 2) A = unclass(model$sys$a) a0 = A[,,1] A1 = -A[,,(p+1):2] dim(A1) = c(m, m*p) A1 = solve(a0, A1) B = unclass(model$sys$b) dim(B) = c(m, n*(q+1)) B = solve(a0, B)  # generate random noise sequence (sample size N = 10) n.obs = 10 u = matrix(rnorm(n.obs*n), nrow = n, ncol = n.obs) print(u) #>           [,1]       [,2]        [,3]      [,4]      [,5]      [,6]       [,7] #> [1,] -3.132142 -1.9753302 -0.06687406 0.7038420  1.611381 -0.438007  1.4678488 #> [2,] -2.150074 -0.8020834  0.83440039 0.1114058 -1.476292 -0.872467 -0.3712195 #>            [,8]       [,9]       [,10] #> [1,] 2.38637657 -0.3992816  0.98022024 #> [2,] 0.05813272  1.1070752 -0.01518782  # generate matrix for the outputs y = matrix(0, nrow = m, ncol = n.obs)  # call outputs_ARMA_cpp() outputs_ARMA_cpp(A1, B, t0 = 2, u, y) # start with t>=2 print(u) #>           [,1]       [,2]        [,3]      [,4]      [,5]      [,6]       [,7] #> [1,] -3.132142 -1.9753302 -0.06687406 0.7038420  1.611381 -0.438007  1.4678488 #> [2,] -2.150074 -0.8020834  0.83440039 0.1114058 -1.476292 -0.872467 -0.3712195 #>            [,8]       [,9]       [,10] #> [1,] 2.38637657 -0.3992816  0.98022024 #> [2,] 0.05813272  1.1070752 -0.01518782 print(y)  # y is overwritten with the computed outputs #>      [,1]       [,2]       [,3]      [,4]      [,5]      [,6]      [,7] #> [1,]    0  0.5152195 -0.1721183 -5.346482 -7.318907 -19.60611 -38.04047 #> [2,]    0  1.8504163  5.3783049 10.302334 25.663588  53.62919 144.83837 #> [3,]    0 -1.3308983 -3.6446976 -5.478886 -6.173523 -25.58684 -45.23886 #>            [,8]      [,9]     [,10] #> [1,]  -94.26689 -254.4698 -492.0407 #> [2,]  308.48027  779.8844 1786.4506 #> [3,] -143.94609 -272.0460 -718.5699"},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Outputs of a statespace system — outputs_STSP_cpp","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"internal helper function computes outputs states statespace system form $$a_{t+1} = a_t + B u_t, \\; y_t   = C a_t + D u_t$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"","code":"outputs_STSP_cpp(A, B, C, D, u, a, y)"},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"\\((s,s)\\) matrix. B \\((s,n)\\) matrix. C \\((m,s)\\) matrix. D \\((m,n)\\) matrix. u \\((n,N)\\) matrix inputs/disturbances: \\((u_1,u_2,\\ldots,u_N)\\). \\((s,N+1)\\) matrix. matrix overwritten (computed) states: \\((a_1,a_2,\\ldots,a_N,a_{N+1})\\). input [,1] must hold initial state \\(a_1\\). y \\((m,N)\\) matrix. matrix overwritten (computed) outputs: \\((y_1,y_2,\\ldots,y_N)\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"RcppArmadillo routine returns NULL overwrites input arguments u!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"Use procedure care! procedure check input arguments. procedure overwrites input arguments u. data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/outputs_STSP_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outputs of a statespace system — outputs_STSP_cpp","text":"","code":"# generate a random statespace model (3 outputs, 2 inputs and 4 states) m = 3 n = 2 s = 4 model = test_stspmod(dim = c(m, n), s = s, digits = 2)  # generate random noise sequence (sample size N = 10) n.obs = 10 u = matrix(rnorm(n.obs*n), nrow = n, ncol = n.obs) print(u) #>           [,1]       [,2]     [,3]       [,4]      [,5]      [,6]      [,7] #> [1,] 0.2173447 -0.8353325 1.496910 -0.6515175 1.1346293 0.6763501 0.3363965 #> [2,] 0.4471227  0.1409061 1.362301 -0.5174458 0.6143891 1.5933323 0.5924614 #>              [,8]       [,9]      [,10] #> [1,]  0.008539218  0.9694180 -1.5718134 #> [2,] -1.085621021 -0.3930895 -0.6153608  # generate matrix for the state sequence a = matrix(0, nrow = s, ncol = n.obs+1) a[,1] = rnorm(s) # random initial state a[1] print(a) #>            [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] #> [1,] -0.2412325    0    0    0    0    0    0    0    0     0     0 #> [2,]  0.2719050    0    0    0    0    0    0    0    0     0     0 #> [3,] -1.0406623    0    0    0    0    0    0    0    0     0     0 #> [4,]  0.5281270    0    0    0    0    0    0    0    0     0     0  # generate matrix for the outputs y = matrix(0, nrow = m, ncol = n.obs)  # call outputs_STSP_cpp() outputs_STSP_cpp(model$sys$A, model$sys$B, model$sys$C, model$sys$D, u, a, y) print(u) #>           [,1]       [,2]     [,3]       [,4]      [,5]      [,6]      [,7] #> [1,] 0.2173447 -0.8353325 1.496910 -0.6515175 1.1346293 0.6763501 0.3363965 #> [2,] 0.4471227  0.1409061 1.362301 -0.5174458 0.6143891 1.5933323 0.5924614 #>              [,8]       [,9]      [,10] #> [1,]  0.008539218  0.9694180 -1.5718134 #> [2,] -1.085621021 -0.3930895 -0.6153608 print(a)  # a is overwritten with the computed states #>            [,1]      [,2]      [,3]      [,4]       [,5]      [,6]      [,7] #> [1,] -0.2412325 1.9396248 -3.363503  1.199680  -5.903463 -6.793850 14.033443 #> [2,]  0.2719050 0.2963779 -6.528416  6.617881  -8.596936 18.492112 15.799060 #> [3,] -1.0406623 0.6957607 -2.229484  6.207147   2.824222  2.378189 11.417787 #> [4,]  0.5281270 1.3115528 -1.932456 11.033960 -10.124434 12.781377 -5.512745 #>           [,8]     [,9]      [,10]     [,11] #> [1,] -10.38477 66.56542  -63.98627 107.75464 #> [2,] -14.51215 25.25327 -148.70864  96.55825 #> [3,] -46.86630 36.18867 -130.58331 200.13577 #> [4,] -17.59122 26.03063  -71.92477 168.91551 print(y)  # y is overwritten with the computed outputs #>            [,1]       [,2]       [,3]      [,4]       [,5]      [,6]      [,7] #> [1,] -0.3002033  1.2092360   1.070953  3.031778  -1.281007 -9.037767  4.143743 #> [2,]  0.1471419  0.4491558  -2.837089 13.045537  -3.369193 23.436127  6.933759 #> [3,]  0.9877319 -1.7203977 -11.166463 13.992650 -13.182688 52.098444 19.372472 #>           [,8]      [,9]      [,10] #> [1,] -23.67842  60.03310  -41.93191 #> [2,] -50.17609  17.76221 -183.69595 #> [3,] -19.67283 -24.13063 -267.10533"},{"path":"https://bfunovits.github.io/RLDM/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"Pipe operator","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Forecast Error Variance Decomposition — plot.fevardec","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"Plot Forecast Error Variance Decomposition","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"","code":"# S3 method for class 'fevardec' plot(   x,   main = NA,   xlab = NA,   col = NA,   y_names = x$names,   u_names = y_names,   parse_names = FALSE,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"x fevardec() object. main (character string) overall title plot. main=NULL omits title main = NA sets default title. xlab (character string) title x-axis. xlab=NULL omits title xlab = NA sets default x-axis title. col (m)-dimensional vector colors. NA default colormap chosen. y_names optional (m)-dimensional character vector names components time-series/process. u_names optional (m)-dimensional character vector names orthogonalized shocks. parse_names boolean. TRUE series- shock- names parsed expression() plotting. See also grDevices::plotmath() usage expressions plot annotations. ... used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"plot routine returns (invisibly) function, subfig say, may used add additional graphic elements subfigures. call opar = subfig() creates new (sub) plot ()-th position suitable margins axis limits. See example .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.fevardec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Forecast Error Variance Decomposition — plot.fevardec","text":"","code":"# set seed for reproducible results set.seed(1995)  model = test_stspmod(dim = c(2,2), s = 3, bpoles = 1, bzeroes = 1) model$names = c('x[t]', 'y[t]')  # impulse response irf = impresp(model, lag.max = 11, H = 'eigen')  # forecast error variance decomposition fevd = fevardec(irf) # plot it subfig = plot(fevd, col = c('lightgray','darkgray'),               u_names = c('epsilon[t]', 'eta[t]'), parse_names = TRUE)  opar = subfig(1) graphics::text(x = 1, y = 0.5, 'EXAMPLE PLOT', col = 'blue', adj = c(0, 0.5))  graphics::par(opar)  # reset seed set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Methods — plot methods","title":"Plot Methods — plot methods","text":"Plot methods impulse response functions (impresp() objects), autocovariance functions (autocov() objects), frequency response functions (freqresp() objects) spectral densities (spectrald() objects).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Methods — plot methods","text":"","code":"# S3 method for class 'impresp' plot(   x,   x_list = NULL,   xlim = c(\"global\", \"column\", \"subfig\"),   ylim = c(\"row\", \"subfig\", \"global\"),   main = NA,   xlab = NA,   ylab = NULL,   subfigure_main = NA,   parse_subfigure_main = FALSE,   style = c(\"gray\", \"bw\", \"bw2\", \"colored\"),   col = NA,   type = \"l\",   lty = \"solid\",   lwd = 1,   pch = 16,   cex.points = 1,   bg.points = \"black\",   legend = NULL,   legend_args = NA,   ... )  # S3 method for class 'autocov' plot(   x,   x_list = NULL,   xlim = c(\"global\", \"column\", \"subfig\"),   ylim = c(\"row\", \"subfig\", \"global\"),   main = NA,   xlab = NA,   ylab = NULL,   subfigure_main = NA,   parse_subfigure_main = FALSE,   style = c(\"gray\", \"bw\", \"bw2\", \"colored\"),   col = NA,   type = \"l\",   lty = \"solid\",   lwd = 1,   pch = 16,   cex.points = 1,   bg.points = \"black\",   legend = NULL,   legend_args = NA,   ... )  # S3 method for class 'freqresp' plot(   x,   x_list = NULL,   sampling_rate = 1,   unit = \"\",   which = c(\"gain\", \"phase\", \"nyquist\"),   xlim = NA,   ylim = NA,   log = \"\",   main = NA,   xlab = NA,   ylab = NA,   subfigure_main = NA,   parse_subfigure_main = FALSE,   style = c(\"gray\", \"bw\", \"bw2\", \"colored\"),   col = NA,   type = \"l\",   lty = \"solid\",   lwd = 1,   pch = 16,   cex.points = 1,   bg.points = \"black\",   legend = NULL,   legend_args = NA,   ... )  # S3 method for class 'spectrald' plot(   x,   x_list = NULL,   sampling_rate = 1,   unit = \"\",   which = c(\"modulus\", \"phase\", \"coherence\"),   xlim = c(0, 0.5) * sampling_rate,   ylim = \"row\",   log = \"\",   main = NA,   xlab = NA,   ylab = NA,   subfigure_main = NA,   parse_subfigure_main = FALSE,   style = c(\"gray\", \"bw\", \"bw2\", \"colored\"),   col = NA,   type = \"l\",   lty = \"solid\",   lwd = 1,   pch = 16,   cex.points = 1,   bg.points = \"black\",   legend = NULL,   legend_args = NA,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Methods — plot methods","text":"x impresp(), autocov(), freqresp() spectrald()  object. x_list (optional) list additional objects (class \"x\"). xlim, ylim determine axis limits subfigures. E.g. xlim = 'column' means subfigures column use x-axis limits. Analogously y = 'row' implies subfigures row share limits y-axis.  \"freqresp\" \"spectrald\" plots parameter xlim may also numeric 2-dimensional vector xlim = c(x1,x2). case sub-figures use given limits x-axis. Furthermore limits y-axis computed based corresponding data subset. option may used \"zoom\" certain range frequencies. ... used. sampling_rate (number) sampling rate. unit (character string) time frequency unit. (character string) plot. parameter used plotting frequency response objects spectral densities. See details . log character string contains \"x\" x axis logarithmic, \"y\" y axis logarithmic \"xy\" \"yx\" axes logarithmic.  parameter used plotting frequency response objects spectral densities. Note logarithmic y-axis makes sense plotting moduli frequency response spectral density.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Methods — plot methods","text":"plot methods return (invisibly) \"closure()\", subfig say, may used add additional graphic elements subfigures. call opar = subfig(,j) creates new (sub) plot (,j)-th position suitable margins axis limits. See examples .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Methods — plot methods","text":"x \\((m,n)\\) dimensional object plot divided \\((m,n)\\) array subfigures. subfigures respective \\((,j)\\)-th element object x displayed. methods allow simultaneous plotting several objects, passing list x_list additional objects procedure. following assume x_list contains \\(k-1\\) objects, .e. total \\(k\\) objects plotted. parameter \"xlim\" determines x-limits subfigures: xlim='global' uses x-limits subfigures (limits determined data). case frequency response spectral density objects one may also pass two-dimensional vector xlim = c(x1,x2) plot method. case subfigures use values common x-limits. xlim='column' means sub figures \"column\" x-limits. limits determined data. Finally xlim='subfigure' means subfigure gets x-limits (determined data). Quite analogously parameter ylim determines limits y-axes. (Just replace 'column' 'row'). plot methods quite number optional design parameters. cases parameters interpreted follows. NA values mean methods use suitable defaults. E.g. labels x- y-axis chosen according class object(s) plotted parameter \"\". NULL values (optional) parameters mean respective graphic element omitted. E.g. subfigure_main = NULL skips titles subfigures. titles (m,n) subfigures determined parameter subfigure_main. One may pass \\((m,n)\\) character matrix scalar character (string) procedure. subfigure_main scalar (character string) procedures creates respective titles replacing \"place holders\" i_ j_ respective row column number. See examples . \"style\" parameters col, type, ..., bg.points determine appearance \"lines\" k objects. (necessary values \"recycled\".) See also graphics::lines() graphics::points() detailed explanation parameters. one object plotted (optional parameter x_list empty) suitable legend may added parameters legend legend_args. Note legend character (expression) vector length k. parameter \"\" determines plot case \"freqresp\" \"spectrald\" objects. gain,modulus plot moduli abs(x[,j]) versus frequencies. phase plot arguments Arg(x[,j]) versus frequencies. nyquist plot imaginary part Im(x[,j]) versus real part Re(x[,j]). coherence plot coherence. plot somewhat special. \"coherence matrix\" symmetric diagonal entries equal one (frequencies). Therefore entries diagonal contain additional information. reason subfigures diagonal display coherence, subfigures show \"scaled arguments\" Arg(x[,j])/(2*pi)+0.5 subfigures diagonal display scaled auto spectra \\(m\\) component processes. plot methods use internal helper function rationalmatrices::plot_3D().","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Methods — plot methods","text":"","code":"set.seed(1995)  # set seed to get reproducible results n.obs = 2^8 m = 2 s = 3  # generate a random, stable and minimum phase state space model # for a bivariate process (x[t], y[t]) model = test_stspmod(dim = c(m,m), s = s, bpoles = 1, bzeroes = 1) model$names = c('x[t]', 'y[t]')  # simulate data data = sim(model, n.obs = n.obs)  #### plot impulse response # overlay three different \"orthogonalization\" schemes plot(impresp(model), list(impresp(model, H = 'eigen'),                           impresp(model, H = 'chol')),      legend = c('none','chol','eigen'),      legend_args = list(title = 'orthogonalization', fill = NA, border = NA, bty = 'n'),      style = 'colored', ylim = 'subfig', xlab = NA)   #### plot partial autocorrelation function # overlay with the corresponding sample partial ACF  par(lend = 1) # in order to get a \"barplot\" plot(autocov(data$y, lag.max = 12, type = 'partial'),      list(autocov(model, lag.max = 12, type = 'partial')),      subfigure_main = 'delta[i_*j_](k)', parse_subfigure_main = TRUE,      style = 'bw', type = c('h','l'), pch = 19, lwd = c(15,2),      legend = c('sample', 'true'))  par(lend = 0) # reset 'lend=0'  # frequency response of the model n.f = 2^11 frr = freqresp(model, n.f = n.f)  #### plot \"gain\" subfig = plot(frr, which = 'gain',               sampling_rate = 60, unit = 'Hz',               ylim = 'row', log = 'y',               subfigure_main = 'k[i_*j_](lambda)', parse_subfigure_main = TRUE)  # mark the frequencies with the max gain! junk = unclass(frr$frr) i_max = apply(Mod(junk), MARGIN = c(1,2), FUN = which.max) f_max = matrix(60*((0:(n.f-1))/n.f)[i_max], nrow = 2, ncol = 2) for (i in (1:2)) {   for (j in (1:2)) {     subfig(i,j)     abline(v = f_max[i,j], col = 'steelblue')   } }   #### create a \"Nyquist\" plot of the frequency response plot(frr, which = 'nyquist',      xlim = 'subfig', ylim = 'subfig',      subfigure_main = 'k[i_*j_](lambda)', parse_subfigure_main = TRUE)    # compute spectral density spd = spectrald(model, n.f = 256)  #### plot the coherence # the subfigure above the diagonal shows the coherenec between # the two component proceses x[t] and y[t] # the sub figures on the diagonal show the scaled autospectra # of the two component processes x[t] and y[t]. # and the subfigure below the diagonal shows the # phase/argument of the cross spectral density between the # two component processes x[t] and y[t] plot(spd, sampling_rate = 60, unit=\"Hz\",      main = expression(spectral~density~~Gamma[i*j] == kappa[i*j]*exp(i*Phi[i*j])),      which = 'coherence',      style = 'bw')   # periodogram per = spectrald(data$y)  # smoothed periodogram sacf = autocov(data$y, lag.max = floor(sqrt(n.obs))) per2 = spectrald(sacf, n.f = 256)   #### make a plot of the absolute value of the spectral density, # of the periodogram and the smoothed periogram. # with a logarithmic y-axis # skip zero frequency, since the periodogram is zero at lambda=0 plot(spd, list(per, per2), sampling_rate = 12, unit = '/year', which = 'modulus',      log = 'y', xlim = c(1/n.obs, 0.5) * 12,  # skip zero frequency      legend = c('true','periodogram', 'smoothed per.'),      legend_args = list(bty = 'n', col = NA, lty = NA, pch = NA, lwd = 4),      style = 'colored', ylim = 'subfig',      subfigure_main = 'kappa[i_*j_] == group(\"|\", Gamma[i_*j_], \"|\")',      parse_subfigure_main = TRUE,      col = c('red', 'black', 'blue'), type = 'o', lty = c(1,0,1),      pch = c(NA, 19, NA), cex.points = 0.1)   set.seed(NULL) # reset seed"},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Forecasts — plot_prediction","title":"Plot Forecasts — plot_prediction","text":"function plot_prediction generates standard plots forecasts forecast errors.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Forecasts — plot_prediction","text":"","code":"plot_prediction(   pred,   which = c(\"prediction\", \"error\", \"cusum\", \"cusum2\", \"y0\", \"u0\"),   qu = stats::qnorm(0.95),   col = NULL,   lty = NULL,   style = c(\"gray\", \"colored\", \"bw\", \"bw2\"),   parse_names = FALSE,   plot = TRUE,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Forecasts — plot_prediction","text":"pred list true data forecasts, produced predict(). One may also add slot \"date\" numeric vector indices vector type Date POSIXct contains date/time values. (character string) selects type plot. qu (numeric scalar vector) determines width plotted confidence intervalls. entry NA equal zero confidence band plotted. col, lty optional (vectors ) colors line styles. style character string determines general style plot (background color, grid style, axis axis-labels colors, ...). See also style_parameters(). parse_names parse series names predictor names expression(). See grDevices::plotmath(). plot (boolean) produce plot just return \"closure\" produces plot. ... used","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Forecasts — plot_prediction","text":"plot=TRUE plot_prediction returns (invisibly) function, subfig(= 1) say, may used add additional graphic elements subfigures. call opar = subfig() creates new (sub) plot ()-th position suitable margins axis limits. output opar contains original graphics parameters, see graphics::par().  plot=FALSE function, plotfun(xlim = NULL) say, returned produces desired plot. optional parameter xlim = c(x1,x2) may used zoom certain time range. function plotfun returns  function/closure add graphical elements plot described .  See also examples .","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/plot_prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Forecasts — plot_prediction","text":"","code":"# set seed for random number generation, to get reproducable results set.seed(1609)  # generate a random state space model with three outputs and 4 states model = test_stspmod(dim = c(3,3), s = 4, bpoles = 1, bzeroes = 1)  # create a vector \"date\" with date/time info date = seq(as.POSIXct('2017-01-01'), by = 15*60, length.out = 768) n.obs = sum(date < as.POSIXct('2017-01-08')) n.ahead = length(date) - n.obs  # generate random data data = sim(model, n.obs = n.obs, s1 = NA)  # compute predictions pred = predict(model, data$y, h = c(1, 5), n.ahead = n.ahead) # add the date/time information to the list \"pred\" pred$date = date  # the default \"predictor names\" h=1, h=2, ... # don't look well, when plotted as expressions dimnames(pred$yhat)[[3]] = gsub('=','==',dimnames(pred$yhat)[[3]])  # generate some plots ####################  # a simple/compressed plot of the data p.y0 = plot_prediction(pred, which = 'y0', style = 'bw',                        parse_names = TRUE, plot = FALSE) # p.y0()  # a simple/compressed plot of the prediction errors plot_prediction(pred, which = 'u0', parse_names = TRUE)   # plot of the prediction errors (with 95% confidence intervalls) # plot_prediction(pred, which = 'error', qu = c(2,2,2), #                 parse_names = TRUE)  # plot of the true vales and the predicted values (+ 50% confidence region # for the 1-step ahead prediction and the \"out of sample\" predictions) p.y = plot_prediction(pred, qu = c(qnorm(0.75), NA, qnorm(0.75)),                       parse_names = TRUE, plot = FALSE) # subfig = p.y(xlim = date[c(n.obs-20, n.obs+20)]) # opar = subfig(1) # abline(v = mean(as.numeric(date[c(n.obs, n.obs+1)])), col = 'red') # mtext(paste(' example plot:', date()), side = 1, outer = TRUE, #       cex = 0.5, col = 'gray', adj = 0) # graphics::par(opar) # reset the graphical parameters  # CUSUM plot of the prediction errors # plot_prediction(pred, which = 'cusum', #                 style = 'gray', parse_names = TRUE)  # CUSUM2 plot of the prediction errors # plot_prediction(pred, which = 'cusum2', parse_names = TRUE)  set.seed(NULL) # reset seed  if (FALSE) { # \\dontrun{ # open a 'shiny-App' window, where we can zoom # into the plot with the prediction(s) require(shiny) zoom_plot(p.y, p.y0, 'Test zoom & scroll') } # }"},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Portmanteau Test for Serial Correlation — pm_test","title":"Portmanteau Test for Serial Correlation — pm_test","text":"Test whether residuals estimated model serially correlated. test statistic $$Q = N^2\\sum_{k=1}^{K} (N-k)^{-1}\\mbox{tr} (G_k G_0^{-1} G_k' G_0^{-1})$$ \\(G_k\\) sample covariances residuals. Null correctly specified estimated model test statistic asmyptotically Chi-squared distributed \\(Km^2-\\kappa\\) degrees freedom, \\(\\kappa\\) number (free) parameters model (class).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Portmanteau Test for Serial Correlation — pm_test","text":"","code":"pm_test(u, lag.max, n.par)"},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Portmanteau Test for Serial Correlation — pm_test","text":"u (N--m) matrix residuals (object may coerced matrix .matrix(u)). lag.max (integer) maximum number lags. n.par (integer) number parameters estimated model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Portmanteau Test for Serial Correlation — pm_test","text":"Matrix four columns (\"lags\" number lags, \"df\" degrees freedom, \"Q\" test statistics  \"p\" p values).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/pm_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Portmanteau Test for Serial Correlation — pm_test","text":"","code":"u = matrix(rnorm(100*3), nrow = 100, ncol = 3) pm_test(u, 4, 0) #>      lags        Q df         p #> [1,]    1  8.90583  9 0.4460120 #> [2,]    2 15.31458 18 0.6402657 #> [3,]    3 23.18377 27 0.6751013 #> [4,]    4 26.67290 36 0.8710157"},{"path":"https://bfunovits.github.io/RLDM/reference/poles_and_zeroes.html","id":null,"dir":"Reference","previous_headings":"","what":"Poles and Zeroes — poles and zeroes","title":"Poles and Zeroes — poles and zeroes","text":"Compute poles zeroes VARMA Statespace models. Note models describe corresponding processes $$x_t = k(B) u_t$$ \\((u_t)\\) white noise process \\(k(B)\\) rational filter (\\(B\\) denotes lag- backward shift operator). poles zeroes poles zeroes rational transfer function \\(k(z)\\) filter.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/poles_and_zeroes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poles and Zeroes — poles and zeroes","text":"","code":"# S3 method for class 'armamod' zeroes(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for class 'armamod' poles(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for class 'rmfdmod' zeroes(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for class 'rmfdmod' poles(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for class 'stspmod' zeroes(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)  # S3 method for class 'stspmod' poles(x, tol = sqrt(.Machine$double.eps), print_message = TRUE, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/poles_and_zeroes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poles and Zeroes — poles and zeroes","text":"x object represents VARMA, RMFD statespace model (.e. armamod(), rmfdmod() stspmod() object). tol Double. Default set sqrt(.Machine$double.eps). Required decide root considered \"infinity\". print_message Boolean. Default set TRUE. Prints message roots \"infinity \" discarded. ... used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/poles_and_zeroes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poles and Zeroes — poles and zeroes","text":"Vector poles, respectively zeroes.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Predictions — predict","title":"Model Predictions — predict","text":"Compute forecasts based VARMA state space model. procedure implements simplified approach. uses formulas prediction infinite past sets unknown initial values (prior \\(t < 1\\)) simply zero. simple approach assumes model stable strictly miniphase thus disturbances \\(u_t\\) innovations process. Note also forecasts known exogenous inputs calculated, .e. \"conditional forecasts\". honest prediction, forecasts exogenous inputs used.  forecast error covariance matrix computed assumes true model used. error stems estimation model taken account.  utility function evaluate_prediction may used assess quality predictions.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Predictions — predict","text":"","code":"# S3 method for class 'armamod' predict(object, y, h = 1, n.ahead = 0, ...)  # S3 method for class 'stspmod' predict(object, y, x, h = 1, n.ahead = 0, ...)  evaluate_prediction(   y,   yhat,   h,   criteria = list(\"RMSE\"),   benchmark = NULL,   samples = list(1:nrow(y)) )"},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Predictions — predict","text":"object rldm_varma rldm_ss object represents model. y \\((T,n)\\) matrix observed outputs (\\(y_t\\), \\(t=1,...,T\\)). h (integer) vector forecast horizons. n.ahead (integer) number time steps look ahead (sample). number also denoted \\(T_0\\). ... used. x \\((T+T_0,r)\\) matrix exogenous inputs (\\(x_t\\), \\(t=1,...,T+T_0\\)). input parameter ignored, model exogenous inputs. Note condition forecasts computed hence (model exogenous inputs) need values inputs time \\(t=T+T_0\\). yhat \\((T,n,l)\\) dimensional array forecasts. entries yhat[t,,] contain prediction \\(y_t\\). criteria list \"evaluation criteria\". See details. benchmark \\((T,n,l)\\) dimensional array \"benchmark\" forecasts. NULL naive (\\(h\\)-step ahead) forecasts used benchmark. samples list \"(sub) samples\". See details.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Predictions — predict","text":"function predict returns list components yhat \\((T,n,l)\\) dimensional array h-step ahead forecast. \\(T\\) sample size, \\(n\\) dimension outputs \\(y_t\\) \\(l\\) number forecasts made, .e. length vector h. entries yhat[t,,] h[]-step ahead forecast \\(y_t\\). sigmahat \\((n,n,l)\\) dimensional array, sigmahat[,,] contains theoretical covariance matrix \\(h\\)-step ahead prediction error h=h[]. h (integer) vector forecasts horizons considered. yhat.ahead \\((T_0,n)\\) dimensional matrix, contains \"--sample\" forecasts \\(t=T+1, t=T+2,...,t=T+T_0\\). sigmahat.ahead \\((n,n,T_0)\\) dimensional array, sigmahat.ahead[,,h] contains theoretical covariance matrix \\(h\\)-step ahead prediction error. y,x original data. function evaluate_prediction  returns 4-dimensional array dimensions refer evaluation criteria, (sub) samples, predictors components output \\(y_t\\). Note evaluation criteria applied (\\(n\\)) individual components well joint vector hence 4-th dimension array size \\(n+1\\). E.g. consider \"RMSE\" \"MAE\" forecast errors, two samples (training sample test sample), 5 forecast horizons \\(h=1,\\ldots,5\\) process \\((y_t)\\) 2 components, result \\((2,2,5,3)\\)-dimensional array.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Predictions — predict","text":"utility function evaluate_prediction may used asses quality given predictions. (E.g. computed predict). evaluation criteria used passed parameter criteria function. parameter list components either character strings (selection one implemented quality measures) user defined function. function takes three arguments fun(uhat, y, utilde) uhat matrix prediction errors, y matrix (corresponding) true values ytilde matrix predictions benchmark prediction procedures. allows compute relative error measures. benchmark predictions passed via parameter benchmark procedure. input parameter missing naive \\(h\\)-step ahead predictions used benchmark. (Therefore user also specify respective forecast horizons via paramater h.) following evaluation criteria implemented (\\(\\hat{y}_{}\\) denotes prediction error \\(y_{}\\) \\(\\tilde{u}_{}\\) corresponding error benchmark procedure.) MSE Mean Square Error RMSE Root Mean Square Error MAE Mean Absolute Error MdAE Median Absolute Error MAPE Mean Absolute Percentage Error \\(100 mean(|\\hat{u}_{}/y_{}|)\\) MdAPE Median Absolute Percentage Error \\(100 median(|\\hat{u}_{}/y_{}|)\\) RMdSPE Root Median Square Percentage Error \\(100 \\sqrt{median(\\hat{u}^2_{}/y^2_{})}\\) RelRMSE Relative Root Mean Square Error \\(\\sqrt{mean(\\hat{u}^2_{})}/\\sqrt{mean(\\tilde{u}^2_{})}\\) RelMAE Relative Mean Absolute Error \\(mean(|\\hat{u}_{}|)/mean(|\\tilde{u}^2_{}|)\\) PB Percentage better \\(mean(100 (|\\hat{u}_{}|< |\\tilde{u}_{}|))\\) HR Hit Rate \\(100 mean( ((\\tilde{u}_{} - \\hat{u}_{})\\tilde{u}_{} \\geq 0))\\). precise measure computes hit rate naive prediction benchmark. procedure also supports evaluation different (sub) samples. parameter samples simply list integer vectors, vector defines sub sample. E.g. daily data, one evaluate predictions different weekdays.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Predictions — predict","text":"","code":"# create a \"random\" ARMA(1,1) model (stable and miniphase) model = test_armamod(dim = c(2,2), degrees = c(1,1), bpoles = 1, bzeroes = 1)  # generate data (sample size n.obs = 200, \"burn_in\" phase has length 100.) data = sim(model, n.obs = 200, n.burn_in = 100)  # predict with true model pred_true = predict(model, data$y, h = c(1,5))  # estimate AR model, order selection by AIC n.train = 110   # use the first 110 observation for estimation n.test = 90     # the last 90 observations are used for (a fair) comparison model_ar = est_ar(data$y[1:n.train,],  mean_estimate = \"zero\",                   ic = 'AIC', method = 'ols')$model  # predict with AR model pred_ar = predict(model_ar, data$y, h = c(1,5))  # estimate AR1 model (Yule-Walker) model_ar1 = est_ar(data$y[1:n.train,],  mean_estimate = \"zero\",                   penalty = -1, p.max = 1, method = 'yule-walker')$model  # predict with AR1 model pred_ar1 = predict(model_ar1, data$y, h = c(1,5))  # evaluate prediction of the AR model (with the AR1 prediction as benchmark) stats = evaluate_prediction(data$y, pred_ar$yhat, h = pred_ar$h,                             criteria = list('RMSE', 'MAE', 'PB'),                             samples = list(train = 21:n.train, test = (n.train+1):(n.train+n.test)),                             benchmark = pred_ar1$yhat)  # use array2data.frame for \"tabular\" display of the results print(array2data.frame(stats, rows = 1:3, cols = 4)) #>    criterion sample predictor      y[1]        y[2]      total #> 1       RMSE  train       h=1  1.581590  0.02788022  1.1185268 #> 2        MAE  train       h=1  1.292886  0.02163501  0.6572603 #> 3         PB  train       h=1 51.111111 75.55555556 63.3333333 #> 4       RMSE   test       h=1  1.611489  0.02871524  1.1396757 #> 5        MAE   test       h=1  1.265299  0.02190208  0.6436004 #> 6         PB   test       h=1 45.555556 87.77777778 66.6666667 #> 7       RMSE  train       h=5  1.749987  0.50162780  1.2872618 #> 8        MAE  train       h=5  1.392897  0.40512846  0.8990125 #> 9         PB  train       h=5 52.222222 46.66666667 49.4444444 #> 10      RMSE   test       h=5  1.612239  0.50362675  1.1943520 #> 11       MAE   test       h=5  1.213223  0.40452278  0.8088731 #> 12        PB   test       h=5 44.444444 50.00000000 47.2222222  # evaluate all predictions # join predictions yhat  = dbind(3, pred_true$yhat, pred_ar1$yhat, pred_ar$yhat)  # define a function to compute the \"Median Relative Absolute Error\" MdRAE_ = function(u.hat, y, u.bench){    stats::median(abs(u.hat/u.bench), na.rm = TRUE) } stats = evaluate_prediction(data$y, yhat,                             h = c(pred_true$h, pred_ar1$h, pred_ar$h),                             criteria = list('RMSE', 'MAE', MdRAE = MdRAE_),                             samples = list(train = 21:n.train, test = (n.train+1):(n.train+n.test)))  # split prediction method and forecast horizon dimnames.stats = dimnames(stats) stats = stats[,,c(1,3,5,2,4,6),] dim(stats) = c(3,2,3,2,3) dimnames(stats) = list(criterion = dimnames.stats[[1]], sample = dimnames.stats[[2]],                       model = c('true','AR1','AR'), h = paste('h=',c(1,5),sep=''),                       data = dimnames.stats[[4]])  # use array2data.frame for \"tabular\" display of the results print(array2data.frame(stats, cols = 5, rows = c(3,4,1,2))) #>    model   h criterion sample      y[1]       y[2]     total #> 1   true h=1      RMSE  train 1.6934124 0.02952683 1.1976054 #> 2    AR1 h=1      RMSE  train 1.6932010 0.08461760 1.1987681 #> 3     AR h=1      RMSE  train 1.5815900 0.02788022 1.1185268 #> 4   true h=5      RMSE  train 1.8237975 0.52615332 1.3422136 #> 5    AR1 h=5      RMSE  train 1.8054364 0.51155715 1.3268933 #> 6     AR h=5      RMSE  train 1.7499873 0.50162780 1.2872618 #> 7   true h=1       MAE  train 1.3542487 0.02379324 0.6890210 #> 8    AR1 h=1       MAE  train 1.3396762 0.06517521 0.7024257 #> 9     AR h=1       MAE  train 1.2928857 0.02163501 0.6572603 #> 10  true h=5       MAE  train 1.4402109 0.43114789 0.9356794 #> 11   AR1 h=5       MAE  train 1.4176281 0.41286399 0.9152460 #> 12    AR h=5       MAE  train 1.3928966 0.40512846 0.8990125 #> 13  true h=1     MdRAE  train 0.6470609 0.05429154 0.2378054 #> 14   AR1 h=1     MdRAE  train 0.6079586 0.14506506 0.3293400 #> 15    AR h=1     MdRAE  train 0.6392057 0.05059007 0.2203919 #> 16  true h=5     MdRAE  train 0.8171496 0.98500188 0.8872385 #> 17   AR1 h=5     MdRAE  train 0.8191178 1.01087683 0.8861237 #> 18    AR h=5     MdRAE  train 0.8127587 0.94625998 0.8565500 #> 19  true h=1      RMSE   test 1.5292605 0.02802385 1.0815320 #> 20   AR1 h=1      RMSE   test 1.5527279 0.08241224 1.0994898 #> 21    AR h=1      RMSE   test 1.6114890 0.02871524 1.1396757 #> 22  true h=5      RMSE   test 1.5968055 0.48483869 1.1800119 #> 23   AR1 h=5      RMSE   test 1.5987971 0.49913896 1.1843335 #> 24    AR h=5      RMSE   test 1.6122387 0.50362675 1.1943520 #> 25  true h=1       MAE   test 1.1691349 0.02105252 0.5950937 #> 26   AR1 h=1       MAE   test 1.2020720 0.06628620 0.6341791 #> 27    AR h=1       MAE   test 1.2652987 0.02190208 0.6436004 #> 28  true h=5       MAE   test 1.1771857 0.39086052 0.7840231 #> 29   AR1 h=5       MAE   test 1.1854835 0.40537031 0.7954269 #> 30    AR h=5       MAE   test 1.2132234 0.40452278 0.8088731 #> 31  true h=1     MdRAE   test 0.6272284 0.04769589 0.1762662 #> 32   AR1 h=1     MdRAE   test 0.6488267 0.16345762 0.3293592 #> 33    AR h=1     MdRAE   test 0.7003001 0.05752692 0.2239963 #> 34  true h=5     MdRAE   test 0.7191348 0.62282870 0.6443024 #> 35   AR1 h=5     MdRAE   test 0.7371333 0.62450028 0.6636491 #> 36    AR h=5     MdRAE   test 0.6912901 0.65825976 0.6656079"},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Methods — print methods","title":"Print Methods — print methods","text":"Print Methods","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Methods — print methods","text":"","code":"# S3 method for class 'armamod' print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\", \"character\"),   ... )  # S3 method for class 'rmfdmod' print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\", \"character\"),   ... )  # S3 method for class 'stspmod' print(x, digits = NULL, ...)  # S3 method for class 'impresp' print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )  # S3 method for class 'autocov' print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )  # S3 method for class 'fevardec' print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )  # S3 method for class 'freqresp' print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )  # S3 method for class 'spectrald' print(   x,   digits = NULL,   format = c(\"i|jz\", \"i|zj\", \"iz|j\", \"zi|j\", \"i|j|z\"),   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Methods — print methods","text":"x RLDM object, .e. armamod(), rmfdmod(), stspmod(), impresp(), autocov(), freqresp(), spectrum() fevardec() object. digits (integer) non NULL correspondingly rounded numbers printed, see round(). format (character string) selects specific output formats. Note stsp() fevardec() objects format option. option 'character' implemented (V)ARMA models. ... parameters ignored.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Methods — print methods","text":"invisible(x)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/print.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Methods — print methods","text":"","code":"# for VARMA models six different print formats are implemented ################### m = armamod(test_lmfd(dim = c(2,2), degrees = c(1,1)), sigma_L = diag(2)) print(m, digits = 2, format = \"i|jz\") #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0     0.89 -0.82 #> [2,]        0     1    -1.12 -0.69 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]    -1.36 -1.75    -1.63  1.75 #> [2,]    -0.02  1.21    -0.42 -0.10 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a Random Model — r_model","title":"Generate a Random Model — r_model","text":"function may used generate random state space VARMA models. main argument model template, defines type model generate, see e.g. model structures(). bounds poles /zeroes given, procedure simply generates random models model satisfies constraint found. course crude method may need large number randomly generated model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a Random Model — r_model","text":"","code":"r_model(   template,   ntrials.max = 100,   bpoles = NULL,   bzeroes = NULL,   rand.gen = stats::rnorm,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a Random Model — r_model","text":"template model template computed e.g. model2template(). ntrials.max Maximum number trials. bpoles, bzeroes Lower bounds poles zeroes model (stability invertibility assumptions satisfied). set NA, corresponding test skipped. rand.gen (optional) function generate random, \"free\" parameters. ... Additional parameters, passed rand.gen. particular, \"free\" paramameters generated rnorm(), standard deviation sd may set. Choosing small values sd makes easier find stable miniphase model. course \"trick\" works reference model, obtained zero parameter vector, satisfies constraints.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a Random Model — r_model","text":"Model object whose class depends template.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/r_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a Random Model — r_model","text":"","code":"# Generate a random VARMA model in echelon form ############  # Compute the appropriate model template tmpl = tmpl_arma_echelon(nu = c(1,2,1))  # Create a random model, which is stable but not necessarily miniphase model = r_model(tmpl, bpoles = 1, sd = 0.5) model #> ARMA model [3,3] with orders p = 2 and q = 2 #> AR polynomial a(z): #>      z^0 [,1]      [,2]  [,3]   z^1 [,1]        [,2]       [,3]   z^2 [,1] #> [1,]        1 0.0000000     0 0.24097016  0.01663105 -0.1597946  0.0000000 #> [2,]        0 1.0000000     0 0.00000000 -0.31538394  0.0000000 -0.2758003 #> [3,]        0 0.2001581     1 0.05906883  0.35436034  0.4563334  0.0000000 #>           [,2]      [,3] #> [1,] 0.0000000 0.0000000 #> [2,] 0.1798877 0.1491349 #> [3,] 0.0000000 0.0000000 #> MA polynomial b(z): #>      z^0 [,1]      [,2]  [,3] z^1 [,1]       [,2]         [,3]  z^2 [,1] #> [1,]        1 0.0000000     0 1.034615 -0.9216181  0.265717438 0.0000000 #> [2,]        0 1.0000000     0 1.150798 -0.6000085 -0.007246912 0.2857984 #> [3,]        0 0.2001581     1 0.723430  0.8488433 -0.374071926 0.0000000 #>           [,2]      [,3] #> [1,] 0.0000000 0.0000000 #> [2,] 0.6305671 0.1034917 #> [3,] 0.0000000 0.0000000 #> Left square root of noise covariance Sigma: #>            u[1]       u[2]       u[3] #> u[1] -0.1662601  0.0000000  0.0000000 #> u[2]  0.5251204  0.6084734  0.0000000 #> u[3]  0.5476129 -0.4049386 -0.6795729  # Check whether the poles satisfy the constraint min(abs(poles(model))) #> There are determinantal roots at (or close to) infinity. #> Roots close to infinity got discarded. #> [1] 2.334861 min(abs(zeroes(model))) #> There are determinantal roots at (or close to) infinity. #> Roots close to infinity got discarded. #> [1] 0.8560205"},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Residuals of an ARMA system — residuals_ARMA_cpp","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"internal helper function computes residuals directional derivatives residuals ARMA system form $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + \\cdots + b_q u_{t-q}$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"","code":"residuals_ARMA_cpp(ib0, B1, A, t0, y, u, dU)"},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"ib0 \\((m, m)\\) matrix, inverse coefficient matrix \\(b[0]\\). B1 \\((m, mq)\\) matrix, \\(-b_0^{-1}(b_q,...,b_1)\\). \\((m, n(q+1))\\) matrix \\(b_0^{-1}(a_0,...,a_p\\). t0 integer, start iteration t = t0. y \\((m, N)\\) matrix observed outputs \\((y_1,...,y_N\\). u \\((m, N)\\) matrix. matrix overwritten computed residuals \\((u_1,...,u_N\\). dU \\((mN, m^2(p+q+2))\\) matrix empty matrix. non empty matrix overwritten directional derivatives vectorized residuals. \\(j\\)-th column dU derivative \\(vec(u)\\) respect \\(j\\)-th entry \\(\\mathrm{vec}(a_0,a_1,\\ldots,a_p,b_0,\\ldots,b_q)\\)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"RcppArmadillo routine returns NULL overwrites input arguments u (dU)!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitly set zero. However, starting iteration \\(t_0>1\\) can enforce non-zero initial values.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"Use procedure care! procedure check input arguments. require \\(m = n > 0\\), \\(p,q \\geq 0\\) \\(1 \\leq t_0 \\leq N\\). procedure overwrites input argument u (dU). data matrices organized columnwise (avoid memory shuffling)! Note also non standard representation coefficient matrices.","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_ARMA_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Residuals of an ARMA system — residuals_ARMA_cpp","text":"","code":"# generate a random ARMA(2,1) model (3 outputs, 2 inputs) p = 2 q = 1 m = 2 model = test_armamod(dim = c(m, m), degrees = c(p,q), digits = 2)  # prepare parameters for \"outputs_ARMA_cpp\" A = unclass(model$sys$a) a0 = A[,,1] A1 = -A[,,(p+1):2] dim(A1) = c(m, m*p) A1 = solve(a0, A1)  B = unclass(model$sys$b) dim(B) = c(m, m*(q+1)) B = solve(a0, B)  # generate random noise sequence (sample size N = 10) n.obs = 10 u = matrix(rnorm(n.obs*m), nrow = m, ncol = n.obs)  # generate matrix for the outputs y = matrix(0, nrow = m, ncol = n.obs)  # compute outputs t0 = 2   # start iterations from t>=t0=2 outputs_ARMA_cpp(A1, B, t0, u, y)  # recompute the disturbances/residuals from the given outputs: B = unclass(model$sys$b) ib0 = B[,,1] B1 = -B[,,(q+1):2] dim(B1) = c(m, m*q) B1 = solve(ib0, B1)  A = unclass(model$sys$a) dim(A) = c(m, m*(p+1)) A = solve(ib0, A)  ib0 = solve(ib0)  uu = u + 0 # \"deep copy\" of the disturbances uu[, t0:(n.obs)] = 0 # clear values for t >= t0 residuals_ARMA_cpp(ib0, B1, A, t0 = 2, y, uu, diag(0)) all.equal(u, uu) # check #> [1] TRUE  # compute directional derivatives of residuals dU = matrix(0, nrow = n.obs*m, ncol = (m^2)*(p+q+2)) residuals_ARMA_cpp(ib0, B1, A, t0 = 2, y, uu, dU)"},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Residuals of a statespace system — residuals_STSP_cpp","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"internal helper function computes residuals (directional derivatives residuals) statespace system form $$a_{t+1} = a_t + B u_t, \\; y_t = C a_t + D u_t$$ system must square non-empty, .e. \\(m=n>0\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"","code":"residuals_STSP_cpp(A, B, C, D, y, a, u, dPI, dU)"},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"\\((s,s)\\) matrix. B \\((s,m)\\) matrix. C \\((m,s)\\) matrix. D \\((m,m)\\) matrix, must regular. y \\((m,N)\\) matrix outputs: \\((y_1,y_2,\\ldots,y_N)\\). \\((s,N+1)\\) matrix. matrix overwritten (computed) states: \\((a_1,a_2,\\ldots,a_N,a_{N+1})\\). input [,1] must hold initial state \\(a_1\\). u \\((m,N)\\) matrix. matrix overwritten (computed) residuals: \\((u_1,u_2,\\ldots,u_N)\\). dPI \\(((m+s)^2,K)\\) matrix. dU \\((mN,K)\\) matrix \\((0,0)\\) matrix. matrix overwritten directional derivatives residuals. However, matrix empty derivatives computed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"RcppArmadillo implementation returns NULL overwrites input arguments , u dU!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"Use procedure care! procedure check input arguments. procedure overwrites input arguments , u dU. data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/residuals_STSP_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Residuals of a statespace system — residuals_STSP_cpp","text":"","code":"# generate a random statespace model (3 outputs, 3 inputs and 4 states) m = 2 s = 3 model = test_stspmod(dim = c(m, m), s = s, digits = 2)  # generate random noise sequence (sample size N = 10) n.obs = 10 u = matrix(rnorm(n.obs*m), nrow = m, ncol = n.obs)  # generate matrix for the state sequence a = matrix(0, nrow = s, ncol = n.obs+1) a[,1] = rnorm(s) # random initial state a[1]  # generate matrix for the outputs y = matrix(0, nrow = m, ncol = n.obs)  # compute outputs and states outputs_STSP_cpp(model$sys$A, model$sys$B, model$sys$C, model$sys$D, u, a, y)  # recompute the states and disturbances/residuals from the given outputs: uu = u + 0 # \"deep copy\" of the disturbances aa = a + 0 # and the states aa[, 2:(n.obs+1)] = 0 # clear all states a[t], t > 1 residuals_STSP_cpp(model$sys$A, model$sys$B, model$sys$C, model$sys$D,                    y, aa, uu, diag(0), diag(0)) all.equal(u, uu) # check #> [1] TRUE all.equal(a, aa) # check #> [1] TRUE  # compute directional derivatives of residuals dPI = diag((m+s)^2) dU = matrix(0, nrow = n.obs*m, ncol = ncol(dPI)) residuals_STSP_cpp(model$sys$A, model$sys$B, model$sys$C, model$sys$D,                    y, aa, uu, dPI, dU)  # check the directional derivatives eps = 1e-8 dU_num = matrix(0, nrow = m*n.obs, ncol = (m+s)^2) dPI = matrix(0, nrow = (m+s), ncol = (m+s)) for (k in (1:((m+s)^2))) {   dPI[] = 0   dPI[k] = eps   uu = u + 0 # \"deep copy\" of the disturbances   aa = a + 0 # and the states   residuals_STSP_cpp(model$sys$A + dPI[1:s,1:s],                      model$sys$B + dPI[1:s,(s+1):(s+m)],                      model$sys$C + dPI[(s+1):(s+m),1:s],                      model$sys$D + dPI[(s+1):(s+m),(s+1):(s+m)],                      y, aa, uu, diag(0), diag(0))   dU_num[, k] = c(uu - u )/eps  # num. approx. of the derivative in direction \"dPI\" } # relative error of the numerical approximation junk = (abs(dU)+abs(dU_num)) junk[junk == 0] = 1 2*abs(dU_num - dU)/junk #>               [,1]         [,2]         [,3]         [,4]         [,5] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 3.539123e-11 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.539123e-11 #>  [3,] 9.271545e-08 1.475098e-08 2.170907e-07 1.108795e-07 9.080888e-09 #>  [4,] 1.222304e-06 4.254935e-08 1.295921e-07 8.160470e-08 5.821469e-08 #>  [5,] 3.580341e-07 1.394300e-07 1.130386e-07 2.328873e-07 2.771399e-07 #>  [6,] 1.520322e-06 2.569418e-09 8.779160e-08 6.356559e-08 1.415965e-07 #>  [7,] 1.485957e-07 3.158238e-07 2.668712e-07 5.540776e-10 5.333695e-08 #>  [8,] 4.814363e-07 4.438798e-08 1.524144e-07 1.154069e-07 7.112715e-08 #>  [9,] 1.051356e-07 6.948119e-08 2.958370e-07 2.473956e-08 1.603950e-07 #> [10,] 2.865098e-08 2.678232e-07 1.892716e-07 7.129843e-07 5.105203e-08 #> [11,] 3.304802e-07 2.234660e-07 1.446996e-07 2.282665e-08 2.810666e-08 #> [12,] 9.712362e-07 1.075640e-07 3.722035e-06 9.948874e-09 1.132505e-07 #> [13,] 1.009672e-07 4.824878e-07 6.600101e-08 9.771811e-09 8.105989e-08 #> [14,] 3.164795e-07 1.912975e-06 9.621592e-07 2.354486e-06 3.611797e-08 #> [15,] 3.930023e-07 1.092518e-07 3.954097e-07 2.798584e-07 1.457090e-09 #> [16,] 5.741859e-07 4.761899e-07 1.834419e-06 7.070846e-07 8.253886e-07 #> [17,] 1.027980e-06 2.677483e-05 2.531114e-07 1.810991e-07 9.607898e-07 #> [18,] 3.743842e-06 1.574752e-07 3.047850e-08 3.956977e-07 9.220477e-08 #> [19,] 2.713116e-08 6.359518e-07 2.438524e-06 4.635316e-07 1.530584e-07 #> [20,] 1.662677e-06 6.111871e-07 8.140541e-07 7.344509e-07 1.129148e-06 #>               [,6]         [,7]         [,8]         [,9]        [,10] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 1.866027e-08 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.921910e-08 #>  [3,] 4.814591e-08 3.101647e-08 1.984627e-07 9.228377e-09 2.344545e-08 #>  [4,] 1.136101e-06 3.002408e-08 1.265440e-07 2.959716e-08 4.569787e-08 #>  [5,] 1.507067e-07 8.339649e-08 7.333008e-08 1.969406e-08 5.093333e-08 #>  [6,] 9.250020e-08 1.884521e-08 4.584914e-09 5.481872e-09 9.722425e-09 #>  [7,] 7.434066e-09 2.942299e-09 4.403511e-09 9.052865e-09 3.448199e-08 #>  [8,] 4.470846e-07 1.791174e-08 2.469904e-08 5.918884e-09 3.906170e-08 #>  [9,] 1.169560e-09 8.591558e-08 1.086511e-08 8.822512e-09 2.517854e-08 #> [10,] 1.046609e-07 3.427066e-08 1.098287e-08 9.808491e-09 3.608004e-08 #> [11,] 5.133852e-08 8.654159e-08 5.139415e-08 2.949290e-08 3.218333e-08 #> [12,] 1.854763e-08 3.935641e-08 9.045052e-09 1.702129e-08 1.220973e-08 #> [13,] 3.135439e-08 3.938882e-08 7.474015e-08 6.514208e-09 3.278134e-08 #> [14,] 2.511903e-07 9.311619e-09 1.984626e-08 2.505397e-08 7.876682e-08 #> [15,] 1.466685e-08 8.590687e-08 5.137938e-08 1.299977e-08 2.454514e-08 #> [16,] 3.350457e-07 1.720098e-10 3.298758e-08 1.037292e-08 2.285369e-08 #> [17,] 2.443962e-08 2.019015e-08 5.146781e-08 8.969537e-09 5.421068e-08 #> [18,] 5.297140e-08 2.996221e-08 1.338090e-08 3.250788e-08 1.199714e-08 #> [19,] 2.017288e-08 2.253046e-08 2.637356e-08 9.574674e-09 1.033680e-08 #> [20,] 2.830408e-07 3.184994e-08 5.999948e-08 5.271886e-08 3.798645e-08 #>              [,11]        [,12]        [,13]        [,14]        [,15] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 1.804277e-08 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.804277e-08 #>  [3,] 8.897281e-08 1.049453e-07 1.247306e-08 1.219940e-07 6.254397e-08 #>  [4,] 2.496383e-06 8.503293e-08 1.809113e-07 6.889618e-08 1.319117e-06 #>  [5,] 8.366543e-07 1.007178e-06 1.606254e-07 1.101220e-06 3.111178e-05 #>  [6,] 1.104504e-06 8.382899e-08 8.603361e-08 1.694161e-07 4.183553e-07 #>  [7,] 6.745299e-07 2.338120e-07 3.980898e-07 2.023761e-08 6.761233e-08 #>  [8,] 1.145941e-06 3.753377e-07 3.409140e-07 4.253644e-07 9.469227e-08 #>  [9,] 1.029409e-07 5.063525e-08 4.228585e-07 2.616068e-08 7.987357e-08 #> [10,] 1.264637e-06 4.617074e-08 2.685786e-07 5.774424e-08 2.490763e-08 #> [11,] 2.885239e-07 1.249883e-07 2.302225e-07 4.586764e-07 3.651409e-08 #> [12,] 1.184225e-06 3.154263e-08 1.524328e-07 2.863893e-08 1.242265e-06 #> [13,] 7.025556e-07 6.162769e-07 1.140161e-07 6.886399e-08 1.920368e-07 #> [14,] 9.188629e-07 4.188185e-09 2.784730e-07 2.083320e-07 1.616494e-07 #> [15,] 2.087436e-07 3.847606e-08 2.142563e-07 4.529135e-08 9.664082e-08 #> [16,] 6.389605e-07 9.009719e-08 2.707680e-07 2.858368e-07 9.542442e-07 #> [17,] 1.002654e-06 1.973819e-06 3.452643e-07 1.541856e-07 4.393807e-07 #> [18,] 4.531135e-07 1.148982e-07 2.189085e-07 2.666217e-08 3.616405e-08 #> [19,] 2.959542e-07 9.496835e-08 2.509351e-07 2.208704e-07 9.632206e-08 #> [20,] 1.551630e-06 3.076706e-07 6.749534e-07 3.945037e-07 5.152125e-07 #>              [,16]        [,17]        [,18]        [,19]        [,20] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 1.852913e-08 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.034849e-09 #>  [3,] 7.484641e-08 9.127449e-09 1.672122e-07 2.882179e-08 8.745737e-09 #>  [4,] 1.978964e-06 4.320591e-08 1.753598e-07 1.041411e-07 1.868496e-07 #>  [5,] 4.932044e-07 1.320882e-06 9.772636e-08 2.778196e-07 4.158722e-07 #>  [6,] 1.835297e-06 4.445854e-08 3.619274e-08 7.497472e-08 9.876125e-08 #>  [7,] 2.850728e-08 1.141324e-07 3.594570e-10 5.290737e-08 6.236537e-08 #>  [8,] 3.123198e-07 2.519447e-07 1.492429e-07 4.103750e-07 1.145940e-06 #>  [9,] 4.581291e-07 2.115134e-07 8.784805e-05 4.124625e-08 4.286420e-08 #> [10,] 1.433182e-07 6.717882e-05 2.628002e-07 1.415223e-06 7.267614e-07 #> [11,] 7.147772e-06 1.861006e-06 6.612250e-07 7.869246e-07 9.033520e-06 #> [12,] 4.356749e-06 1.051435e-06 7.223923e-06 2.717371e-07 9.275316e-07 #> [13,] 6.904849e-07 2.295236e-08 1.762178e-06 5.331568e-07 1.893998e-07 #> [14,] 2.050053e-08 6.615831e-07 2.163386e-06 3.987112e-07 1.567312e-07 #> [15,] 2.018946e-06 4.923921e-07 5.318629e-08 2.275570e-06 1.061980e-06 #> [16,] 2.737082e-06 2.385166e-06 2.253986e-06 1.393739e-06 3.883465e-07 #> [17,] 3.220067e-07 7.688024e-07 2.824648e-06 8.014961e-06 3.382005e-06 #> [18,] 1.211786e-05 2.889050e-05 1.834763e-06 9.555796e-06 1.435613e-06 #> [19,] 4.279066e-07 1.362312e-06 4.238437e-06 4.850393e-06 2.165238e-06 #> [20,] 1.438408e-04 3.156808e-06 4.704458e-05 1.429157e-05 1.670327e-04 #>              [,21]        [,22]        [,23]        [,24]        [,25] #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 6.756948e-09 0.000000e+00 #>  [2,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.274011e-08 #>  [3,] 5.253348e-08 1.819712e-08 3.518909e-07 1.382927e-08 3.395437e-08 #>  [4,] 2.512061e-06 6.520936e-08 2.295098e-07 3.481519e-08 2.570054e-09 #>  [5,] 7.721357e-07 4.724670e-07 5.745153e-08 5.997662e-08 8.945064e-08 #>  [6,] 1.442825e-06 7.639200e-08 8.161731e-09 1.235278e-07 4.368609e-08 #>  [7,] 1.437249e-07 3.696277e-08 4.099080e-06 1.131123e-08 1.607805e-08 #>  [8,] 1.078506e-06 3.497617e-08 4.182280e-07 6.915019e-07 9.789639e-08 #>  [9,] 7.675484e-08 2.148120e-06 1.841685e-07 2.342044e-07 1.713009e-08 #> [10,] 2.781496e-07 1.550404e-07 1.913979e-07 4.821868e-07 5.690571e-07 #> [11,] 4.030265e-07 1.364649e-05 8.662905e-07 1.094429e-07 3.019317e-07 #> [12,] 2.853635e-07 1.035722e-06 1.248195e-06 1.539139e-06 6.531209e-05 #> [13,] 7.154630e-07 5.056973e-07 5.720648e-07 2.512433e-07 3.997466e-07 #> [14,] 3.192322e-05 2.655662e-06 1.133153e-06 3.501194e-08 3.177518e-07 #> [15,] 1.223599e-06 6.173064e-06 2.565832e-06 6.535432e-07 4.366864e-07 #> [16,] 3.703150e-06 1.202635e-06 3.023286e-06 2.069073e-06 1.571834e-06 #> [17,] 1.541322e-06 4.207910e-06 4.695087e-06 3.073141e-06 2.627747e-06 #> [18,] 1.312804e-05 4.408733e-07 2.154293e-06 1.539842e-06 5.671674e-06 #> [19,] 3.603971e-07 1.902746e-05 8.123247e-07 4.094441e-06 2.209542e-07 #> [20,] 1.423707e-05 8.069586e-05 2.440665e-05 2.871509e-04 6.877259e-06"},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve a discrete time, algebraic Riccati equation — riccati","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"function solves discrete time, algebraic Riccati equation $$X = AXA' + (M -AXC')(G-CXC')^{-1}(M-AXC')'$$ square (s--s) matrix, M C' matrices dimension (s--m) G square (positive definite) matrix dimension (m--m). Given certain regularity conditions (see discussion ) solution X computed riccati positive definite matrix (size (s--s)).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"","code":"riccati(A, M, C, G, only.X = TRUE)"},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"(s--s) matrix M (s--m) matrix C (m--s) matrix G (m--m) matrix .X boolean","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"(.X) TRUE riccati just returns solution X, otherwise list slots X solution Ricatti equation B matrix \\(B = (M- AXC')\\Sigma^{-1}\\) sigma matrix \\(\\Sigma=G-CXC'\\) lambda (2m) vector eigenvalues associated generalized eigenvalue problem. first \\(m\\) entries eigenvalues \\(-BC\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"(within package) function mainly used construct state space model given autocovariance function process \\((y_t)\\) rational spectral density. ACF represented four matrices (,M,C,G) \\(\\gamma(0)=G\\) \\(\\gamma(k) = CA^{k-1}M\\) \\(k>0\\). realization problem related called spectral factorization problem. matrix \\(\\) stable, pair \\((,C)\\) controllable, pair \\((,M)\\) controllable (.e. (,M,C,G) \"minimal\" realization ACF) spectral density positive definite (.e. zeros) Riccati equation (unique) solution \\(X\\) positive definite matrix \\(- (M-AXC')(G-CXC')^{-1}C\\) stable. process  \\((y_t)\\) state space representation parameters \\((,B,C,D=)\\), \\(B=(M-AXC')\\Sigma^{-1}\\) \\(\\Sigma=(G-CXC')\\) innovation covariance. solution computed via (2m--2m) dimensional generalized eigenvalue problem, turn solved QZ decomposition. See QZ::qz.dgges() QZ::qz.dtgsen(). eigenvalues modulus less one eigenvalues matrix \\(-BC\\). addition riccati also used compute stochastically balanced realization state space model, see rationalmatrices::grammians() rationalmatrices::balance(). Note function mainly used utility function therefore checks given input parameters performed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/riccati.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve a discrete time, algebraic Riccati equation — riccati","text":"","code":"# create a \"random\" state space model, which satisfies the # stability and the (strict) miniphase assumption m = 2 # number of outputs s = 4 # number of states  model = r_model(template = tmpl_stsp_full(m, m, s),                 bpoles = 1, bzeroes = 1, sd = 0.25) # scale sigma model$sigma_L = model$sigma_L / sqrt(sum(diag(model$sigma_L %*% t(model$sigma_L))))  # extract the model parameter matrices A = model$sys$A B = model$sys$B C = model$sys$C sigma = model$sigma_L %*% t(model$sigma_L)  # compute the variance of the state P = A P A' + B sigma B' P = lyapunov(A, B %*% sigma %*% t(B))  # variance of the output y[t]: G = C P C' + sigma G = C %*% P %*% t(C) + sigma # covariance between s[t+1] and y[t]: M = A P C' + B sigma M = A %*% P %*% t(C) + B %*% sigma  # check that P solves the Riccati equation P = APA' + (M -APC')(G-CPC')^{-1}(M-APC')' all.equal(P,           A %*% P %*% t(A) +             (M - A %*% P %*% t(C)) %*% solve(G - C%*% P %*% t(C), t(M - A %*% P %*% t(C)))) #> [1] TRUE  # compute P from the Riccati equation: P = APA' + (M -APC')(G-CPC')^{-1}(M-APC')' out = riccati(A, M, C, G, only.X=FALSE)  # check the solution all.equal(P, out$X) #> [1] TRUE all.equal(B, out$B) #> [1] TRUE all.equal(sigma, out$sigma) #> [1] TRUE  # eigenvalues of (A-BC) ( <=> reciprocals of the zeroes of the system) lambda = eigen(A - B %*% C, only.values=TRUE)$values all.equal(sort(lambda), sort(out$lambda[1:s])) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/rls_exp_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"(Multivariate) Recursive Least Squares — rls_exp_cpp","title":"(Multivariate) Recursive Least Squares — rls_exp_cpp","text":"function implements Recursive Least Squares (RLS) algorithm exponentially -weighted past fixed window size. allows multivariate regressions, .e. multiple left-hand-side variables y. However, algorithm formulated regressors individual component LHS variable, .e. $$Y = XB + U$$ Y U \\((T \\times n_{y})\\) dimensional, X \\((T \\times n_{x})\\) dimensional, B \\((n_{x} \\times n_{y})\\) dimensional, VAR(p) context endogenous variable y n-dimensional, corresponds dimensions \\((T \\times n)\\), \\((T \\times n p)\\), \\(( n p \\times n)\\) Y, X, B respectively. fact use regressors component LHS simplifies updating formula RLS bit.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rls_exp_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Multivariate) Recursive Least Squares — rls_exp_cpp","text":"","code":"rls_exp_cpp(Y, X, r, n_init, allow_neg = TRUE, debug_flag = FALSE)  rls_window_cpp(Y, X, ws, allow_neg = TRUE, debug_flag = FALSE)"},{"path":"https://bfunovits.github.io/RLDM/reference/rls_exp_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Multivariate) Recursive Least Squares — rls_exp_cpp","text":"Y, X Matrices doubles. Left-hand-side right-hand-side variables possibly multivariate regression. number rows corresponds number observations r Matrix doubles dimension \\((n_{r} \\times 1)\\). Contains forgetting factors. Note observation weight (.e. different components ) n_init Integer. Number observations used initial estimate regression coefficients. Default set twice number regressors X. Note forecasts forecast errors produced initial estimate. allow_neg Boolean. Default set true. false, negative forecasts allowed set zero. debug_flag Boolean. Default set false. true, output printed console. ws Integer. Fixed number observation used calculate estimates. Number observations used initial estimate regression coefficients.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rls_exp_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Multivariate) Recursive Least Squares — rls_exp_cpp","text":"List containing y_pred: Cube doubles dimension \\((n_{obs} \\times n_y \\times n_{r})\\). Contains (one-step-ahead) predictions forgetting factors. case windowed RLS, third dimension (containing forgetting factors) discarded (output matrix). fe_honest: Cube doubles dimension \\((n_{obs} \\times n_y \\times n_{r})\\). Contains (one-step-ahead) forecast errors forgetting factors. case windowed RLS, third dimension (containing forgetting factors) discarded (output matrix).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rls_exp_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"(Multivariate) Recursive Least Squares — rls_exp_cpp","text":"Inputs checked, done within R calling function. main reference Chapter 4 Young (2012).","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor for RMFD Models — rmfdmod","text":"","code":"rmfdmod(sys, sigma_L = NULL, names = NULL, label = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor for RMFD Models — rmfdmod","text":"sys rationalmatrices::rmfd() object sigma_L Left-factor noise covariance, .e. covariance \\(\\sigma\\) obtained sigma_L * t(sigma_L). sigma_L vector dimension \\(n\\), \\(n\\) input dimension, diagonal elements parametrized. vector dimension \\(n^2\\), elements sigma_L filled column column. names optional vector character strings label optional character string","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor for RMFD Models — rmfdmod","text":"Object class rmfdmod.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Constructor for RMFD Models — rmfdmod","text":"right-matrix fraction description (RMFD) plus parameterisation noise covariance. (Hannan Deistler 2012) , RMFDs also called dynamic adjustment forms. Internally, MFDs lists slots sys, sigma_L, names, label. Many generic functions construct derived objects like autocovariance autocov() yet implemented rmfdmod objects.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Constructor for RMFD Models — rmfdmod","text":"Hannan EJ, Deistler M (2012). Statistical Theory Linear Systems,  Classics Applied Mathematics. SIAM, Philadelphia. Originally published: John Wiley & Sons, New York, 1988.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/rmfdmod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructor for RMFD Models — rmfdmod","text":"","code":"y = rmfdmod(sys = test_rmfd(dim = c(3,2), degrees = c(2,2))) y #> RMFD model [3,2] with orders p = 2 and q = 2 #> right factor polynomial c(z): #>      z^0 [,1]  [,2]   z^1 [,1]      [,2]  z^2 [,1]      [,2] #> [1,]        1     0 -0.5349281 1.5632988 0.8315751 1.2387464 #> [2,]        0     1  2.0605885 0.7144591 1.5079436 0.1634034 #> left factor polynomial d(z): #>        z^0 [,1]       [,2]   z^1 [,1]       [,2]   z^2 [,1]       [,2] #> [1,]  0.8804698 -0.3063182 -0.2733697 -0.1739394 -1.9072101 -1.6174181 #> [2,] -0.7263570  0.9326638  1.2064370  1.3499435  0.4256843  0.3100937 #> [3,]  0.4788533  1.9304179  1.0867108 -0.6818069  1.0034773  0.7847326 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from a State Space or VARMA Model — sim","title":"Simulate from a State Space or VARMA Model — sim","text":"Generate time series given process model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from a State Space or VARMA Model — sim","text":"","code":"sim(model, n.obs, rand.gen, n.burnin, ...)  # S3 method for class 'armamod' sim(model, n.obs, rand.gen = stats::rnorm, n.burnin = 0, ...)  # S3 method for class 'stspmod' sim(model, n.obs, rand.gen = stats::rnorm, n.burnin = 0, a1 = NULL, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from a State Space or VARMA Model — sim","text":"model either armamod() stspmod() object. n.obs sample size (\\(N\\)). rand.gen (optional) function generate disturbances \\(u_t\\). Note rand.gen() generate iid sample random variable mean zero variance one. n.burnin length initial \"burn-\" phase (denoted \\(N_0\\)). ... used. a1 (otional) vector initial state (start \"burn--phase\"). default a1 = NULL means zero initial state used. a1 = NA random initial state according state covariance generated. rand.gen used. model stable covariance defined procedure break .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from a State Space or VARMA Model — sim","text":"List slots y \\((N,m)\\) matrix generated outputs. u \\((N,n)\\) matrix noise. \\((N+1,s)\\) matrix generated states (\\(a_t\\), \\(t=1,...,N+1\\)). Note matrix (\\(N+1\\)) rows! slot present state space models.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate from a State Space or VARMA Model — sim","text":"order generate \"stationary\" trajectory (stable model) one chose suitable initial starting values. quite easy, particular VARMA models. simple remedy, procedure offers option \"burn-\" phase. length phase chosen user. state space model, value state first time point may passed procedure parameter a1. a1 = NULL (default value) zero vector used. a1 = NA random initial state according state covariance generated. model stable, covariance defined procedure break . rand.gen used. user like control disturbances initial values, solve_de() may used.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from a State Space or VARMA Model — sim","text":"","code":"# Random Walk ############################################################################ model = armamod(lmfd(a = c(1,-1), b = 1)) # generate outputs \"y\" n.obs = 100 data = sim(model, n.obs = n.obs, y0 = 1) plot(data$y, type = 'l')   # bivariate ARMA(2,1) model ############################################################## model = test_armamod(dim = c(2,2), degrees = c(2,1), bpoles = 1, bzeroes = 1) # generate outputs \"y\" with zero initial conditions n.obs = 50 data =  sim(model, n.obs = n.obs) # reconstruct noise \"u\" from given outputs \"y\" data1 = solve_inverse_de(model$sys, y = data$y) all.equal(data$u, data1$u) #> [1] TRUE  # bivariate state space model with 5 states ############################################## model = test_stspmod(dim = c(2,2), s = 5, bpoles = 1, bzeroes = 1) # generate outputs \"y\" with random initial state a[1] n.obs = 50 data =  sim(model, n.obs = n.obs, a1 = NA) # reconstruct noise \"u\" from given outputs \"y\" data1 = solve_inverse_de(model$sys, y = data$y, a1 = data$a[1,]) all.equal(data$u, data1$u) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve ARMA system — solve_ARMA","title":"Solve ARMA system — solve_ARMA","text":"Compute outputs ARMA(p, q) systems form $$y_t = a_1 y_{t-1} + ... + a_p y_{t-p} + b_0 u_t + \\cdots + b_q u_{t-q}$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve ARMA system — solve_ARMA","text":"","code":"solve_ARMA_R(a, b, u, y, t0)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve ARMA system — solve_ARMA","text":"\\((m, mp)\\) matrix \\((a_p,...,a_1)\\). b \\((m, n(q+1))\\) matrix \\((b_0,...,b_q\\). u \\((n, N)\\) matrix inputs \\((u_1,...,u_N\\). y \\((m, N)\\) matrix outputs \\((y_1,...,y_N\\). t0 integer, start iteration t=t0.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve ARMA system — solve_ARMA","text":"R implementation solve_ARMA_R returns matrix y computed outputs. RcppArmadillo implementation returns NULL overwrites input argument y!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_ARMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve ARMA system — solve_ARMA","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitly set zero. However, start iteration \\(t_0>1\\) can enforce non-zero initial values. routines used internally hence check arguments. require \\(m > 0\\), \\(p \\geq 0\\), \\(n \\geq 0\\), \\((q+1) \\geq 0\\) \\(1 \\leq t_0 \\leq N\\). Note also RcppArmadillo implementation overwrites input argument y. Use procedure care! Note non standard arguments: order AR coefficients reversed. data matrices organized column-wise (avoid memory shuffling)!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve RMFD system for given inputs — solve_RMFD_R","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"Compute outputs \\(y_t\\) RMFD(p, q) systems form $$y_t = d_0 v_t + d_1 v_{t-1} + \\cdots + d_q v_{t-q}$$ $$v_t + c_1 v_{t-1} + \\cdots + c_p v_{t-p} = u_t$$ given inputs \\(u_t\\) contained column-wis data matrix data_input, see .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"","code":"solve_RMFD_R(polm_c, polm_d, data_input, t0 = 1)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"polm_c, polm_d polm objects. Describe jointly RMFD. \\(c(z)\\) square, identity zero-lag coefficient, coefficients reversed procedure: \\((c_p,...,c_1)\\). \\(d(z)\\) might tall, zero-lag coefficient matrix general free. data_input \\((n, N)\\) matrix inputs \\((u_1,...,u_N\\). t0 integer, start iteration t=t0.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"R implementation solve_RMFD_R() returns matrix y computed outputs. $$y_t = d(z) c(z)^{-1} u_t$$ RcppArmadillo implementation solve_rmfd_cpp() returns NULL overwrites input argument. Note RcppArmadillo implementation different user interface (intended internal use ).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_RMFD_R.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve RMFD system for given inputs — solve_RMFD_R","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitely set zero. However, start iteration \\(t_0>1\\) can enforce non-zero initial values. routines used internally hence check arguments. require number outputs positive \\(m > 0\\), number inputs non-negative \\(n \\geq 0\\), degree \\(c(z)\\) %>%  non-negative \\(p \\geq 0\\), degree \\(d(z)\\) unrestricted, .e. \\((q+1) \\geq 0\\), starting value sample size \\(1 \\leq t_0 \\leq N\\) holds. Note also RcppArmadillo implementation overwrites input argument y. Use procedure care! Note non standard arguments: polynomial matrices \\(c(z)\\) \\(d(z)\\) saved \"wide\" matrices. order coefficients \\(c(z)\\) reversed \\(c_0\\) coefficient (required identity matrix). order coefficients \\(d(z)\\) usual, \\(d_0\\) available . data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve (linear) Difference Equations — solve_de","title":"Solve (linear) Difference Equations — solve_de","text":"procedure solve_de() solves difference equations associated (V)ARMA models $$a_0 y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t  + b_1 u_{t-1} + ... b_1 u_{t-q}$$ state space models $$a_{t+1} = a_t + B u_t \\mbox{ } y_t = C a_t + D u_t.$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve (linear) Difference Equations — solve_de","text":"","code":"solve_de(sys, u, ...)  # S3 method for class 'stsp' solve_de(sys, u, a1 = NULL, ...)  # S3 method for class 'lmfd' solve_de(sys, u, u0 = NULL, y0 = NULL, ...)  # S3 method for class 'rmfd' solve_de(sys, u, u0 = NULL, y0 = NULL, ...)  solve_inverse_de(sys, y, ...)  # S3 method for class 'stsp' solve_inverse_de(sys, y, a1 = NULL, ...)  # S3 method for class 'lmfd' solve_inverse_de(sys, y, u0 = NULL, y0 = NULL, ...)  # S3 method for class 'rmfd' solve_inverse_de(sys, y, u0 = NULL, y0 = NULL, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve (linear) Difference Equations — solve_de","text":"sys rationalmatrices::lmfd() rationalmatrices::stsp() object describes difference equation. u \\((N,n)\\) matrix noise (\\(u_t\\), \\(t=1,...,N\\)). ... used. a1 \\(m\\) dimensional vector initial state \\(a_1\\). a1=NULL zero vector used. u0 \\((h,n)\\) dimensional matrix starting values disturbances \\((u_{1-h}, \\ldots, u_{-1}, u_0)\\). Note last row corresponds \\(u_0\\), last one row \\(u_{-1}\\) . \\(h>q\\) last \\(q\\) rows u0 used. case \\(h<q\\) \"missing\" initial values set zero vectors.  default value u0=NULL sets initial values \\(u_t\\), \\(t \\leq 0\\) equal zero vectors. y0 \\((h,m)\\) dimensional matrix starting values outputs \\((y_{1-h}, \\ldots, y_{-1}, y_0)\\). (optional) parameter interpreted analogously u0. y \\((N,m)\\) matrix outputs (\\(y_t\\), \\(t=1,...,N\\)).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve (linear) Difference Equations — solve_de","text":"List slots y \\((N,n)\\) matrix (computed) outputs. u \\((N,n)\\) matrix (computed) noise. \\((N+1,n)\\) matrix (computed) states (\\(a_t\\), \\(t=1,...,N+1\\)). Note matrix (\\(N+1\\)) rows! slot present state space models.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve (linear) Difference Equations — solve_de","text":"solve_de() computes outputs \\(y_t\\) \\(t=1,\\ldots,N\\) given disturbances \\(u_t\\) \\(t=1,\\ldots,N\\). starting values  (\\(u_t\\) \\(y_t\\) \\(t\\leq 0\\) VARMA models \\(a_1\\) state space models) may given optional arguments. default use zero vectors. reverse direction, .e. reconstruct disturbances outputs given, function solve_inverse_de may used. case system must square matrix \\(D\\) respectively \\(b_0\\) must invertible. functions mainly intended internal use hence basic checks input parameters performed.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_de.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve (linear) Difference Equations — solve_de","text":"","code":"### generate a random ARMA(2,1) model (with two outputs) ######### model = test_armamod(dim = c(2,2), degrees = c(2,1),                      digits = 2, bpoles = 1, bzeroes = 1)  # generate random noise sequence (sample size N = 100) u = matrix(rnorm(100*2), nrow = 100, ncol = 2)  # generate random initial values u0 = matrix(rnorm(2), nrow = 1, ncol = 2) # u[0] y0 = matrix(rnorm(2), nrow = 1, ncol = 2) # y[0]  # compute outputs \"y[t]\" # note that y0 has only one row, thus y[-1] is set to zero! data = solve_de(model$sys, u = u, y0 = y0, u0 = u0)  # we can reconstruct the noise \"u\" from given outputs \"y\" data1 = solve_inverse_de(model$sys, y = data$y, u0 = u0, y0 = y0) all.equal(data$u, data1$u) #> [1] TRUE  ### generate a random state space model (3 outputs and 4 states) ## model = test_stspmod(dim = c(3,3), s = 4,                      digits = 2, bpoles = 1, bzeroes = 1)  # generate random noise sequence (sample size N = 100) u = matrix(rnorm(100*3), nrow = 100, ncol = 3)  # generate random initial state a[1] a1 = rnorm(4)  # compute outputs \"y[t]\" data = solve_de(model$sys, u = u, a1 = a1)  # we can reconstruct the noise \"u\" from given outputs \"y\" data1 = solve_inverse_de(model$sys, y = data$y, a1 = data$a[1,]) all.equal(data$u, data1$u) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"Compute inputs \\(u_t\\) RMFD(p, q) systems form $$y_t = d_0 v_t + d_1 v_{t-1} + \\cdots + d_q v_{t-q}$$ $$v_t + c_1 v_{t-1} + \\cdots + c_p v_{t-p} = u_t$$ given data \\(y_t\\) contained column-wise matrix data_output, see .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"","code":"solve_inverse_RMFD_R(polm_c, polm_d, data_output, t0 = 1)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"polm_c, polm_d polm objects. Jointly, reprsent RMFD. \\(c(z)\\) square, identity zero-lag coefficient. \\(d(z)\\) might tall, zero-lag coefficient matrix general free. data_output \\((m, N)\\) matrix outputs \\((y_1,...,y_N\\). t0 integer, start iteration t=t0.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"R implementation solve_inverse_RMFD_R returns matrix u computed inputs $$u_t = d^{+}(z) c(z) y_t$$ columns. RcppArmadillo implementation solve_rmfd_cpp() returns NULL overwrites input argument! Note RcppArmadillo implementation different user interface (intended internal use ).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_inverse_RMFD_R.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Obtain Inputs of RMFD System for Given Data — solve_inverse_RMFD_R","text":"Values \\(y_t\\), \\(u_t\\) \\(t\\leq 0\\) implicitely set zero. However, start iteration \\(t_0>1\\) can enforce non-zero initial values. routines used internally hence check arguments. require number outputs positive \\(m > 0\\), number inputs non-negative \\(n \\geq 0\\), degree \\(c(z)\\) non-negative \\(p \\geq 0\\), degree \\(d(z)\\) unrestricted, .e. \\((q+1) \\geq 0\\), starting value sample size \\(1 \\leq t_0 \\leq N\\) holds. Note also RcppArmadillo implementation overwrites input argument y. Use procedure care! Note non standard arguments: polynomial matrices \\(c(z)\\) \\(d(z)\\) saved \"wide\" matrices. order coefficients \\(c(z)\\) reversed \\(c_0\\) coefficient (required identity matrix). order coefficients \\(d(z)\\) usual, \\(d_0\\) available . data matrices organized columnwise (avoid memory shuffling)!","code":""},{"path":[]},{"path":"https://bfunovits.github.io/RLDM/reference/solve_rmfd_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","title":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","text":"RcppArmadillo function calculates given inputs data_in dimension \\((n \\times nobs)\\),  \\(nobs\\) sample size, outputs dimension \\(m\\). Note data matrices \"transposed\" sense every column corresponds one observation memory management. data_out thus dimension \\((m x nobs)\\). function intended internal use thus arguments checked.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_rmfd_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","text":"","code":"solve_rmfd_cpp(poly_inv, poly_fwd, data_in, data_out, t0)"},{"path":"https://bfunovits.github.io/RLDM/reference/solve_rmfd_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","text":"poly_inv Matrix dimension \\((n \\times n p)\\), representing square matrix polynomial \\(c(z)\\) \\(c_0\\) equal identity matrix (therefore stored). coefficients need reverse direction, .e. \\((c_p, ... , c_1)\\), \\(p\\) denotes degree \\(c(z)\\). poly_fwd Matrix dimensions \\((m \\times n(q+1))\\), representing (possibly tall) matrix polynomial \\(d(z)\\) dimension \\((m \\times n)\\), \\(m \\geq n\\). coefficient stored \"usual\" including \\(d_0\\), .e. \\((d_0, d_1, ... , d_{q-1}, d_{q})\\), \\(q\\) denotes degree \\(d(z)\\). data_in Matrix dimension \\((n \\times n_obs)\\), .e. \\((u_1, ..., u_T)\\). Inputs RMFD system. data_out Matrix dimension \\((m \\times n_obs)\\), .e. \\((y_1, ..., y_T)\\). Outputs RMFD system. Initially zero overwritten. t0 Integer. Time index start calculating solution. Usually equal 1.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/solve_rmfd_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulating Output from an RMFD Model (or obtain residuals) — solve_rmfd_cpp","text":"data_out overwritten outputs RMFD system.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":null,"dir":"Reference","previous_headings":"","what":"Spectral Density — spectrald","title":"Spectral Density — spectrald","text":"Compute spectral density ARMA process process defined state space model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spectral Density — spectrald","text":"","code":"spectrald(obj, n.f, ...)  # S3 method for class 'armamod' spectrald(obj, n.f = 128, ...)  # S3 method for class 'stspmod' spectrald(obj, n.f = 128, ...)  # S3 method for class 'autocov' spectrald(obj, n.f = 128, ...)  # S3 method for class 'impresp' spectrald(obj, n.f = 128, ...)  # Default S3 method spectrald(obj, n.f = NULL, demean = TRUE, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spectral Density — spectrald","text":"obj armamod(), stspmod(), autocov(), impresp() object \"time series\" object, .e. object may coerced data matrix y = .matrix(obj). n.f number frequencies. ... used. demean (logical) data demeaned computing periodogram?","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spectral Density — spectrald","text":"freqresp object, .e. list slots spd rationalmatrices::zvalues() object. names (m)-dimensional character vector NULL. optional slot stores names components time series/process. label character string NULL. n.obs (optional) integer NULL.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Spectral Density — spectrald","text":"spectral density stationary process absolutely summable autocovariance function \\((\\gamma_j)\\) given $$ \\Gamma(\\lambda) = \\frac{1}{2\\pi}\\sum_{j=-\\infty}^{\\infty} \\gamma_j e^{-\\lambda j}. $$ ARMA process, process defined state space model spectral density equal $$ \\Gamma(\\lambda) = \\frac{1}{2\\pi} K(\\lambda) \\Sigma K^*(\\lambda) $$ \\(\\Sigma\\) noise covariance, \\(K()\\) frequency response model \\(K^*(\\lambda)\\) Hermitean transpose \\(K(\\lambda)\\). See also autocov() freqresp(). Note \\(\\Gamma()\\) (factor \\(2\\pi\\)) discrete-time Fourier transform (DTFT) autocovariance function therefore ACF \\(\\gamma_j\\) may reconstructed spectral density via inverse DTFT $$ \\gamma_j = \\int_{-\\pi}^{\\pi} \\Gamma(\\lambda) e^{\\lambda j} d\\lambda $$ S3 methods spectrald.* evaluate spectral density function grid angular frequencies \\(\\lambda_j = 2\\pi j/N\\), \\(j=0,\\ldots,N-1\\) store result spectrald object. several possible ways specify process. One may provide ARMA (armamod) respectively state space model (stspmod), autocovariance function (autocov) impulse response function (impresp) maps noise outputs. Note however, given autocov impresp object computed spectral density approximation true spectral density since finite number covariances respectively impulse response coefficients given. type autocovariance function (\"covariances\", \"correlations\" \"partial correlations\") irrelevenat since procedure alwayas uses slot \"gamma\" contains covariances. default method spectrald.default assumes obj \"time series\" object tries coerce object data matrix via y = .matrix(obj). case procedure computes periodogram simple estimate spectral density. periodgram may also computed call spectrald(autocov(obj, max.lag = n.obs-1)), .e. first computing sample auto covariance function computing corresponding spectral density. Note use different scaling stats::[spectrum][stats::spectrum] routine.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/spectrald.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spectral Density — spectrald","text":"","code":"#' ### generate random 3-dimensional ARMA(1,1) model # \"bpoles = 1.1\" implies that the poles have moduli larger than 1.1 # and therefore the impulse response coefficients decay with a rate (1.1)^k arma_model = test_armamod(dim = c(3,3), degrees = c(1,1), bpoles = 1.1)  # spectral density spd = spectrald(arma_model)  # compute the spectral density via the impulse response spd1 = spectrald(impresp(arma_model, lag.max = 100))  # since the impulse response quickly decays # the \"truncated\" spectral density should be close to the true one all.equal(spd, spd1) #> [1] TRUE  # compute the spectral density via the autocovariance function spd1 = spectrald(autocov(arma_model, lag.max = 100))  # since the ACF quickly decays # the \"truncated\" spectral density should be close to the true one all.equal(spd, spd1) #> [1] TRUE  # create an equivalent state space model stsp_model = as.stspmod(arma_model)  # of course the state space model gives the same spectrum # as the original ARMA model spd1 = spectrald(stsp_model) all.equal(spd, spd1) #> [1] TRUE"},{"path":"https://bfunovits.github.io/RLDM/reference/str.html","id":null,"dir":"Reference","previous_headings":"","what":"Display the Structure of Objects — str methods","title":"Display the Structure of Objects — str methods","text":"Display Structure Objects","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display the Structure of Objects — str methods","text":"","code":"# S3 method for class 'armamod' str(object, ...)  # S3 method for class 'stspmod' str(object, ...)  # S3 method for class 'impresp' str(object, ...)  # S3 method for class 'autocov' str(object, ...)  # S3 method for class 'fevardec' str(object, ...)  # S3 method for class 'freqresp' str(object, ...)  # S3 method for class 'spectrald' str(object, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/str.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display the Structure of Objects — str methods","text":"object object ... used","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/str.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display the Structure of Objects — str methods","text":"invisible(NULL)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":null,"dir":"Reference","previous_headings":"","what":"Creator for stspmod class — stspmod","title":"Creator for stspmod class — stspmod","text":"Creator stspmod class","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creator for stspmod class — stspmod","text":"","code":"stspmod(sys, sigma_L = NULL, names = NULL, label = NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creator for stspmod class — stspmod","text":"sys rationalmatrices::stsp() object sigma_L noise covariance left names optional vector character strings label optional chracter string","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creator for stspmod class — stspmod","text":"Object class stspmod.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/stspmod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creator for stspmod class — stspmod","text":"","code":"x = stspmod(sys = test_stsp(dim = c(2,2), s = 2), sigma_L = diag(2)) x #> state space model [2,2] with s = 2 states #>            s[1]       s[2]      u[1]      u[2] #> s[1] -0.1385598 -0.1071151 0.9055928 0.4116807 #> s[2]  1.1899153  0.7262129 0.7234385 0.9463023 #> x[1]  0.1320469 -1.6041407 1.0000000 0.0000000 #> x[2] -0.4050430 -0.8048852 0.0000000 1.0000000 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1]    1    0 #> u[2]    0    1"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Subspace Helper Methods — subspace helpers","title":"Subspace Helper Methods — subspace helpers","text":"procedure implement two subspace algorithms estimation state space models, AOKI method, described (Aoki 1990)  CCA algorithm (see e.g. (Dahlen Scherrer 2004)  (Bauer 2001) ). subspace algorithms center weighted Hankel matrix $$(R_f')^{-T} H_{fp} R_p^{-1}$$ block Hankel matrix \\(H_{fp}\\) covariance \"past\" \\((y_{t-1}',\\cdots,y_{t-p}')'\\) \"future\" \\((y_{t}',\\cdots,y_{t+f-1}')'\\) \\(R_f\\) \\(R_p\\) cholesky factors covariance matrices \"future\" \"past\" respectively. singular values weighted Hankel matrix canonical correlation coefficients past future. Note implementation always sets \\(f = p+1\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subspace Helper Methods — subspace helpers","text":"","code":"est_stsp_aoki(   gamma,   s.max,   p,   estorder = estorder_SVC,   keep_models = FALSE,   n.obs = NULL,   ... )  est_stsp_cca(   gamma,   s.max,   p,   estorder = estorder_SVC,   keep_models = FALSE,   n.obs = NULL,   ... )  est_stsp_cca_sample(   y,   s.max,   p,   estorder = estorder_SVC,   keep_models = FALSE,   mean_estimate = c(\"sample.mean\", \"zero\"),   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subspace Helper Methods — subspace helpers","text":"gamma \\((m,m,L+1)\\)-dimensional array (sample) autocovariance function. s.max (integer) maximum possible order. p (integer) number block columns Hankel matrix (size \"past\") estorder function, estimate order system. keep_models (boolean) function return list estimated system order 0:s.max? n.obs sample size \\(N\\). ... additional parameters, passed order estimation routine. y \\((N,m)\\)-dimensional matrix object, may coerced matrix .matrix{y}. mean_estimate Character string giving method used estimate mean \\(\\mu = E y_t\\). Default use sample mean.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subspace Helper Methods — subspace helpers","text":"List slots: model stsp() object, represents estimated state space model. models either NULL (!keep_models) list parameters estimated models orders (s=0:s.max+1). slot may e.g. used estimate model order user defined model selection procedure. s (integer) estimate model order. info list information data design parameters estimation procedure. stats ((s.max+1)--5)-dimensional matrix statistics (estimated) state space models.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subspace Helper Methods — subspace helpers","text":"AOKIs method realization algorithm, .e. reconstructs underlying state space model (population) autocovariance function. end Riccati equation solved, see riccati(). estimated ACF fed algorithm one obtains estimate state space model. However note may fail (particular Riccati equation may positive definite solution) estimate ACF positive definite, Hankel matrix small state dimension correct. CCA method estimates state space model first constructing estimate states. parameter matrices estimated via simple LS regressions. procedure give \"true\" model, even case population ACF used. However, \"distance\" true model estimated model converges zero, estimate ACF converges population ACF size \\(p\\) Hankel matrix converges infinity. two implementations CCA method: routine est_stsp_cca_sample() operates directly supplied data. routine est_stsp_cca() uses (estimated) autocovariance function. algorithms may also used simple \"model reduction algorithms\". want approximate high dimensional state space model model lower order, may proceed follows. First compute ACF high dimensional model fed ACF subspace routines est_stsp_cca est_stsp_aoki, however setting maximum order s.max value less true order. Order Estimation order estimation based Hankel singular values \\(\\sigma_s\\) /log det values estimated noise covariance matrices \\(\\ln\\det \\hat{\\Sigma}_s\\). Using Hankel singular values advantage one model estimated, whereas otherwise estimates models orders \\(s=0,\\ldots,s_{\\max}\\) computed. order exploit (small) advantage singular values based criteria order estimation runs follows: First procedures call  estorder(s.max, Hsv, n.par, m, n.obs, Hsize=c(f,p), ...)  Hsv \\(pm\\) dimensional vector Hankel singular values n.par \\((s_{\\max}+1)\\) dimensional vector respective number parameters models orders \\(s=0,\\ldots,s_{\\max}\\). call returns estimate order procedures estimate corresonding state space model. call fails (.e returns NULL) procedures estimate models orders \\(s_{\\max}\\) corresponding noise covariance matrices. order estimated calling  estorder(s.max = s.max, Hsv, lndetSigma, n.par, m, n.obs, Hsize, ...)  lndetSigma vector log det values estimated noise covariance matrices (\\(\\ln\\det \\hat{\\Sigma}_s\\)). package offers predefined order selection procedures (see also subspace order estimates): estorder_max(s.max, ...) simply returns maximum order s.max considered. estorder_rkH(s.max, Hsv, tol, ...) estimates order estimate rank Hankel matrix. estorder_MOE(s.max, Hsv, ...) estimates order searching \"gap\" singular values. estorder_SVC(s.max, Hsv, n.par, n.obs, Hsize, penalty, ...) implements called Singular Value Criteria, see (Bauer 2001) : $$svc(s) = \\sigma_{s+1}^2 + c(N)d(s)/N$$ \\(\\sigma_s\\) \\(s\\)-th singular value weighted Hankel marix, \\(N\\) sample size, \\(d(s) = 2ms\\) denotes number parameters state space model \\(s\\) states (\\(m\\) outputs) \\(c(N)\\)) \"penalty\" (depending sample size). order estimation procedures use Hankel singular values, whereas following procedure based estimated noise covariances. estorder_IVC(s.max, lndetSigma, n.par, n.obs, penalty, ...) estimates order via information criterion form $$ivc(s) = \\ln\\det\\hat\\Sigma_{s} + c(N)d(s)/N$$ \\(\\hat\\Sigma_s\\) estimate noise covariace matrix obtained model order \\(s\\), \\(d(s)\\) denotes number parameters \\(c(N)\\) \"penalty\" (depending sample size). estorder_SVC estorder_IVC (optional) parameter penalty controls penalty term \\(c(N)\\). Note also  keep_models==TRUE estimation procedures compute models even case Hankel singular value based selection criterion.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-helpers.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Subspace Helper Methods — subspace helpers","text":"Bauer D (2001). “Order estimation subspace methods.” Automatica, 37(10), 1561 - 1573. doi:10.1016/S0005-1098(01)00118-2 .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate State Space Models with Subspace Methods — subspace methods","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"Estimate (respectively construct) state space model given sample given (sample) autocovariance function.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"","code":"est_stsp_ss(   obj,   method = c(\"cca\", \"aoki\"),   s.max = NULL,   p = NULL,   p.ar.max = NULL,   p.factor = 2,   extend_acf = FALSE,   sample2acf = TRUE,   estorder = estorder_SVC,   keep_models = FALSE,   mean_estimate = c(\"sample.mean\", \"zero\"),   n.obs = NULL,   ... )"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"obj Either \"time series\" object (.e .matrix(obj) returns \\((N,m)\\)-dimensional numeric matrix) autocov() object (\\(L\\) lags) represents (estimated) autocovariance function. type autocov object irrelevant since est_stsp_ss always uses slot obj$gamma contains autocovariance function. method Character string giving method used fit model. s.max (integer) maximum order state space model. NULL default value chosen based sample size \\(N\\), respectively based number lags \\(L\\) ACF. p (integer) number block columns Hankel matrix (size \"past\"). NULL p chosen fitting \"long\" AR model. p.ar.max (integer) maximum order \"long\" AR model. NULL default choice made. parameter needed case p=NULL. p.factor (integer) p=NULL, number block columns Hankel matrix set \\(p = p_f\\hat{p}_{AIC}\\) \\(p_f\\) parameter p.factor \\(\\hat{p}_{AIC}\\) (AIC) estimate order \"long\" AR model. See also est_ar(). extend_acf (boolean) TRUE ACF extended via AR(p) model (MEST). sample2acf (boolean) obj data object sample2acf TRUE, first sample autocovariance function computed used actual computations. estorder function, used select order state space model. keep_models (boolean) function return list estimated system order 0:s.max? mean_estimate Character string giving method used estimate mean \\(\\mu = E y_t\\). Default use sample mean. See details . n.obs Optional integer gives sample size \\(N\\). parameter used, obj autocov() object. n.obs=NULL slot obj$n.obs used. Note obj$n.obs=NULL obj$n.obs=Inf refers case population autocovariance function, .e. \\(N=\\infty\\). \"time series\" object sample size course set number observations, .e. n.obs = nrow(.matrix(obj)). sample size \\(N\\) controls computation default (maximum) orders estimation order state space model. ... additional parameters, passed order estimation routine.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"list slots model stsp() object, represents estimated state space model. models either NULL (!keep_models) list parameters estimated models orders (s=0:s.max+1). slot may e.g. used estimate model order user defined model selection procedure. s (integer) estimate model order. info list information data design parameters estimation procedure. stats ((s.max+1)--5)-dimensional matrix statistics (estimated) state space models. y.mean estimate mean \\(\\mu\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"procedure implements three subspace algorithms estimation state space models, AOKI method, described (Aoki 1990)  CCA MEST algorithms (see e.g. (Dahlen Scherrer 2004) ). three algorithms center weighted Hankel matrix $$(R_f')^{-T} H_{fp} R_p^{-1}$$ block Hankel matrix \\(H_{fp}\\) covariance \"past\" \\((y_{t-1}',\\cdots,y_{t-p}')'\\) \"future\" \\((y_{t}',\\cdots,y_{t+f-1}')'\\) \\(R_f\\) \\(R_p\\) cholesky factors covariance matrices \"future\" \"past\" respectively. singular values weighted Hankel matrix canonical correlation coefficients past future. Note implementation always sets \\(f = p+1\\). AOKIs method realization algorithm, .e. reconstructs underlying state space model (population) autocovariance function. end Riccati equation solved, see riccati(). estimated ACF fed algorithm one obtains estimate state space model. However note may fail (particular Riccati equation may positive definite solution) estimate ACF positive definite, Hankel matrix small state dimension correct. CCA method estimates state space model first constructing estimate states. parameter matrices estimated via simple LS regressions. procedure give \"true\" model, even case population ACF used. However, \"distance\" true model estimated model converges zero, estimate ACF converges population ACF size \\(p\\) Hankel matrix converges infinity. two implementations CCA method: obj \"time series\" object sample2acf==FALSE helper function est_stsp_cca_sample() called. implementation CCA operates directly supplied data. obj autocov() object obj \"time series\" object sample2acf==TRUE helper function est_stsp_cca() called. implementation uses (estimated) autocovariance function. time series object, first sample autocovariance function computed fed helper function. key idea MEST algorithm first estimate \"long\" AR model, convert AR model state space model use \"balancing truncation\" method obtain final estimate state space model. scheme may obtained calling est_stsp_ss option extend_acf=TRUE: option instructs procedure first estimate AR(p) model use model \"extend\" ACF, .e. compute values ACF lags \\(p+1,\\ldots,2p\\). extended ACF fed helper function  est_stsp_cca(). Note MEST uses autocovariance function. \"time series\" object one set sample2acf=TRUE. algorithms may used model reduction (.e. find model smaller state space dimension true model) estimation (feeding sample autocovariance function ). algorithms may also used simple \"model reduction algorithms\". want approximate high dimensional state space model model lower order, may proceed follows. First compute ACF high dimensional model fed ACF subspace routine est_stsp_ss, however setting maximum order s.max value less true order. Note thet AOKI procedure however, may break , since guaranteed Riccati equation, needs solved, positive semidefinite solution. Size Hankel matrix input parameter p=NULL \\(p\\) chosen follows. procedure estimates order \"long\" AR model AIC criterion. size \"past\" \\(p\\) set \\(p = p_f\\hat{p}_{AIC}\\) \\(p_f\\) factor (defaults \\(2\\)) \\(\\hat{p}_{AIC}\\) (AIC) estimate order \"long\" AR model. See also est_ar(). Estimation Mean input parameter obj autocov() object (contains info mean \\(\\mu=E y_t\\)) \"estimate\" mean simply set vector NA's. input parameter obj \"time series\" object, two options. mean_estimate == 'zero' procedure assumes process centered (\\(\\mu=E y_t=0\\)) thus sets estimate zero vector. case mean_estimate == 'sample.mean'  sample mean data used. Order Estimation input parameter s.max defines maximum order considered. order estimation based Hankel singular values \\(\\sigma_s\\) /log det values estimated noise covariance matrices \\(\\ln\\det \\hat{\\Sigma}_s\\). Using Hankel singular values advantage one model estimated, whereas otherwise estimates models orders \\(s=0,\\ldots,s_{\\max}\\) computed. order exploit (small) advantage singular values based criteria order estimation runs follows: First procedures call  estorder(s.max, Hsv, n.par, m, n.obs, Hsize=c(f,p), ...)  Hsv \\(pm\\) dimensional vector Hankel singular values n.par \\((s_{\\max}+1)\\) dimensional vector respective number parameters models orders \\(s=0,\\ldots,s_{\\max}\\). call returns estimate order procedures estimate corresonding state space model. call fails (.e returns NULL) procedures estimate models orders \\(s_{\\max}\\) corresponding noise covariance matrices. order estimated calling  estorder(s.max = s.max, Hsv, lndetSigma, n.par, m, n.obs, Hsize, ...)  lndetSigma vector log det values estimated noise covariance matrices (\\(\\ln\\det \\hat{\\Sigma}_s\\)). package offers predefined order selection procedures (see also subspace order estimates): estorder_max(s.max, ...) simply returns maximum order s.max considered. estorder_rkH(s.max, Hsv, tol, ...) estimates order estimate rank Hankel matrix. estorder_MOE(s.max, Hsv, ...) estimates order searching \"gap\" singular values. estorder_SVC(s.max, Hsv, n.par, n.obs, Hsize, penalty, ...) implements called Singular Value Criteria, see (Bauer 2001) : $$svc(s) = \\sigma_{s+1}^2 + c(N)d(s)/N$$ \\(\\sigma_s\\) \\(s\\)-th singular value weighted Hankel marix, \\(N\\) sample size, \\(d(s) = 2ms\\) denotes number parameters state space model \\(s\\) states (\\(m\\) outputs) \\(c(N)\\)) \"penalty\" (depending sample size).  order estimation procedures use Hankel singular values, whereas following procedure based estimated noise covariances. estorder_IVC(s.max, lndetSigma, n.par, n.obs, penalty, ...) estimates order via information criterion form $$ivc(s) = \\ln\\det\\hat\\Sigma_{s} + c(N)d(s)/N$$ \\(\\hat\\Sigma_s\\) estimate noise covariace matrix obtained model order \\(s\\), \\(d(s)\\) denotes number parameters \\(c(N)\\) \"penalty\" (depending sample size). estorder_SVC estorder_IVC (optional) parameter penalty controls penalty term \\(c(N)\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"further-notes","dir":"Reference","previous_headings":"","what":"Further Notes","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"actual computations done helper routines detailed subspace helpers. type autocov() object irrelevenat since function always uses slot obj$gamma.  keep_models==TRUE estimation procedure compute models even case Hankel singular value based selection criterion.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"Aoki M (1990). State Space Modeling Time Series. Springer Verlag, New York. Bauer D (2001). “Order estimation subspace methods.” Automatica, 37(10), 1561 - 1573. doi:10.1016/S0005-1098(01)00118-2 . Dahlen , Scherrer W (2004). “relation CCA subspace method balanced reduction autoregressive model.” Journal Econometrics, 118, 293–312. doi:10.1016/S0304-4076(03)00144-1 .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate State Space Models with Subspace Methods — subspace methods","text":"","code":"set.seed(3421) # in order to get reproducible results  # create a \"random\", stable and miniphase state space model m = 2 # number of outputs s = 3 # number of states s.max = 2*s lag.max = max(4*s, 25) n.obs = 1000  model = r_model(tmpl_stsp_full(m, m, s),                 bpoles = 1, bzeroes = 1,  sd = 0.5) # scale sigma_L diag(model$sigma_L) = 1  # compute ACF gam = autocov(model, lag.max = lag.max)  # simulate data data = sim(model, n.obs)  # sample ACF gam.sample = autocov(data$y, lag.max = lag.max, demean = FALSE)  # AOKIs method ############################################################## # reconstruct the true model from the population ACF # \"estimate\" the order by the rank of the Hankel matrix out = est_stsp_ss(gam, method = 'aoki', s.max = 2*s, estorder = estorder_rkH)  # compute the ACF of the constructed model. gam.hat = autocov(out$model, lag.max = lag.max)  # check that the constructed model is equivalent to the original model all.equal(dim(model$sys), dim(out$model$sys)) #> [1] TRUE all.equal(gam, gam.hat) #> [1] TRUE   # CCA based on the sample ################################################### # estimate the order by a \"singular value criterion\" out = est_stsp_ss(data$y, method = 'cca', sample2acf = FALSE, s.max = 2*s,                   estorder = estorder_SVC)  # compute the ACF of the constructed model. gam.hat = autocov(out$model, lag.max = lag.max)  all.equal(dim(model$sys), dim(out$model$sys)) # the estimated order is correct #> [1] TRUE all.equal(gam$gamma, gam.hat$gamma)           # but of course the estimated model is not perfect #> [1] \"Mean relative difference: 0.1680467\"  # CCA based on the sample ACF ############################################### # estimate the order by an \"information criterion\" out = est_stsp_ss(gam.sample, method = 'cca', s.max = 2*s,                   estorder = estorder_IVC)  # compute the ACF of the constructed model. gam.hat = autocov(out$model, lag.max = lag.max)  cat('s.hat=', dim(out$model$sys)[3], '\\n') # the estimated order is s.hat=2, the true order is s=3! #> s.hat= 2  all.equal(gam$gamma, gam.hat$gamma)        # relative error of the TRUE and the estimated ACF #> [1] \"Mean relative difference: 0.1966654\"  # alternatively, we may also use out2 = est_stsp_ss(data$y, sample2acf = TRUE, mean_estimate = 'zero',                    method = 'cca', s.max = 2*s, estorder = estorder_IVC) all.equal(out$model, out2$model) #> [1] TRUE  # MEST algorithm ############################################################# # estimate the order by an \"information criterion\" out = est_stsp_ss(gam.sample, method = 'cca', extend_acf = TRUE, s.max = 2*s,                   estorder = estorder_IVC)  # compute the ACF of the constructed model. gam.hat = autocov(out$model, lag.max = lag.max)  cat('s.hat=', dim(out$model$sys)[3], '\\n') # the estimated order is s.hat=2, the true order is s=3! #> s.hat= 2  all.equal(gam$gamma, gam.hat$gamma)        # relative error of the TRUE and the estimated ACF #> [1] \"Mean relative difference: 0.196599\"  # make a plot of the ACFs plot(gam, list(gam.sample, gam.hat), legend = c('TRUE', 'sample', 'subspace'))   # reset seed set.seed(NULL)"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Functions for Order Estimation — subspace order estimates","title":"Helper Functions for Order Estimation — subspace order estimates","text":"helper function used subspace estimation routine subspace methods estimation order state space model. discussion order estimation context subspace methods see e.g (Bauer 2001) .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Functions for Order Estimation — subspace order estimates","text":"","code":"estorder_SVC(s.max, Hsv = NULL, n.par, n.obs, Hsize, penalty = \"lnN\", ...)  estorder_IVC(s.max, lndetSigma = NULL, n.par, n.obs, penalty = \"BIC\", ...)  estorder_max(s.max, ...)  estorder_rkH(s.max, Hsv = NULL, tol = sqrt(.Machine$double.eps), ...)  estorder_MOE(s.max, Hsv = NULL, ...)"},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper Functions for Order Estimation — subspace order estimates","text":"s.max (integer) maximum order (maximum state space dimension). Hsv vector Hankel singular values (must least s.max entries). n.par (s.max+1) dimensional vector respective number parameters. n.obs (integer) sample size \\(N\\) (Inf). Hsize two dimensional integer vector number block rows block columns Hankel matrix (Hsize = c(f,p)). penalty determines penalty term. See details . ... optional additional parameters. lndetSigma (s.max+1) dimensional vector logarithms determinants respective estimated noise covariance matrices. tol (small) tolarenace used determine rank Hankel matrix.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Functions for Order Estimation — subspace order estimates","text":"Either NULL list slots $s (selected/estimated order) $criterion ((s.max+1) dimensional vector).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helper Functions for Order Estimation — subspace order estimates","text":"estorder_max simply returns maximum order s.max considered. estorder_rkH estimates order estimate rank Hankel matrix. maximum singular value smaller equal .Machine$double.eps estimate set s=0. Otherwise estimated order equal number singular values larger equal tol times maximum singular value. function estorder_MOE searches \"gap\" singular values. order set maximum \\(s\\) satisfies $$\\ln(\\sigma_s) > (\\ln(\\sigma_1)+\\ln(\\sigma_m))/2$$ \\(\\sigma_m\\) minimum, non zero singular value. scheme also implemented N4SID procedure system identification toolbox MATLAB (Ljung, 1991). function estorder_SVC implements called Singular Value Criterion $$svc(s) = \\sigma_{s+1}^2 + c(N)d(s)/N$$ (see e.g. (Bauer 2001) ). \\(\\sigma_s\\) \\(s\\)-th singular value weighted Hankel marix, \\(N\\) sample size, \\(d(s) = 2ms\\) denotes number parameters state space model \\(s\\) states (\\(m\\) outputs) \\(c(N)\\) \"penalty\" term. term \\(c(N)=\\ln(N)\\) penalty = \"lnN\" \\(c(N)=fp\\ln(N)\\) penalty = \"fplnN\". estimate order minimizer criterion. estorder_IVC estimates order via information criterion form $$ivc(s) = \\ln\\det\\hat\\Sigma_{s} + c(N)d(s)/N$$ \\(\\hat\\Sigma_s\\) estimate noise covariace matrix obtained model order \\(s\\). term \\(c(N)\\) chosen \\(c(N)=2\\) penalty = \"AIC\" \\(c(N)=\\ln(N)\\) penalty = \"BIC\". Note also routines estorder_SVC estorder_IVC one may also set penalty arbitrary numeric value! E.g. setting penalty=-1 ensure  estorder_SVC  always choses maximum possible order s=s.max.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/subspace-order-estimates.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Helper Functions for Order Estimation — subspace order estimates","text":"Bauer D (2001). “Order estimation subspace methods.” Automatica, 37(10), 1561 - 1573. doi:10.1016/S0005-1098(01)00118-2 .","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Test ARMA model — test_armamod","title":"Create Test ARMA model — test_armamod","text":"simple tool may used create random ARMA model $$y_t + a_1 y_{t-1} + \\cdots + a_p y_{t-p} = b_0 u_t + b_1 u_{t-1} + \\cdots + b_q u_{t-q}$$ given order \\((p,q)\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Test ARMA model — test_armamod","text":"","code":"test_armamod(   dim = c(1, 1),   degrees = c(1, 1),   b0 = NULL,   sigma_L = NULL,   digits = NULL,   bpoles = NULL,   bzeroes = NULL,   n.trials = 100 )"},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Test ARMA model — test_armamod","text":"dim integer vector c(m,n). degrees integer vector c(p,q). b0 \\((m,n)\\) dimensional matrix (NULL). See details . sigma_L \\((n,n)\\) dimensional matrix (NULL). See details . digits integer, non NULL randomly generated numbers rounded \"digits\" number decimal places. bpoles lower bound moduli poles corresponding transfer function (NULL). bzeroes lower bound moduli zeroes corresponding tranmsfer function (NULL). parameter ignored non-square matrices (m != n). n.trials maximum number trials.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Test ARMA model — test_armamod","text":"armamod() object, represents generated ARMA model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Test ARMA model — test_armamod","text":"require \\(m>0\\) \\(p\\geq 0\\). \\(b_0\\) matrix defaults \\((m,n)\\)-dimensional diagonal matrix ones diagonal (diag(x=1, nrow = m, ncol = n)). However, one may also pass arbitray (compatible) matrix procedure. matrix may contain NA's, replaced random numbers. \\(sigma_L\\) matrix defaults \\((n,n)\\)-dimensional lower, triangular matrix However, one may also pass arbitrary (compatible) \\(sigma_L\\) matrix procedure. user may prescribe lower bounds moduli zeroes /poles transfer function $$k(z) = ^{-1}(z) b(z).$$ case procedure simply generates (n.trials) random models model found satisfies constraint. standard deviation normal distribution, used generate random entries, decreased step. course crude method may fail need large number randomly generated matrices.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_armamod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Test ARMA model — test_armamod","text":"","code":"### generate a random ARMA(1,1) model (with two outputs) ### we require that the model is stable and minimum phase model = try(test_armamod(dim = c(2,2), degrees = c(1,1), digits = 2, bpoles = 1, bzeroes = 1)) if (!inherits(model, 'try-error')) {    print(model)    print(abs(poles(model$sys)))    print(abs(zeroes(model$sys))) } #> ARMA model [2,2] with orders p = 1 and q = 1 #> AR polynomial a(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0     0.12 -0.11 #> [2,]        0     1     0.84 -0.27 #> MA polynomial b(z): #>      z^0 [,1]  [,2] z^1 [,1]  [,2] #> [1,]        1     0     0.01 -0.47 #> [2,]        0     1    -0.18 -0.01 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1] 1.98 0.00 #> u[2] 0.45 0.68 #> [1] 4.082483 4.082483 #> [1] 3.436041 3.436041"},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Test state space Model — test_stspmod","title":"Create Test state space Model — test_stspmod","text":"simple tool may used create random, state space model $$a_{t+1} = a_t + B u_t \\mbox{ } y_t = C a_t + D u_t.$$","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Test state space Model — test_stspmod","text":"","code":"test_stspmod(   dim = c(1, 1),   s = NULL,   nu = NULL,   D = NULL,   sigma_L = NULL,   digits = NULL,   bpoles = NULL,   bzeroes = NULL,   n.trials = 100 )"},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Test state space Model — test_stspmod","text":"dim integer vector c(m,n). s state dimension (NULL). nu vector Kronecker indices (NULL). Either state space dimension s Kronecker indices nu must non NULL. parameters given, parameter s ignored. D \\((m,n)\\) dimensional matrix (NULL). See details . sigma_L \\((n,n)\\) dimensional matrix (NULL). See details . digits integer, non NULL randomly generated numbers rounded \"digits\" number decimal places. bpoles lower bound moduli poles corresponding transfer function (NULL). bzeroes lower bound moduli zeroes corresponding tranmsfer function (NULL). parameter ignored non-square matrices (m != n). n.trials maximum number trials.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Test state space Model — test_stspmod","text":"stspmod() object, represents generated model.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Test state space Model — test_stspmod","text":"Kronecker indices (parameter nu) given, state space model echelon canonical form generated. means entries \\(,B,C\\) matrices fixed one zero others considerd \"free\". See also rationalmatrices::Kronecker-Indices(). entries \\(, B, C\\) matrices, priori fixed randomly generated. state dimension \\(s\\) (parameter s) given, entries \\(, B, C\\) matrices considered \"free\". \\(D\\) matrix defaults \\((m,n)\\)-dimensional diagonal matrix ones diagonal (diag(x=1, nrow = m, ncol = n)). However, one may also pass arbitray (compatible) \\(D\\) matrix procedure. matrix may contain NA's, replaced random numbers. \\(sigma_L\\) matrix defaults \\((n,n)\\)-dimensional lower, triangular matrix However, one may also pass arbitray (compatible) \\(sigma_L\\) matrix procedure. user may prescribe lower bounds moduli zeroes /poles transfer function $$k(z) = C(I_m z{-1} - )^{-1} B + D.$$ case procedure simply generates (n.trials) random models model found satisfies constraint. standard deviation normal distribution, used generate random entries, decreased step. course crude method may fail need large number randomly generated matrices. Note also, generated model may non-minimal.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/test_stspmod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Test state space Model — test_stspmod","text":"","code":"### random state space model with two outputs and state dimension s = 3 ### The model is required to be stable and minimum phase model = try(test_stspmod(dim = c(2,2), s = 3, digits = 2, bpoles = 1, bzeroes = 1)) if (!inherits(model, 'try-error')) {    print(model)    print(min(abs(poles(model$sys))) > 1)    print(min(abs(zeroes(model$sys))) > 1)    print(pseries2nu(pseries(model$sys, lag.max = 10))) # Kronecker indices } #> state space model [2,2] with s = 3 states #>       s[1]  s[2]  s[3]  u[1]  u[2] #> s[1]  0.11 -0.20  0.18 -0.14 -0.15 #> s[2] -0.42 -0.18  0.00 -0.89  0.42 #> s[3] -0.52 -0.07 -0.54  0.19 -0.08 #> x[1] -0.16  0.27 -0.38  1.00  0.00 #> x[2] -0.30  0.14  0.07  0.00  1.00 #> Left square root of noise covariance Sigma: #>      u[1] u[2] #> u[1] 1.23  0.0 #> u[2] 0.47  3.9 #> [1] TRUE #> [1] TRUE #> [1] 2 1  ### random state space model with three outputs and 2 inputs in echelon canonical form ### D is lower triangular (with ones on the diagonal) ### the model is required to stable (the transfer function has no poles within the unit circle) model = try(test_stspmod(dim = c(3, 2), nu = c(2,3,0),                          D = matrix(c(1,NA,NA,0,1,NA), nrow = 3, ncol = 2),                          digits = 2, bpoles = 1))  if (!inherits(model, 'try-error')) {    print(model)    print(min(abs(poles(model$sys))) > 1)    print(pseries2nu(pseries(model$sys, lag.max = 10))) # Kronecker indices } #> state space model [3,2] with s = 5 states #>       s[1]  s[2]  s[3]  s[4] s[5]  u[1]  u[2] #> s[1]  0.00  0.00  1.00  0.00 0.00  0.84 -0.44 #> s[2]  0.00  0.00  0.00  1.00 0.00 -0.26 -0.92 #> s[3] -0.30 -0.46  0.46 -0.03 0.00  0.98 -0.43 #> s[4]  0.00  0.00  0.00  0.00 1.00  0.49  0.44 #> s[5]  0.12  0.38 -0.50 -0.13 0.26  0.16  0.40 #> x[1]  1.00  0.00  0.00  0.00 0.00  1.00  0.00 #> x[2]  0.00  1.00  0.00  0.00 0.00 -0.33  1.00 #> x[3] -0.50 -0.56  0.00  0.00 0.00 -0.27  0.06 #> Left square root of noise covariance Sigma: #>       u[1] u[2] #> u[1]  1.09 0.00 #> u[2] -0.52 0.73 #> [1] TRUE #> [1] 2 3 0"},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":null,"dir":"Reference","previous_headings":"","what":"sigma_L Structure — tmpl_sigma_L","title":"sigma_L Structure — tmpl_sigma_L","text":"Create templates left square root \\(L\\) noise covariance matrix \\(\\Sigma = LL'\\). means \\(L\\) parametrized $$\\mbox{vec}(L) = h + H \\theta$$ (\\(k\\)-dimensional) parameter vector \\(\\theta\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"sigma_L Structure — tmpl_sigma_L","text":"","code":"tmpl_sigma_L(   sigma_L,   structure = c(\"as_given\", \"chol\", \"symm\", \"identity\", \"full_normalized\") )"},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"sigma_L Structure — tmpl_sigma_L","text":"sigma_L numeric (n x n) matrix, free entries coded NAs structure character string, determines \"structure\" sigma_L, see examples.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"sigma_L Structure — tmpl_sigma_L","text":"List slots h (\\(n^2\\)-dimensional vector), H (\\((n^2, k)\\)-dimensional matrix, \\(k\\) denotes number  free/deep parameters) n.par (integer) number free/deep parameters (\\(=k\\)).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"sigma_L Structure — tmpl_sigma_L","text":"parameter structure following meaning as_given Use given parameter sigma_L construct template: NA entries considered free entries fixed. chol Set entries sigma_L diagonal zero proceed . symm First make sigma_L symmetric (sigma_L = (sigma_L + t(sigma_L))/2) use sigma_L template. However, h, H constructed \\(h + H\\theta\\) gives symmetric matrix! Note NAs overwrite fixed values, see examples. identity Use identity matrix template. case free parameters, .e. \\(\\theta\\) empty vector (vector zero length). full_normalized Ones diagonal, otherwise parameters free.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/tmpl_sigma_L.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"sigma_L Structure — tmpl_sigma_L","text":"","code":"sigma_L = matrix(c(0, NA, 1, 0, 2, 3, NA, 1, 1), nrow = 3, ncol = 3) sigma_L #>      [,1] [,2] [,3] #> [1,]    0    0   NA #> [2,]   NA    2    1 #> [3,]    1    3    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'as_given') th = -(1:tmpl$n.par) matrix(tmpl$h + tmpl$H %*% th, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    0    0   -2 #> [2,]   -1    2    1 #> [3,]    1    3    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'chol') th = -(1:tmpl$n.par) matrix(tmpl$h + tmpl$H %*% th, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    0    0    0 #> [2,]   -1    2    0 #> [3,]    1    3    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'symm') th = -(1:tmpl$n.par) matrix(tmpl$h + tmpl$H %*% th, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    0   -1   -2 #> [2,]   -1    2    2 #> [3,]   -2    2    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'identity') tmpl$n.par # = 0 #> [1] 0 matrix(tmpl$h, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    0 #> [3,]    0    0    1  tmpl = tmpl_sigma_L(sigma_L, structure = 'full_normalized') th = -(1:tmpl$n.par) matrix(tmpl$h + tmpl$H %*% th, nrow = 3, ncol = 3) #>      [,1] [,2] [,3] #> [1,]    1   -3   -5 #> [2,]   -1    1   -6 #> [3,]   -2   -4    1"},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":null,"dir":"Reference","previous_headings":"","what":"Toeplitz Calculations — toepl_fwd","title":"Toeplitz Calculations — toepl_fwd","text":"Multiplication stacked data vector block Toeplitz matrix (toepl_fwd() MA calculations) \"inversion\" block Toeplitz matrix order perform calculations equivalent multiplying given stacked data vector inverse lower-triangular banded block Toeplitz matrix (toepl_inv() AR calculations). Note matrix polynomials can mapped one--one banded lower-triangular block Toeplitz matrices.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Toeplitz Calculations — toepl_fwd","text":"","code":"toepl_fwd(polm_wide, data_in, t0 = 1)  toepl_inv(polm_rev, data_in, t0 = 1)"},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Toeplitz Calculations — toepl_fwd","text":"polm_wide Wide matrix \\(( d_0, d_1, \\ldots, d_q )\\) dimension \\((m \\times (q+1) n)\\) represents matrix polynomial \\(d(z)\\) degree \\(q\\). data_in Data matrix dimension \\((dim(inputs) x nobs)\\). Every column corresponds one observation. t0 Integer. Time index calculations start. Default set 1. AR calculations, \\(degree + 1\\) another smart option. polm_rev Wide matrix \\((c_p, ... , c_1)\\) dimension \\((n \\times (q+1) n)\\) coefficients ordered reverse direction, zero-lag coefficient matrix included. represents square polynomial matrix \\(c(z)\\) \\(c_0\\) equal identity matrix degree \\(p\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Toeplitz Calculations — toepl_fwd","text":"data_out Data matrix dimension \\((dim_out x n_obs)\\)","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"ma-type-toeplitz-calculations","dir":"Reference","previous_headings":"","what":"MA-type Toeplitz calculations","title":"Toeplitz Calculations — toepl_fwd","text":"Given polynomial matrix degree \\(q\\) dimension \\((m \\times n)\\), \\(m \\geq n\\), given \"wide\" input data matrix dimension \\((n \\times nobs)\\), \\(nobs\\) number observations column corresponds one observation number columns equal number observations, calculate \"wide\" output data matrix dimension \\((m \\times nobs)\\). function name toepl_fwd stems multiplication \"stacked\" input data vector \\((u_1', \\ldots , u_{nobs}')'\\) banded lower-triangular block Toeplitz matrix \\(T\\) dimension \\((nobs m \\times nobs n)\\) whose block elements depend difference row- column-index  \\(T_{,j} = d_{-j}\\).","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"ar-type-toeplitz-calcuations","dir":"Reference","previous_headings":"","what":"AR-type Toeplitz calcuations","title":"Toeplitz Calculations — toepl_fwd","text":"Given square polynomial matrix \\(c(z)\\) \\(c_0\\) identity matrix given wide data matrix y = data_in, obtain solution u, wide data matrix, Toeplitz equation $$T (y_1', \\ldots , y_{nobs}')' =  (u_1', ... , u_{nobs}')'$$ Note zero-lag coefficient discarded coefficients reversed order since simplifies computations implementation.","code":""},{"path":"https://bfunovits.github.io/RLDM/reference/toepl_fwd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Toeplitz Calculations — toepl_fwd","text":"","code":"p = test_polm(dim = c(2,2), degree = 2) %>% unclass() dim(p) = c(2,2*3) data = matrix(rnorm(2*100), 2, 100) toepl_fwd(p, data) #>           [,1]     [,2]     [,3]     [,4]      [,5]      [,6]      [,7] #> [1,] -35.05413 122.4093 32.33197 23.40080 -140.9991 -278.3618 -200.0227 #> [2,] -76.43227 222.9411 50.03340 41.54931 -274.2953 -533.4930 -383.1974 #>           [,8]      [,9]     [,10]     [,11]      [,12]     [,13]     [,14] #> [1,] -334.3543 -144.0283 -172.2246 -62.33118  -52.97848 -357.9832 -476.9522 #> [2,] -630.8153 -263.9452 -306.7330 -99.81826 -102.07409 -676.3232 -892.9667 #>           [,15]     [,16]     [,17]     [,18]    [,19]    [,20]      [,21] #> [1,]  -550.2408 -487.1566 -261.5457 -31.29698 327.7533 160.8773  -74.33956 #> [2,] -1011.9046 -913.2394 -492.4754 -68.86695 617.8572 297.7309 -135.08121 #>           [,22]     [,23]     [,24]      [,25]     [,26]     [,27]     [,28] #> [1,]  -538.2684 -362.3175 -246.6079  -69.32463 -167.2260 -284.1703  4.744184 #> [2,] -1006.8516 -669.6878 -458.3411 -140.75320 -319.3051 -538.0137 17.135358 #>          [,29]    [,30]     [,31]     [,32]     [,33]     [,34]     [,35] #> [1,] -8.941897 278.0233 -1.321262  5.515009 -477.9331 -163.9486 -148.5204 #> [2,] -9.561806 535.7349  8.157037 41.975720 -865.6481 -282.8428 -267.5348 #>         [,36]     [,37]      [,38]     [,39]     [,40]     [,41]     [,42] #> [1,]  64.9754 -180.3866  -95.38995  69.43865 -105.7511 -167.1772 -49.16714 #> [2,] 126.0136 -321.1460 -168.31603 138.82349 -205.6106 -313.0978 -88.62185 #>          [,43]     [,44]     [,45]     [,46]     [,47]    [,48]     [,49] #> [1,]  74.49028 -189.2950 -366.3280 -453.4131 -360.1436 -227.108 -280.7616 #> [2,] 142.24321 -358.3924 -683.7868 -844.3438 -653.3827 -394.616 -498.7625 #>         [,50]      [,51]    [,52]     [,53]    [,54]      [,55]     [,56] #> [1,] 143.3409  -79.67451 262.6210 -27.24914 25.75118  -71.03016 -185.8742 #> [2,] 290.1269 -128.60668 495.5401 -48.07460 35.82062 -130.82488 -341.1189 #>          [,57]    [,58]    [,59]    [,60]      [,61]     [,62]    [,63] #> [1,] -139.0424 38.29507 225.8776 10.12065  -96.14332 -134.2067 324.5914 #> [2,] -242.0143 82.84753 423.7890 21.69106 -176.18104 -248.1971 600.6494 #>         [,64]    [,65]     [,66]     [,67]     [,68]     [,69]     [,70] #> [1,] 423.6956 486.8932  60.83966  84.12854 -237.4002 -150.8155 -259.8206 #> [2,] 784.9108 905.2350 116.80695 170.81842 -444.0290 -281.0863 -489.5001 #>          [,71]      [,72]     [,73]     [,74]     [,75]     [,76]     [,77] #> [1,] -130.4348  -89.34535 -199.0224 -449.5946 -403.4716 -162.5038  92.43052 #> [2,] -245.2253 -179.05775 -386.6744 -850.9120 -755.0332 -298.7031 165.56693 #>           [,78]     [,79]     [,80]    [,81]    [,82]    [,83]     [,84] #> [1,]  -66.60848 -239.6173 -334.5101 40.13898 15.59849 53.65836 -270.5573 #> [2,] -145.02136 -468.5950 -639.4135 73.45729 26.11279 91.01191 -506.8290 #>          [,85]      [,86]     [,87]     [,88]   [,89]     [,90]    [,91] #> [1,] -467.3606  -547.2691 -315.8910 -144.0754 1.16607  -49.5735 152.3350 #> [2,] -853.2599 -1010.3276 -574.6504 -270.8081 3.63942 -101.7371 276.5421 #>         [,92]    [,93]     [,94]     [,95]     [,96]    [,97]    [,98] #> [1,] 290.6325 130.1955 -165.4963 -154.2781  63.37445 242.1052 18.35597 #> [2,] 539.5531 253.9921 -294.0088 -274.6314 124.42711 446.8419 18.31746 #>          [,99]    [,100] #> [1,] -153.1036 -145.7916 #> [2,] -297.8760 -279.9255 p = test_polm(dim = c(2,2), degree = 2) %>% unclass() dim(p) = c(2,2*3) data = matrix(rnorm(2*100), 2, 100) toepl_inv(p, data) #>           [,1]      [,2]     [,3]      [,4]        [,5]          [,6] #> [1,] 0.9016598 -159.4440 54002.21 -18141220  6094977884 -2.047751e+12 #> [2,] 0.4787514 -297.5516 99561.62 -33452043 11238993461 -3.776004e+12 #>              [,7]          [,8]         [,9]         [,10]        [,11] #> [1,] 6.879902e+14 -2.311465e+17 7.765911e+19 -2.609141e+22 8.766022e+24 #> [2,] 1.268638e+15 -4.262286e+17 1.432015e+20 -4.811193e+22 1.616434e+25 #>              [,12]        [,13]         [,14]        [,15]         [,16] #> [1,] -2.945151e+27 9.894929e+29 -3.324434e+32 1.116922e+35 -3.752562e+37 #> [2,] -5.430789e+27 1.824601e+30 -6.130178e+32 2.059577e+35 -6.919635e+37 #>             [,17]         [,18]        [,19]         [,20]        [,21] #> [1,] 1.260762e+40 -4.235825e+42 1.423125e+45 -4.781324e+47 1.606398e+50 #> [2,] 2.324814e+40 -7.810761e+42 2.624209e+45 -8.816647e+47 2.962160e+50 #>              [,22]        [,23]         [,24]        [,25]         [,26] #> [1,] -5.397073e+52 1.813274e+55 -6.092120e+57 2.046791e+60 -6.876677e+62 #> [2,] -9.952074e+52 3.343634e+55 -1.123372e+58 3.774234e+60 -1.268043e+63 #>             [,27]         [,28]        [,29]         [,30]        [,31] #> [1,] 2.310381e+65 -7.762270e+67 2.607917e+70 -8.761912e+72 2.943771e+75 #> [2,] 4.260288e+65 -1.431344e+68 4.808937e+70 -1.615676e+73 5.428243e+75 #>              [,32]        [,33]         [,34]        [,35]         [,36] #> [1,] -9.890290e+77 3.322876e+80 -1.116398e+83 3.750803e+85 -1.260170e+88 #> [2,] -1.823746e+78 6.127303e+80 -2.058612e+83 6.916391e+85 -2.323724e+88 #>             [,37]         [,38]        [,39]         [,40]         [,41] #> [1,] 4.233839e+90 -1.422458e+93 4.779082e+95 -1.605645e+98 5.394543e+100 #> [2,] 7.807099e+90 -2.622979e+93 8.812514e+95 -2.960771e+98 9.947408e+100 #>               [,42]         [,43]          [,44]         [,45]          [,46] #> [1,] -1.812424e+103 6.089264e+105 -2.045832e+108 6.873453e+110 -2.309298e+113 #> [2,] -3.342066e+103 1.122846e+106 -3.772465e+108 1.267448e+111 -4.258291e+113 #>              [,47]          [,48]         [,49]          [,50]         [,51] #> [1,] 7.758631e+115 -2.606695e+118 8.757804e+120 -2.942390e+123 9.885653e+125 #> [2,] 1.430673e+116 -4.806683e+118 1.614918e+121 -5.425698e+123 1.822891e+126 #>               [,52]         [,53]          [,54]         [,55]          [,56] #> [1,] -3.321318e+128 1.115875e+131 -3.749044e+133 1.259580e+136 -4.231854e+138 #> [2,] -6.124431e+128 2.057647e+131 -6.913148e+133 2.322635e+136 -7.803438e+138 #>              [,57]          [,58]         [,59]          [,60]         [,61] #> [1,] 1.421791e+141 -4.776842e+143 1.604892e+146 -5.392014e+148 1.811574e+151 #> [2,] 2.621749e+141 -8.808382e+143 2.959383e+146 -9.942745e+148 3.340499e+151 #>               [,62]         [,63]          [,64]         [,65]          [,66] #> [1,] -6.086409e+153 2.044872e+156 -6.870230e+158 2.308215e+161 -7.754993e+163 #> [2,] -1.122319e+154 3.770696e+156 -1.266854e+159 4.256294e+161 -1.430002e+164 #>              [,67]          [,68]         [,69]          [,70]         [,71] #> [1,] 2.605472e+166 -8.753698e+168 2.941011e+171 -9.881018e+173 3.319761e+176 #> [2,] 4.804429e+166 -1.614161e+169 5.423154e+171 -1.822036e+174 6.121559e+176 #>               [,72]         [,73]          [,74]        [,75]          [,76] #> [1,] -1.115352e+179 3.747287e+181 -1.258989e+184 4.22987e+186 -1.421124e+189 #> [2,] -2.056682e+179 6.909907e+181 -2.321546e+184 7.79978e+186 -2.620520e+189 #>              [,77]          [,78]         [,79]          [,80]         [,81] #> [1,] 4.774602e+191 -1.604140e+194 5.389486e+196 -1.810725e+199 6.083555e+201 #> [2,] 8.804252e+191 -2.957996e+194 9.938083e+196 -3.338933e+199 1.121793e+202 #>               [,82]         [,83]          [,84]         [,85]          [,86] #> [1,] -2.043914e+204 6.867009e+206 -2.307133e+209 7.751357e+211 -2.604251e+214 #> [2,] -3.768928e+204 1.266260e+207 -4.254299e+209 1.429332e+212 -4.802176e+214 #>              [,87]          [,88]         [,89]          [,90]         [,91] #> [1,] 8.749594e+216 -2.939632e+219 9.876385e+221 -3.318204e+224 1.114829e+227 #> [2,] 1.613404e+217 -5.420611e+219 1.821182e+222 -6.118689e+224 2.055718e+227 #>               [,92]         [,93]          [,94]         [,95]          [,96] #> [1,] -3.745530e+229 1.258399e+232 -4.227887e+234 1.420458e+237 -4.772364e+239 #> [2,] -6.906667e+229 2.320457e+232 -7.796123e+234 2.619291e+237 -8.800125e+239 #>              [,97]          [,98]         [,99]         [,100] #> [1,] 1.603388e+242 -5.386959e+244 1.809876e+247 -6.080703e+249 #> [2,] 2.956609e+242 -9.933424e+244 3.337367e+247 -1.121267e+250"}]
