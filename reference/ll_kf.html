<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Gaussian log Likelihood of a State Space Model — ll_kf • RLDM</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Gaussian log Likelihood of a State Space Model — ll_kf"><meta name="description" content="These routines compute the log Likelihood for time invariant, linear state space models of the form
$$a_{t+1} = A a_t + Bu_t$$
$$y_t = C a_t + Du_t$$
with \(m\)-dimensional outputs \(y_t\), \(s\)-dimensional states
\(a_t\) and \(n\)-dimensional disturbances \(u_t\).
The disturbances are white noise with a covariance matrix
\(\mathbf{E} u_t u_t'=\Sigma\).
Note that the disturbances and the outputs may have different dimensions, however,
only &quot;wide&quot; systems with (\(m\leq n\)) are implemented.
The Gaussian log likelihood (for the case of Gaussian disturbances
\(u_t\sim N(0,\Sigma)\) and
\(a_1\sim N(a_{1|0},\Pi_{1|0})\)) here is computed by the
standard Kalman Filter or the square root Kalman filter, see kf().
The Kalman filter is a recursive
scheme to compute the linear, least squares predictions
for \(a_{t+1}\) and \(y_{t+1}\) given the observations
\(y_t,\ldots,y_1\) up to time \(t\). These predictions are notated with
\(a_{t+1|t}\) and \(y_{t+1|t}\), the
prediction error for the output \(y_{t+1}\) is
\(\epsilon_{t+1|t}=(y_{t+1}-y_{t+1|t})\)
and the corresponding variances of the prediction errors are
$$\Pi_{t+1|t}=\mathbf{E}(a_{t+1}-a_{t+1|t})
(a_{t+1}-a_{t+1|t})',$$
$$\Sigma_{t+1|t}=\mathbf{E}(\epsilon_{t+1|t}
\epsilon_{t+1|t}').$$
The standard form of the Kalman filter is based on the parameter matrices \(A,C\), the variance of
&quot;state disturbances&quot;
\(Q=\mathbf{E}(Bu_t (Bu_t)')=(B\Sigma B')\), the variance
of the &quot;measurement disturbances&quot;
\(R=\mathbf{E}(Du_t (Du_t)')=(D\Sigma D')\) and the covariance
\(S=\mathbf{E}(Bu_t(Du_t)')=(B\Sigma D')\).
Furthermore we need the initial prediction
\(a_{1|0}\) and the corresponding error variance
\(\Pi_{1|0}\).
For the square root form of the filter we need the &quot;square roots&quot;
\(\Pi_{1|0}^{1/2}\) and \(\Sigma^{1/2}\), i.e. matrices such that
\(\Pi_{1|0} = \Pi_{1|0}^{1/2} (\Pi_{1|0}^{1/2})'\)
and \(\Sigma = \Sigma^{1/2}(\Sigma^{1/2})'\). In addition, we define
\(H=(D',B')'\Sigma^{1/2}\).
The (scaled) Gaussian log Likelihood of this model then may be expressed as
$$\frac{-1}{2N}\sum_{t=1}^{N}\left(m\log(2\pi) + \log\det\Sigma_{t|t-1} +
          (y_t - y_{t|t-1})' \Sigma_{t|t-1}^{-1} (y_t - y_{t|t-1}) \right).$$"><meta property="og:description" content="These routines compute the log Likelihood for time invariant, linear state space models of the form
$$a_{t+1} = A a_t + Bu_t$$
$$y_t = C a_t + Du_t$$
with \(m\)-dimensional outputs \(y_t\), \(s\)-dimensional states
\(a_t\) and \(n\)-dimensional disturbances \(u_t\).
The disturbances are white noise with a covariance matrix
\(\mathbf{E} u_t u_t'=\Sigma\).
Note that the disturbances and the outputs may have different dimensions, however,
only &quot;wide&quot; systems with (\(m\leq n\)) are implemented.
The Gaussian log likelihood (for the case of Gaussian disturbances
\(u_t\sim N(0,\Sigma)\) and
\(a_1\sim N(a_{1|0},\Pi_{1|0})\)) here is computed by the
standard Kalman Filter or the square root Kalman filter, see kf().
The Kalman filter is a recursive
scheme to compute the linear, least squares predictions
for \(a_{t+1}\) and \(y_{t+1}\) given the observations
\(y_t,\ldots,y_1\) up to time \(t\). These predictions are notated with
\(a_{t+1|t}\) and \(y_{t+1|t}\), the
prediction error for the output \(y_{t+1}\) is
\(\epsilon_{t+1|t}=(y_{t+1}-y_{t+1|t})\)
and the corresponding variances of the prediction errors are
$$\Pi_{t+1|t}=\mathbf{E}(a_{t+1}-a_{t+1|t})
(a_{t+1}-a_{t+1|t})',$$
$$\Sigma_{t+1|t}=\mathbf{E}(\epsilon_{t+1|t}
\epsilon_{t+1|t}').$$
The standard form of the Kalman filter is based on the parameter matrices \(A,C\), the variance of
&quot;state disturbances&quot;
\(Q=\mathbf{E}(Bu_t (Bu_t)')=(B\Sigma B')\), the variance
of the &quot;measurement disturbances&quot;
\(R=\mathbf{E}(Du_t (Du_t)')=(D\Sigma D')\) and the covariance
\(S=\mathbf{E}(Bu_t(Du_t)')=(B\Sigma D')\).
Furthermore we need the initial prediction
\(a_{1|0}\) and the corresponding error variance
\(\Pi_{1|0}\).
For the square root form of the filter we need the &quot;square roots&quot;
\(\Pi_{1|0}^{1/2}\) and \(\Sigma^{1/2}\), i.e. matrices such that
\(\Pi_{1|0} = \Pi_{1|0}^{1/2} (\Pi_{1|0}^{1/2})'\)
and \(\Sigma = \Sigma^{1/2}(\Sigma^{1/2})'\). In addition, we define
\(H=(D',B')'\Sigma^{1/2}\).
The (scaled) Gaussian log Likelihood of this model then may be expressed as
$$\frac{-1}{2N}\sum_{t=1}^{N}\left(m\log(2\pi) + \log\det\Sigma_{t|t-1} +
          (y_t - y_{t|t-1})' \Sigma_{t|t-1}^{-1} (y_t - y_{t|t-1}) \right).$$"><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">RLDM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9006</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/0_getting_started.html">Getting Started with RLDM</a></li>
    <li><a class="dropdown-item" href="../articles/1_case_study.html">Case Study: Economic Data Analysis with RLDM</a></li>
    <li><a class="dropdown-item" href="../articles/2_technical_reference.html">Technical Reference: RLDM Classes and Methods</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/bfunovits/RLDM/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Gaussian log Likelihood of a State Space Model</h1>

      <div class="d-none name"><code>ll_kf.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>These routines compute the log Likelihood for time invariant, linear state space models of the form
$$a_{t+1} = A a_t + Bu_t$$
$$y_t = C a_t + Du_t$$
with \(m\)-dimensional outputs \(y_t\), \(s\)-dimensional states
\(a_t\) and \(n\)-dimensional disturbances \(u_t\).
The disturbances are white noise with a covariance matrix
\(\mathbf{E} u_t u_t'=\Sigma\).
Note that the disturbances and the outputs may have <em>different</em> dimensions, however,
only "wide" systems with (\(m\leq n\)) are implemented.</p>
<p>The Gaussian log likelihood (for the case of Gaussian disturbances
\(u_t\sim N(0,\Sigma)\) and
\(a_1\sim N(a_{1|0},\Pi_{1|0})\)) here is computed by the
standard Kalman Filter or the square root Kalman filter, see <code><a href="kf.html">kf()</a></code>.
The Kalman filter is a recursive
scheme to compute the linear, least squares predictions
for \(a_{t+1}\) and \(y_{t+1}\) given the observations
\(y_t,\ldots,y_1\) up to time \(t\). These predictions are notated with
\(a_{t+1|t}\) and \(y_{t+1|t}\), the
prediction error for the output \(y_{t+1}\) is
\(\epsilon_{t+1|t}=(y_{t+1}-y_{t+1|t})\)
and the corresponding variances of the prediction errors are
$$\Pi_{t+1|t}=\mathbf{E}(a_{t+1}-a_{t+1|t})
(a_{t+1}-a_{t+1|t})',$$
$$\Sigma_{t+1|t}=\mathbf{E}(\epsilon_{t+1|t}
\epsilon_{t+1|t}').$$</p>
<p>The standard form of the Kalman filter is based on the parameter matrices \(A,C\), the variance of
"state disturbances"
\(Q=\mathbf{E}(Bu_t (Bu_t)')=(B\Sigma B')\), the variance
of the "measurement disturbances"
\(R=\mathbf{E}(Du_t (Du_t)')=(D\Sigma D')\) and the covariance
\(S=\mathbf{E}(Bu_t(Du_t)')=(B\Sigma D')\).
Furthermore we need the initial prediction
\(a_{1|0}\) and the corresponding error variance
\(\Pi_{1|0}\).</p>
<p>For the square root form of the filter we need the "square roots"
\(\Pi_{1|0}^{1/2}\) and \(\Sigma^{1/2}\), i.e. matrices such that
\(\Pi_{1|0} = \Pi_{1|0}^{1/2} (\Pi_{1|0}^{1/2})'\)
and \(\Sigma = \Sigma^{1/2}(\Sigma^{1/2})'\). In addition, we define
\(H=(D',B')'\Sigma^{1/2}\).</p>
<p>The (scaled) Gaussian log Likelihood of this model then may be expressed as
$$\frac{-1}{2N}\sum_{t=1}^{N}\left(m\log(2\pi) + \log\det\Sigma_{t|t-1} +
          (y_t - y_{t|t-1})' \Sigma_{t|t-1}^{-1} (y_t - y_{t|t-1}) \right).$$</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">ll_kf</span><span class="op">(</span><span class="va">model</span>, <span class="va">y</span>, method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"kf"</span>, <span class="st">"kf2"</span><span class="op">)</span>, P1 <span class="op">=</span> <span class="cn">NULL</span>, a1 <span class="op">=</span> <span class="cn">NULL</span>, tol <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-model">model<a class="anchor" aria-label="anchor" href="#arg-model"></a></dt>
<dd><p><code><a href="stspmod.html">stspmod()</a></code> object, which represents the state space model.</p></dd>


<dt id="arg-y">y<a class="anchor" aria-label="anchor" href="#arg-y"></a></dt>
<dd><p>sample, i.e. an \((N,m)\) dimensional matrix,
or a "time series" object (i.e. <code>as.matrix(y)</code> should return an
\((N,m)\)-dimensional numeric matrix). Missing values (<code>NA</code>, <code>NaN</code> and
<code>Inf</code>) are <strong>not</strong> supported.</p></dd>


<dt id="arg-method">method<a class="anchor" aria-label="anchor" href="#arg-method"></a></dt>
<dd><p>Character string. If <code>method="kf"</code> then <code>ll_kf</code> calls
the internal C++ implementation ("standard form" of the Kalman filter) and for
<code>method="kf2"</code> the "square root" form of the Kalman filter is used,
i.e. the internal square root implementation is called. Up to numerical errors the outputs should not
depend on the chosen method.</p></dd>


<dt id="arg-p-">P1<a class="anchor" aria-label="anchor" href="#arg-p-"></a></dt>
<dd><p>\((s,s)\) dimensional covariance matrix of the error of the initial state estimate,
i.e. \(\Pi_{1|0}\).
If <code>NULL</code>, then the state covariance \(P = APA'+B\Sigma B'\) is used.
Note that this scheme assumes that the state space model is stable,
i.e. that the state transition matrix \(A\) is stable.</p></dd>


<dt id="arg-a-">a1<a class="anchor" aria-label="anchor" href="#arg-a-"></a></dt>
<dd><p>\(s\) dimensional vector, which holds the initial estimate \(a_{1|0}\)
for the state at time \(t=1\).  If <code>a1=NULL</code>, then a zero vector is used.</p></dd>


<dt id="arg-tol">tol<a class="anchor" aria-label="anchor" href="#arg-tol"></a></dt>
<dd><p>(small) tolerance value (or zero). In order to speed up the computations,
the algorithm(s) switch to a constant Kalman gain when there is no significant change in
state error covariance. This behavior is controlled by the parameter <code>tol</code> and
may be switched off by setting <code>tol=0</code>.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>(double) The Gaussian log Likelihood of the model.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>The core routines are internal C++ implementations (<code>ll_kf_cpp</code> and <code>ll_kf2_cpp</code>) which are <span class="pkg">RcppArmadillo</span> implementations
of the standard and the square root Kalman filter. The function <code>ll_kf</code> is a wrapper function,
which extracts the necessary parameters from an <code><a href="stspmod.html">stspmod()</a></code> object,
computes the initial covariance matrix <code>P1</code> and the initial state
estimate <code>a1</code> (if not provided) and then calls the internal C++ implementations.</p>
<p>Square root Kalman filter: For the square root
\(\Pi_{1|0}^{1/2}\) the procedure first tries the Cholesky decomposition.
If this fails (since \(\Pi_{1|0}^{1/2}\) is (close to) singular),
then <code>ll_kf</code> tries to compute a symmetric square root via the eigenvalue decomposition
of \(\Pi_{1|0}^{1/2}\).</p>
    </div>
    <div class="section level2">
    <h2 id="notes">Notes<a class="anchor" aria-label="anchor" href="#notes"></a></h2>



<p>The procedures only accept "wide" state space systems (\(m \leq n\)), since for
"tall" systems (\(m &gt; n\)) the variance of the prediction errors
(\(\Sigma_{t+1|t}\)) is singular for \(t\) larger than some threshold.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="kf.html">kf()</a></code> for computation of the predictions \(a_{t+1|t}\) and
\(y_{t+1|t}\).</p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">s</span> <span class="op">=</span> <span class="fl">4</span>  <span class="co"># state dimension</span></span></span>
<span class="r-in"><span><span class="va">m</span> <span class="op">=</span> <span class="fl">2</span>  <span class="co"># number of outputs</span></span></span>
<span class="r-in"><span><span class="va">n</span> <span class="op">=</span> <span class="va">m</span>  <span class="co"># number of inputs (square case m=n)</span></span></span>
<span class="r-in"><span><span class="va">n.obs</span> <span class="op">=</span> <span class="fl">100</span> <span class="co"># sample size</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># generate a (stable) state space model (in innovation form)</span></span></span>
<span class="r-in"><span><span class="va">tmpl</span> <span class="op">=</span> <span class="fu"><a href="model_structures.html">tmpl_stsp_full</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">n</span>, <span class="va">s</span>, sigma_L <span class="op">=</span> <span class="st">"chol"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="r_model.html">r_model</a></span><span class="op">(</span><span class="va">tmpl</span>, bpoles <span class="op">=</span> <span class="fl">1</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># generate a sample</span></span></span>
<span class="r-in"><span><span class="va">data</span> <span class="op">=</span> <span class="fu"><a href="sim.html">sim</a></span><span class="op">(</span><span class="va">model</span>, n.obs <span class="op">=</span> <span class="va">n.obs</span>, a1 <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># compute Q, R, S and P1</span></span></span>
<span class="r-in"><span><span class="va">sigma_L</span> <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">sigma_L</span></span></span>
<span class="r-in"><span><span class="va">sigma</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">tcrossprod</a></span><span class="op">(</span><span class="va">sigma_L</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">R</span> <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">D</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">sigma</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">D</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">S</span> <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">B</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">sigma</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">D</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">Q</span> <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">B</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">sigma</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">B</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">P1</span> <span class="op">=</span> <span class="fu"><a href="https://bfunovits.github.io/rationalmatrices/reference/lyapunov.html" class="external-link">lyapunov</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">A</span>, <span class="va">Q</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># compute H and square root of P1</span></span></span>
<span class="r-in"><span><span class="va">H</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">D</span>, <span class="va">model</span><span class="op">$</span><span class="va">sys</span><span class="op">$</span><span class="va">B</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">sigma_L</span></span></span>
<span class="r-in"><span><span class="va">P1_R</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/chol.html" class="external-link">chol</a></span><span class="op">(</span><span class="va">P1</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># compute logLikelihood (via Kalman Filter)</span></span></span>
<span class="r-in"><span><span class="va">ll</span> <span class="op">=</span> <span class="fu">ll_kf</span><span class="op">(</span><span class="va">model</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># compute logLikelihood (via square root Kalman Filter)</span></span></span>
<span class="r-in"><span><span class="va">ll_test</span> <span class="op">=</span> <span class="fu">ll_kf</span><span class="op">(</span><span class="va">model</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span>, method <span class="op">=</span> <span class="st">'kf2'</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html" class="external-link">all.equal</a></span><span class="op">(</span><span class="va">ll</span>, <span class="va">ll_test</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] TRUE</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Note: ll_kf_cpp and ll_kf2_cpp are internal C++ implementations</span></span></span>
<span class="r-in"><span><span class="co"># called via .Call() by ll_kf()</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># call the "full" kf routines</span></span></span>
<span class="r-in"><span><span class="va">out</span> <span class="op">=</span> <span class="fu"><a href="kf.html">kf</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html" class="external-link">all.equal</a></span><span class="op">(</span><span class="va">ll</span>, <span class="va">out</span><span class="op">$</span><span class="va">ll</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] TRUE</span>
<span class="r-in"><span><span class="va">out</span> <span class="op">=</span> <span class="fu"><a href="kf.html">kf</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span>, method <span class="op">=</span> <span class="st">'kf2'</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html" class="external-link">all.equal</a></span><span class="op">(</span><span class="va">ll</span>, <span class="va">out</span><span class="op">$</span><span class="va">ll</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] TRUE</span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://scholar.google.com/citations?user=-Ytb9BYAAAAJ" class="external-link">Wolfgang Scherrer</a>, <a href="https://ch.linkedin.com/in/bernd-funovits-phd-cfa-a8215016" class="external-link">Bernd Funovits</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>

