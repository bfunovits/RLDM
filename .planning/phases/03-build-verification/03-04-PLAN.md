---
phase: 03-build-verification
plan: 04
type: execute
wave: 1
depends_on: ["03-03"]
files_modified: ["tests/testthat/test-pfilter.R", "tests/testthat/helper-test-setup.R", ".planning/phases/03-build-verification/test-fix-analysis.md"]
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Test failures are addressed (pfilter test either passes or is properly skipped)"
    - "Test infrastructure issues are documented as known limitations"
    - "Package check runs with 0 test errors (or test errors are properly handled)"
  artifacts:
    - path: "tests/testthat/test-pfilter.R"
      provides: "Fixed or properly handled test infrastructure issues"
      contains: ["skip_if() for known issues", "proper test setup", "clear failure messages"]
    - path: ".planning/phases/03-build-verification/test-fix-analysis.md"
      provides: "Analysis of test failures and resolution strategy"
      min_lines: 10
    - path: ".planning/phases/03-build-verification/check-tests.log"
      provides: "Test check results after fixes"
      min_lines: 20
  key_links:
    - from: "test setup code"
      to: "test environment"
      via: "helper files and setup functions"
      pattern: "testthat::setup|testthat::teardown"
    - from: "test expectations"
      to: "actual test results"
      via: "testthat assertions"
      pattern: "expect_|testthat::"
    - from: "test infrastructure documentation"
      to: "STATE.md blockers"
      via: "known issues tracking"
      pattern: "known issue|test infrastructure"
---

<objective>
Address test infrastructure failures identified in build verification gaps, specifically the pfilter test failure that prevents BUILD-01 (0 errors).

Purpose: Either fix the test infrastructure issue (tmpl_stsp_full not found in test context) or properly document/skip it as a known limitation. Ensure package check can run with 0 test errors or properly handled test failures.
Output: Test suite that either passes or has properly documented/skipped failures; analysis of test infrastructure issues for future resolution.
</objective>

<execution_context>
@/home/bernd/.claude/get-shit-done/workflows/execute-plan.md
@/home/bernd/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-build-verification/03-VERIFICATION.md
@.planning/phases/03-build-verification/03-02-SUMMARY.md

# Test failure from check-final.log:
# "Failure ('test-pfilter.R:255:3'): optimal proposal performs well with cross-covariance"
# Error: rmse < 0.5 is not TRUE
#
# Known issue from STATE.md: "Test infrastructure: pfilter tests fail due to test environment setup issues (`tmpl_stsp_full` not found in test context)"
#
# Need to investigate: Is this a test infrastructure issue (function not available) or a genuine test failure?
</context>

<tasks>

<task type="auto">
  <name>Task 1: Analyze test failure and reproduce issue</name>
  <files>tests/testthat/test-pfilter.R, .planning/phases/03-build-verification/test-fix-analysis.md</files>
  <action>
1. **Reproduce test failure:**
   - Run specific failing test: `testthat::test_file("tests/testthat/test-pfilter.R", filter = "optimal proposal performs well")`
   - Capture full error output and traceback
   - Check if `tmpl_stsp_full` is available in test environment

2. **Analyze test infrastructure:**
   - Check test setup: Look for `tests/testthat/helper-*.R` or setup files
   - Check if `tmpl_stsp_full` needs to be imported or made available
   - Examine test environment vs. package environment differences

3. **Examine the failing test (line 255):**
   - What is the test trying to do?
   - Is `rmse < 0.5` a reasonable expectation?
   - Is this a stochastic test that might fail occasionally?

4. **Document analysis in test-fix-analysis.md:**
   - Root cause: test infrastructure vs. genuine failure
   - Recommended fix: fix test vs. skip vs. adjust expectations
   - Impact on BUILD-01 requirement
  </action>
  <verify>Create test-fix-analysis.md with: 1) Error reproduction, 2) Root cause analysis, 3) Recommended solution.</verify>
  <done>Test failure is understood and documented with clear reproduction steps and analysis.</done>
</task>

<task type="auto">
  <name>Task 2: Implement test fix or proper handling</name>
  <files>tests/testthat/test-pfilter.R, tests/testthat/helper-test-setup.R</files>
  <action>
Based on analysis from Task 1, implement appropriate fix:

**Option A: Fix test infrastructure (if `tmpl_stsp_full` not available):**
1. Check if `tmpl_stsp_full` needs to be imported in test environment
2. Add necessary imports to test setup: `library(RLDM)` or specific function imports
3. Ensure test environment matches package environment

**Option B: Fix test expectations (if test is too strict):**
1. Adjust `rmse < 0.5` threshold if it's too strict for stochastic test
2. Use `testthat::skip_on_cran()` or `skip_if()` for flaky tests
3. Add seed setting for reproducibility

**Option C: Skip test with proper documentation (if genuine infrastructure issue):**
1. Add `skip_if_not()` or `skip()` with clear message
2. Document as known limitation in test file
3. Reference STATE.md blocker

**Implementation steps:**
1. Modify test-pfilter.R based on chosen option
2. If adding imports/setup, update helper-test-setup.R
3. Ensure fix addresses the specific failure at line 255
4. Consider if other tests might have similar issues

**Test the fix:**
1. Run the specific test again: `testthat::test_file("tests/testthat/test-pfilter.R", filter = "optimal proposal")`
2. Verify it either passes or is properly skipped
3. Check no new issues introduced
  </action>
  <verify>Run failing test specifically and verify it either passes or is properly skipped with informative message.</verify>
  <done>Test either passes with fix or is properly skipped with documentation; no "Error: Test failures" in test output.</done>
</task>

<task type="auto">
  <name>Task 3: Run test verification and update documentation</name>
  <files>.planning/phases/03-build-verification/check-tests.log, .planning/STATE.md</files>
  <action>
1. **Run comprehensive test check:**
   - `devtools::test(filter = "pfilter")` - run all pfilter tests
   - Save output to `.planning/phases/03-build-verification/check-tests.log`
   - Verify all tests pass or are properly skipped

2. **Run full test suite:**
   - `devtools::test()` - run all package tests
   - Check for any other test failures
   - Document any additional issues found

3. **Update STATE.md blockers:**
   - If test infrastructure issue is resolved, update blocker status
   - If test is skipped as known limitation, document in STATE.md
   - Add reference to test-fix-analysis.md for future work

4. **Verify BUILD-01 impact:**
   - Check if test error count in `devtools::check()` is reduced
   - Document remaining test issues (if any)
   - Prepare for final verification in Plan 03-05
  </action>
  <verify>check-tests.log shows 0 test failures (or properly skipped tests); STATE.md updated with current test status.</verify>
  <done>Test suite runs without errors; test infrastructure issues are either resolved or properly documented as known limitations.</done>
</task>

</tasks>

<verification>
1. Run `testthat::test_file("tests/testthat/test-pfilter.R")` - should show 0 failures (or properly skipped tests)
2. Check `check-tests.log` for test execution results
3. Verify STATE.md accurately reflects test infrastructure status
4. Test error should not appear in `devtools::check()` output
</verification>

<success_criteria>
- [ ] pfilter test either passes or is properly skipped with informative message
- [ ] `devtools::test()` runs with 0 failures (or properly handled skips)
- [ ] test-fix-analysis.md documents root cause and resolution
- [ ] STATE.md updated with current test infrastructure status
- [ ] Package check shows 0 test errors (or test errors properly handled)
</success_criteria>

<output>
After completion, create `.planning/phases/03-build-verification/03-04-SUMMARY.md` documenting test infrastructure fixes and remaining known limitations.
</output>
