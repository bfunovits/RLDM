---
title: "Case Study: Economic Data Analysis with RLDM"
subtitle: "Blanchard-Quah Dataset Analysis"
author: "Wolfgang Scherrer and Bernd Funovits"
date: "`r Sys.Date()`"
bibliography: ../inst/REFERENCES.bib
output:
  rmarkdown::html_vignette:
    fig_width: 7
    fig_height: 5
    toc: yes
    toc_depth: 2
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Case Study: Economic Data Analysis with RLDM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)

library(dplyr)
library(lubridate)
library(RLDM)
library(kableExtra)
library(xts)
```

# Introduction and Research Question

## The Blanchard-Quah Dataset

This case study analyzes quarterly US economic data on **real GDP growth rates** and **detrended unemployment rates** from the Blanchard-Quah (1989) study. The research question is:

> **What underlying shocks drive GDP growth and unemployment, and how do they interact?**

This is a classic question in macroeconomics: separating supply shocks (which permanently affect output) from demand shocks (which temporarily affect unemployment and growth).

## Methods Overview

In this analysis, we'll compare several estimation approaches to find the model that best captures these relationships:

1. **AR Models** (baseline) - Simple autoregressive models
2. **State Space Models** - Flexible representations with different estimation algorithms
3. **ARMA Models** - Parsimonious alternatives combining AR and MA terms

Each method has different strengths, and we'll compare their performance systematically.

# Data Preparation and Visualization

```{r, fig.alt="Time series plot showing quarterly US GDP growth rate and unemployment rate data from approximately 1950 to 2010, with a vertical blue line marking the train/test split at 1970"}
# Load the Blanchard-Quah dataset
y = BQdata_xts

# Define split point for train/test
break_date = as_date("1970-01-01")

y_train = BQdata_xts[index(BQdata_xts) < break_date]
y_test  = BQdata_xts[index(BQdata_xts) >= break_date]
dim_out = ncol(y_train)

# Visualize the data
plot(y)
addLegend('topleft', c('GDP growth rate', 'Unemployment rate'),
          col = c('black', 'red'), lwd = 2, bty = 'n')
addEventLines(xts("Train/Test Split", break_date), col = 'blue', on = NA)
```

**Data Summary:**
- Total observations: `r nrow(y)` quarters from `r start(y)` to `r end(y)`
- Training set: `r nrow(y_train)` observations (for model estimation)
- Test set: `r nrow(y_test)` observations (for out-of-sample validation)
- Variables: GDP growth rate and unemployment rate (both standardized to unit variance)

# Baseline: AR Models

## What are AR Models?

**Autoregressive (AR) models** form the simplest baseline for comparison. An AR(p) model expresses each variable as a linear combination of its past p values plus white noise:

$$y_t = a_1 y_{t-1} + \cdots + a_p y_{t-p} + u_t$$

**When to use:**
- Understanding basic dynamics and lag structure
- Quick baseline for model comparison
- When you need interpretable, simple models
- Automatic order selection via AIC

For multivariate data, we estimate a **VAR(p)** model which treats each variable as AR with cross-variable dependencies.

## Estimation

The `est_ar()` function uses Yule-Walker estimation (statistically efficient) with automatic order selection:

```{r, fig.alt="Two-panel time series plot showing: top panel - model selection statistics (AIC, BIC, etc.) for different VAR orders; bottom panel - log-likelihood values across AR orders"}
# Estimate AR model with automatic order selection
out = est_ar(y_train, mean_estimate = 'zero')

# View available outputs
cat("Output components:\n")
cat(paste(names(out), collapse = ", "), "\n\n")

# Display statistics for different orders
cat("Model selection statistics:\n")
print(out$stats)
```

**Selected AR order:** `r out$p`

## Interpretation

The estimated AR model captures the first-order dynamics in the data:

```{r}
# View the model
print(out$model)

# Store for later comparison
models    = list(AR1 = out$model)
estimates = list(AR1 = list(model = out$model, n.par = out$p * dim_out^2))
```

---

# State Space Models

## What are State Space Models?

**State space models** provide a flexible framework for capturing complex dynamics:

$$s_{t+1} = A s_t + B u_t$$
$$y_t = C s_t + D u_t$$

where $s_t$ are hidden **state variables** and the matrices A, B, C, D define the system dynamics.

**When to use:**
- Complex systems with hidden variables
- When you need interpretable latent factors
- Flexible to different specifications (CCA, DDLC, echelon form)

We'll estimate state space models using three different parameterizations:

### CCA Estimate (Canonical Correlation Analysis)

**CCA** is a data-driven method for finding the most informative state representation. It's good when you don't have a priori knowledge about the system structure.

```{r, fig.alt="Two-panel plot showing: top panel - scree plot of singular values from CCA for order selection; bottom panel - model selection statistics across different state space orders"}
out = est_stsp_ss(y_train, method = 'cca', mean_estimate = 'zero')

cat("CCA estimation output components:\n")
print(names(out))

cat("\n\nModel selection statistics (order selection):\n")
print(out$stats)

cat("\n\nSelected model:\n")
print(out$model)

models$CCA    = out$model
estimates$CCA = list(model = out$model, n.par = 2*dim_out*out$s)
```

### DDLC Estimate (ML with Diagonal Direct-Lead Coefficient)

**DDLC** uses maximum likelihood estimation with a specific parameterization that's often numerically stable. We refine the CCA estimate through iterative ML optimization:

```{r, fig.alt="Four-panel plot showing the two-dimensional impulse response functions between GDP and unemployment variables, displaying how shocks propagate"}
# Create template for ML estimation
tmpl = tmpl_DDLC(models$CCA, balance = 'minimum phase', sigma_L = 'identity')
th0 = numeric(tmpl$n.par)

# Define likelihood function
llfun = ll_FUN(tmpl, y_train, skip = 0, which = "concentrated")

# Optimization with increasing iterations
for (maxit in c(10, 20, 200)) {
  control = list(trace = 0, fnscale = -1, maxit = maxit)
  out = optim(th0, llfun, method = 'BFGS', control = control)
  th = out$par
  model = fill_template(th, tmpl)

  # Reparametrize for next iteration
  if (maxit < 200) {
    tmpl = tmpl_DDLC(model, balance = 'minimum phase', sigma_L = 'identity')
    th0 = numeric(tmpl$n.par)
  }
}

# Ensure Cholesky factor is lower triangular
model$sigma_L = t(chol(model$sigma_L))

models$DDLC    = model
estimates$DDLC = list(model = model, n.par = tmpl$n.par)

cat("DDLC Model (ML refined from CCA):\n")
print(model)
```

### Echelon Form ML Estimate

**Echelon form** is a canonical representation that provides parsimony through structural restrictions. First, we compute Kronecker indices from the impulse response:

```{r, fig.alt="Impulse response functions from echelon form state space model showing responses of GDP and unemployment to structural shocks"}
lag.max = 20
ir = impresp(models$CCA, lag.max = lag.max)$irf     # Impulse response
nu = pseries2nu(ir)                                  # Kronecker indices

cat("Kronecker indices (system order structure):\n")
print(nu)

# Transform CCA estimate into echelon form
model = stspmod(sys = pseries2stsp(ir, method = 'echelon')$Xs,
                sigma_L = models$CCA$sigma_L)

# Verify the conversion preserves the system
cat("\nVerifying echelon form preserves autocovariance:\n")
print(all.equal(autocov(model, lag.max = lag.max),
                autocov(models$CCA, lag.max = lag.max)))

# ML refinement of echelon form
tmpl = tmpl_stsp_echelon(nu, sigma_L = 'identity')
th0 = extract_theta(model, tmpl, on_error = 'stop', ignore_sigma_L = TRUE)

llfun = ll_FUN(tmpl, y_train, skip = 0, which = "concentrated")
control = list(trace = 0, fnscale = -1, maxit = 500)

out = optim(th0, llfun, method = 'BFGS', control = control)
th = out$par
model = fill_template(th, tmpl)

models$SSECF    = model
estimates$SSECF = list(model = model, n.par = tmpl$n.par)

cat("Echelon Form State Space Model (ML):\n")
print(model)
```

---

# ARMA Models

## What are ARMA Models?

**ARMA (VARMA for multivariate)** models combine autoregressive and moving average components:

$$a_0 y_t + a_1 y_{t-1} + \cdots + a_p y_{t-p} = b_0 u_t + b_1 u_{t-1} + \cdots + b_q u_{t-q}$$

**When to use:**
- When you want parsimony (fewer parameters than AR)
- Capturing both short-term and longer-term dependencies
- When you have MA-type features in the data

The Hannan-Rissanen-Kavalieris (HRK) procedure provides good initial estimates, which we then refine with ML.

### HRK Estimate

**HRK** is a three-stage procedure that provides consistent ARMA estimates without requiring nonlinear optimization:

```{r, fig.alt="Four-panel plot showing autocorrelation functions from HRK ARMA estimation, displaying correlations in GDP and unemployment"}
# Define echelon form template for ARMA
tmpl = tmpl_arma_echelon(nu, sigma_L = 'chol')

# HRK estimation
out = est_arma_hrk(y_train, tmpl = tmpl, mean_estimate = 'zero')

models$HRK = out$model
estimates$HRK = list(model = out$model, n.par = tmpl$n.par - dim_out*(dim_out+1)/2)

cat("ARMA HRK Estimate:\n")
print(out$model)
```

### ML Refinement of ARMA

Further optimize the HRK estimate using maximum likelihood:

```{r, fig.alt="Four-panel autocorrelation plot comparing sample and model ACF from the ML-refined ARMA echelon form model"}
tmpl = tmpl_arma_echelon(nu, sigma_L = 'identity')
th0 = extract_theta(models$HRK, tmpl, on_error = 'stop', ignore_sigma_L = TRUE)

llfun = ll_FUN(tmpl, y_train, skip = 0, which = "concentrated")
control = list(trace = 0, fnscale = -1, maxit = 200)

out = optim(th0, llfun, method = 'BFGS', control = control)
th = out$par
model = fill_template(th, tmpl)

models$ARMAECF = model
estimates$ARMAECF = list(model = model, n.par = tmpl$n.par)

cat("ARMA ML (Echelon Form):\n")
print(model)
```

### Converting Between Representations

RLDM provides functions to convert between state space and ARMA representations. Since the ML-refined models are equivalent, we can convert between them:

```{r}
# Convert state space (SSECF) to ARMA representation
arma_from_ss <- armamod(lmfd(models$SSECF$sys),
                       sigma_L = models$SSECF$sigma_L)
cat("ARMA representation of SSECF model:\n")
print(arma_from_ss)
```

---

# Model Comparison and Selection

## Equivalence of ML Estimates

For this dataset, the three ML-refined state space and ARMA models are essentially equivalent (same data generating process):

```{r, fig.alt="Four-panel autocorrelation comparison plot showing sample vs model ACF for different estimated models (AR, CCA, HRK, SSECF)"}
# Compare impulse responses
eq_ddlc_ssecf = all.equal(impresp(models$DDLC, lag.max = lag.max),
                          impresp(models$SSECF, lag.max = lag.max))
eq_ssecf_arma = all.equal(impresp(models$SSECF, lag.max = lag.max),
                          impresp(models$ARMAECF, lag.max = lag.max))

cat("DDLC ≈ SSECF:", isTRUE(eq_ddlc_ssecf), "\n")
cat("SSECF ≈ ARMAECF:", isTRUE(eq_ssecf_arma), "\n\n")

# Keep only the unique models for further analysis
models    = models[c('AR1', 'CCA', 'HRK', 'SSECF')]
estimates = estimates[c('AR1', 'CCA', 'HRK', 'SSECF')]

cat("Models selected for comparison:\n")
print(names(models))
```

## Systematic Model Comparison

Compare models using multiple criteria:

```{r, fig.alt="Four-panel autocorrelation comparison between data and four different models (AR, CCA, HRK, SSECF) showing how well each captures correlations"}
# Residual diagnostics
u = solve_inverse_de(models$AR1$sys, as.matrix(y_train))$u
pm_result = pm_test(u, 8, dim_out^2)

cat("Portmanteau Test for AR1 Model:\n")
print(pm_result)

# Comprehensive comparison
stats = compare_estimates(estimates, y_train, n.lags = 8)

if (requireNamespace("kableExtra", quietly = TRUE)) {
  kable(stats) %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover")) %>%
    kableExtra::column_spec(1, bold = TRUE)
} else {
  print(stats)
}
```

**Interpretation:**
- **Log-Likelihood**: Higher is better (fit quality)
- **AIC/BIC**: Lower is better (penalizes complexity)
- **Portmanteau Test p-value**: Higher is better (residuals are white noise)
- **RMSE**: Lower is better (prediction accuracy)

---

# Model Diagnostics

## Autocorrelation Analysis

Do the models capture the autocorrelation structure of the data?

```{r}
plot(autocov(y, lag.max = lag.max),
     lapply(models, FUN = autocov, lag.max = lag.max),
     legend = c('Data', names(models)),
     col = c('black', default_colmap(length(models))))
```

**What to look for:**
- Model ACF should track the data ACF
- Large deviations indicate missing dynamics
- ARMAECF and SSECF should match data most closely

## Spectral Density

Frequency domain analysis - how does the model fit at different frequencies?

```{r}
plot(spectrald(models[[1]], n.f = 2^10),
     lapply(models[-1], FUN = spectrald, n.f = 2^10),
     legend = names(models))
```

**Interpretation:**
- Peaks show dominant frequencies in the data
- Model spectral densities should follow the data pattern
- Good fit across all frequencies indicates good model

## Impulse Response Functions

How does the system respond to shocks?

```{r, fig.alt="Four-panel impulse response comparison showing how GDP and unemployment respond to shocks across multiple estimated models"}
plot(impresp(models[[1]], lag.max = lag.max),
     lapply(models[-1], FUN = impresp, lag.max = lag.max),
     legend = names(models))
```

**Economic interpretation:**
- Top-left: GDP shock effect on GDP
- Top-right: unemployment shock effect on GDP
- Bottom-left: GDP shock effect on unemployment
- Bottom-right: unemployment shock effect on unemployment

---

# Prediction and Forecasting

## Out-of-Sample Predictions

Forecast the test set using the model fit on training data:

```{r}
n.ahead = 8
n.obs = nrow(y)
pred = predict(models$SSECF, y, h = c(1, 4), n.ahead = n.ahead)

# Clean up prediction names for plotting
dimnames(pred$yhat)[[3]] = gsub('=', '==', dimnames(pred$yhat)[[3]])

# Plot predictions
p.y0 = plot_prediction(pred, which = 'y0', style = 'bw',
                       parse_names = TRUE, plot = FALSE)
p.y0()

# Plot prediction errors
plot_prediction(pred, which = 'error', qu = c(2, 2, 2),
                parse_names = TRUE)

# CUSUM plot for error accumulation
plot_prediction(pred, which = 'cusum', style = 'gray',
                parse_names = TRUE)
```

## Compare Prediction Performance

```{r}
# Generate predictions from all models
out = lapply(models, FUN = function(model) {
  predict(model, y, h = c(1, 4))$yhat
})
yhat = do.call(dbind, c(3, out))
dimnames(yhat)[[3]] = kronecker(names(models), c(1, 4), FUN = paste, sep = ':')

# Evaluate using multiple criteria
stats = evaluate_prediction(y, yhat,
                           h = rep(c(1, 4), length(models)),
                           criteria = list('RMSE', 'MAE', 'MdAPE'),
                           samples = list(
                             in.sample = 1:nrow(y_train),
                             out.of.sample = (nrow(y_train)+1):nrow(y)
                           ))

# Format for display
stats.df = array2data.frame(stats, cols = 4)
stats.df$h = sub("^.*:", "", as.character(stats.df$predictor))
stats.df$predictor = sub(":.$", "", as.character(stats.df$predictor))
stats.df = stats.df[c('sample', 'h', 'criterion', 'predictor',
                      'rGDPgrowth_demeaned', 'unemp_detrended', 'total')]
stats.df = stats.df[order(stats.df$sample, stats.df$h,
                          stats.df$criterion, stats.df$predictor), ]
rownames(stats.df) = NULL

if (requireNamespace("kableExtra", quietly = TRUE)) {
  kable(stats.df) %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover")) %>%
    kableExtra::collapse_rows(columns = 1:3, valign = "top")
} else {
  print(stats.df)
}
```

---

# Conclusions

## Key Findings

1. **Model Selection**: SSECF and ARMAECF models perform best, capturing the complex dynamics of GDP growth and unemployment interactions

2. **Baseline Performance**: The simple AR1 model provides a useful baseline but misses important multivariate dependencies

3. **State Space vs ARMA**: Both approaches are competitive; choice depends on interpretability needs and computational constraints

4. **Forecast Accuracy**: The advanced models show improved out-of-sample prediction compared to baseline AR

## Practical Recommendations

- **For interpretability**: Use state space models with CCA initialization
- **For parsimony**: Use ARMA/VARMA models in echelon form
- **For quick analysis**: Start with AR, then compare to state space
- **For production**: Validate model assumptions and monitor forecast performance over time

## References

[@ScherrerDeistler2019]
