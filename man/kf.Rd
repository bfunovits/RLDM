% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/05_estimation_likelihood.R
\name{kf}
\alias{kf}
\title{Kalman Filter}
\usage{
kf(model, y, method = c("kf", "kf2"), P1 = NULL, a1 = NULL)
}
\arguments{
\item{model}{\code{\link[=stspmod]{stspmod()}} object, which represents the state space model.}

\item{y}{sample, i.e. an \eqn{(N,m)} dimensional matrix,
or a "time series" object (i.e. \code{as.matrix(y)} should return an
\eqn{(N,m)}-dimensional numeric matrix). Missing values (\code{NA}, \code{NaN} and
\code{Inf}) are \strong{not} supported.}

\item{method}{Character string. If \code{method="kf"} then the standard form of the Kalman filter is used,
and for \code{method="kf2"} the square root form is used. Up to numerical errors the outputs should not
depend on the chosen method.}

\item{P1}{\eqn{(s,s)} dimensional covariance matrix of the error of the initial state estimate,
i.e. \eqn{\Pi_{1|0}}{P[1|0]}.
If \code{NULL}, then the state covariance \eqn{P = APA'+B\Sigma B'} is used.
Note that this scheme assumes that the state space model is stable,
i.e. that the state transition matrix \eqn{A} is stable.}

\item{a1}{\eqn{s} dimensional vector, which holds the initial estimate \eqn{a_{1|0}}{a[1|0]}
for the state at time \eqn{t=1}.  If \code{a1=NULL}, then a zero vector is used.}
}
\value{
List with components
\item{e}{\eqn{(N,m)} dimensional matrix with the standardized one-step
ahead prediction errors. The \eqn{t}-th row of the matrix \code{e}
corresponds to
\deqn{e_t = \Sigma_{t|t-1}^{-1/2}\epsilon_{t|t-1}.}{e[t] = \Sigma[t|t-1]^{-1/2}\epsilon[t|t-1].}
If the model is correctly specified then these standardized residuals are white noise
with a unit covariance matrix. So they may be used for validaton of the model.}
\item{a}{\eqn{(N+1,s)} dimensional matrix with the estimated states. The
\eqn{t}-th row of the matrix \code{a} corresponds to
\eqn{a_{t|t-1}}{a[t|t-1]}. Given \code{y} and \code{a}, the one step ahead predictions
\eqn{y_{t|t-1}}{y[t|t-1]} may be computed with \verb{yh = a \\\%*\\\% t(C)}.}
\item{ll}{(scaled) Gaussian log likelihood of the model
\deqn{-\frac{1}{2N}\sum_{t=1}^{N}\left(m\log(2\pi) + \log\det\Sigma_{t|t-1} +
          (y_t - y_{t|t-1})' \Sigma_{t|t-1}^{-1} (y_t - y_{t|t-1}) \right).}{
          (-1/(2N))\sum_{t=1}^{N}[ m log(2\pi)  + log det \Sigma[t|t-1] +
           (y[t] - y[t|t-1])' \Sigma[t|t-1]^{-1} (y[t] - y[t|t-1]) ].}}
\item{P1}{\eqn{(s,s)} dimensional covariance matrix of the error of the state prediction
\eqn{a_{N+1|N}}{a[N+1|N]}, i.e. this matrix corresponds to \eqn{\Pi_{N+1|N}}{P[N+1|N]}.}
}
\description{
These functions implement the "standard" Kalman filter and the "square root" Kalman filter (also called "square root covariance filter") for time invariant, linear state space systems without exogenous inputs, see e.g. \insertCite{AndersonMoore2005}{RLDM}.
}
\details{
The model considered is
\deqn{a_{t+1} = A a_t + Bu_t}{a[t+1] = A a[t] + B u[t]}
\deqn{y_t = C a_t + Du_t}{y[t] = C a[t] + D u[t]}
with \eqn{m}-dimensional outputs \eqn{y_t}{y[t]}, \eqn{s}-dimensional states
\eqn{a_t}{a[t]} and \eqn{n}-dimensional disturbances \eqn{u_t}{u[t]}.
The disturbances are white noise with a covariance matrix
\eqn{\mathbf{E} u_tu_t'=\Sigma}{E u[t]u[t]'=\Sigma}.
Note that the disturbances and the outputs may have \emph{different} dimensions, however,
only "wide" systems with (\eqn{m\leq n}{m\le  n}) are implemented.

The Kalman filter is a recursive scheme to compute the linear, least squares predictions
for \eqn{a_{t+1}}{a[t+1]} and \eqn{y_{t+1}}{y[t+1]} given the observations
\eqn{y_t,\ldots,y_1}{y[t],\ldots,y[1]} up to time \eqn{t}. These predictions are notated with
\eqn{a_{t+1|t}}{a[t+1|t]} and \eqn{y_{t+1|t}}{y_[t+1|t]}, the
prediction error for the output \eqn{y_{t+1}}{y[t+1]} is
\eqn{\epsilon_{t+1|t}=(y_{t+1}-y_{t+1|t})}{\epsilon[t+1|t]=(y[t+1]-y[t+1|t])}
and the corresponding variances of the prediction errors are
\deqn{\Pi_{t+1|t}=\mathbf{E}(a_{t+1}-a_{t+1|t})
(a_{t+1}-a_{t+1|t})',}{P[t+1|t]=E(a[t+1]-a_[t+1|t])(a[t+1]-a_[t+1|t])',}
\deqn{\Sigma_{t+1|t}=\mathbf{E}(\epsilon_{t+1|t}
\epsilon_{t+1|t}').}{\Sigma[t+1|t]=E(\epsilon_[t+1|t]\epsilon_[t+1|t]').}

The standard form of the Kalman filter is based on the parameter matrices \eqn{A,C}, the variance of
"state disturbances"
\eqn{Q=\mathbf{E}(Bu_t (Bu_t)')=(B\Sigma B')}{Q=E(Bu[t](Bu[t])')=(B\Sigma B')}, the variance
of the "measurement disturbances"
\eqn{R=\mathbf{E}(Du_t (Du_t)')=(D\Sigma D')}{R=(Du[t](Du[t])')=E(D\Sigma D')} and the covariance
\eqn{S=\mathbf{E}(Bu_t(Du_t)')=(B\Sigma D')}{S=(Bu[t](Du[t])')=E(B\Sigma D')}.
Furthermore we need the initial prediction
\eqn{a_{1|0}}{a[1|0]} and the corresponding error variance
\eqn{\Pi_{1|0}}{P[1|0]}.

For the square root form of the filter we need the "square roots"
\eqn{\Pi_{1|0}^{1/2}}{P[1|0]^{1/2}} and \eqn{\Sigma^{1/2}}, i.e. matrices such that
\eqn{\Pi_{1|0} = \Pi_{1|0}^{1/2} (\Pi_{1|0}^{1/2})'}{P[1|0] = P[1|0]^{1/2} (P[1|0]^{1/2})'}
and \eqn{\Sigma = \Sigma^{1/2}(\Sigma^{1/2})'}. In addition, we define
\eqn{H=(D',B')'\Sigma^{1/2}}.

The Kalman filter is implemented in C++ via \pkg{RcppArmadillo} for performance. The wrapper function \code{kf} takes an \code{\link[=stspmod]{stspmod()}} object,
which describes the state space model, and then calls the appropriate internal implementation.

Square root Kalman filter: For the square root
\eqn{\Pi_{1|0}^{1/2}}{P[1|0]^{1/2}} the procedure first tries the Cholesky decomposition.
If this fails (since \eqn{\Pi_{1|0}^{1/2}}{P[1|0]^{1/2}} is (close to) singular),
then \code{ll_kf} tries to compute a symmetric square root via the eigenvalue decomposition
of \eqn{\Pi_{1|0}^{1/2}}{P[1|0]^{1/2}}.
}
\section{Notes}{

The internal C++ implementations do not check the input parameters,
so direct use (via \code{.Call()}) must be done with care.

The procedures only accept "wide" state space systems (\eqn{m \leq n}{m \le n}), since for
"tall" systems (\eqn{m > n}) the variance of the prediction errors
(\eqn{\Sigma_{t+1|t}}{\Sigma[t+1|t]}) is singular for \eqn{t} larger than some threshold.

Up to now, there is no support for models with exogenous inputs.
}

\examples{
s = 4  # state dimension
m = 2  # number of outputs
n = 3  # number of inputs,
n.obs = 100 # sample size

# generate a (stable) state space model
tmpl = tmpl_stsp_full(m, n, s, sigma_L = "chol")
model = r_model(tmpl, bpoles = 1, sd = 0.5)
# generate a sample
data = sim(model, n.obs = n.obs, a1 = NA)

# compute Q, R, S and P1
sigma_L = model$sigma_L
sigma = tcrossprod(sigma_L)
R = model$sys$D \%*\% sigma \%*\% t(model$sys$D)
S = model$sys$B \%*\% sigma \%*\% t(model$sys$D)
Q = model$sys$B \%*\% sigma \%*\% t(model$sys$B)
P1 = lyapunov(model$sys$A, Q)

# call Kalman filter using the wrapper function
out = kf(model, data$y, method = 'kf')
# Note: kf_cpp is the internal C++ implementation called by kf()

# compute H and square root of P1
H = rbind(model$sys$D, model$sys$B) \%*\% sigma_L
P1_R = chol(P1)

# call square root Kalman filter using wrapper function
out_test = kf(model, data$y, method = 'kf2')  # using wrapper function
all.equal(out, out_test)

# The one step ahead predictions for y[t] may be computed by
yh = out$a \%*\% t(model$sys$C)
# and the (non scaled) prediction errors are
uh = data$y - out$a[1:n.obs,] \%*\% t(model$sys$C)
}
\references{
\insertRef{AndersonMoore2005}{RLDM}
}
\seealso{
There exist a number of R packages which implement the Kalman filter, e.g.
\pkg{KFAS}. However, most of these packages do not allow for correlations between the
"state noise" and the "measurement noise".

If only the likelihood is needed, then one may use \code{\link[=ll_kf]{ll_kf()}}.
}
