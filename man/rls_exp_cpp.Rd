% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{rls_exp_cpp}
\alias{rls_exp_cpp}
\alias{rls_window_cpp}
\title{(Multivariate) Recursive Least Squares}
\usage{
rls_exp_cpp(Y, X, r, n_init, allow_neg = TRUE, debug_flag = FALSE)

rls_window_cpp(Y, X, ws, allow_neg = TRUE, debug_flag = FALSE)
}
\arguments{
\item{Y, X}{Matrices of doubles.
Left-hand-side and right-hand-side variables in possibly multivariate regression.
The number of rows corresponds to the number of observations}

\item{r}{Matrix of doubles of dimension \eqn{(n_{r} \times 1)}.
Contains forgetting factors. Note that each observation has the same weight (i.e. different components )}

\item{n_init}{Integer. Number of observations used for initial estimate of regression coefficients.
Default is set to twice the number of regressors in \code{X}.
Note that forecasts and forecast errors are only produced AFTER the initial estimate.}

\item{allow_neg}{Boolean. Default set to true. If false, negative forecasts are not allowed and set to zero.}

\item{debug_flag}{Boolean. Default set to false. If true, output is printed to the console.}

\item{ws}{Integer. Fixed number of observation to be used to calculate estimates.
Number of observations used for initial estimate of regression coefficients.}
}
\value{
List containing
\itemize{
\item \code{y_pred}: Cube of doubles of dimension \eqn{(n_{obs} \times n_y \times n_{r})}.
Contains (one-step-ahead) predictions for all forgetting factors.
In case of windowed RLS, the third dimension (containing forgetting factors) is discarded (such that the output is a matrix).
\item \code{fe_honest:} Cube of doubles of dimension \eqn{(n_{obs} \times n_y \times n_{r})}.
Contains (one-step-ahead) forecast errors for all forgetting factors.
In case of windowed RLS, the third dimension (containing forgetting factors) is discarded (such that the output is a matrix).
}
}
\description{
This function implements the Recursive Least Squares (RLS) algorithm with exponentially down-weighted past of fixed window size.
It allows for multivariate regressions, i.e. for multiple left-hand-side variables \code{y}.
However, the algorithm is formulated such that the regressors are the same for each individual component of the LHS variable,
i.e. \deqn{Y = XB + U}
where
\itemize{
\item \code{Y} and \code{U} are \eqn{(T \times n_{y})} dimensional,
\item \code{X} is \eqn{(T \times n_{x})} dimensional,
\item \code{B} is \eqn{(n_{x} \times n_{y})} dimensional,
}
In a VAR(p) context where the endogenous variable \code{y} is \code{n}-dimensional,
this corresponds to dimensions \eqn{(T \times n)}, \eqn{(T \times n p)}, \eqn{( n p \times n)} for \code{Y}, \code{X}, \code{B} respectively.
The fact that we use the same regressors for each component of the LHS simplifies the updating formula in RLS a bit.
}
\details{
Inputs are not checked, so this should be done within R before calling this function.

The main reference is Chapter 4 in Young (2012).
}
