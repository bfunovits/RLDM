% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/afab_estimate_mom_arma.R
\name{est_arma_hrk}
\alias{est_arma_hrk}
\title{Hannan, Rissanen, Kavalieris estimation procedure}
\usage{
est_arma_hrk(
  y,
  e = NULL,
  tmpl,
  maxit = 1,
  tol = 0.001,
  trace = TRUE,
  p.max = NULL,
  ic = c("AIC", "BIC", "max"),
  mean_estimate = c("sample.mean", "intercept", "zero")
)
}
\arguments{
\item{y}{sample, i.e. an \eqn{(N,m)} dimensional matrix,
or a "time series" object (i.e. \code{as.matrix(y)} should return an
\eqn{(N,m)}-dimensional numeric matrix). Missing values (\code{NA}, \code{NaN} and
\code{Inf}) are \strong{not} supported.}

\item{e}{(initial) estimate of the disturbances \eqn{u_t}{u[t]}.
If non \code{NULL} then \code{e} has to be an \eqn{(N,m)} dimensional matrix,
or a "time series" object (i.e an object which may be coerced to an \eqn{(N,m)}
dimensional matrix with \code{as.matrix(e)}).
\cr
If \code{NULL} then the procedure computes an estimate of the disturbances by fitting
a "long" AR model to the data, see \code{\link[=est_ar_ols]{est_ar_ols()}}.
\cr
The matrix \code{e} may contain missing values (\code{NA}, \code{NaN} and
\code{Inf}). Note that e.g. \code{est_ar_ols} returns residuals where the first
\eqn{p} (here \eqn{p} refers to the order of the fitted AR model) values are missing.}

\item{tmpl}{a model template, see \code{\link[=model structures]{model structures()}}. Note that only the case
is implemented, where
\eqn{a_0=b_0}{a[0]=b[0]} holds, the diagonal entries of
\eqn{a_0=b_0}{a[0]=b[0]} are equal to one and all other fixed elements
are equal to zero. Furthermore the square root \code{sigma_L} of the noise covariance matrix
is asssumed to be a lower triangular matrix without any further restrictions.
\cr
The given template is coerced to a template of this kind. If the given template does not
comply to these restrictions, then a warning message is issued.}

\item{maxit}{(integer) maximum number of iterations}

\item{tol}{(numeric) tolerance level}

\item{trace}{(boolean) if \code{trace=TRUE}, then some tracing information on the
iterations is printed.}

\item{p.max}{(integer or \code{NULL}) Maximum order of the candidate AR models.
For the default choice see below.}

\item{ic}{(character string) Which information criterion shall be used to find the
optimal AR order. Note that \code{ic="max"} means that an AR(p) model
with \code{p=p.max} is fitted. Default is \code{ic="AIC"}.}

\item{mean_estimate}{Character string giving the method used to estimate the mean \eqn{\mu}.
Default is \code{mean_estimate = "sample.mean"}.
See the details below.}
}
\value{
List with components
\item{model}{the estimated (V)ARMA model (i.e. an \code{\link[=armamod]{armamod()}} object).}
\item{th}{vector with the (free) parameters of the estimated (V)ARMA model.}
\item{tmpl}{the (coerced) model template.}
\item{y.mean}{estimate of the mean \eqn{\mu}.}
\item{residuals}{the residuals of the model, computed with \code{\link[=solve_inverse_de]{solve_inverse_de()}}.}
\item{sigma}{the sample variance \eqn{S} of the residuals, i.e. an estimate of the
noise covariance matrix \eqn{\Sigma}.}
\item{n.valid}{number of "valid" observations, i.e. observations where all needed
lagged values \eqn{y_{t-i}}{y[t-i]} and \eqn{e_{t-i}}{e[t-i]}
are availiable. For an ARMA(p,q) model this implies
that the number of valid observations is less than or equal
to \code{n.obs -max(p,q)}.}
\item{ll}{Gaussian log likelihood:
\deqn{(-1/2)(m \ln(2\pi) + m + \ln\det(S))}{(-N/2)(m ln(2\pi) + m + ln det(S))}
where \eqn{S} denotes the sample variance of the residuals.}
\item{iter}{number of iterations.}
\item{converged}{(boolean) indicates whether the algorithm converged.}
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#deprecated}{\figure{lifecycle-deprecated.svg}{options: alt='[Deprecated]'}}}{\strong{[Deprecated]}}
Estimate (V)ARMA models with the Hannan, Rissanen Kavalieris procedure, see
e.g. \insertCite{Hannan.Rissanen82}{RLDM} and \insertCite{HannanKavalierisMackisack1986}{RLDM}.
}
\details{
The main idea of the HRK procedure is as follows. If we have given estimates,
\eqn{e_t}{e[t]} say, of the disturbances,
then the ARMA model is estimated from the equation
\deqn{y_t = -a^*_0(y_t+e_t) - a_1 y_{t-1} - \cdots - a_p y_{t-p} +
                b_1 e_{t-1} + \cdots + b_q e_{t-q} + v_{t-1}}{
      y[t] = -a^*[0] (y[t]+e[t]) - a[1] y[t-1] - \dots - a[p] y[t-p] +
                b[1] e[t-1] + \dots + b[q] e[t-q] + v[t]}
where \eqn{a^*_0}{a^*[0]} is obtained from \eqn{a_0 = b_0}{a[0]=b[0]} by setting all
diagonal elements equal to zero.
The entries in the parameter matrices \eqn{a_i}{a[i]} and \eqn{b_i}{b[i]} are
either treated as fixed (and equal to zero)
or "free". Now the above regression is estimated "componentwise", i.e. for
each component of \eqn{y_t}{y[t]} the corresponding
"free" parameters are estimated by OLS.

Given the parameter estimates one computes new estimates for the disturbances,
by recursively solving the ARMA system,
see \code{\link[=solve_inverse_de]{solve_inverse_de()}}. The sample variance of these residuals is
used as an estimate of the
noise covariance matrix \eqn{\Sigma}.

This procedure may be iterated: use the "new" estimates for the disturbances to (re) estimate
the ARMA parameters and to (re) estimate the disturbances, ...

The parameters \code{maxit} and \code{tol} control this iterative scheme. The
iterations are stopped after at most \code{maxit} iterations or when there is
only a "small" change of the estimates. To be more precise, if \code{th},
\code{th0} denote the vector of parameter estimates in the actual round and
the previous round, then the procedure stops if \code{max(abs(th-th0)) <= tol}.

Note that in general there is no guarantee that this iterative scheme
converges or that the estimates are improved by iterating.

The user may supply his "own" (initial) estimates \code{e} of the disturbances.
If the parameter \code{e} is missing (or \code{NULL}) then the procedure \code{est_arma_hrk}
computes estimates of the disturbances by fitting a "long" AR model to the data. To this end
the procedure simply calls \code{\link[=est_ar_ols]{est_ar_ols()}} with the respective paramaters
\code{p.max} (which controls the maximum possible AR order), \code{ic} (which controls the
information criterion used to select the order of the AR model) and \code{mean_estimate}
(which tells \code{est_ar_ols} how to estimate the mean \eqn{\mu}).
The default for the maximum order \code{p.max} is
\deqn{\max(12, 10\log_{10}(N), (N-1)/(m+1))}{max(12, 10 log[10](N), (N-1)/(m+1))}

The procedure supports three options for the estimation of the mean
\eqn{\mu = \mathbf{E} y_t}{\mu = E y[t]}. For \code{mean_estimate="zero"} the
procedure sets the (estimate of the) mean equal to zero. For
\code{mean_estimate="sample.mean"} the procedure simply uses the sample mean
of \code{y} as an estimate. Third option \code{mean_estimate="intercept"}
uses an intercept in the above regression(s) and computes the estimate of the
mean correspondingly. Note that this fails if the estimated AR polynomial has
a unit root, i.e. if \deqn{\det \hat{a}(1) = 0.}{det a(1) = 0.}

There is no guarantee that the HRK algorithm returns a stable and minimum
phase ARMA model. In particular, if the estimated model is \emph{not} minimum
phase then the recursive computation of the residuals often yields useless
results and correspondingly the cholesky decomposition of the sample variance
of the residuals (which is used as estimate of the noise covariance matrix
\eqn{\Sigma}) fails. In this case the procedure stops with an error message.
}
\examples{
# in order to get reproducible results
set.seed(4321)

# generate a random VARMA(p=2,q=1) model with m=2 outputs #####################
tmpl = tmpl_arma_pq(m = 2, n = 2, p = 2, q = 1)
model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25)
diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L
print(model)

# generate a sample with 200 observations
data = sim(model, n.obs = 200, n.burn_in = 100)

# estimate model with HRK
# note: we are cheating here and use the true disturbances!
out = est_arma_hrk(data$y, data$u, tmpl)
print(out$model)
# ll() returns the same logLik value. However, we have to demean the data
all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),
                     'conditional', skip = 2))

# estimate the model with HRK
# use the residuals of a long AR model as estimates for the noise
out = est_arma_hrk(data$y, e = NULL, tmpl,
                   trace = TRUE, maxit = 10, mean_estimate = 'zero')
print(out$model)
# ll() returns the same logLik value. However, we have to demean the data
all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),
                     'conditional', skip = 2))

# Generate a random Model in echelon form model (m = 3) #######################
tmpl = tmpl_arma_echelon(nu = c(1,1,1))
model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25)
diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L
print(model)

# generate a sample with 200 observations
data = sim(model, n.obs = 200, n.burn_in = 100)
# add mean value(s)
data$y = data$y + matrix(1:3, nrow = 200, ncol = 3, byrow = TRUE)

# estimate model with HRK
# note: we are cheating here and use the true disturbances!
out = est_arma_hrk(data$y, data$u, tmpl,
                   trace = FALSE, maxit = 1, mean_estimate = 'sample.mean')
print(out$y.mean)
print(out$model)
# ll() returns the same logLik value. However, we have to demean the data
all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),
                     'conditional', skip = 1))

# estimate the model with HRK
# use the residuals of a long AR model as estimates for the noise
out = est_arma_hrk(data$y, e = NULL, tmpl,
                   maxit = 10, mean_estimate = 'intercept')
print(out$y.mean)
print(out$model)
# ll() returns the same logLik value. However, we have to demean the data
all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),
                     'conditional', skip = 1))

# We may also use this procedure to estimate AR models #####################
# where some coefficients are fixed = 0
a = dbind(d = 3, diag(2), array(NA_real_, dim = c(2,2,2)))
a[1,2,] = 0 # all coefficient matrices are lower triangular, i.e.
# y[2t] does not Granger cause y[1t]
tmpl = model2template(armamod(sys = lmfd(a=a),
                              sigma_L = matrix(NA_real_, nrow = 2, ncol = 2)),
                      sigma_L = 'chol')
model = r_model(template = tmpl, bpoles = 1, bzeroes = 1, sd = 0.25)
diag(model$sigma_L) = 1 # scale the diagonal entries of sigma_L
print(model)

# generate a sample with 200 observations
data = sim(model, n.obs = 200, n.burn_in = 100)

# estimate model with HRK
out = est_arma_hrk(data$y, NULL, tmpl,
                   trace = FALSE, maxit = 1, mean_estimate = 'zero')
print(out$y.mean)
print(out$model)
# ll() returns the same logLik value. However, we have to demean the data
all.equal(out$ll, ll(out$model, scale(data$y, center = out$y.mean, scale = FALSE),
                     'conditional', skip = 2))

# reset the "seed"
set.seed(NULL)
}
\references{
\insertRef{Hannan.Rissanen82}{RLDM}

\insertRef{HannanKavalierisMackisack1986}{RLDM}
}
